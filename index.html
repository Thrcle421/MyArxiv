<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-23T00:00:00Z">2025-05-23</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Staircase of Ethics: Probing LLM Value Priorities through Multi-Step
  Induction to Complex Moral Dilemmas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ya Wu, Qiang Sheng, Danding Wang, Guang Yang, Yifan Sun, Zhengjia Wang, Yuyan Bu, Juan Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ethical decision-making is a critical aspect of human judgment, and the
growing use of LLMs in decision-support systems necessitates a rigorous
evaluation of their moral reasoning capabilities. However, existing assessments
primarily rely on single-step evaluations, failing to capture how models adapt
to evolving ethical challenges. Addressing this gap, we introduce the
Multi-step Moral Dilemmas (MMDs), the first dataset specifically constructed to
evaluate the evolving moral judgments of LLMs across 3,302 five-stage dilemmas.
This framework enables a fine-grained, dynamic analysis of how LLMs adjust
their moral reasoning across escalating dilemmas. Our evaluation of nine widely
used LLMs reveals that their value preferences shift significantly as dilemmas
progress, indicating that models recalibrate moral judgments based on scenario
complexity. Furthermore, pairwise value comparisons demonstrate that while LLMs
often prioritize the value of care, this value can sometimes be superseded by
fairness in certain contexts, highlighting the dynamic and context-dependent
nature of LLM ethical reasoning. Our findings call for a shift toward dynamic,
context-aware evaluation paradigms, paving the way for more human-aligned and
value-sensitive development of LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fann or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry
  Understanding in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wafa Alghallabi, Ritesh Thawkar, Sara Ghaboura, Ketan More, Omkar Thawakar, Hisham Cholakkal, Salman Khan, Rao Muhammad Anwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Arabic poetry stands as one of the most sophisticated and culturally embedded
forms of expression in the Arabic language, known for its layered meanings,
stylistic diversity, and deep historical continuity. Although large language
models (LLMs) have demonstrated strong performance across languages and tasks,
their ability to understand Arabic poetry remains largely unexplored. In this
work, we introduce `Fann or Flop`, the first benchmark designed to assess the
comprehension of Arabic poetry by LLMs in twelve historical eras, covering 21
core poetic genres and a variety of metrical forms, from classical structures
to contemporary free verse. The benchmark comprises a curated corpus of poems
with explanations that assess semantic understanding, metaphor interpretation,
prosodic awareness, and cultural context. We argue that poetic comprehension
offers a strong indicator for testing how good the LLM is in understanding
classical Arabic through the Arabic poetry. Unlike surface-level tasks, this
domain demands deeper interpretive reasoning and cultural sensitivity. Our
evaluation of state-of-the-art LLMs shows that most models struggle with poetic
understanding despite strong results on standard Arabic benchmarks. We release
`Fann or Flop` along with the evaluation suite as an open-source resource to
enable rigorous evaluation and advancement for Arabic language models. Code is
available at: https://github.com/mbzuai-oryx/FannOrFlop.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github:https://github.com/mbzuai-oryx/FannOrFlop,
  Dataset:https://huggingface.co/datasets/omkarthawakar/FannOrFlop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ First Finish Search: Efficient Test-Time Scaling in Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18149v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18149v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aradhye Agarwal, Ayan Sengupta, Tanmoy Chakraborty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test-time scaling (TTS), which involves dynamic allocation of compute during
inference, offers a promising way to improve reasoning in large language
models. While existing TTS methods work well, they often rely on long decoding
paths or require a large number of samples to be generated, increasing the
token usage and inference latency. We observe the surprising fact that for
reasoning tasks, shorter traces are much more likely to be correct than longer
ones. Motivated by this, we introduce First Finish Search (FFS), a
training-free parallel decoding strategy that launches $n$ independent samples
and returns as soon as any one completes. We evaluate FFS alongside simple
decoding, beam search, majority voting, and budget forcing on four reasoning
models (DeepSeek-R1, R1-Distill-Qwen-32B, QwQ-32B and Phi-4-Reasoning-Plus) and
across four datasets (AIME24, AIME25-I, AIME25-II and GPQA Diamond). With
DeepSeek-R1, FFS achieves $82.23\%$ accuracy on the AIME datasets, a $15\%$
improvement over DeepSeek-R1's standalone accuracy, nearly matching OpenAI's
o4-mini performance. Our theoretical analysis explains why stopping at the
shortest trace is likely to yield a correct answer and identifies the
conditions under which early stopping may be suboptimal. The elegance and
simplicity of FFS demonstrate that straightforward TTS strategies can perform
remarkably well, revealing the untapped potential of simple approaches at
inference time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lost in the Haystack: Smaller Needles are More Difficult for LLMs to
  Find 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Owen Bianchi, Mathew J. Koretsky, Maya Willey, Chelsea X. Alvarado, Tanay Nayak, Adi Asija, Nicole Kuznetsov, Mike A. Nalls, Faraz Faghri, Daniel Khashabi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) face significant challenges with
needle-in-a-haystack tasks, where relevant information ("the needle") must be
drawn from a large pool of irrelevant context ("the haystack"). Previous
studies have highlighted positional bias and distractor quantity as critical
factors affecting model performance, yet the influence of gold context size has
received little attention. We address this gap by systematically studying how
variations in gold context length impact LLM performance on long-context
question answering tasks. Our experiments reveal that LLM performance drops
sharply when the gold context is shorter, i.e., smaller gold contexts
consistently degrade model performance and amplify positional sensitivity,
posing a major challenge for agentic systems that must integrate scattered,
fine-grained information of varying lengths. This pattern holds across three
diverse domains (general knowledge, biomedical reasoning, and mathematical
reasoning) and seven state-of-the-art LLMs of various sizes and architectures.
Our work provides clear insights to guide the design of robust, context-aware
LLM-driven systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph-Linguistic Fusion: Using Language Models for Wikidata Vandalism
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18136v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18136v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mykola Trokhymovych, Lydia Pintscher, Ricardo Baeza-Yates, Diego Saez-Trumper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a next-generation vandalism detection system for Wikidata, one
of the largest open-source structured knowledge bases on the Web. Wikidata is
highly complex: its items incorporate an ever-expanding universe of factual
triples and multilingual texts. While edits can alter both structured and
textual content, our approach converts all edits into a single space using a
method we call Graph2Text. This allows for evaluating all content changes for
potential vandalism using a single multilingual language model. This unified
approach improves coverage and simplifies maintenance. Experiments demonstrate
that our solution outperforms the current production system. Additionally, we
are releasing the code under an open license along with a large dataset of
various human-generated knowledge alterations, enabling further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gaming Tool Preferences in Agentic LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazem Faghih, Wenxiao Wang, Yize Cheng, Siddhant Bharti, Gaurang Sriramanan, Sriram Balasubramanian, Parsa Hosseini, Soheil Feizi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can now access a wide range of external tools,
thanks to the Model Context Protocol (MCP). This greatly expands their
abilities as various agents. However, LLMs rely entirely on the text
descriptions of tools to decide which ones to use--a process that is
surprisingly fragile. In this work, we expose a vulnerability in prevalent
tool/function-calling protocols by investigating a series of edits to tool
descriptions, some of which can drastically increase a tool's usage from LLMs
when competing with alternatives. Through controlled experiments, we show that
tools with properly edited descriptions receive over 10 times more usage from
GPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further
evaluate how various edits to tool descriptions perform when competing directly
with one another and how these trends generalize or differ across a broader set
of 10 different models. These phenomenons, while giving developers a powerful
way to promote their tools, underscore the need for a more reliable foundation
for agentic LLMs to select and utilize tools and resources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VideoGameBench: Can Vision-Language Models complete popular video games? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex L. Zhang, Thomas L. Griffiths, Karthik R. Narasimhan, Ofir Press
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have achieved strong results on coding and math
benchmarks that are challenging for humans, yet their ability to perform tasks
that come naturally to humans--such as perception, spatial navigation, and
memory management--remains understudied. Real video games are crafted to be
intuitive for humans to learn and master by leveraging innate inductive biases,
making them an ideal testbed for evaluating such capabilities in VLMs. To this
end, we introduce VideoGameBench, a benchmark consisting of 10 popular video
games from the 1990s that VLMs directly interact with in real-time.
VideoGameBench challenges models to complete entire games with access to only
raw visual inputs and a high-level description of objectives and controls, a
significant departure from existing setups that rely on game-specific
scaffolding and auxiliary information. We keep three of the games secret to
encourage solutions that generalize to unseen environments. Our experiments
show that frontier vision-language models struggle to progress beyond the
beginning of each game. We find inference latency to be a major limitation of
frontier models in the real-time setting; therefore, we introduce
VideoGameBench Lite, a setting where the game pauses while waiting for the LM's
next action. The best performing model, Gemini 2.5 Pro, completes only 0.48% of
VideoGameBench and 1.6% of VideoGameBench Lite. We hope that the formalization
of the human skills mentioned above into this benchmark motivates progress in
these research directions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 33 pages including supplementary</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One RL to See Them All: Visual Triple Unified Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Ma, Linge Du, Xuyang Shen, Shaoxiang Chen, Pengfei Li, Qibing Ren, Lizhuang Ma, Yuchao Dai, Pengfei Liu, Junjie Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) has significantly advanced the reasoning
capabilities of vision-language models (VLMs). However, the use of RL beyond
reasoning tasks remains largely unexplored, especially for perceptionintensive
tasks like object detection and grounding. We propose V-Triune, a Visual Triple
Unified Reinforcement Learning system that enables VLMs to jointly learn visual
reasoning and perception tasks within a single training pipeline. V-Triune
comprises triple complementary components: Sample-Level Data Formatting (to
unify diverse task inputs), Verifier-Level Reward Computation (to deliver
custom rewards via specialized verifiers) , and Source-Level Metric Monitoring
(to diagnose problems at the data-source level). We further introduce a novel
Dynamic IoU reward, which provides adaptive, progressive, and definite feedback
for perception tasks handled by V-Triune. Our approach is instantiated within
off-the-shelf RL training framework using open-source 7B and 32B backbone
models. The resulting model, dubbed Orsta (One RL to See Them All),
demonstrates consistent improvements across both reasoning and perception
tasks. This broad capability is significantly shaped by its training on a
diverse dataset, constructed around four representative visual reasoning tasks
(Math, Puzzle, Chart, and Science) and four visual perception tasks (Grounding,
Detection, Counting, and OCR). Subsequently, Orsta achieves substantial gains
on MEGA-Bench Core, with improvements ranging from +2.1 to an impressive +14.1
across its various 7B and 32B model variants, with performance benefits
extending to a wide range of downstream tasks. These results highlight the
effectiveness and scalability of our unified RL approach for VLMs. The V-Triune
system, along with the Orsta models, is publicly available at
https://github.com/MiniMax-AI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Frankentext: Stitching random text fragments into long-form narratives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chau Minh Pham, Jenna Russell, Dzung Pham, Mohit Iyyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Frankentexts, a new type of long-form narratives produced by
LLMs under the extreme constraint that most tokens (e.g., 90%) must be copied
verbatim from human writings. This task presents a challenging test of
controllable generation, requiring models to satisfy a writing prompt,
integrate disparate text fragments, and still produce a coherent narrative. To
generate Frankentexts, we instruct the model to produce a draft by selecting
and combining human-written passages, then iteratively revise the draft while
maintaining a user-specified copy ratio. We evaluate the resulting Frankentexts
along three axes: writing quality, instruction adherence, and detectability.
Gemini-2.5-Pro performs surprisingly well on this task: 81% of its Frankentexts
are coherent and 100% relevant to the prompt. Notably, up to 59% of these
outputs are misclassified as human-written by detectors like Pangram, revealing
limitations in AI text detectors. Human annotators can sometimes identify
Frankentexts through their abrupt tone shifts and inconsistent grammar between
segments, especially in longer generations. Beyond presenting a challenging
generation task, Frankentexts invite discussion on building effective detectors
for this new grey zone of authorship, provide training data for mixed
authorship detection, and serve as a sandbox for studying human-AI co-writing
processes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reward Model Overoptimisation in Iterated RLHF 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18126v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18126v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lorenz Wolf, Robert Kirk, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning from human feedback (RLHF) is a widely used method for
aligning large language models with human preferences. However, RLHF often
suffers from reward model overoptimisation, in which models overfit to the
reward function, resulting in non-generalisable policies that exploit the
idiosyncrasies and peculiarities of the reward function. A common mitigation is
iterated RLHF, in which reward models are repeatedly retrained with updated
human feedback and policies are re-optimised. Despite its increasing adoption,
the dynamics of overoptimisation in this setting remain poorly understood. In
this work, we present the first comprehensive study of overoptimisation in
iterated RLHF. We systematically analyse key design choices - how reward model
training data is transferred across iterations, which reward function is used
for optimisation, and how policies are initialised. Using the controlled
AlpacaFarm benchmark, we observe that overoptimisation tends to decrease over
successive iterations, as reward models increasingly approximate ground-truth
preferences. However, performance gains diminish over time, and while
reinitialising from the base policy is robust, it limits optimisation
flexibility. Other initialisation strategies often fail to recover from early
overoptimisation. These findings offer actionable insights for building more
stable and generalisable RLHF pipelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 17 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TabSTAR: A Foundation Tabular Model With Semantically Target-Aware
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18125v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18125v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alan Arazi, Eilam Shapira, Roi Reichart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While deep learning has achieved remarkable success across many domains, it
has historically underperformed on tabular learning tasks, which remain
dominated by gradient boosting decision trees (GBDTs). However, recent
advancements are paving the way for Tabular Foundation Models, which can
leverage real-world knowledge and generalize across diverse datasets,
particularly when the data contains free-text. Although incorporating language
model capabilities into tabular tasks has been explored, most existing methods
utilize static, target-agnostic textual representations, limiting their
effectiveness. We introduce TabSTAR: a Foundation Tabular Model with
Semantically Target-Aware Representations. TabSTAR is designed to enable
transfer learning on tabular data with textual features, with an architecture
free of dataset-specific parameters. It unfreezes a pretrained text encoder and
takes as input target tokens, which provide the model with the context needed
to learn task-specific embeddings. TabSTAR achieves state-of-the-art
performance for both medium- and large-sized datasets across known benchmarks
of classification tasks with text features, and its pretraining phase exhibits
scaling laws in the number of datasets, offering a pathway for further
performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UNJOIN: Enhancing Multi-Table Text-to-SQL Generation via Schema
  Simplification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18122v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18122v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Poojah Ganesan, Rajat Aayush Jha, Dan Roth, Vivek Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) have greatly improved
Text-to-SQL performance for single-table queries. But, it remains challenging
in multi-table databases due to complex schema and relational operations.
Existing methods often struggle with retrieving the right tables and columns,
generating accurate JOINs and UNIONs, and generalizing across diverse schemas.
To address these issues, we introduce UNJOIN, a two-stage framework that
decouples the retrieval of schema elements from SQL logic generation. In the
first stage, we merge the column names of all tables in the database into a
single-table representation by prefixing each column with its table name. This
allows the model to focus purely on accurate retrieval without being distracted
by the need to write complex SQL logic. In the second stage, the SQL query is
generated on this simplified schema and mapped back to the original schema by
reconstructing JOINs, UNIONs, and relational logic. Evaluations on SPIDER and
BIRD datasets show that UNJOIN matches or exceeds the state-of-the-art
baselines. UNJOIN uses only schema information, which does not require data
access or fine-tuning, making it scalable and adaptable across databases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProgRM: Build Better GUI Agents with Progress Rewards 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18121v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18121v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danyang Zhang, Situo Zhang, Ziyue Yang, Zichen Zhu, Zihan Zhao, Ruisheng Cao, Lu Chen, Kai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based (Large Language Model) GUI (Graphical User Interface) agents can
potentially reshape our daily lives significantly. However, current LLM-based
GUI agents suffer from the scarcity of high-quality training data owing to the
difficulties of trajectory collection and reward annotation. Existing works
have been exploring LLMs to collect trajectories for imitation learning or to
offer reward signals for online RL training. However, the Outcome Reward Model
(ORM) used in existing works cannot provide finegrained feedback and can
over-penalize the valuable steps in finally failed trajectories. To this end,
we propose Progress Reward Model (ProgRM) to provide dense informative
intermediate rewards by predicting a task completion progress for each step in
online training. To handle the challenge of progress reward label annotation,
we further design an efficient LCS-based (Longest Common Subsequence)
self-annotation algorithm to discover the key steps in trajectories and assign
progress labels accordingly. ProgRM is evaluated with extensive experiments and
analyses. Actors trained with ProgRM outperform leading proprietary LLMs and
ORM-trained actors, illustrating the effectiveness of ProgRM. The codes for
experiments will be made publicly available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Supervised Learning and Reinforcement Learning in Math
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18116v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18116v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huayu Chen, Kaiwen Zheng, Qinsheng Zhang, Ganqu Cui, Yin Cui, Haotian Ye, Tsung-Yi Lin, Ming-Yu Liu, Jun Zhu, Haoxiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning (RL) has played a central role in the recent surge of
LLMs' math abilities by enabling self-improvement through binary verifier
signals. In contrast, Supervised Learning (SL) is rarely considered for such
verification-driven training, largely due to its heavy reliance on reference
answers and inability to reflect on mistakes. In this work, we challenge the
prevailing notion that self-improvement is exclusive to RL and propose
Negative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to
reflect on their failures and improve autonomously with no external teachers.
In online training, instead of throwing away self-generated negative answers,
NFT constructs an implicit negative policy to model them. This implicit policy
is parameterized with the same positive LLM we target to optimize on positive
data, enabling direct policy optimization on all LLMs' generations. We conduct
experiments on 7B and 32B models in math reasoning tasks. Results consistently
show that through the additional leverage of negative feedback, NFT
significantly improves over SL baselines like Rejection sampling Fine-Tuning,
matching or even surpassing leading RL algorithms like GRPO and DAPO.
Furthermore, we demonstrate that NFT and GRPO are actually equivalent in
strict-on-policy training, even though they originate from entirely different
theoretical foundations. Our experiments and theoretical findings bridge the
gap between SL and RL methods in binary-feedback learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Watch and Listen: Understanding Audio-Visual-Speech Moments with
  Multimodal LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18110v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18110v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zinuo Li, Xian Zhang, Yongxin Guo, Mohammed Bennamoun, Farid Boussaid, Girish Dwivedi, Luqi Gong, Qiuhong Ke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans naturally understand moments in a video by integrating visual and
auditory cues. For example, localizing a scene in the video like "A scientist
passionately speaks on wildlife conservation as dramatic orchestral music
plays, with the audience nodding and applauding" requires simultaneous
processing of visual, audio, and speech signals. However, existing models often
struggle to effectively fuse and interpret audio information, limiting their
capacity for comprehensive video temporal understanding. To address this, we
present TriSense, a triple-modality large language model designed for holistic
video temporal understanding through the integration of visual, audio, and
speech modalities. Central to TriSense is a Query-Based Connector that
adaptively reweights modality contributions based on the input query, enabling
robust performance under modality dropout and allowing flexible combinations of
available inputs. To support TriSense's multimodal capabilities, we introduce
TriSense-2M, a high-quality dataset of over 2 million curated samples generated
via an automated pipeline powered by fine-tuned LLMs. TriSense-2M includes
long-form videos and diverse modality combinations, facilitating broad
generalization. Extensive experiments across multiple benchmarks demonstrate
the effectiveness of TriSense and its potential to advance multimodal video
analysis. Code and dataset will be publicly released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ManuSearch: Democratizing Deep Search in Large Language Models with a
  Transparent and Open Multi-Agent Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18105v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18105v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lisheng Huang, Yichen Liu, Jinhao Jiang, Rongxiang Zhang, Jiahao Yan, Junyi Li, Wayne Xin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in web-augmented large language models (LLMs) have exhibited
strong performance in complex reasoning tasks, yet these capabilities are
mostly locked in proprietary systems with opaque architectures. In this work,
we propose \textbf{ManuSearch}, a transparent and modular multi-agent framework
designed to democratize deep search for LLMs. ManuSearch decomposes the search
and reasoning process into three collaborative agents: (1) a solution planning
agent that iteratively formulates sub-queries, (2) an Internet search agent
that retrieves relevant documents via real-time web search, and (3) a
structured webpage reading agent that extracts key evidence from raw web
content. To rigorously evaluate deep reasoning abilities, we introduce
\textbf{ORION}, a challenging benchmark focused on open-web reasoning over
long-tail entities, covering both English and Chinese. Experimental results
show that ManuSearch substantially outperforms prior open-source baselines and
even surpasses leading closed-source systems. Our work paves the way for
reproducible, extensible research in open deep search systems. We release the
data and code in https://github.com/RUCAIBox/ManuSearch
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>LLM, Complex Search Benchmark</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Can I Publish My LLM Benchmark Without Giving the True Answers Away? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18102v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18102v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takashi Ishida, Thanawat Lodkaew, Ikko Yamane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Publishing a large language model (LLM) benchmark on the Internet risks
contaminating future LLMs: the benchmark may be unintentionally (or
intentionally) used to train or select a model. A common mitigation is to keep
the benchmark private and let participants submit their models or predictions
to the organizers. However, this strategy will require trust in a single
organization and still permits test-set overfitting through repeated queries.
To overcome this issue, we propose a way to publish benchmarks without
completely disclosing the ground-truth answers to the questions, while still
maintaining the ability to openly evaluate LLMs. Our main idea is to inject
randomness to the answers by preparing several logically correct answers, and
only include one of them as the solution in the benchmark. This reduces the
best possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is
this helpful to keep us from disclosing the ground truth, but this approach
also offers a test for detecting data contamination. In principle, even fully
capable models should not surpass the Bayes accuracy. If a model surpasses this
ceiling despite this expectation, this is a strong signal of data
contamination. We present experimental evidence that our method can detect data
contamination accurately on a wide range of benchmarks, models, and training
methodologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Planning without Search: Refining Frontier LLMs with Offline
  Goal-Conditioned RL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joey Hong, Anca Dragan, Sergey Levine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) excel in tasks like question answering and
dialogue, but complex tasks requiring interaction, such as negotiation and
persuasion, require additional long-horizon reasoning and planning.
Reinforcement learning (RL) fine-tuning can enable such planning in principle,
but suffers from drawbacks that hinder scalability. In particular, multi-turn
RL training incurs high memory and computational costs, which are exacerbated
when training LLMs as policies. Furthermore, the largest LLMs do not expose the
APIs necessary to be trained in such manner. As a result, modern methods to
improve the reasoning of LLMs rely on sophisticated prompting mechanisms rather
than RL fine-tuning. To remedy this, we propose a novel approach that uses
goal-conditioned value functions to guide the reasoning of LLM agents, that
scales even to large API-based models. These value functions predict how a task
will unfold given an action, allowing the LLM agent to evaluate multiple
possible outcomes, both positive and negative, to plan effectively. In
addition, these value functions are trained over reasoning steps rather than
full actions, to be a concise and light-weight module that facilitates
decision-making in multi-turn interactions. We validate our method on tasks
requiring interaction, including tool use, social deduction, and dialogue,
demonstrating superior performance over both RL fine-tuning and prompting
methods while maintaining efficiency and scalability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 4 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18092v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18092v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weizhou Shen, Chenliang Li, Fanqi Wan, Shengyi Liao, Shaopeng Lai, Bo Zhang, Yingcheng Shi, Yuning Wu, Gang Fu, Zhansheng Li, Bin Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This technical report presents QwenLong-CPRS, a context compression framework
designed for explicit long-context optimization, addressing prohibitive
computation overhead during the prefill stage and the "lost in the middle"
performance degradation of large language models (LLMs) during long sequence
processing. Implemented through a novel dynamic context optimization mechanism,
QwenLong-CPRS enables multi-granularity context compression guided by natural
language instructions, achieving both efficiency gains and improved
performance.
  Evolved from the Qwen architecture series, QwenLong-CPRS introduces four key
innovations: (1) Natural language-guided dynamic optimization, (2)
Bidirectional reasoning layers for enhanced boundary awareness, (3) Token
critic mechanisms with language modeling heads, and (4) Window-parallel
inference.
  Comprehensive evaluations across five benchmarks (4K-2M word contexts)
demonstrate QwenLong-CPRS's threefold effectiveness: (1) Consistent superiority
over other context management methods like RAG and sparse attention in both
accuracy and efficiency. (2) Architecture-agnostic integration with all
flagship LLMs, including GPT-4o, Gemini2.0-pro, Claude3.7-sonnet, DeepSeek-v3,
and Qwen2.5-max, achieves 21.59$\times$ context compression alongside
19.15-point average performance gains; (3) Deployed with Qwen2.5-32B-Instruct,
QwenLong-CPRS surpasses leading proprietary LLMs by 4.85 and 10.88 points on
Ruler-128K and InfiniteBench, establishing new SOTA performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Mixing Can Induce Phase Transitions in Knowledge Acquisition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinran Gu, Kaifeng Lyu, Jiazheng Li, Jingzhao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are typically trained on data mixtures: most
data come from web scrapes, while a small portion is curated from high-quality
sources with dense domain-specific knowledge. In this paper, we show that when
training LLMs on such data mixtures, knowledge acquisition from knowledge-dense
datasets, unlike training exclusively on knowledge-dense data
(arXiv:2404.05405), does not always follow a smooth scaling law but can exhibit
phase transitions with respect to the mixing ratio and model size. Through
controlled experiments on a synthetic biography dataset mixed with web-scraped
data, we demonstrate that: (1) as we increase the model size to a critical
value, the model suddenly transitions from memorizing very few to most of the
biographies; (2) below a critical mixing ratio, the model memorizes almost
nothing even with extensive training, but beyond this threshold, it rapidly
memorizes more biographies. We attribute these phase transitions to a capacity
allocation phenomenon: a model with bounded capacity must act like a knapsack
problem solver to minimize the overall test loss, and the optimal allocation
across datasets can change discontinuously as the model size or mixing ratio
varies. We formalize this intuition in an information-theoretic framework and
reveal that these phase transitions are predictable, with the critical mixing
ratio following a power-law relationship with the model size. Our findings
highlight a concrete case where a good mixing recipe for large models may not
be optimal for small models, and vice versa.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Video Discovery: Agentic Search with Tool Use for Long-form Video
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18079v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18079v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-form video understanding presents significant challenges due to
extensive temporal-spatial complexity and the difficulty of question answering
under such extended contexts. While Large Language Models (LLMs) have
demonstrated considerable advancements in video analysis capabilities and long
context handling, they continue to exhibit limitations when processing
information-dense hour-long videos. To overcome such limitations, we propose
the Deep Video Discovery agent to leverage an agentic search strategy over
segmented video clips. Different from previous video agents manually designing
a rigid workflow, our approach emphasizes the autonomous nature of agents. By
providing a set of search-centric tools on multi-granular video database, our
DVD agent leverages the advanced reasoning capability of LLM to plan on its
current observation state, strategically selects tools, formulates appropriate
parameters for actions, and iteratively refines its internal reasoning in light
of the gathered information. We perform comprehensive evaluation on multiple
long video understanding benchmarks that demonstrates the advantage of the
entire system design. Our DVD agent achieves SOTA performance, significantly
surpassing prior works by a large margin on the challenging LVBench dataset.
Comprehensive ablation studies and in-depth tool analyses are also provided,
yielding insights to further advance intelligent agents tailored for long-form
video understanding tasks. The code will be released later.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extended Inductive Reasoning for Personalized Preference Inference from
  Behavioral Signals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18071v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18071v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia-Nan Li, Jian Guan, Wei Wu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated significant success in complex
reasoning tasks such as math and coding. In contrast to these tasks where
deductive reasoning predominates, inductive reasoning\textemdash the ability to
derive general rules from incomplete evidence, remains underexplored. This
paper investigates extended inductive reasoning in LLMs through the lens of
personalized preference inference, a critical challenge in LLM alignment where
current approaches struggle to capture diverse user preferences. The task
demands strong inductive reasoning capabilities as user preferences are
typically embedded implicitly across various interaction forms, requiring
models to synthesize consistent preference patterns from scattered signals. We
propose \textsc{AlignXplore}, a model that leverages extended reasoning chains
to enable systematic preference inference from behavioral signals in users'
interaction histories. We develop \textsc{AlignXplore} by combining cold-start
training based on synthetic data with subsequent online reinforcement learning.
Through extensive experiments, we demonstrate that \textsc{AlignXplore}
achieves substantial improvements over the backbone model by an average of
11.05\% on in-domain and out-of-domain benchmarks, while maintaining strong
generalization ability across different input formats and downstream models.
Further analyses establish best practices for preference inference learning
through systematic comparison of reward modeling strategies, while revealing
the emergence of human-like inductive reasoning patterns during training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MathEDU: Towards Adaptive Feedback for Student Mathematical
  Problem-Solving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18056v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18056v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei-Ling Hsu, Yu-Chien Tang, An-Zi Yen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online learning enhances educational accessibility, offering students the
flexibility to learn anytime, anywhere. However, a key limitation is the lack
of immediate, personalized feedback, particularly in helping students correct
errors in math problem-solving. Several studies have investigated the
applications of large language models (LLMs) in educational contexts. In this
paper, we explore the capabilities of LLMs to assess students' math
problem-solving processes and provide adaptive feedback. The MathEDU dataset is
introduced, comprising authentic student solutions annotated with teacher
feedback. We evaluate the model's ability to support personalized learning in
two scenarios: one where the model has access to students' prior answer
histories, and another simulating a cold-start context. Experimental results
show that the fine-tuned model performs well in identifying correctness.
However, the model still faces challenges in generating detailed feedback for
pedagogical purposes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contrastive Distillation of Emotion Knowledge from LLMs for Zero-Shot
  Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18040v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18040v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minxue Niu, Emily Mower Provost
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to handle various emotion labels without dedicated training is
crucial for building adaptable Emotion Recognition (ER) systems. Conventional
ER models rely on training using fixed label sets and struggle to generalize
beyond them. On the other hand, Large Language Models (LLMs) have shown strong
zero-shot ER performance across diverse label spaces, but their scale limits
their use on edge devices. In this work, we propose a contrastive distillation
framework that transfers rich emotional knowledge from LLMs into a compact
model without the use of human annotations. We use GPT-4 to generate
descriptive emotion annotations, offering rich supervision beyond fixed label
sets. By aligning text samples with emotion descriptors in a shared embedding
space, our method enables zero-shot prediction on different emotion classes,
granularity, and label schema. The distilled model is effective across multiple
datasets and label spaces, outperforming strong baselines of similar size and
approaching GPT-4's zero-shot performance, while being over 10,000 times
smaller.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structured Thinking Matters: Improving LLMs Generalization in Causal
  Inference Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18034v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18034v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentao Sun, Joao Paulo Nogueira, Alonso Silva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite remarkable advances in the field, LLMs remain unreliable in
distinguishing causation from correlation. Recent results from the Corr2Cause
dataset benchmark reveal that state-of-the-art LLMs -- such as GPT-4 (F1 score:
29.08) -- only marginally outperform random baselines (Random Uniform, F1
score: 20.38), indicating limited capacity of generalization. To tackle this
limitation, we propose a novel structured approach: rather than directly
answering causal queries, we provide the model with the capability to structure
its thinking by guiding the model to build a structured knowledge graph,
systematically encoding the provided correlational premises, to answer the
causal queries. This intermediate representation significantly enhances the
model's causal capabilities. Experiments on the test subset of the Corr2Cause
dataset benchmark with Qwen3-32B model (reasoning model) show substantial gains
over standard direct prompting methods, improving F1 scores from 32.71 to 48.26
(over 47.5% relative increase), along with notable improvements in precision
and recall. These results underscore the effectiveness of providing the model
with the capability to structure its thinking and highlight its promising
potential for broader generalization across diverse causal inference tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training with Pseudo-Code for Instruction Following 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18011v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18011v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prince Kumar, Rudra Murthy, Riyaz Bhat, Danish Contractor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the rapid progress in the capabilities of Large Language Models
(LLMs), they continue to have difficulty following relatively simple,
unambiguous instructions, especially when compositions are involved. In this
paper, we take inspiration from recent work that suggests that models may
follow instructions better when they are expressed in pseudo-code. However,
writing pseudo-code programs can be tedious and using few-shot demonstrations
to craft code representations for use in inference can be unnatural for
non-expert users of LLMs. To overcome these limitations, we propose fine-tuning
LLMs with instruction-tuning data that additionally includes instructions
re-expressed in pseudo-code along with the final response. We evaluate models
trained using our method on $11$ publicly available benchmarks comprising of
tasks related to instruction-following, mathematics, and common-sense
reasoning. We conduct rigorous experiments with $5$ different models and find
that not only do models follow instructions better when trained with
pseudo-code, they also retain their capabilities on the other tasks related to
mathematical and common sense reasoning. Specifically, we observe a relative
gain of $3$--$19$% on instruction-following benchmark, and an average gain of
upto 14% across all tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TRACE for Tracking the Emergence of Semantic Representations in
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17998v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17998v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nura Aljaafari, Danilo S. Carvalho, André Freitas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern transformer models exhibit phase transitions during training, distinct
shifts from memorisation to abstraction, but the mechanisms underlying these
transitions remain poorly understood. Prior work has often focused on endpoint
representations or isolated signals like curvature or mutual information,
typically in symbolic or arithmetic domains, overlooking the emergence of
linguistic structure. We introduce TRACE (Tracking Representation Abstraction
and Compositional Emergence), a diagnostic framework combining geometric,
informational, and linguistic signals to detect phase transitions in
Transformer-based LMs. TRACE leverages a frame-semantic data generation method,
ABSynth, that produces annotated synthetic corpora with controllable
complexity, lexical distributions, and structural entropy, while being fully
annotated with linguistic categories, enabling precise analysis of abstraction
emergence. Experiments reveal that (i) phase transitions align with clear
intersections between curvature collapse and dimension stabilisation; (ii)
these geometric shifts coincide with emerging syntactic and semantic accuracy;
(iii) abstraction patterns persist across architectural variants, with
components like feedforward networks affecting optimisation stability rather
than fundamentally altering trajectories. This work advances our understanding
of how linguistic abstractions emerge in LMs, offering insights into model
interpretability, training efficiency, and compositional generalisation that
could inform more principled approaches to LM development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Analyzing and Understanding the Limitations of VAPO: A
  Theoretical Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Shao, Yiming Cheng, Hongyi Huang, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The VAPO framework has demonstrated significant empirical success in
enhancing the efficiency and reliability of reinforcement learning for long
chain-of-thought (CoT) reasoning tasks with large language models (LLMs). By
systematically addressing challenges such as value model bias, heterogeneous
sequence lengths, and sparse reward signals, VAPO achieves state-of-the-art
performance. While its practical benefits are evident, a deeper theoretical
understanding of its underlying mechanisms and potential limitations is crucial
for guiding future advancements. This paper aims to initiate such a discussion
by exploring VAPO from a theoretical perspective, highlighting areas where its
assumptions might be challenged and where further investigation could yield
more robust and generalizable reasoning agents. We delve into the intricacies
of value function approximation in complex reasoning spaces, the optimality of
adaptive advantage estimation, the impact of token-level optimization, and the
enduring challenges of exploration and generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AVerImaTeC: A <span class="highlight-title">Dataset</span> for Automatic Verification of Image-Text Claims
  with Evidence from the Web 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17978v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17978v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Cao, Zifeng Ding, Zhijiang Guo, Michael Schlichtkrull, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Textual claims are often accompanied by images to enhance their credibility
and spread on social media, but this also raises concerns about the spread of
misinformation. Existing datasets for automated verification of image-text
claims remain limited, as they often consist of synthetic claims and lack
evidence annotations to capture the reasoning behind the verdict. In this work,
we introduce AVerImaTeC, a dataset consisting of 1,297 real-world image-text
claims. Each claim is annotated with question-answer (QA) pairs containing
evidence from the web, reflecting a decomposed reasoning regarding the verdict.
We mitigate common challenges in fact-checking datasets such as contextual
dependence, temporal leakage, and evidence insufficiency, via claim
normalization, temporally constrained evidence annotation, and a two-stage
sufficiency check. We assess the consistency of the annotation in AVerImaTeC
via inter-annotator studies, achieving a $\kappa=0.742$ on verdicts and
$74.7\%$ consistency on QA pairs. We also propose a novel evaluation method for
evidence retrieval and conduct extensive experiments to establish baselines for
verifying image-text claims using open-web evidence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Large Language Models Reliable AI Scientists? Assessing
  Reverse-Engineering of Black-Box Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17968v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17968v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Geng, Howard Chen, Dilip Arumugam, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Using AI to create autonomous researchers has the potential to accelerate
scientific discovery. A prerequisite for this vision is understanding how well
an AI model can identify the underlying structure of a black-box system from
its behavior. In this paper, we explore how well a large language model (LLM)
learns to identify a black-box function from passively observed versus actively
collected data. We investigate the reverse-engineering capabilities of LLMs
across three distinct types of black-box systems, each chosen to represent
different problem domains where future autonomous AI researchers may have
considerable impact: Program, Formal Language, and Math Equation. Through
extensive experiments, we show that LLMs fail to extract information from
observations, reaching a performance plateau that falls short of the ideal of
Bayesian inference. However, we demonstrate that prompting LLMs to not only
observe but also intervene -- actively querying the black-box with specific
inputs to observe the resulting output -- improves performance by allowing LLMs
to test edge cases and refine their beliefs. By providing the intervention data
from one LLM to another, we show that this improvement is partly a result of
engaging in the process of generating effective interventions, paralleling
results in the literature on human learning. Further analysis reveals that
engaging in intervention can help LLMs escape from two common failure modes:
overcomplication, where the LLM falsely assumes prior knowledge about the
black-box, and overlooking, where the LLM fails to incorporate observations.
These insights provide practical guidance for helping LLMs more effectively
reverse-engineer black-box systems, supporting their use in making new
discoveries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Counting Cycles with Deepseek 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17964v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17964v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiashun Jin, Tracy Ke, Bingcheng Sui, Zhenggang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent progress, AI still struggles on advanced mathematics. We
consider a difficult open problem: How to derive a Computationally Efficient
Equivalent Form (CEEF) for the cycle count statistic? The CEEF problem does not
have known general solutions, and requires delicate combinatorics and tedious
calculations. Such a task is hard to accomplish by humans but is an ideal
example where AI can be very helpful. We solve the problem by combining a novel
approach we propose and the powerful coding skills of AI. Our results use
delicate graph theory and contain new formulas for general cases that have not
been discovered before. We find that, while AI is unable to solve the problem
all by itself, it is able to solve it if we provide it with a clear strategy, a
step-by-step guidance and carefully written prompts. For simplicity, we focus
our study on DeepSeek-R1 but we also investigate other AI approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with
  Minimalist Rule-Based RL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17952v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17952v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, Daniel Rueckert, Rossella Arcucci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Improving performance on complex tasks and enabling interpretable decision
making in large language models (LLMs), especially for clinical applications,
requires effective reasoning. Yet this remains challenging without supervised
fine-tuning (SFT) on costly chain-of-thought (CoT) data distilled from
closed-source models (e.g., GPT-4o). In this work, we present AlphaMed, the
first medical LLM to show that reasoning capability can emerge purely through
reinforcement learning (RL), using minimalist rule-based rewards on public
multiple-choice QA datasets, without relying on SFT or distilled CoT data.
AlphaMed achieves state-of-the-art results on six medical QA benchmarks,
outperforming models trained with conventional SFT+RL pipelines. On challenging
benchmarks (e.g., MedXpert), AlphaMed even surpasses larger or closed-source
models such as DeepSeek-V3-671B and Claude-3.5-Sonnet. To understand the
factors behind this success, we conduct a comprehensive data-centric analysis
guided by three questions: (i) Can minimalist rule-based RL incentivize
reasoning without distilled CoT supervision? (ii) How do dataset quantity and
diversity impact reasoning? (iii) How does question difficulty shape the
emergence and generalization of reasoning? Our findings show that dataset
informativeness is a key driver of reasoning performance, and that minimalist
RL on informative, multiple-choice QA data is effective at inducing reasoning
without CoT supervision. We also observe divergent trends across benchmarks,
underscoring limitations in current evaluation and the need for more
challenging, reasoning-oriented medical QA benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Handling Symbolic Language in Student Texts: A Comparative Study of NLP
  Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17950v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17950v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tom Bleckmann, Paul Tschisgale
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Natural Language Processing (NLP) have facilitated the
analysis of student-generated language products in learning analytics (LA),
particularly through the use of NLP embedding models. Yet when it comes to
science-related language, symbolic expressions such as equations and formulas
introduce challenges that current embedding models struggle to address.
Existing studies and applications often either overlook these challenges or
remove symbolic expressions altogether, potentially leading to biased findings
and diminished performance of LA applications. This study therefore explores
how contemporary embedding models differ in their capability to process and
interpret science-related symbolic expressions. To this end, various embedding
models are evaluated using physics-specific symbolic expressions drawn from
authentic student responses, with performance assessed via two approaches:
similarity-based analyses and integration into a machine learning pipeline. Our
findings reveal significant differences in model performance, with OpenAI's
GPT-text-embedding-3-large outperforming all other examined models, though its
advantage over other models was moderate rather than decisive. Beyond
performance, additional factors such as cost, regulatory compliance, and model
transparency are discussed as key considerations for model selection. Overall,
this study underscores the importance for LA researchers and practitioners of
carefully selecting NLP embedding models when working with science-related
language products that include symbolic expressions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Gated Neurons in <span class="highlight-title">Transformer</span>s from Their Input-Output
  Functionality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Gerstner, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interpretability researchers have attempted to understand MLP neurons of
language models based on both the contexts in which they activate and their
output weight vectors. They have paid little attention to a complementary
aspect: the interactions between input and output. For example, when neurons
detect a direction in the input, they might add much the same direction to the
residual stream ("enrichment neurons") or reduce its presence ("depletion
neurons"). We address this aspect by examining the cosine similarity between
input and output weights of a neuron. We apply our method to 12 models and find
that enrichment neurons dominate in early-middle layers whereas later layers
tend more towards depletion. To explain this finding, we argue that enrichment
neurons are largely responsible for enriching concept representations, one of
the first steps of factual recall. Our input-output perspective is a complement
to activation-dependent analyses and to approaches that treat input and output
separately.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Practical Defect-Focused Automated Code <span class="highlight-title">Review</span> <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyi Lu, Lili Jiang, Xiaojia Li, Jianbing Fang, Fengjun Zhang, Li Yang, Chun Zuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The complexity of code reviews has driven efforts to automate review
comments, but prior approaches oversimplify this task by treating it as
snippet-level code-to-text generation and relying on text similarity metrics
like BLEU for evaluation. These methods overlook repository context, real-world
merge request evaluation, and defect detection, limiting their practicality. To
address these issues, we explore the full automation pipeline within the online
recommendation service of a company with nearly 400 million daily active users,
analyzing industry-grade C++ codebases comprising hundreds of thousands of
lines of code. We identify four key challenges: 1) capturing relevant context,
2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and
4) integrating human workflows. To tackle these, we propose 1) code slicing
algorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a
filtering mechanism for FAR reduction, and 4) a novel prompt design for better
human interaction. Our approach, validated on real-world merge requests from
historical fault reports, achieves a 2x improvement over standard LLMs and a
10x gain over previous baselines. While the presented results focus on C++, the
underlying framework design leverages language-agnostic principles (e.g.,
AST-based analysis), suggesting potential for broader applicability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Forty-Second International Conference on Machine Learning
  (ICML 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Language models can learn implicit multi-hop reasoning, but only if they
  have lots of training data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17923v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17923v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuekun Yao, Yupei Du, Dawei Zhu, Michael Hahn, Alexander Koller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit reasoning is the ability of a language model to solve multi-hop
reasoning tasks in a single forward pass, without chain of thought. We
investigate this capability using GPT2-style language models trained from
scratch on controlled $k$-hop reasoning datasets ($k = 2, 3, 4$). We show that
while such models can indeed learn implicit $k$-hop reasoning, the required
training data grows exponentially in $k$, and the required number of
transformer layers grows linearly in $k$. We offer a theoretical explanation
for why this depth growth is necessary. We further find that the data
requirement can be mitigated, but not eliminated, through curriculum learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ T2I-Eval-R1: Reinforcement Learning-Driven Reasoning for Interpretable
  Text-to-Image Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17897v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17897v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Shu-Hang Liu, Heyan Huang, Zhijing Wu, Chen Xu, Xian-Ling Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid progress in diffusion-based text-to-image (T2I) generation has
created an urgent need for interpretable automatic evaluation methods that can
assess the quality of generated images, therefore reducing the human annotation
burden. To reduce the prohibitive cost of relying on commercial models for
large-scale evaluation, and to improve the reasoning capabilities of
open-source models, recent research has explored supervised fine-tuning (SFT)
of multimodal large language models (MLLMs) as dedicated T2I evaluators.
However, SFT approaches typically rely on high-quality critique datasets, which
are either generated by proprietary LLMs-with potential issues of bias and
inconsistency-or annotated by humans at high cost, limiting their scalability
and generalization. To address these limitations, we propose T2I-Eval-R1, a
novel reinforcement learning framework that trains open-source MLLMs using only
coarse-grained quality scores, thereby avoiding the need for annotating
high-quality interpretable evaluation rationale. Our approach integrates Group
Relative Policy Optimization (GRPO) into the instruction-tuning process,
enabling models to generate both scalar scores and interpretable reasoning
chains with only easy accessible annotated judgment scores or preferences.
Furthermore, we introduce a continuous reward formulation that encourages score
diversity and provides stable optimization signals, leading to more robust and
discriminative evaluation behavior. Experimental results on three established
T2I meta-evaluation benchmarks demonstrate that T2I-Eval-R1 achieves
significantly higher alignment with human assessments and offers more accurate
interpretable score rationales compared to strong baseline methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mutarjim: Advancing Bidirectional Arabic-English Translation with a
  Small Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17894v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17894v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khalil Hennara, Muhammad Hreden, Mohamed Motaism Hamed, Zeina Aldallal, Sara Chrouf, Safwan AlModhayan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Mutarjim, a compact yet powerful language model for
bidirectional Arabic-English translation. While large-scale LLMs have shown
impressive progress in natural language processing tasks, including machine
translation, smaller models. Leveraging this insight, we developed Mutarjim
based on Kuwain-1.5B , a language model tailored for both Arabic and English.
Despite its modest size, Mutarjim outperforms much larger models on several
established benchmarks, achieved through an optimized two-phase training
approach and a carefully curated, high-quality training corpus.. Experimental
results show that Mutarjim rivals models up to 20 times larger while
significantly reducing computational costs and training requirements. We also
introduce Tarjama-25, a new benchmark designed to overcome limitations in
existing Arabic-English benchmarking datasets, such as domain narrowness, short
sentence lengths, and English-source bias. Tarjama-25 comprises 5,000
expert-reviewed sentence pairs and spans a wide range of domains, offering a
more comprehensive and balanced evaluation framework. Notably, Mutarjim
achieves state-of-the-art performance on the English-to-Arabic task in
Tarjama-25, surpassing even significantly larger and proprietary models like
GPT-4o mini. We publicly release Tarjama-25 to support future research and
advance the evaluation of Arabic-English translation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MOOSE-Chem3: Toward Experiment-Guided Hypothesis Ranking via Simulated
  Experimental Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17873v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17873v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanhao Liu, Zonglin Yang, Jue Wang, Lidong Bing, Di Zhang, Dongzhan Zhou, Yuqiang Li, Houqiang Li, Erik Cambria, Wanli Ouyang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hypothesis ranking is a crucial component of automated scientific discovery,
particularly in natural sciences where wet-lab experiments are costly and
throughput-limited. Existing approaches focus on pre-experiment ranking,
relying solely on large language model's internal reasoning without
incorporating empirical outcomes from experiments. We introduce the task of
experiment-guided ranking, which aims to prioritize candidate hypotheses based
on the results of previously tested ones. However, developing such strategies
is challenging due to the impracticality of repeatedly conducting real
experiments in natural science domains. To address this, we propose a simulator
grounded in three domain-informed assumptions, modeling hypothesis performance
as a function of similarity to a known ground truth hypothesis, perturbed by
noise. We curate a dataset of 124 chemistry hypotheses with experimentally
reported outcomes to validate the simulator. Building on this simulator, we
develop a pseudo experiment-guided ranking method that clusters hypotheses by
shared functional characteristics and prioritizes candidates based on insights
derived from simulated experimental feedback. Experiments show that our method
outperforms pre-experiment baselines and strong ablations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat
  Falsehoods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17870v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17870v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaina Raza, Rizwan Qureshi, Marcelo Lotif, Aman Chadha, Deval Pandya, Christos Emmanouilidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative AI models often learn and reproduce false information present in
their training corpora. This position paper argues that, analogous to
biological immunization, where controlled exposure to a weakened pathogen
builds immunity, AI models should be fine tuned on small, quarantined sets of
explicitly labeled falsehoods as a "vaccine" against misinformation. These
curated false examples are periodically injected during finetuning,
strengthening the model ability to recognize and reject misleading claims while
preserving accuracy on truthful inputs. An illustrative case study shows that
immunized models generate substantially less misinformation than baselines. To
our knowledge, this is the first training framework that treats fact checked
falsehoods themselves as a supervised vaccine, rather than relying on input
perturbations or generic human feedback signals, to harden models against
future misinformation. We also outline ethical safeguards and governance
controls to ensure the safe use of false data. Model immunization offers a
proactive paradigm for aligning AI systems with factuality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explaining Sources of Uncertainty in Automated Fact-Checking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17855v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17855v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyi Sun, Greta Warren, Irina Shklovski, Isabelle Augenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding sources of a model's uncertainty regarding its predictions is
crucial for effective human-AI collaboration. Prior work proposes using
numerical uncertainty or hedges ("I'm not sure, but ..."), which do not explain
uncertainty that arises from conflicting evidence, leaving users unable to
resolve disagreements or rely on the output. We introduce CLUE
(Conflict-and-Agreement-aware Language-model Uncertainty Explanations), the
first framework to generate natural language explanations of model uncertainty
by (i) identifying relationships between spans of text that expose
claim-evidence or inter-evidence conflicts and agreements that drive the
model's predictive uncertainty in an unsupervised way, and (ii) generating
explanations via prompting and attention steering that verbalize these critical
interactions. Across three language models and two fact-checking datasets, we
show that CLUE produces explanations that are more faithful to the model's
uncertainty and more consistent with fact-checking decisions than prompting for
uncertainty explanations without span-interaction guidance. Human evaluators
judge our explanations to be more helpful, more informative, less redundant,
and more logically consistent with the input than this baseline. CLUE requires
no fine-tuning or architectural changes, making it plug-and-play for any
white-box language model. By explicitly linking uncertainty to evidence
conflicts, it offers practical support for fact-checking and generalises
readily to other tasks that require reasoning over complex information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating Affect Mining Techniques for Annotation Sample Selection
  in the Creation of Finnish Affective Speech Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17833v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17833v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kalle Lahtinen, Einari Vaaras, Liisa Mustanoja, Okko Räsänen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Study of affect in speech requires suitable data, as emotional expression and
perception vary across languages. Until now, no corpus has existed for natural
expression of affect in spontaneous Finnish, existing data being acted or from
a very specific communicative setting. This paper presents the first such
corpus, created by annotating 12,000 utterances for emotional arousal and
valence, sampled from three large-scale Finnish speech corpora. To ensure
diverse affective expression, sample selection was conducted with an affect
mining approach combining acoustic, cross-linguistic speech emotion, and text
sentiment features. We compare this method to random sampling in terms of
annotation diversity, and conduct post-hoc analyses to identify sampling
choices that would have maximized the diversity. As an outcome, the work
introduces a spontaneous Finnish affective speech corpus and informs sampling
strategies for affective speech corpus creation in other languages or domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at Interspeech 2025, Rotterdam, The
  Netherlands</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emerging categories in scientific explanations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17832v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17832v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giacomo Magnifico, Eduard Barbu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clear and effective explanations are essential for human understanding and
knowledge dissemination. The scope of scientific research aiming to understand
the essence of explanations has recently expanded from the social sciences to
machine learning and artificial intelligence. Explanations for machine learning
decisions must be impactful and human-like, and there is a lack of large-scale
datasets focusing on human-like and human-generated explanations. This work
aims to provide such a dataset by: extracting sentences that indicate
explanations from scientific literature among various sources in the
biotechnology and biophysics topic domains (e.g. PubMed's PMC Open Access
subset); providing a multi-class notation derived inductively from the data;
evaluating annotator consensus on the emerging categories. The sentences are
organized in an openly-available dataset, with two different classifications
(6-class and 3-class category annotation), and the 3-class notation achieves a
0.667 Krippendorf Alpha value.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 3rd TRR 318 Conference: Contextualizing Explanations
  (ContEx25), as a two-pager abstract. Will be published at BiUP (Bielefeld
  University Press) at a later date</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stepwise Reasoning Checkpoint Analysis: A Test Time Scaling Method to
  Enhance LLMs' Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical reasoning through Chain-of-Thought (CoT) has emerged as a
powerful capability of Large Language Models (LLMs), which can be further
enhanced through Test-Time Scaling (TTS) methods like Beam Search and DVTS.
However, these methods, despite improving accuracy by allocating more
computational resources during inference, often suffer from path homogenization
and inefficient use of intermediate results. To address these limitations, we
propose Stepwise Reasoning Checkpoint Analysis (SRCA), a framework that
introduces checkpoints between reasoning steps. It incorporates two key
strategies: (1) Answer-Clustered Search, which groups reasoning paths by their
intermediate checkpoint answers to maintain diversity while ensuring quality,
and (2) Checkpoint Candidate Augmentation, which leverages all intermediate
answers for final decision-making. Our approach effectively reduces path
homogenization and creates a fault-tolerant mechanism by utilizing high-quality
intermediate results. Experimental results show that SRCA improves reasoning
accuracy compared to existing TTS methods across various mathematical datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Not All Tokens Are What You Need In Thinking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17827v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17827v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Yuan, Bin Yu, Haotian Li, Shijun Yang, Christina Dan Wang, Zhou Yu, Xueyin Xu, Weizhen Qi, Kai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern reasoning models, such as OpenAI's o1 and DeepSeek-R1, exhibit
impressive problem-solving capabilities but suffer from critical
inefficiencies: high inference latency, excessive computational resource
consumption, and a tendency toward overthinking -- generating verbose chains of
thought (CoT) laden with redundant tokens that contribute minimally to the
final answer. To address these issues, we propose Conditional Token Selection
(CTS), a token-level compression framework with a flexible and variable
compression ratio that identifies and preserves only the most essential tokens
in CoT. CTS evaluates each token's contribution to deriving correct answers
using conditional importance scoring, then trains models on compressed CoT.
Extensive experiments demonstrate that CTS effectively compresses long CoT
while maintaining strong reasoning performance. Notably, on the GPQA benchmark,
Qwen2.5-14B-Instruct trained with CTS achieves a 9.1% accuracy improvement with
13.2% fewer reasoning tokens (13% training token reduction). Further reducing
training tokens by 42% incurs only a marginal 5% accuracy drop while yielding a
75.8% reduction in reasoning tokens, highlighting the prevalence of redundancy
in existing CoT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 7 figures and 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement
  Fine-Tuning of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuchen Pan, Yanxi Chen, Yushuo Chen, Yuchang Sun, Daoyuan Chen, Wenhao Zhang, Yuexiang Xie, Yilun Huang, Yilei Zhang, Dawei Gao, Yaliang Li, Bolin Ding, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Trinity-RFT is a general-purpose, flexible and scalable framework designed
for reinforcement fine-tuning (RFT) of large language models. It is built with
a decoupled design, consisting of (1) an RFT-core that unifies and generalizes
synchronous/asynchronous, on-policy/off-policy, and online/offline modes of
RFT, (2) seamless integration for agent-environment interaction with high
efficiency and robustness, and (3) systematic data pipelines optimized for RFT.
Trinity-RFT can be easily adapted for diverse application scenarios, and serves
as a unified platform for exploring advanced reinforcement learning paradigms.
This technical report outlines the vision, features, design and implementations
of Trinity-RFT, accompanied by extensive examples demonstrating the utility and
user-friendliness of the proposed framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This technical report will be continuously updated as the codebase
  evolves. GitHub: https://github.com/modelscope/Trinity-RFT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient
  Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17818v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17818v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daeun Kyung, Hyunseung Chung, Seongsu Bae, Jiho Kim, Jae Ho Sohn, Taerim Kim, Soo Kyung Kim, Edward Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Doctor-patient consultations require multi-turn, context-aware communication
tailored to diverse patient personas. Training or evaluating doctor LLMs in
such settings requires realistic patient interaction systems. However, existing
simulators often fail to reflect the full range of personas seen in clinical
practice. To address this, we introduce PatientSim, a patient simulator that
generates realistic and diverse patient personas for clinical scenarios,
grounded in medical expertise. PatientSim operates using: 1) clinical profiles,
including symptoms and medical history, derived from real-world data in the
MIMIC-ED and MIMIC-IV datasets, and 2) personas defined by four axes:
personality, language proficiency, medical history recall level, and cognitive
confusion level, resulting in 37 unique combinations. We evaluated eight LLMs
for factual accuracy and persona consistency. The top-performing open-source
model, Llama 3.3, was validated by four clinicians to confirm the robustness of
our framework. As an open-source, customizable platform, PatientSim provides a
reproducible and scalable solution that can be customized for specific training
needs. Offering a privacy-compliant environment, it serves as a robust testbed
for evaluating medical dialogue systems across diverse patient presentations
and shows promise as an educational tool for healthcare.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages for main text, 4 pages for references, 27 pages for
  supplementary materials</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Resource NMT: A Case Study on the Written and Spoken Languages in
  Hong Kong 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17816v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17816v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hei Yi Mak, Tan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The majority of inhabitants in Hong Kong are able to read and write in
standard Chinese but use Cantonese as the primary spoken language in daily
life. Spoken Cantonese can be transcribed into Chinese characters, which
constitute the so-called written Cantonese. Written Cantonese exhibits
significant lexical and grammatical differences from standard written Chinese.
The rise of written Cantonese is increasingly evident in the cyber world. The
growing interaction between Mandarin speakers and Cantonese speakers is leading
to a clear demand for automatic translation between Chinese and Cantonese. This
paper describes a transformer-based neural machine translation (NMT) system for
written-Chinese-to-written-Cantonese translation. Given that parallel text data
of Chinese and Cantonese are extremely scarce, a major focus of this study is
on the effort of preparing good amount of training data for NMT. In addition to
collecting 28K parallel sentences from previous linguistic studies and
scattered internet resources, we devise an effective approach to obtaining 72K
parallel sentences by automatically extracting pairs of semantically similar
sentences from parallel articles on Chinese Wikipedia and Cantonese Wikipedia.
We show that leveraging highly similar sentence pairs mined from Wikipedia
improves translation performance in all test sets. Our system outperforms Baidu
Fanyi's Chinese-to-Cantonese translation on 6 out of 8 test sets in BLEU
scores. Translation examples reveal that our system is able to capture
important linguistic transformations between standard Chinese and spoken
Cantonese.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 2021 5th International Conference on Natural
  Language Processing and Information Retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17813v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17813v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Hassid, Gabriel Synnaeve, Yossi Adi, Roy Schwartz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reasoning large language models (LLMs) heavily rely on scaling test-time
compute to perform complex reasoning tasks by generating extensive "thinking"
chains. While demonstrating impressive results, this approach incurs
significant computational costs and inference time. In this work, we challenge
the assumption that long thinking chains results in better reasoning
capabilities. We first demonstrate that shorter reasoning chains within
individual questions are significantly more likely to yield correct answers -
up to 34.5% more accurate than the longest chain sampled for the same question.
Based on these results, we suggest short-m@k, a novel reasoning LLM inference
method. Our method executes k independent generations in parallel and halts
computation once the first m thinking processes are done. The final answer is
chosen using majority voting among these m chains. Basic short-1@k demonstrates
similar or even superior performance over standard majority voting in
low-compute settings - using up to 40% fewer thinking tokens. short-3@k, while
slightly less efficient than short-1@k, consistently surpasses majority voting
across all compute budgets, while still being substantially faster (up to 33%
wall time reduction). Inspired by our results, we finetune an LLM using short,
long, and randomly selected reasoning chains. We then observe that training on
the shorter ones leads to better performance. Our findings suggest rethinking
current methods of test-time compute in reasoning LLMs, emphasizing that longer
"thinking" does not necessarily translate to improved performance and can,
counter-intuitively, lead to degraded results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DialogXpert: Driving Intelligent and Emotion-Aware Conversations through
  Online Value-Based Reinforcement Learning with LLM Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tazeek Bin Abdur Rakib, Ambuj Mehrish, Lay-Ki Soon, Wern Han Lim, Soujanya Poria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-language-model (LLM) agents excel at reactive dialogue but struggle
with proactive, goal-driven interactions due to myopic decoding and costly
planning. We introduce DialogXpert, which leverages a frozen LLM to propose a
small, high-quality set of candidate actions per turn and employs a compact
Q-network over fixed BERT embeddings trained via temporal-difference learning
to select optimal moves within this reduced space. By tracking the user's
emotions, DialogXpert tailors each decision to advance the task while nurturing
a genuine, empathetic connection. Across negotiation, emotional support, and
tutoring benchmarks, DialogXpert drives conversations to under $3$ turns with
success rates exceeding 94\% and, with a larger LLM prior, pushes success above
97\% while markedly improving negotiation outcomes. This framework delivers
real-time, strategic, and emotionally intelligent dialogue planning at scale.
Code available at https://github.com/declare-lab/dialogxpert/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compression Hacking: A Supplementary Perspective on Informatics Metric
  of Language Models from Geometric Distortion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17793v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17793v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianxiang Zang, Meiling Ning, Yongda Wei, Shihan Dou, Jiazheng Zhang, Nijia Mo, Binhong Li, Tao Gui, Qi Zhang, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the concept of ``compression as intelligence'' has provided a novel
informatics metric perspective for language models (LMs), emphasizing that
highly structured representations signify the intelligence level of LMs.
However, from a geometric standpoint, the word representation space of highly
compressed LMs tends to degenerate into a highly anisotropic state, which
hinders the LM's ability to comprehend instructions and directly impacts its
performance. We found this compression-anisotropy synchronicity is essentially
the ``Compression Hacking'' in LM representations, where noise-dominated
directions tend to create the illusion of high compression rates by sacrificing
spatial uniformity. Based on this, we propose three refined compression metrics
by incorporating geometric distortion analysis and integrate them into a
self-evaluation pipeline. The refined metrics exhibit strong alignment with the
LM's comprehensive capabilities, achieving Spearman correlation coefficients
above 0.9, significantly outperforming both the original compression and other
internal structure-based metrics. This confirms that compression hacking
substantially enhances the informatics interpretation of LMs by incorporating
geometric distortion of representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EXECUTE: A Multilingual Benchmark for LLM Token Understanding <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Edman, Helmut Schmid, Alexander Fraser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The CUTE benchmark showed that LLMs struggle with character understanding in
English. We extend it to more languages with diverse scripts and writing
systems, introducing EXECUTE. Our simplified framework allows easy expansion to
any language. Tests across multiple LLMs reveal that challenges in other
languages are not always on the character level as in English. Some languages
show word-level processing issues, some show no issues at all. We also examine
sub-character tasks in Chinese, Japanese, and Korean to assess LLMs'
understanding of character components.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Findings of ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Real Barrier to LLM Agent Usability is Agentic ROI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiwen Liu, Jiarui Qin, Xu Huang, Xingshan Zeng, Yunjia Xi, Jianghao Lin, Chuhan Wu, Yasheng Wang, Lifeng Shang, Ruiming Tang, Defu Lian, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) agents represent a promising shift in human-AI
interaction, moving beyond passive prompt-response systems to autonomous agents
capable of reasoning, planning, and goal-directed action. Despite the
widespread application in specialized, high-effort tasks like coding and
scientific research, we highlight a critical usability gap in high-demand,
mass-market applications. This position paper argues that the limited
real-world adoption of LLM agents stems not only from gaps in model
capabilities, but also from a fundamental tradeoff between the value an agent
can provide and the costs incurred during real-world use. Hence, we call for a
shift from solely optimizing model performance to a broader, utility-driven
perspective: evaluating agents through the lens of the overall agentic return
on investment (Agent ROI). By identifying key factors that determine Agentic
ROI--information quality, agent time, and cost--we posit a zigzag development
trajectory in optimizing agentic ROI: first scaling up to improve the
information quality, then scaling down to minimize the time and cost. We
outline the roadmap across different development stages to bridge the current
usability gaps, aiming to make LLM agents truly scalable, accessible, and
effective in real-world contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Resolving Conflicting Evidence in Automated Fact-Checking: A Study on
  Retrieval-Augmented LLMs <span class="chip">IJCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17762v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17762v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee, Rui Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) augmented with retrieval mechanisms have
demonstrated significant potential in fact-checking tasks by integrating
external knowledge. However, their reliability decreases when confronted with
conflicting evidence from sources of varying credibility. This paper presents
the first systematic evaluation of Retrieval-Augmented Generation (RAG) models
for fact-checking in the presence of conflicting evidence. To support this
study, we introduce \textbf{CONFACT} (\textbf{Con}flicting Evidence for
\textbf{Fact}-Checking) (Dataset available at
https://github.com/zoeyyes/CONFACT), a novel dataset comprising questions
paired with conflicting information from various sources. Extensive experiments
reveal critical vulnerabilities in state-of-the-art RAG methods, particularly
in resolving conflicts stemming from differences in media source credibility.
To address these challenges, we investigate strategies to integrate media
background information into both the retrieval and generation stages. Our
results show that effectively incorporating source credibility significantly
enhances the ability of RAG models to resolve conflicting evidence and improve
fact-checking performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready for IJCAI 2025, AI and Social Good</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Discriminating Form and Meaning in Multilingual Models with Minimal-Pair
  ABX Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17747v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17747v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maureen de Seyssel, Jie Chi, Skyler Seto, Maartje ter Hoeve, Masha Fedzechkina, Natalie Schluter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a set of training-free ABX-style discrimination tasks to
evaluate how multilingual language models represent language identity (form)
and semantic content (meaning). Inspired from speech processing, these
zero-shot tasks measure whether minimal differences in representation can be
reliably detected. This offers a flexible and interpretable alternative to
probing. Applied to XLM-R (Conneau et al, 2020) across pretraining checkpoints
and layers, we find that language discrimination declines over training and
becomes concentrated in lower layers, while meaning discrimination strengthens
over time and stabilizes in deeper layers. We then explore probing tasks,
showing some alignment between our metrics and linguistic learning performance.
Our results position ABX tasks as a lightweight framework for analyzing the
structure of multilingual representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast Quiet-STaR: Thinking Without Thought Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17746v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17746v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Huang, Yizhe Xiong, Xin Ye, Zhijie Deng, Hui Chen, Zijia Lin, Guiguang Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have achieved impressive performance across a
range of natural language processing tasks. However, recent advances
demonstrate that further gains particularly in complex reasoning tasks require
more than merely scaling up model sizes or training data. One promising
direction is to enable models to think during the reasoning process. Recently,
Quiet STaR significantly improves reasoning by generating token-level thought
traces, but incurs substantial inference overhead. In this work, we propose
Fast Quiet STaR, a more efficient reasoning framework that preserves the
benefits of token-level reasoning while reducing computational cost. Our method
introduces a curriculum learning based training strategy that gradually reduces
the number of thought tokens, enabling the model to internalize more abstract
and concise reasoning processes. We further extend this approach to the
standard Next Token Prediction (NTP) setting through reinforcement
learning-based fine-tuning, resulting in Fast Quiet-STaR NTP, which eliminates
the need for explicit thought token generation during inference. Experiments on
four benchmark datasets with Mistral 7B and Qwen2.5 7B demonstrate that Fast
Quiet-STaR consistently outperforms Quiet-STaR in terms of average accuracy
under the same inference time budget. Notably, Fast Quiet-STaR NTP achieves an
average accuracy improvement of 9\% on Mistral 7B and 5.7\% on Qwen2.5 7B,
while maintaining the same inference latency. Our code will be available at
https://github.com/huangwei200012/Fast-Quiet-STaR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Pilot Corpus of the English Semantic Sketches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17733v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17733v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maria Petrova, Maria Ponomareva, Alexandra Ivoylova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paper is devoted to the creation of the semantic sketches for English
verbs. The pilot corpus consists of the English-Russian sketch pairs and is
aimed to show what kind of contrastive studies the sketches help to conduct.
Special attention is paid to the cross-language differences between the
sketches with similar semantics. Moreover, we discuss the process of building a
semantic sketch, and analyse the mistakes that could give insight to the
linguistic nature of sketches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PPO-BR: Dual-Signal Entropy-Reward Adaptation for Trust Region Policy
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17714v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17714v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ben Rahman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite Proximal Policy Optimization (PPO) dominating policy gradient methods
-- from robotic control to game AI -- its static trust region forces a brittle
trade-off: aggressive clipping stifles early exploration, while late-stage
updates destabilize convergence. PPO-BR establishes a new paradigm in adaptive
RL by fusing exploration and convergence signals into a single bounded trust
region -- a theoretically grounded innovation that outperforms five SOTA
baselines with less than 2% overhead. This work bridges a critical gap in
phase-aware learning, enabling real-world deployment in safety-critical systems
like robotic surgery within a single adaptive mechanism. PPO-BR achieves 29.1%
faster convergence by combining: (1) entropy-driven expansion (epsilon up) for
exploration in high-uncertainty states, and (2) reward-guided contraction
(epsilon down) for convergence stability. On six diverse benchmarks (MuJoCo,
Atari, sparse-reward), PPO-BR achieves 29.1% faster convergence (p < 0.001),
2.3x lower reward variance than PPO, and less than 1.8% runtime overhead with
only five lines of code change. PPO-BR's simplicity and theoretical guarantees
make it ready-to-deploy in safety-critical domains -- from surgical robotics to
autonomous drones. In contrast to recent methods such as Group Relative Policy
Optimization (GRPO), PPO-BR offers a unified entropy-reward mechanism
applicable to both language models and general reinforcement learning
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript builds upon an earlier version posted to TechRxiv.
  This arXiv version includes an updated comparison with GRPO (Group Relative
  Policy Optimization)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding How Value Neurons Shape the Generation of Specified Values
  in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Su, Jiayi Zhang, Shu Yang, Xinhai Wang, Lijie Hu, Di Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rapid integration of large language models (LLMs) into societal applications
has intensified concerns about their alignment with universal ethical
principles, as their internal value representations remain opaque despite
behavioral alignment advancements. Current approaches struggle to
systematically interpret how values are encoded in neural architectures,
limited by datasets that prioritize superficial judgments over mechanistic
analysis. We introduce ValueLocate, a mechanistic interpretability framework
grounded in the Schwartz Values Survey, to address this gap. Our method first
constructs ValueInsight, a dataset that operationalizes four dimensions of
universal value through behavioral contexts in the real world. Leveraging this
dataset, we develop a neuron identification method that calculates activation
differences between opposing value aspects, enabling precise localization of
value-critical neurons without relying on computationally intensive attribution
methods. Our proposed validation method demonstrates that targeted manipulation
of these neurons effectively alters model value orientations, establishing
causal relationships between neurons and value representations. This work
advances the foundation for value alignment by bridging psychological value
frameworks with neuron analysis in LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SemSketches-2021: experimenting with the machine processing of the pilot
  semantic sketches corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maria Ponomareva, Maria Petrova, Julia Detkova, Oleg Serikov, Maria Yarova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paper deals with elaborating different approaches to the machine
processing of semantic sketches. It presents the pilot open corpus of semantic
sketches. Different aspects of creating the sketches are discussed, as well as
the tasks that the sketches can help to solve. Special attention is paid to the
creation of the machine processing tools for the corpus. For this purpose, the
SemSketches-2021 Shared Task was organized. The participants were given the
anonymous sketches and a set of contexts containing the necessary predicates.
During the Task, one had to assign the proper contexts to the corresponding
sketches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary
  Weights in Down Projection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaewon Cheon, Pilsung Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing size of large language models has created significant
computational inefficiencies. To address this challenge, sparse activation
methods selectively deactivates non-essential parameters during inference,
reducing computational costs in FFNN layers. While existing methods focus on
non-linear gating mechanisms, we hypothesize that the sparsity of the FFNN
layer lies globally in the form of a linear combination over its internal down
projection matrix. Based on this insight, we propose two methods: M-COUNTDOWN,
leveraging indirect coefficients, and D-COUNTDOWN, utilizing direct
coefficients of the linear combination. Experimental results demonstrate that
D-COUNTDOWN can omit 90% of computations with performance loss as low as 5.5%
ideally, while M-COUNTDOWN provides a predictor-free solution with up to 29.4%
better performance preservation compared to existing methods. Our specialized
kernel implementations effectively realize these theoretical gains into
substantial real-world acceleration.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Activation Control for Efficiently Eliciting Long Chain-of-thought
  Ability of Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zekai Zhao, Qi Liu, Kun Zhou, Zihan Liu, Yifei Shao, Zhiting Hu, Biwei Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable reasoning performance, eliciting the long
chain-of-thought (CoT) ability in large language models (LLMs) typically
requires costly reinforcement learning or supervised fine-tuning on
high-quality distilled data. We investigate the internal mechanisms behind this
capability and show that a small set of high-impact activations in the last few
layers largely governs long-form reasoning attributes, such as output length
and self-reflection. By simply amplifying these activations and inserting
"wait" tokens, we can invoke the long CoT ability without any training,
resulting in significantly increased self-reflection rates and accuracy.
Moreover, we find that the activation dynamics follow predictable trajectories,
with a sharp rise after special tokens and a subsequent exponential decay.
Building on these insights, we introduce a general training-free activation
control technique. It leverages a few contrastive examples to identify key
activations, and employs simple analytic functions to modulate their values at
inference time to elicit long CoTs. Extensive experiments confirm the
effectiveness of our method in efficiently eliciting long CoT reasoning in LLMs
and improving their performance. Additionally, we propose a parameter-efficient
fine-tuning method that trains only a last-layer activation amplification
module and a few LoRA layers, outperforming full LoRA fine-tuning on reasoning
benchmarks with significantly fewer parameters. Our code and data are publicly
released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive
  Preferences via Tournament Graph Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Yu, Yilun Liu, Minggui He, Shimin Tao, Weibin Meng, Xinhua Yang, Li Zhang, Hongxia Ma, Chang Su, Hao Yang, Fuliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are widely used as evaluators for open-ended
tasks, while previous research has emphasized biases in LLM evaluations, the
issue of non-transitivity in pairwise comparisons remains unresolved:
non-transitive preferences for pairwise comparisons, where evaluators prefer A
over B, B over C, but C over A. Our results suggest that low-quality training
data may reduce the transitivity of preferences generated by the Evaluator LLM.
To address this, We propose a graph-theoretic framework to analyze and mitigate
this problem by modeling pairwise preferences as tournament graphs. We quantify
non-transitivity and introduce directed graph structural entropy to measure the
overall clarity of preferences. Our analysis reveals significant
non-transitivity in advanced Evaluator LLMs (with Qwen2.5-Max exhibiting
67.96%), as well as high entropy values (0.8095 for Qwen2.5-Max), reflecting
low overall clarity of preferences. To address this issue, we designed a
filtering strategy, ELSPR, to eliminate preference data that induces
non-transitivity, retaining only consistent and transitive preference data for
model fine-tuning. Experiments demonstrate that models fine-tuned with filtered
data reduce non-transitivity by 13.78% (from 64.28% to 50.50%), decrease
structural entropy by 0.0879 (from 0.8113 to 0.7234), and align more closely
with human evaluators (human agreement rate improves by 0.6% and Spearman
correlation increases by 0.01).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tuning Language Models for Robust Prediction of Diverse User Behaviors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17682v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17682v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanjin Meng, Jingtao Ding, Jiahui Gong, Chen Yang, Hong Chen, Zuojian Wang, Haisheng Lu, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting user behavior is essential for intelligent assistant services, yet
deep learning models often struggle to capture long-tailed behaviors. Large
language models (LLMs), with their pretraining on vast corpora containing rich
behavioral knowledge, offer promise. However, existing fine-tuning approaches
tend to overfit to frequent ``anchor'' behaviors, reducing their ability to
predict less common ``tail'' behaviors. In this paper, we introduce BehaviorLM,
a progressive fine-tuning approach that addresses this issue. In the first
stage, LLMs are fine-tuned on anchor behaviors while preserving general
behavioral knowledge. In the second stage, fine-tuning uses a balanced subset
of all behaviors based on sample difficulty to improve tail behavior
predictions without sacrificing anchor performance. Experimental results on two
real-world datasets demonstrate that BehaviorLM robustly predicts both anchor
and tail behaviors and effectively leverages LLM behavioral knowledge to master
tail behavior prediction with few-shot examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIDB: Multilingual Instruction Data Booster for Enhancing Multilingual
  Instruction Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilun Liu, Chunguang Zhao, Xinhua Yang, Hongyong Zeng, Shimin Tao, Weibin Meng, Minggui He, Chang Su, Yan Yu, Hongxia Ma, Li Zhang, Daimeng Wei, Hao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite doubts on data quality, instruction synthesis has been widely applied
into instruction tuning (IT) of LLMs as an economic and rapid alternative.
Recent endeavors focus on improving data quality for synthesized instruction
pairs in English and have facilitated IT of English-centric LLMs. However, data
quality issues in multilingual synthesized instruction pairs are even more
severe, since the common synthesizing practice is to translate English
synthesized data into other languages using machine translation (MT). Besides
the known content errors in these English synthesized data, multilingual
synthesized instruction data are further exposed to defects introduced by MT
and face insufficient localization of the target languages. In this paper, we
propose MIDB, a Multilingual Instruction Data Booster to automatically address
the quality issues in multilingual synthesized data. MIDB is trained on around
36.8k revision examples across 16 languages by human linguistic experts,
thereby can boost the low-quality data by addressing content errors and MT
defects, and improving localization in these synthesized data. Both automatic
and human evaluation indicate that not only MIDB steadily improved instruction
data quality in 16 languages, but also the instruction-following and
cultural-understanding abilities of multilingual LLMs fine-tuned on
MIDB-boosted data were significantly enhanced.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QwenLong-L1: Towards Long-Context Large Reasoning Models with
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanqi Wan, Weizhou Shen, Shengyi Liao, Yingcheng Shi, Chenliang Li, Ziyi Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent large reasoning models (LRMs) have demonstrated strong reasoning
capabilities through reinforcement learning (RL). These improvements have
primarily been observed within the short-context reasoning tasks. In contrast,
extending LRMs to effectively process and reason on long-context inputs via RL
remains a critical unsolved challenge. To bridge this gap, we first formalize
the paradigm of long-context reasoning RL, and identify key challenges in
suboptimal training efficiency and unstable optimization process. To address
these issues, we propose QwenLong-L1, a framework that adapts short-context
LRMs to long-context scenarios via progressive context scaling. Specifically,
we utilize a warm-up supervised fine-tuning (SFT) stage to establish a robust
initial policy, followed by a curriculum-guided phased RL technique to
stabilize the policy evolution, and enhanced with a difficulty-aware
retrospective sampling strategy to incentivize the policy exploration.
Experiments on seven long-context document question-answering benchmarks
demonstrate that QwenLong-L1-32B outperforms flagship LRMs like OpenAI-o3-mini
and Qwen3-235B-A22B, achieving performance on par with
Claude-3.7-Sonnet-Thinking, demonstrating leading performance among
state-of-the-art LRMs. This work advances the development of practical
long-context LRMs capable of robust reasoning across information-intensive
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal
  Evolution of Human States <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17663v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17663v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Xiao, Jiashuo Wang, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) increasingly participate in human-AI
interactions, evaluating their Theory of Mind (ToM) capabilities - particularly
their ability to track dynamic mental states - becomes crucial. While existing
benchmarks assess basic ToM abilities, they predominantly focus on static
snapshots of mental states, overlooking the temporal evolution that
characterizes real-world social interactions. We present \textsc{DynToM}, a
novel benchmark specifically designed to evaluate LLMs' ability to understand
and track the temporal progression of mental states across interconnected
scenarios. Through a systematic four-step framework, we generate 1,100 social
contexts encompassing 5,500 scenarios and 78,100 questions, each validated for
realism and quality. Our comprehensive evaluation of ten state-of-the-art LLMs
reveals that their average performance underperforms humans by 44.7\%, with
performance degrading significantly when tracking and reasoning about the shift
of mental states. This performance gap highlights fundamental limitations in
current LLMs' ability to model the dynamic nature of human mental states.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL 2025 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs <span class="chip">EMNLP25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17656v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17656v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hexiang Tan, Fei Sun, Sha Liu, Du Su, Qi Cao, Xin Chen, Jingang Wang, Xunliang Cai, Yuanzhuo Wang, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) often generate plausible but incorrect
content, error detection has become increasingly critical to ensure
truthfulness. However, existing detection methods often overlook a critical
problem we term as self-consistent error, where LLMs repeatly generate the same
incorrect response across multiple stochastic samples. This work formally
defines self-consistent errors and evaluates mainstream detection methods on
them. Our investigation reveals two key findings: (1) Unlike inconsistent
errors, whose frequency diminishes significantly as LLM scale increases, the
frequency of self-consistent errors remains stable or even increases. (2) All
four types of detection methshods significantly struggle to detect
self-consistent errors. These findings reveal critical limitations in current
detection methods and underscore the need for improved methods. Motivated by
the observation that self-consistent errors often differ across LLMs, we
propose a simple but effective cross-model probe method that fuses hidden state
evidence from an external verifier LLM. Our method significantly enhances
performance on self-consistent errors across three LLM families.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Underreview in EMNLP25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce
  Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17654v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17654v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  E-commerce platforms increasingly rely on Large Language Models (LLMs) and
Vision-Language Models (VLMs) to detect illicit or misleading product content.
However, these models remain vulnerable to evasive content: inputs (text or
images) that superficially comply with platform policies while covertly
conveying prohibited claims. Unlike traditional adversarial attacks that induce
overt failures, evasive content exploits ambiguity and context, making it far
harder to detect. Existing robustness benchmarks provide little guidance for
this demanding, real-world challenge. We introduce EVADE, the first
expert-curated, Chinese, multimodal benchmark specifically designed to evaluate
foundation models on evasive content detection in e-commerce. The dataset
contains 2,833 annotated text samples and 13,961 images spanning six demanding
product categories, including body shaping, height growth, and health
supplements. Two complementary tasks assess distinct capabilities:
Single-Violation, which probes fine-grained reasoning under short prompts, and
All-in-One, which tests long-context reasoning by merging overlapping policy
rules into unified instructions. Notably, the All-in-One setting significantly
narrows the performance gap between partial and full-match accuracy, suggesting
that clearer rule definitions improve alignment between human and model
judgment. We benchmark 26 mainstream LLMs and VLMs and observe substantial
performance gaps: even state-of-the-art models frequently misclassify evasive
samples. By releasing EVADE and strong baselines, we provide the first rigorous
standard for evaluating evasive-content detection, expose fundamental
limitations in current multimodal reasoning, and lay the groundwork for safer
and more transparent content moderation systems in e-commerce. The dataset is
publicly available at https://huggingface.co/datasets/koenshen/EVADE-Bench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HoloLLM: Multisensory Foundation Model for Language-Grounded Human
  Sensing and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17645v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17645v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhao Zhou, Jianfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied agents operating in smart homes must understand human behavior
through diverse sensory inputs and communicate via natural language. While
Vision-Language Models (VLMs) have enabled impressive language-grounded
perception, their reliance on visual data limits robustness in real-world
scenarios with occlusions, poor lighting, or privacy constraints. In this
paper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that
integrates uncommon but powerful sensing modalities, such as LiDAR, infrared,
mmWave radar, and WiFi, to enable seamless human perception and reasoning
across heterogeneous environments. We address two key challenges: (1) the
scarcity of aligned modality-text data for rare sensors, and (2) the
heterogeneity of their physical signal representations. To overcome these, we
design a Universal Modality-Injection Projector (UMIP) that enhances
pre-aligned modality embeddings with fine-grained, text-aligned features from
tailored encoders via coarse-to-fine cross-attention without introducing
significant alignment overhead. We further introduce a human-VLM collaborative
data curation pipeline to generate paired textual annotations for sensing
datasets. Extensive experiments on two newly constructed benchmarks show that
HoloLLM significantly outperforms existing MLLMs, improving language-grounded
human sensing accuracy by up to 30%. This work establishes a new foundation for
real-world, language-informed multisensory embodied intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 13 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Electronic Health Records and Clinical Texts: Contrastive
  Learning for Enhanced Clinical Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Ketabi, Dhanesh Ramachandram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conventional machine learning models, particularly tree-based approaches,
have demonstrated promising performance across various clinical prediction
tasks using electronic health record (EHR) data. Despite their strengths, these
models struggle with tasks that require deeper contextual understanding, such
as predicting 30-day hospital readmission. This can be primarily due to the
limited semantic information available in structured EHR data. To address this
limitation, we propose a deep multimodal contrastive learning (CL) framework
that aligns the latent representations of structured EHR data with unstructured
discharge summary notes. It works by pulling together paired EHR and text
embeddings while pushing apart unpaired ones. Fine-tuning the pretrained EHR
encoder extracted from this framework significantly boosts downstream task
performance, e.g., a 4.1% AUROC enhancement over XGBoost for 30-day readmission
prediction. Such results demonstrate the effect of integrating domain knowledge
from clinical notes into EHR-based pipelines, enabling more accurate and
context-aware clinical decision support systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stereotype Detection in Natural Language Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandra Teresa Cignarella, Anastasia Giachanou, Els Lefever
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stereotypes influence social perceptions and can escalate into discrimination
and violence. While NLP research has extensively addressed gender bias and hate
speech, stereotype detection remains an emerging field with significant
societal implications. In this work is presented a survey of existing research,
analyzing definitions from psychology, sociology, and philosophy. A
semi-automatic literature review was performed by using Semantic Scholar. We
retrieved and filtered over 6,000 papers (in the year range 2000-2025),
identifying key trends, methodologies, challenges and future directions. The
findings emphasize stereotype detection as a potential early-monitoring tool to
prevent bias escalation and the rise of hate speech. Conclusions highlight the
need for a broader, multilingual, and intersectional approach in NLP studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A
  Multi-Dimensional Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Bennion, Shaona Ghosh, Mantek Singh, Nouha Dziri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various AI safety datasets have been developed to measure LLMs against
evolving interpretations of harm. Our evaluation of five recently published
open-source safety benchmarks reveals distinct semantic clusters using UMAP
dimensionality reduction and kmeans clustering (silhouette score: 0.470). We
identify six primary harm categories with varying benchmark representation.
GretelAI, for example, focuses heavily on privacy concerns, while WildGuardMix
emphasizes self-harm scenarios. Significant differences in prompt length
distribution suggests confounds to data collection and interpretations of harm
as well as offer possible context. Our analysis quantifies benchmark
orthogonality among AI benchmarks, allowing for transparency in coverage gaps
despite topical similarities. Our quantitative framework for analyzing semantic
orthogonality across safety benchmarks enables more targeted development of
datasets that comprehensively address the evolving landscape of harms in AI
use, however that is defined in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6th International Conference on Advanced Natural Language Processing
  (AdNLP 2025), May 17 ~ 18, 2025, Zurich, Switzerland</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GIM: Improved Interpretability for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joakim Edin, Róbert Csordás, Tuukka Ruotsalo, Zhengxuan Wu, Maria Maistro, Jing Huang, Lars Maaløe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring faithful interpretability in large language models is imperative for
trustworthy and reliable AI. A key obstacle is self-repair, a phenomenon where
networks compensate for reduced signal in one component by amplifying others,
masking the true importance of the ablated component. While prior work
attributes self-repair to layer normalization and back-up components that
compensate for ablated components, we identify a novel form occurring within
the attention mechanism, where softmax redistribution conceals the influence of
important attention scores. This leads traditional ablation and gradient-based
methods to underestimate the significance of all components contributing to
these attention scores. We introduce Gradient Interaction Modifications (GIM),
a technique that accounts for self-repair during backpropagation. Extensive
experiments across multiple large language models (Gemma 2B/9B, LLAMA 1B/3B/8B,
Qwen 1.5B/3B) and diverse tasks demonstrate that GIM significantly improves
faithfulness over existing circuit identification and feature attribution
methods. Our work is a significant step toward better understanding the inner
mechanisms of LLMs, which is crucial for improving them and ensuring their
safety. Our code is available at https://github.com/JoakimEdin/gim.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Large Vision-Language Models with Layout Modality for Table
  Question Answering on Japanese Annual Securities Reports 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hayato Aida, Kosuke Takahashi, Takahiro Omi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With recent advancements in Large Language Models (LLMs) and growing interest
in retrieval-augmented generation (RAG), the ability to understand table
structures has become increasingly important. This is especially critical in
financial domains such as securities reports, where highly accurate question
answering (QA) over tables is required. However, tables exist in various
formats-including HTML, images, and plain text-making it difficult to preserve
and extract structural information. Therefore, multimodal LLMs are essential
for robust and general-purpose table understanding. Despite their promise,
current Large Vision-Language Models (LVLMs), which are major representatives
of multimodal LLMs, still face challenges in accurately understanding
characters and their spatial relationships within documents. In this study, we
propose a method to enhance LVLM-based table understanding by incorporating
in-table textual content and layout features. Experimental results demonstrate
that these auxiliary modalities significantly improve performance, enabling
robust interpretation of complex document layouts without relying on explicitly
structured input formats.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IIAI AAI 2025, the 3rd International Conference on
  Computational and Data Sciences in Economics and Finance</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large
  Language Model-based Agents in Embodied Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingyu Lu, Liang Ding, Siyi Cao, Xuebo Liu, Kanjian Zhang, Jinxia Zhang, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Agents powered by large language models (LLMs) have demonstrated strong
planning and decision-making capabilities in complex embodied environments.
However, such agents often suffer from inefficiencies in multi-turn
interactions, frequently trapped in repetitive loops or issuing ineffective
commands, leading to redundant computational overhead. Instead of relying
solely on learning from trajectories, we take a first step toward exploring the
early-exit behavior for LLM-based agents. We propose two complementary
approaches: 1. an $\textbf{intrinsic}$ method that injects exit instructions
during generation, and 2. an $\textbf{extrinsic}$ method that verifies task
completion to determine when to halt an agent's trial. To evaluate early-exit
mechanisms, we introduce two metrics: one measures the reduction of
$\textbf{redundant steps}$ as a positive effect, and the other evaluates
$\textbf{progress degradation}$ as a negative effect. Experiments with 4
different LLMs across 5 embodied environments show significant efficiency
improvements, with only minor drops in agent performance. We also validate a
practical strategy where a stronger agent assists after an early-exit agent,
achieving better performance with the same total steps. We will release our
code to support further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large language model as user daily behavior data generator: balancing
  population diversity and individual personality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxin Li, Jingtao Ding, Jiahui Gong, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting human daily behavior is challenging due to the complexity of
routine patterns and short-term fluctuations. While data-driven models have
improved behavior prediction by leveraging empirical data from various
platforms and devices, the reliance on sensitive, large-scale user data raises
privacy concerns and limits data availability. Synthetic data generation has
emerged as a promising solution, though existing methods are often limited to
specific applications. In this work, we introduce BehaviorGen, a framework that
uses large language models (LLMs) to generate high-quality synthetic behavior
data. By simulating user behavior based on profiles and real events,
BehaviorGen supports data augmentation and replacement in behavior prediction
models. We evaluate its performance in scenarios such as pertaining
augmentation, fine-tuning replacement, and fine-tuning augmentation, achieving
significant improvements in human mobility and smartphone usage predictions,
with gains of up to 18.9%. Our results demonstrate the potential of BehaviorGen
to enhance user behavior modeling through flexible and privacy-preserving
synthetic data generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 7 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask
  Multimodal Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihan Yao, Yushi Hu, Yujie Yi, Bin Han, Shangbin Feng, Guang Yang, Bingbing Wen, Ranjay Krishna, Lucy Lu Wang, Yulia Tsvetkov, Noah A. Smith, Banghua Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatically evaluating multimodal generation presents a significant
challenge, as automated metrics often struggle to align reliably with human
evaluation, especially for complex tasks that involve multiple modalities. To
address this, we present MMMG, a comprehensive and human-aligned benchmark for
multimodal generation across 4 modality combinations (image, audio, interleaved
text and image, interleaved text and audio), with a focus on tasks that present
significant challenges for generation models, while still enabling reliable
automatic evaluation through a combination of models and programs. MMMG
encompasses 49 tasks (including 29 newly developed ones), each with a carefully
designed evaluation pipeline, and 937 instructions to systematically assess
reasoning, controllability, and other key capabilities of multimodal generation
models. Extensive validation demonstrates that MMMG is highly aligned with
human evaluation, achieving an average agreement of 94.3%. Benchmarking results
on 24 multimodal generation models reveal that even though the state-of-the-art
model, GPT Image, achieves 78.3% accuracy for image generation, it falls short
on multimodal reasoning and interleaved generation. Furthermore, results
suggest considerable headroom for improvement in audio generation, highlighting
an important direction for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distilling LLM Agent into Small Models with Retrieval and Code Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17612v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17612v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minki Kang, Jongwon Jeong, Seanie Lee, Jaewoong Cho, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) excel at complex reasoning tasks but remain
computationally expensive, limiting their practical deployment. To address
this, recent works have focused on distilling reasoning capabilities into
smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher
LLMs. However, this approach struggles in scenarios requiring rare factual
knowledge or precise computation, where sLMs often hallucinate due to limited
capability. In this work, we propose Agent Distillation, a framework for
transferring not only reasoning capability but full task-solving behavior from
LLM-based agents into sLMs with retrieval and code tools. We improve agent
distillation along two complementary axes: (1) we introduce a prompting method
called first-thought prefix to enhance the quality of teacher-generated
trajectories; and (2) we propose a self-consistent action generation for
improving test-time robustness of small agents. We evaluate our method on eight
reasoning tasks across factual and mathematical domains, covering both
in-domain and out-of-domain generalization. Our results show that sLMs as small
as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier
larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the
potential of agent distillation for building practical, tool-using small
agents. Our code is available at https://github.com/Nardien/agent-distillation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, v1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Controlled Agentic Planning & Reasoning for Mechanism Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17607v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17607v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        João Pedro Gandarela, Thiago Rios, Stefan Menzel, André Freitas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents a dual-agent Large Language Model (LLM)-based reasoning
method for mechanism synthesis, capable of reasoning at both linguistic and
symbolic levels to generate geometrical and dynamic outcomes. The model
consists of a composition of well-defined functions that, starting from a
natural language specification, references abstract properties through
supporting equations, generates and parametrizes simulation code, and elicits
feedback anchor points using symbolic regression and distance functions. This
process closes an actionable refinement loop at the linguistic and symbolic
layers. The approach is shown to be both effective and convergent in the
context of planar mechanisms. Additionally, we introduce MSynth, a novel
benchmark for planar mechanism synthesis, and perform a comprehensive analysis
of the impact of the model components. We further demonstrate that symbolic
regression prompts unlock mechanistic insights only when applied to
sufficiently large architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based
  Backdoor Attacks for Jailbreaking Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Kong, Hao Fang, Xiaochen Yang, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Supervised fine-tuning (SFT) aligns large language models (LLMs) with human
intent by training them on labeled task-specific data. Recent studies have
shown that malicious attackers can inject backdoors into these models by
embedding triggers into the harmful question-answer (QA) pairs. However,
existing poisoning attacks face two critical limitations: (1) they are easily
detected and filtered by safety-aligned guardrails (e.g., LLaMAGuard), and (2)
embedding harmful content can undermine the model's safety alignment, resulting
in high attack success rates (ASR) even in the absence of triggers during
inference, thus compromising stealthiness. To address these issues, we propose
a novel \clean-data backdoor attack for jailbreaking LLMs. Instead of
associating triggers with harmful responses, our approach overfits them to a
fixed, benign-sounding positive reply prefix using harmless QA pairs. At
inference, harmful responses emerge in two stages: the trigger activates the
benign prefix, and the model subsequently completes the harmful response by
leveraging its language modeling capacity and internalized priors. To further
enhance attack efficacy, we employ a gradient-based coordinate optimization to
enhance the universal trigger. Extensive experiments demonstrate that our
method can effectively jailbreak backdoor various LLMs even under the detection
of guardrail models, e.g., an ASR of 86.67% and 85% on LLaMA-3-8B and
Qwen-2.5-7B judged by GPT-4o.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Model Transfer to All: On Robust Jailbreak <span class="highlight-title">Prompt</span>s Generation
  against LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linbao Li, Yannan Liu, Daojing He, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety alignment in large language models (LLMs) is increasingly compromised
by jailbreak attacks, which can manipulate these models to generate harmful or
unintended content. Investigating these attacks is crucial for uncovering model
vulnerabilities. However, many existing jailbreak strategies fail to keep pace
with the rapid development of defense mechanisms, such as defensive suffixes,
rendering them ineffective against defended models. To tackle this issue, we
introduce a novel attack method called ArrAttack, specifically designed to
target defended LLMs. ArrAttack automatically generates robust jailbreak
prompts capable of bypassing various defense measures. This capability is
supported by a universal robustness judgment model that, once trained, can
perform robustness evaluation for any target model with a wide variety of
defenses. By leveraging this model, we can rapidly develop a robust jailbreak
prompt generator that efficiently converts malicious input prompts into
effective attacks. Extensive evaluations reveal that ArrAttack significantly
outperforms existing attack strategies, demonstrating strong transferability
across both white-box and black-box models, including GPT-4 and Claude-3. Our
work bridges the gap between jailbreak attacks and defenses, providing a fresh
perspective on generating robust jailbreak prompts. We make the codebase
available at https://github.com/LLBao/ArrAttack.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NeUQI: Near-Optimal Uniform Quantization Parameter Initialization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Lin, Xinyu Hu, Xiaojun Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) achieve impressive performance across domains
but face significant challenges when deployed on consumer-grade GPUs or
personal devices such as laptops, due to high memory consumption and inference
costs. Post-training quantization (PTQ) of LLMs offers a promising solution
that reduces their memory footprint and decoding latency. In practice, PTQ with
uniform quantization representation is favored for its efficiency and ease of
deployment since uniform quantization is widely supported by mainstream
hardware and software libraries. Recent studies on $\geq 2$-bit uniform
quantization have led to noticeable improvements in post-quantization model
performance; however, they primarily focus on quantization methodologies, while
the initialization of quantization parameters is underexplored and still relies
on the suboptimal Min-Max strategies. In this work, we propose NeUQI, a method
devoted to efficiently determining near-optimal initial parameters for uniform
quantization. NeUQI is orthogonal to prior quantization methodologies and can
seamlessly integrate with them. The experiments with the LLaMA and Qwen
families on various tasks demonstrate that our NeUQI consistently outperforms
existing methods. Furthermore, when combined with a lightweight distillation
strategy, NeUQI can achieve superior performance to PV-tuning, a much more
resource-intensive approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reasoning Meets Personalization: Unleashing the Potential of Large
  Reasoning Model for Personalized Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sichun Luo, Guanzhi Deng, Jian Xu, Xiaojie Zhang, Hanxu Hou, Linqi Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalization is a critical task in modern intelligent systems, with
applications spanning diverse domains, including interactions with large
language models (LLMs). Recent advances in reasoning capabilities have
significantly enhanced LLMs, enabling unprecedented performance in tasks such
as mathematics and coding. However, their potential for personalization tasks
remains underexplored.
  In this paper, we present the first systematic evaluation of large reasoning
models (LRMs) for personalization tasks. Surprisingly, despite generating more
tokens, LRMs do not consistently outperform general-purpose LLMs, especially in
retrieval-intensive scenarios where their advantages diminish. Our analysis
identifies three key limitations: divergent thinking, misalignment of response
formats, and ineffective use of retrieved information. To address these
challenges, we propose Reinforced Reasoning for Personalization (\model), a
novel framework that incorporates a hierarchical reasoning thought template to
guide LRMs in generating structured outputs. Additionally, we introduce a
reasoning process intervention method to enforce adherence to designed
reasoning patterns, enhancing alignment. We also propose a cross-referencing
mechanism to ensure consistency. Extensive experiments demonstrate that our
approach significantly outperforms existing techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PPT: A Process-based Preference Learning Framework for Self Improving
  Table Question Answering Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Improving large language models (LLMs) with self-generated data has
demonstrated success in tasks such as mathematical reasoning and code
generation. Yet, no exploration has been made on table question answering
(TQA), where a system answers questions based on tabular data. Addressing this
gap is crucial for TQA, as effective self-improvement can boost performance
without requiring costly or manually annotated data. In this work, we propose
PPT, a Process-based Preference learning framework for TQA. It decomposes
reasoning chains into discrete states, assigns scores to each state, and
samples contrastive steps for preference learning. Experimental results show
that PPT effectively improves TQA models by up to 5% on in-domain datasets and
2.4% on out-of-domain datasets, with only 8,000 preference pairs. Furthermore,
the resulting models achieve competitive results compared to more complex and
larger state-of-the-art TQA systems, while being five times more efficient
during inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Your Paper Being <span class="highlight-title">Review</span>ed by an LLM? Benchmarking AI Text Detection
  in Peer <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sungduk Yu, Man Luo, Avinash Madusu, Vasudev Lal, Phillip Howard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Peer review is a critical process for ensuring the integrity of published
scientific research. Confidence in this process is predicated on the assumption
that experts in the relevant domain give careful consideration to the merits of
manuscripts which are submitted for publication. With the recent rapid
advancements in large language models (LLMs), a new risk to the peer review
process is that negligent reviewers will rely on LLMs to perform the often time
consuming process of reviewing a paper. However, there is a lack of existing
resources for benchmarking the detectability of AI text in the domain of peer
review. To address this deficiency, we introduce a comprehensive dataset
containing a total of 788,984 AI-written peer reviews paired with corresponding
human reviews, covering 8 years of papers submitted to each of two leading AI
research conferences (ICLR and NeurIPS). We use this new resource to evaluate
the ability of 18 existing AI text detection algorithms to distinguish between
peer reviews fully written by humans and different state-of-the-art LLMs.
Additionally, we explore a context-aware detection method called Anchor, which
leverages manuscript content to detect AI-generated reviews, and analyze the
sensitivity of detection models to LLM-assisted editing of human-written text.
Our work reveals the difficulty of identifying AI-generated text at the
individual peer review level, highlighting the urgent need for new tools and
methods to detect this unethical use of generative AI. Our dataset is publicly
available at:
https://huggingface.co/datasets/IntelLabs/AI-Peer-Review-Detection-Benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HausaNLP: Current Status, Challenges and Future Directions for Hausa
  Natural Language Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14311v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14311v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shamsuddeen Hassan Muhammad, Ibrahim Said Ahmad, Idris Abdulmumin, Falalu Ibrahim Lawan, Babangida Sani, Sukairaj Hafiz Imam, Yusuf Aliyu, Sani Abdullahi Sani, Ali Usman Umar, Tajuddeen Gwadabe, Kenneth Church, Vukosi Marivate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hausa Natural Language Processing (NLP) has gained increasing attention in
recent years, yet remains understudied as a low-resource language despite
having over 120 million first-language (L1) and 80 million second-language (L2)
speakers worldwide. While significant advances have been made in high-resource
languages, Hausa NLP faces persistent challenges, including limited open-source
datasets and inadequate model representation. This paper presents an overview
of the current state of Hausa NLP, systematically examining existing resources,
research contributions, and gaps across fundamental NLP tasks: text
classification, machine translation, named entity recognition, speech
recognition, and question answering. We introduce HausaNLP
(https://catalog.hausanlp.org), a curated catalog that aggregates datasets,
tools, and research works to enhance accessibility and drive further
development. Furthermore, we discuss challenges in integrating Hausa into large
language models (LLMs), addressing issues of suboptimal tokenization and
dialectal variation. Finally, we propose strategic research directions
emphasizing dataset expansion, improved language modeling approaches, and
strengthened community collaboration to advance Hausa NLP. Our work provides
both a foundation for accelerating Hausa NLP progress and valuable insights for
broader multilingual NLP research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hogwild! Inference: Parallel LLM Generation via Concurrent Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.06261v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.06261v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gleb Rodionov, Roman Garipov, Alina Shutova, George Yakushev, Erik Schultheis, Vage Egiazarian, Anton Sinitsin, Denis Kuznedelev, Dan Alistarh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated the ability to tackle
increasingly complex tasks through advanced reasoning, long-form content
generation, and tool use. Solving these tasks often involves long
inference-time computations. In human problem solving, a common strategy to
expedite work is collaboration: by dividing the problem into sub-tasks,
exploring different strategies concurrently, etc. Recent research has shown
that LLMs can also operate in parallel by implementing explicit cooperation
frameworks, such as voting mechanisms or the explicit creation of independent
sub-tasks that can be executed in parallel. However, each of these frameworks
may not be suitable for all types of tasks, which can hinder their
applicability. In this work, we propose a different design approach: we run LLM
"workers" in parallel , allowing them to synchronize via a concurrently-updated
attention cache and prompt these workers to decide how best to collaborate. Our
approach allows the LLM instances to come up with their own collaboration
strategy for the problem at hand, all the while "seeing" each other's memory in
the concurrent KV cache. We implement this approach via Hogwild! Inference: a
parallel LLM inference engine where multiple instances of the same LLM run in
parallel with the same attention cache, with "instant" access to each other's
memory. Hogwild! Inference takes advantage of Rotary Position Embeddings (RoPE)
to avoid recomputation while improving parallel hardware utilization. We find
that modern reasoning-capable LLMs can perform inference with shared Key-Value
cache out of the box, without additional fine-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Lists to Emojis: How Format Bias Affects Model Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11704v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11704v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study format biases in reinforcement learning from human
feedback (RLHF). We observe that many widely-used preference models, including
human evaluators, GPT-4, and top-ranking models on the RewardBench benchmark,
exhibit strong biases towards specific format patterns, such as lists, links,
bold text, and emojis. Furthermore, large language models (LLMs) can exploit
these biases to achieve higher rankings on popular benchmarks like AlpacaEval
and LMSYS Chatbot Arena. One notable example of this is verbosity bias, where
current preference models favor longer responses that appear more
comprehensive, even when their quality is equal to or lower than shorter,
competing responses. However, format biases beyond verbosity remain largely
underexplored in the literature. In this work, we extend the study of biases in
preference learning beyond the commonly recognized length bias, offering a
comprehensive analysis of a wider range of format biases. Additionally, we show
that with a small amount of biased data (less than 1%), we can inject
significant bias into the reward model. Moreover, these format biases can also
be easily exploited by downstream alignment algorithms, such as best-of-n
sampling and online iterative DPO, as it is usually easier to manipulate the
format than to improve the quality of responses. Our findings emphasize the
need to disentangle format and content both for designing alignment algorithms
and evaluating models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in
  Post-Training <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Feuer, Chinmay Hegde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model (LLM) post-training, from DPO to distillation, can refine
behaviors and unlock new skills, but the open science supporting these
post-training techniques is still in its infancy. One limiting factor has been
the difficulty of conducting large-scale comparative analyses of synthetic data
generating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,
the largest public chat dataset to date. We extend the existing WildChat
dataset to include responses not only from GPT, but from over 50 different
open-weight models, ranging in size from 0.5B to 104B parameters. We conduct an
extensive comparative analysis and demonstrate the potential of this dataset by
creating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3
SFT mixture from Allen AI with only 40% as many samples. Our dataset, samples
and code are available at https://github.com/penfever/wildchat-50m.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing
  in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16023v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16023v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheshera Mysore, Debarati Das, Hancheng Cao, Bahareh Sarrafzadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) are used in complex writing workflows, users
engage in multi-turn interactions to steer generations to better fit their
needs. Rather than passively accepting output, users actively refine, explore,
and co-construct text. We conduct a large-scale analysis of this collaborative
behavior for users engaged in writing tasks in the wild with two popular AI
assistants, Bing Copilot and WildChat. Our analysis goes beyond simple task
classification or satisfaction estimation common in prior work and instead
characterizes how users interact with LLMs through the course of a session. We
identify prototypical behaviors in how users interact with LLMs in prompts
following their original request. We refer to these as Prototypical Human-AI
Collaboration Behaviors (PATHs) and find that a small group of PATHs explain a
majority of the variation seen in user-LLM interaction. These PATHs span users
revising intents, exploring texts, posing questions, adjusting style or
injecting new content. Next, we find statistically significant correlations
between specific writing intents and PATHs, revealing how users' intents shape
their collaboration behaviors. We conclude by discussing the implications of
our findings on LLM alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print under-review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KCIF: Knowledge-Conditioned Instruction Following 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12972v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12972v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rudra Murthy, Praveen Venkateswaran, Prince Kumar, Danish Contractor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM evaluation benchmarks have traditionally separated the testing of
knowledge/reasoning capabilities from instruction following. In this work, we
study the interaction between knowledge and instruction following, and observe
that LLMs struggle to follow simple answer modifying instructions, and are also
distracted by instructions that should have no bearing on the original
knowledge task answer. We leverage existing multiple-choice answer based
knowledge benchmarks and apply a set of simple instructions which include
manipulating text (eg.: change case), numeric quantities (eg.: increase value,
change formatting), operate on lists (eg.: sort answer candidates) and
distractor instructions (eg.: change case of numeric answers). We evaluate
models at varying parameter sizes (1B-405B) from different model families and
find that, surprisingly, all models report a significant drop in performance on
such simple task compositions. While large-sized and frontier models report
performance drops of 40-50%, in small and medium sized models the drop is
severe (sometimes exceeding 80%). Our results highlight a limitation in the
traditional separation of knowledge/reasoning and instruction following, and
suggest that joint-study of these capabilities are important. We release our
benchmark dataset, evaluation framework code, and results for future work.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Compositional Causal Reasoning Evaluation in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04556v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04556v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal reasoning and compositional reasoning are two core aspirations in AI.
Measuring the extent of these behaviors requires principled evaluation methods.
We explore a unified perspective that considers both behaviors simultaneously,
termed compositional causal reasoning (CCR): the ability to infer how causal
measures compose and, equivalently, how causal quantities propagate through
graphs. We instantiate a framework for the systematic evaluation of CCR for the
average treatment effect and the probability of necessity and sufficiency. As
proof of concept, we demonstrate CCR evaluation for language models in the
LLama, Phi, and GPT families. On a math word problem, our framework revealed a
range of taxonomically distinct error patterns. CCR errors increased with the
complexity of causal paths for all models except o1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Playpen: An Environment for Exploring Learning Through Conversational
  Interaction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08590v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08590v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Horst, Davide Mazzaccara, Antonia Schmidt, Michael Sullivan, Filippo Momentè, Luca Franceschetti, Philipp Sadler, Sherzod Hakimov, Alberto Testoni, Raffaella Bernardi, Raquel Fernández, Alexander Koller, Oliver Lemon, David Schlangen, Mario Giulianelli, Alessandro Suglia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interaction between learner and feedback-giver has come into focus recently
for post-training of Large Language Models (LLMs), through the use of reward
models that judge the appropriateness of a model's response. In this paper, we
investigate whether Dialogue Games -- goal-directed and rule-governed
activities driven predominantly by verbal actions -- can also serve as a source
of feedback signals for learning. We introduce Playpen, an environment for off-
and online learning through Dialogue Game self-play, and investigate a
representative set of post-training methods: supervised fine-tuning; direct
alignment (DPO); and reinforcement learning with GRPO. We experiment with
post-training a small LLM (Llama-3.1-8B-Instruct), evaluating performance on
unseen instances of training games as well as unseen games, and on standard
benchmarks. We find that imitation learning through SFT improves performance on
unseen instances, but negatively impacts other skills, while interactive
learning with GRPO shows balanced improvements without loss of skills. We
release the framework and the baseline training setups to foster research in
the promising new direction of learning in (synthetic) interaction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Source code: https://github.com/lm-playpen/playpen Please send
  correspodence to: lm-playschool@googlegroups.com</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Copyright Protection for Knowledge Bases of Retrieval-augmented
  Language Models via Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.10440v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.10440v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly integrated into real-world
personalized applications through retrieval-augmented generation (RAG)
mechanisms to supplement their responses with domain-specific knowledge.
However, the valuable and often proprietary nature of the knowledge bases used
in RAG introduces the risk of unauthorized usage by adversaries. Existing
methods that can be generalized as watermarking techniques to protect these
knowledge bases typically involve poisoning or backdoor attacks. However, these
methods require altering the LLM's results of verification samples, inevitably
making these watermarks susceptible to anomaly detection and even introducing
new security risks. To address these challenges, we propose \name{} for
`harmless' copyright protection of knowledge bases. Instead of manipulating
LLM's final output, \name{} implants distinct yet benign verification behaviors
in the space of chain-of-thought (CoT) reasoning, maintaining the correctness
of the final answer. Our method has three main stages: (1) Generating CoTs: For
each verification question, we generate two `innocent' CoTs, including a target
CoT for building watermark behaviors; (2) Optimizing Watermark Phrases and
Target CoTs: Inspired by our theoretical analysis, we optimize them to minimize
retrieval errors under the \emph{black-box} and \emph{text-only} setting of
suspicious LLM, ensuring that only watermarked verification queries can
retrieve their correspondingly target CoTs contained in the knowledge base; (3)
Ownership Verification: We exploit a pairwise Wilcoxon test to verify whether a
suspicious LLM is augmented with the protected knowledge base by comparing its
responses to watermarked and benign verification queries. Our experiments on
diverse benchmarks demonstrate that \name{} effectively protects knowledge
bases and its resistance to adaptive attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally to this work. 25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HICD: Hallucination-Inducing via Attention Dispersion for Contrastive
  Decoding to Mitigate Hallucinations in Large Language Models <span class="chip">ACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.12908v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.12908v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) often generate hallucinations, producing outputs
that are contextually inaccurate or factually incorrect. We introduce HICD, a
novel method designed to induce hallucinations for contrastive decoding to
mitigate hallucinations. Unlike existing contrastive decoding methods, HICD
selects attention heads crucial to the model's prediction as inducing heads,
then induces hallucinations by dispersing attention of these inducing heads and
compares the hallucinated outputs with the original outputs to obtain the final
result. Our approach significantly improves performance on tasks requiring
contextual faithfulness, such as context completion, reading comprehension, and
question answering. It also improves factuality in tasks requiring accurate
knowledge recall. We demonstrate that our inducing heads selection and
attention dispersion method leads to more "contrast-effective" hallucinations
for contrastive decoding, outperforming other hallucination-inducing methods.
Our findings provide a promising strategy for reducing hallucinations by
inducing hallucinations in a controlled manner, enhancing the performance of
LLMs in a wide range of tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL2025 findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TrendFact: A Benchmark for Explainable Hotspot Perception in
  Fact-Checking with Natural Language Explanation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.15135v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.15135v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaocheng Zhang, Xi Wang, Yifei Lu, Jianing Wang, Zhuangzhuang Ye, Mengjiao Bao, Peng Yan, Xiaohong Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although fact verification remains fundamental, explanation generation serves
as a critical enabler for trustworthy fact-checking systems by producing
interpretable rationales and facilitating comprehensive verification processes.
However, current benchmarks have limitations that include the lack of impact
assessment, insufficient high-quality explanatory annotations, and an
English-centric bias. To address these, we introduce TrendFact, the first
hotspot perception fact-checking benchmark that comprehensively evaluates fact
verification, evidence retrieval, and explanation generation tasks. TrendFact
consists of 7,643 carefully curated samples sourced from trending platforms and
professional fact-checking datasets, as well as an evidence library of 66,217
entries with publication dates. We further propose two metrics, ECS and HCPI,
to complement existing benchmarks by evaluating the system's explanation
consistency and hotspot perception capability, respectively. Experimental
results show that current fact-checking systems, including advanced RLMs such
as DeepSeek-R1, face significant limitations when evaluated on TrendFact,
highlighting the real-world challenges posed by it. To enhance the
fact-checking capabilities of reasoning large language models (RLMs), we
propose FactISR, which integrates dynamic evidence augmentation, evidence
triangulation, and an iterative self-reflection mechanism. Accordingly, FactISR
effectively improves RLM performance, offering new insights for explainable and
complex fact-checking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The AI Gap: How Socioeconomic Status Affects Language Technology
  Interactions <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Socioeconomic status (SES) fundamentally influences how people interact with
each other and more recently, with digital technologies like Large Language
Models (LLMs). While previous research has highlighted the interaction between
SES and language technology, it was limited by reliance on proxy metrics and
synthetic data. We survey 1,000 individuals from diverse socioeconomic
backgrounds about their use of language technologies and generative AI, and
collect 6,482 prompts from their previous interactions with LLMs. We find
systematic differences across SES groups in language technology usage (i.e.,
frequency, performed tasks), interaction styles, and topics. Higher SES entails
a higher level of abstraction, convey requests more concisely, and topics like
'inclusivity' and 'travel'. Lower SES correlates with higher
anthropomorphization of LLMs (using ''hello'' and ''thank you'') and more
concrete language. Our findings suggest that while generative language
technologies are becoming more accessible to everyone, socioeconomic linguistic
differences still stratify their use to exacerbate the digital divide. These
differences underscore the importance of considering SES in developing language
technologies to accommodate varying linguistic needs rooted in socioeconomic
factors and limit the AI Gap across SES groups.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACL Main 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual
  Program Generation <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16529v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16529v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual programming languages (VPLs) allow users to create programs through
graphical interfaces, which results in easier accessibility and their
widespread usage in various domains. To further enhance this accessibility,
recent research has focused on generating VPL code from user instructions using
large language models (LLMs). Specifically, by employing prompting-based
methods, these studies have shown promising results. Nevertheless, such
approaches can be less effective for industrial VPLs such as Ladder Diagram
(LD). LD is a pivotal language used in industrial automation processes and
involves extensive domain-specific configurations, which are difficult to
capture in a single prompt. In this work, we demonstrate that training-based
methods outperform prompting-based methods for LD generation accuracy, even
with smaller backbone models. Building on these findings, we propose a
two-stage training strategy to further enhance VPL generation. First, we employ
retrieval-augmented fine-tuning to leverage the repetitive use of subroutines
commonly seen in industrial VPLs. Second, we apply direct preference
optimization (DPO) to further guide the model toward accurate outputs, using
systematically generated preference pairs through graph editing operations.
Extensive experiments on real-world LD data demonstrate that our approach
improves program-level accuracy by over 10% compared to supervised fine-tuning,
which highlights its potential to advance industrial automation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACL 2025 (Main, long paper)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.11960v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.11960v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Cao, Sikun Yang, Chen Li, Haolong Xiang, Lianyong Qi, Bo Liu, Rongsheng Li, Ming Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text anomaly detection is crucial for identifying spam, misinformation, and
offensive language in natural language processing tasks. Despite the growing
adoption of embedding-based methods, their effectiveness and generalizability
across diverse application scenarios remain under-explored. To address this, we
present TAD-Bench, a comprehensive benchmark designed to systematically
evaluate embedding-based approaches for text anomaly detection. TAD-Bench
integrates multiple datasets spanning different domains, combining
state-of-the-art embeddings from large language models with a variety of
anomaly detection algorithms. Through extensive experiments, we analyze the
interplay between embeddings and detection methods, uncovering their strengths,
weaknesses, and applicability to different tasks. These findings offer new
perspectives on building more robust, efficient, and generalizable anomaly
detection systems for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Table-Critic: A Multi-Agent Framework for Collaborative Criticism and
  Refinement in Table Reasoning <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11799v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11799v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peiying Yu, Guoxin Chen, Jingjing Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable capabilities of large language models (LLMs) in
various reasoning tasks, they still struggle with table reasoning tasks,
particularly in maintaining consistency throughout multi-step reasoning
processes. While existing approaches have explored various decomposition
strategies, they often lack effective mechanisms to identify and correct errors
in intermediate reasoning steps, leading to cascading error propagation. To
address these issues, we propose Table-Critic, a novel multi-agent framework
that facilitates collaborative criticism and iterative refinement of the
reasoning process until convergence to correct solutions. Our framework
consists of four specialized agents: a Judge for error identification, a Critic
for comprehensive critiques, a Refiner for process improvement, and a Curator
for pattern distillation. To effectively deal with diverse and unpredictable
error types, we introduce a self-evolving template tree that systematically
accumulates critique knowledge through experience-driven learning and guides
future reflections. Extensive experiments have demonstrated that Table-Critic
achieves substantial improvements over existing methods, achieving superior
accuracy and error correction rates while maintaining computational efficiency
and lower solution degradation rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17900v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17900v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent success in applying large language models (LLMs) to electronic
health records (EHR), most systems focus primarily on assessment rather than
treatment planning. We identify three critical limitations in current
approaches: they generate treatment plans in a single pass rather than
following the sequential reasoning process used by clinicians; they rarely
incorporate patient-specific historical context; and they fail to effectively
distinguish between subjective and objective clinical information. Motivated by
the SOAP methodology (Subjective, Objective, Assessment, Plan), we introduce
\ours{}, a novel framework that structures LLM reasoning to align with
real-life clinician workflows. Our approach employs a two-stage architecture
that first generates a clinical assessment based on patient symptoms and
objective data, then formulates a structured treatment plan informed by this
assessment and enriched with patient-specific information through
retrieval-augmented generation. Comprehensive evaluation demonstrates that our
method significantly outperforms baseline approaches in both assessment
accuracy and treatment plan quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual
  Knowledge Synchronization in LLMs <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14645v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14645v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge editing allows for efficient adaptation of large language models
(LLMs) to new information or corrections without requiring full retraining.
However, prior methods typically focus on either single-language editing or
basic multilingual editing, failing to achieve true cross-linguistic knowledge
synchronization. To address this, we present a simple and practical
state-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE),
designed to propagate knowledge from a dominant language to other languages
effectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition
Instruction Tuning (XE-IT), which fine-tunes the model on a curated parallel
dataset to modify in-scope knowledge while preserving unrelated information,
and (ii) Target-language Preference Optimization (TL-PO), which applies
advanced optimization techniques to ensure consistency across languages,
fostering the transfer of updates. Additionally, we contribute a high-quality,
cross-lingual dataset, specifically designed to enhance knowledge transfer
across languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks
show that X-KDE significantly enhances cross-lingual performance, achieving an
average improvement of +8.19%, while maintaining high accuracy in monolingual
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2025 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-modal Retrieval Augmented Multi-modal Generation: <span class="highlight-title">Dataset</span>s,
  Evaluation Metrics and Strong Baselines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16365v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16365v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Yu-Shi Zhu, Tong Zhang, Heyan Huang, Zhijing Wu, Xian-Ling Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a systematic investigation of Multi-modal Retrieval Augmented
Multi-modal Generation (M$^2$RAG), a novel task that enables foundation models
to process multi-modal web content and generate multi-modal responses, which
exhibits better information density and readability. Despite its potential
impact, M$^2$RAG remains understudied, lacking comprehensive analysis and
high-quality data resources. To address this gap, we establish a comprehensive
benchmark through a rigorous data curation pipeline, and employ text-modal
metrics and multi-modal metrics based on foundation models for evaluation. We
further propose several strategies for foundation models to process M$^2$RAG
task effectively and construct a training set by filtering high-quality samples
using our designed metrics. Our extensive experiments demonstrate the
reliability of our proposed metrics, a landscape of model performance within
our designed strategies, and show that our fine-tuned 7B-8B models outperform
the GPT-4o model and approach the state-of-the-art OpenAI o3-mini.
Additionally, we perform fine-grained analyses across diverse domains and
validate the effectiveness of our designs in data curation pipeline. All
resources, including codes, datasets, and model weights, will be publicly
released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ "Reasoning" with Rhetoric: On the Style-Evidence Tradeoff in
  LLM-Generated Counter-Arguments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08498v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08498v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Preetika Verma, Kokil Jaidka, Svetlana Churina
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) play a key role in generating evidence-based and
stylistic counter-arguments, yet their effectiveness in real-world applications
has been underexplored. Previous research often neglects the balance between
evidentiality and style, which are crucial for persuasive arguments. To address
this, we evaluated the effectiveness of stylized evidence-based
counter-argument generation in Counterfire, a new dataset of 38,000
counter-arguments generated by revising counter-arguments to Reddit's
ChangeMyView community to follow different discursive styles. We evaluated
generic and stylized counter-arguments from basic and fine-tuned models such as
GPT-3.5, PaLM-2, and Koala-13B, as well as newer models (GPT-4o, Claude Haiku,
LLaMA-3.1) focusing on rhetorical quality and persuasiveness. Our findings
reveals that humans prefer stylized counter-arguments over the original
outputs, with GPT-3.5 Turbo performing well, though still not reaching human
standards of rhetorical quality nor persuasiveness indicating a persisting
style-evidence tradeoff in counter-argument generation by LLMs. We conclude
with an examination of ethical considerations in LLM persuasion research,
addressing potential risks of deceptive practices and the need for transparent
deployment methodologies to safeguard against misuse in public discourse. The
code and dataset are available at
https://github.com/Preetika764/Style_control/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 9 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models Share Representations of Latent Grammatical
  Concepts Across Typologically Diverse Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.06346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.06346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jannik Brinkmann, Chris Wendler, Christian Bartelt, Aaron Mueller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human bilinguals often use similar brain regions to process multiple
languages, depending on when they learned their second language and their
proficiency. In large language models (LLMs), how are multiple languages
learned and encoded? In this work, we explore the extent to which LLMs share
representations of morphsyntactic concepts such as grammatical number, gender,
and tense across languages. We train sparse autoencoders on Llama-3-8B and
Aya-23-8B, and demonstrate that abstract grammatical concepts are often encoded
in feature directions shared across many languages. We use causal interventions
to verify the multilingual nature of these representations; specifically, we
show that ablating only multilingual features decreases classifier performance
to near-chance across languages. We then use these features to precisely modify
model behavior in a machine translation task; this demonstrates both the
generality and selectivity of these feature's roles in the network. Our
findings suggest that even models trained predominantly on English data can
develop robust, cross-lingual abstractions of morphosyntactic concepts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ActiveLLM: Large Language Model-based Active Learning for Textual
  Few-Shot Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.10808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.10808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Markus Bayer, Justin Lutz, Christian Reuter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Active learning is designed to minimize annotation efforts by prioritizing
instances that most enhance learning. However, many active learning strategies
struggle with a `cold-start' problem, needing substantial initial data to be
effective. This limitation reduces their utility in the increasingly relevant
few-shot scenarios, where the instance selection has a substantial impact. To
address this, we introduce ActiveLLM, a novel active learning approach that
leverages Large Language Models such as GPT-4, o1, Llama 3, or Mistral Large
for selecting instances. We demonstrate that ActiveLLM significantly enhances
the classification performance of BERT classifiers in few-shot scenarios,
outperforming traditional active learning methods as well as improving the
few-shot learning methods ADAPET, PERFECT, and SetFit. Additionally, ActiveLLM
can be extended to non-few-shot scenarios, allowing for iterative selections.
In this way, ActiveLLM can even help other active learning strategies to
overcome their cold-start problem. Our results suggest that ActiveLLM offers a
promising solution for improving model performance across various learning
setups.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 10 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLäMmlein: Compact and Competitive German-Only Language Models from
  Scratch 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11171v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11171v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Pfister, Julia Wunderle, Andreas Hotho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We create two German-only decoder models, LL\"aMmlein 120M and 1B,
transparently from scratch and publish them, along with the training data, for
the German NLP research community to use. The model training involved several
key steps, including extensive data preprocessing, the creation of a custom
German tokenizer, the training itself, as well as the evaluation of the final
models on various benchmarks. Throughout the training process, multiple
checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor
the models' learning dynamics. Compared to state-of-the-art models on the
SuperGLEBer benchmark, both LL\"aMmlein models performed competitively,
consistently matching or surpassing models with similar parameter sizes. The
results show that the models' quality scales with size as expected, but
performance improvements on some tasks plateaued early, offering valuable
insights into resource allocation for future model development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>camera ready;
  https://www.informatik.uni-wuerzburg.de/datascience/projects/nlp/llammlein/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GRADIEND: Monosemantic Feature Learning within Neural Networks Applied
  to Gender Debiasing of <span class="highlight-title">Transformer</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.01406v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.01406v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Drechsel, Steffen Herbold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI systems frequently exhibit and amplify social biases, including gender
bias, leading to harmful consequences in critical areas. This study introduces
a novel encoder-decoder approach that leverages model gradients to learn a
single monosemantic feature neuron encoding gender information. We show that
our method can be used to debias transformer-based language models, while
maintaining other capabilities. We demonstrate the effectiveness of our
approach across various model architectures and highlight its potential for
broader applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VeriFastScore: Speeding up long-form factuality evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16973v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16973v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rishanth Rajendhran, Amir Zadeh, Matthew Sarte, Chuan Li, Mohit Iyyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Metrics like FactScore and VeriScore that evaluate long-form factuality
operate by decomposing an input response into atomic claims and then
individually verifying each claim. While effective and interpretable, these
methods incur numerous LLM calls and can take upwards of 100 seconds to
evaluate a single response, limiting their practicality in large-scale
evaluation and training scenarios. To address this, we propose VeriFastScore,
which leverages synthetic data to fine-tune Llama3.1 8B for simultaneously
extracting and verifying all verifiable claims within a given text based on
evidence from Google Search. We show that this task cannot be solved via
few-shot prompting with closed LLMs due to its complexity: the model receives
~4K tokens of evidence on average and needs to concurrently decompose claims,
judge their verifiability, and verify them against noisy evidence. However, our
fine-tuned VeriFastScore model demonstrates strong correlation with the
original VeriScore pipeline at both the example level (r=0.80) and system level
(r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence
retrieval) over VeriScore. To facilitate future factuality research, we
publicly release our VeriFastScore model and synthetic datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Human-Like Text Liked by Humans? Multilingual Human Detection and
  Preference Against AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxia Wang, Rui Xing, Jonibek Mansurov, Giovanni Puccetti, Zhuohan Xie, Minh Ngoc Ta, Jiahui Geng, Jinyan Su, Mervat Abassy, Saad El Dine Ahmed, Kareem Elozeiri, Nurkhan Laiyk, Maiya Goloburda, Tarek Mahmoud, Raj Vardhan Tomar, Alexander Aziz, Ryuto Koike, Masahiro Kaneko, Artem Shelmanov, Ekaterina Artemova, Vladislav Mikhailov, Akim Tsvigun, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior studies have shown that distinguishing text generated by large language
models (LLMs) from human-written one is highly challenging, and often no better
than random guessing. To verify the generalizability of this finding across
languages and domains, we perform an extensive case study to identify the upper
bound of human detection accuracy. Across 16 datasets covering 9 languages and
9 domains, 19 annotators achieved an average detection accuracy of 87.6\%, thus
challenging previous conclusions. We find that major gaps between human and
machine text lie in concreteness, cultural nuances, and diversity. Prompting by
explicitly explaining the distinctions in the prompts can partially bridge the
gaps in over 50\% of the cases. However, we also find that humans do not always
prefer human-written text, particularly when they cannot clearly identify its
source.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Triangulating LLM Progress through Benchmarks, Games, and Cognitive
  Tests 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14359v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14359v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Filippo Momentè, Alessandro Suglia, Mario Giulianelli, Ambra Ferrari, Alexander Koller, Oliver Lemon, David Schlangen, Raquel Fernández, Raffaella Bernardi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We examine three evaluation paradigms: standard benchmarks (e.g., MMLU and
BBH), interactive games (e.g., Signalling Games or Taboo), and cognitive tests
(e.g., for working memory or theory of mind). First, we investigate which of
the former two-benchmarks or games-is most effective at discriminating LLMs of
varying quality. Then, inspired by human cognitive assessments, we compile a
suite of targeted tests that measure cognitive abilities deemed essential for
effective language use, and we investigate their correlation with model
performance in benchmarks and games. Our analyses reveal that interactive games
are superior to standard benchmarks in discriminating models. Causal and
logical reasoning correlate with both static and interactive tests, while
differences emerge regarding core executive functions and social/emotional
skills, which correlate more with games. We advocate for the development of new
interactive benchmarks and targeted cognitive tasks inspired by assessing human
abilities but designed specifically for LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-lingual Human-Preference Alignment for Neural Machine Translation
  with Direct Quality Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17673v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17673v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaden Uhlig, Joern Wuebker, Raphael Reinauer, John DeNero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from Human Feedback (RLHF) and derivative techniques
like Direct Preference Optimization (DPO) are task-alignment algorithms used to
repurpose general, foundational models for specific tasks. We show that
applying task-alignment to neural machine translation (NMT) addresses an
existing task--data mismatch in NMT, leading to improvements across all
languages of a multilingual model, even when task-alignment is only applied to
a subset of those languages. We do so by introducing Direct Quality
Optimization (DQO), a variant of DPO leveraging a pre-trained translation
quality estimation model as a proxy for human preferences, and verify the
improvements with both automatic metrics and human evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ThinkLess: A Training-Free Inference-Efficient Method for Reducing
  Reasoning Redundancy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15684v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15684v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gengyang Li, Yifeng Gao, Yuming Li, Yunfang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Chain-of-Thought (CoT) prompting improves reasoning in large language
models (LLMs), the excessive length of reasoning tokens increases latency and
KV cache memory usage, and may even truncate final answers under context
limits. We propose ThinkLess, an inference-efficient framework that terminates
reasoning generation early and maintains output quality without modifying the
model. Atttention analysis reveals that answer tokens focus minimally on
earlier reasoning steps and primarily attend to the reasoning terminator token,
due to information migration under causal masking. Building on this insight,
ThinkLess inserts the terminator token at earlier positions to skip redundant
reasoning while preserving the underlying knowledge transfer. To prevent format
discruption casued by early termination, ThinkLess employs a lightweight
post-regulation mechanism, relying on the model's natural instruction-following
ability to produce well-structured answers. Without fine-tuning or auxiliary
data, ThinkLess achieves comparable accuracy to full-length CoT decoding while
greatly reducing decoding time and memory consumption.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ None of the Others: a General Technique to Distinguish Reasoning from
  Memorization in Multiple-Choice LLM Evaluation Benchmarks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12896v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12896v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eva Sánchez Salido, Julio Gonzalo, Guillermo Marco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In LLM evaluations, reasoning is often distinguished from recall/memorization
by performing numerical variations to math-oriented questions. Here we
introduce a general variation method for multiple-choice questions that
completely dissociates the correct answer from previously seen tokens or
concepts, requiring LLMs to understand and reason (rather than memorizing) in
order to answer correctly. Using this method, we evaluate state-of-the-art
proprietary and open-source LLMs on two datasets available in English and
Spanish: the public MMLU benchmark and the private UNED-Access 2024 dataset.
Results show that all models experience remarkable accuracy drops under our
proposed variation, with an average loss of 57% on MMLU and 50% on UNED-Access
2024, ranging from 10% to 93% across models. Notably, the most accurate model
in our experimentation (OpenAI-o3-mini) is not the most robust
(DeepSeek-R1-70B), suggesting that the best models in standard evaluations may
not be the ones with better reasoning capabilities. Also, we see larger
accuracy drops in public (vs private) datasets and questions posed in their
original language (vs a manual translation), which are signs of contamination
and also point to a relevant role of recall/memorization in current LLMs'
answers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Power-Law Decay Loss for Large Language Model Finetuning: Focusing on
  Information Sparsity to Enhance Generation Quality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16900v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16900v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Shao, Yiming Cheng, Hongyi Huang, Jiayi Wu, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  During the finetuning stage of text generation tasks, standard cross-entropy
loss treats all tokens equally. This can lead models to overemphasize
high-frequency, low-information tokens, neglecting lower-frequency tokens
crucial for specificity and informativeness in generated content. This paper
introduces a novel loss function, Power-Law Decay Loss (PDL), specifically
designed to optimize the finetuning process for text generation. The core
motivation for PDL stems from observations in information theory and
linguistics: the informativeness of a token is often inversely proportional to
its frequency of occurrence. PDL re-weights the contribution of each token in
the standard cross-entropy loss based on its frequency in the training corpus,
following a power-law decay. Specifically, the weights for high-frequency
tokens are reduced, while low-frequency, information-dense tokens are assigned
higher weights. This mechanism guides the model during finetuning to focus more
on learning and generating tokens that convey specific and unique information,
thereby enhancing the quality, diversity, and informativeness of the generated
text. We theoretically elaborate on the motivation and construction of PDL and
discuss its potential applications and advantages across various text
generation finetuning tasks, such as abstractive summarization, dialogue
systems, and style transfer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Retrieval-Based Approach to Medical Procedure Matching in Romanian <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.20556v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.20556v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrei Niculae, Adrian Cosma, Emilian Radoi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately mapping medical procedure names from healthcare providers to
standardized terminology used by insurance companies is a crucial yet complex
task. Inconsistencies in naming conventions lead to missclasified procedures,
causing administrative inefficiencies and insurance claim problems in private
healthcare settings. Many companies still use human resources for manual
mapping, while there is a clear opportunity for automation. This paper proposes
a retrieval-based architecture leveraging sentence embeddings for medical name
matching in the Romanian healthcare system. This challenge is significantly
more difficult in underrepresented languages such as Romanian, where existing
pretrained language models lack domain-specific adaptation to medical text. We
evaluate multiple embedding models, including Romanian, multilingual, and
medical-domain-specific representations, to identify the most effective
solution for this task. Our findings contribute to the broader field of medical
NLP for low-resource languages such as Romanian.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at BIONLP 2025 and Shared Tasks, ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Low-Resource Language and Instruction Following Capabilities
  of Audio Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10999v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10999v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Potsawee Manakul, Guangzhi Sun, Warit Sirichotedumrong, Kasima Tharnpipitchai, Kunat Pipatanakul
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio language models process audio inputs using textual prompts for tasks
like speech recognition and audio captioning. Although built on multilingual
pre-trained components, most are trained primarily on English, limiting their
usability for other languages. This paper evaluates audio language models on
Thai, a low-resource language, and finds that they lack emergent cross-lingual
abilities despite their multilingual foundations. To address this, we explore
data mixtures that optimize audio language models for both a target language
and English while integrating audio comprehension and speech
instruction-following into a unified model. Our experiments provide insights
into improving instruction-following in low-resource languages by balancing
language-specific and multilingual training data. The proposed model,
Typhoon-Audio, significantly outperforms existing open-source models and
achieves performance comparable to state-of-the-art Gemini-1.5-Pro in both
English and Thai.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Interspeech 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Quantum LLM: Modeling Semantic Spaces with Quantum Principles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13202v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13202v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timo Aukusti Laine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the previous article, we presented a quantum-inspired framework for
modeling semantic representation and processing in Large Language Models
(LLMs), drawing upon mathematical tools and conceptual analogies from quantum
mechanics to offer a new perspective on these complex systems. In this paper,
we clarify the core assumptions of this model, providing a detailed exposition
of six key principles that govern semantic representation, interaction, and
dynamics within LLMs. The goal is to justify that a quantum-inspired framework
is a valid approach to studying semantic spaces. This framework offers valuable
insights into their information processing and response generation, and we
further discuss the potential of leveraging quantum computing to develop
significantly more powerful and efficient LLMs based on these principles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 6 figures. Some corrections</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ InfoDeepSeek: Benchmarking Agentic Information Seeking for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15872v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15872v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
grounding responses with retrieved information. As an emerging paradigm,
Agentic RAG further enhances this process by introducing autonomous LLM agents
into the information seeking process. However, existing benchmarks fall short
in evaluating such systems, as they are confined to a static retrieval
environment with a fixed, limited corpus} and simple queries that fail to
elicit agentic behavior. Moreover, their evaluation protocols assess
information seeking effectiveness by pre-defined gold sets of documents, making
them unsuitable for the open-ended and dynamic nature of real-world web
environments. To bridge this gap, we present InfoDeepSeek, a new benchmark with
challenging questions designed for assessing agentic information seeking in
real-world, dynamic web environments. We propose a systematic methodology for
constructing challenging queries satisfying the criteria of determinacy,
difficulty, and diversity. Based on this, we develop the first evaluation
framework tailored to dynamic agentic information seeking, including
fine-grained metrics about the accuracy, utility, and compactness of
information seeking outcomes. Through extensive experiments across LLMs, search
engines, and question types, InfoDeepSeek reveals nuanced agent behaviors and
offers actionable insights for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SemEval-2025 Task 5: LLMs4Subjects -- LLM-based Automated Subject
  Tagging for a National Technical Library's Open-Access Catalog <span class="chip">SemEval 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.07199v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.07199v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jennifer D'Souza, Sameer Sadruddin, Holger Israel, Mathias Begoin, Diana Slawig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated
subject tagging for scientific and technical records in English and German
using the GND taxonomy. Participants developed LLM-based systems to recommend
top-k subjects, evaluated through quantitative metrics (precision, recall,
F1-score) and qualitative assessments by subject specialists. Results highlight
the effectiveness of LLM ensembles, synthetic data generation, and multilingual
processing, offering insights into applying LLMs for digital library
classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures, Accepted as SemEval 2025 Task 5 description
  paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12345v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12345v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model editing aims to enhance the accuracy and reliability of large language
models (LLMs) by efficiently adjusting their internal parameters. Currently,
most LLM editing datasets are confined to narrow knowledge domains and cover a
limited range of editing evaluation. They often overlook the broad scope of
editing demands and the diversity of ripple effects resulting from edits. In
this context, we introduce UniEdit, a unified benchmark for LLM editing
grounded in open-domain knowledge. First, we construct editing samples by
selecting entities from 25 common domains across five major categories,
utilizing the extensive triple knowledge available in open-domain knowledge
graphs to ensure comprehensive coverage of the knowledge domains. To address
the issues of generality and locality in editing, we design an Neighborhood
Multi-hop Chain Sampling (NMCS) algorithm to sample subgraphs based on a given
knowledge piece to entail comprehensive ripple effects to evaluate. Finally, we
employ proprietary LLMs to convert the sampled knowledge subgraphs into natural
language text, guaranteeing grammatical accuracy and syntactical diversity.
Extensive statistical analysis confirms the scale, comprehensiveness, and
diversity of our UniEdit benchmark. We conduct comprehensive experiments across
multiple LLMs and editors, analyzing their performance to highlight strengths
and weaknesses in editing across open knowledge domains and various evaluation
criteria, thereby offering valuable insights for future research endeavors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>UniEdit Dataset: https://huggingface.co/datasets/qizhou/UniEdit Code:
  https://github.com/qizhou000/UniEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personality Editing for Language Models through Relevant Knowledge
  Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11789v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11789v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seojin Hwang, Yumin Kim, Byeongjeong Kim, Donghoon Shin, Hwanhee Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) play a vital role in applications like
conversational agents and content creation, where controlling a model's
personality is crucial for maintaining tone, consistency, and engagement.
However, traditional prompt-based techniques for controlling personality often
fall short, as they do not effectively mitigate the model's inherent biases. In
this paper, we introduce a novel method PALETTE that enhances personality
control through knowledge editing. By generating adjustment queries inspired by
psychological assessments, our approach systematically adjusts responses to
personality-related queries similar to modifying factual knowledge, thereby
achieving controlled shifts in personality traits. Experimental results from
both automatic and human evaluations demonstrate that our method enables more
stable and well-balanced personality control in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 3 figures, 24 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mitigate Position Bias in Large Language Models via Scaling a Single
  Dimension <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02536v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02536v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly applied in various real-world
scenarios due to their excellent generalization capabilities and robust
generative abilities. However, they exhibit position bias, also known as "lost
in the middle", a phenomenon that is especially pronounced in long-context
scenarios, which indicates the placement of the key information in different
positions of a prompt can significantly affect accuracy. This paper first
explores the micro-level manifestations of position bias, concluding that
attention weights are a micro-level expression of position bias. It further
identifies that, in addition to position embeddings, causal attention mask also
contributes to position bias by creating position-specific hidden states. Based
on these insights, we propose a method to mitigate position bias by scaling
this positional hidden states. Experiments on the NaturalQuestions
Multi-document QA, KV retrieval, LongBench and timeline reorder tasks, using
various models including RoPE models, context windowextended models, and Alibi
models, demonstrate the effectiveness and generalizability of our approach. Our
method can improve performance by up to 15.2% by modifying just one dimension
of hidden states. Our code is available at https://aka.ms/PositionalHidden.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Findings of ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task Arithmetic for Language Expansion in Speech Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao-Fei Cheng, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Wen Shen Teo, Siddhant Arora, Shinji Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in large language models (LLMs) has gained interest in
speech-text multimodal foundation models, achieving strong performance on
instruction-tuned speech translation (ST). However, expanding language pairs is
costly due to re-training on combined new and previous datasets. To address
this, we aim to build a one-to-many ST system from existing one-to-one ST
systems using task arithmetic without re-training. Direct application of task
arithmetic in ST leads to language confusion; therefore, we introduce an
augmented task arithmetic method incorporating a language control model to
ensure correct target language generation. Our experiments on MuST-C and
CoVoST-2 show BLEU score improvements of up to 4.66 and 4.92, with COMET gains
of 8.87 and 11.83. In addition, we demonstrate our framework can extend to
language pairs lacking paired ST training data or pre-trained ST models by
synthesizing ST models based on existing machine translation (MT) and ST models
via task analogies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Black-box Model Predictions via Two-level Nested Feature
  Attributions with Consistency Property <span class="chip">IJCAI2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14522v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14522v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuya Yoshikawa, Masanari Kimura, Ryotaro Shimizu, Yuki Saito
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Techniques that explain the predictions of black-box machine learning models
are crucial to make the models transparent, thereby increasing trust in AI
systems. The input features to the models often have a nested structure that
consists of high- and low-level features, and each high-level feature is
decomposed into multiple low-level features. For such inputs, both high-level
feature attributions (HiFAs) and low-level feature attributions (LoFAs) are
important for better understanding the model's decision. In this paper, we
propose a model-agnostic local explanation method that effectively exploits the
nested structure of the input to estimate the two-level feature attributions
simultaneously. A key idea of the proposed method is to introduce the
consistency property that should exist between the HiFAs and LoFAs, thereby
bridging the separate optimization problems for estimating them. Thanks to this
consistency property, the proposed method can produce HiFAs and LoFAs that are
both faithful to the black-box models and consistent with each other, using a
smaller number of queries to the models. In experiments on image classification
in multiple instance learning and text classification using language models, we
demonstrate that the HiFAs and LoFAs estimated by the proposed method are
accurate, faithful to the behaviors of the black-box models, and provide
consistent explanations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript is an extended version of our paper accepted at
  IJCAI2025, with detailed proofs and additional experimental results</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EduBench: A Comprehensive Benchmarking <span class="highlight-title">Dataset</span> for Evaluating Large
  Language Models in Diverse Educational Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16160v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16160v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Xu, Yu Bai, Huashan Sun, Yiguan Lin, Siming Liu, Xinyue Liang, Yaolin Li, Yang Gao, Heyan Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models continue to advance, their application in
educational contexts remains underexplored and under-optimized. In this paper,
we address this gap by introducing the first diverse benchmark tailored for
educational scenarios, incorporating synthetic data containing 9 major
scenarios and over 4,000 distinct educational contexts. To enable comprehensive
assessment, we propose a set of multi-dimensional evaluation metrics that cover
12 critical aspects relevant to both teachers and students. We further apply
human annotation to ensure the effectiveness of the model-generated evaluation
responses. Additionally, we succeed to train a relatively small-scale model on
our constructed dataset and demonstrate that it can achieve performance
comparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on
the test set. Overall, this work provides a practical foundation for the
development and evaluation of education-oriented language models. Code and data
are released at https://github.com/ybai-nlp/EduBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EpiCoder: Encompassing Diversity and Complexity in Code Generation <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04694v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04694v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaoxiang Wang, Haoling Li, Xin Zhang, Jie Wu, Xiao Liu, Wenxiang Hu, Zhongxin Guo, Yangyu Huang, Ying Xin, Yujiu Yang, Jinsong Su, Qi Chen, Scarlett Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for code generation use code snippets as seed data,
restricting the complexity and diversity of the synthesized data. In this
paper, we introduce a novel feature tree-based synthesis framework, which
revolves around hierarchical code features derived from high-level abstractions
of code. The feature tree is constructed from raw data and refined iteratively
to increase the quantity and diversity of the extracted features, which
captures and recognizes more complex patterns and relationships within the
code. By adjusting the depth and breadth of the sampled subtrees, our framework
provides precise control over the complexity of the generated code, enabling
functionalities that range from function-level operations to multi-file
scenarios. We fine-tuned widely-used base models to obtain EpiCoder series,
achieving state-of-the-art performance on multiple benchmarks at both the
function and file levels. In particular, empirical evidence indicates that our
approach shows significant potential in the synthesizing of repository-level
code data. Our code and data are publicly available at
https://github.com/microsoft/EpiCoder.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimizing Large Language Model Training Using FP4 Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17116v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17116v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing computational demands of training large language models (LLMs)
necessitate more efficient methods. Quantized training presents a promising
solution by enabling low-bit arithmetic operations to reduce these costs. While
FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge
due to significant quantization errors and limited representational capacity.
This work introduces the first FP4 training framework for LLMs, addressing
these challenges with two key innovations: a differentiable quantization
estimator for precise weight updates and an outlier clamping and compensation
strategy to prevent activation collapse. To ensure stability, the framework
integrates a mixed-precision training scheme and vector-wise quantization.
Experimental results demonstrate that our FP4 framework achieves accuracy
comparable to BF16 and FP8, with minimal degradation, scaling effectively to
13B-parameter LLMs trained on up to 100B tokens. With the emergence of
next-generation hardware supporting FP4, our framework sets a foundation for
efficient ultra-low precision training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rewarding Doubt: A Reinforcement Learning Approach to Calibrated
  Confidence Expression of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02623v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02623v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Stangel, David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Kamilia Zaripova, Matthias Keicher, Nassir Navab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A safe and trustworthy use of Large Language Models (LLMs) requires an
accurate expression of confidence in their answers. We propose a novel
Reinforcement Learning approach that allows to directly fine-tune LLMs to
express calibrated confidence estimates alongside their answers to factual
questions. Our method optimizes a reward based on the logarithmic scoring rule,
explicitly penalizing both over- and under-confidence. This encourages the
model to align its confidence estimates with the actual predictive accuracy.
The optimal policy under our reward design would result in perfectly calibrated
confidence expressions. Unlike prior approaches that decouple confidence
estimation from response generation, our method integrates confidence
calibration seamlessly into the generative process of the LLM. Empirically, we
demonstrate that models trained with our approach exhibit substantially
improved calibration and generalize to unseen tasks without further
fine-tuning, suggesting the emergence of general confidence awareness. We
provide our training and evaluation code in the supplementary and will make it
publicly available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boosting Long-Context Management via Query-Guided Activation Refilling <span class="chip">ACL25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12486v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12486v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Processing long contexts poses a significant challenge for large language
models (LLMs) due to their inherent context-window limitations and the
computational burden of extensive key-value (KV) activations, which severely
impact efficiency. For information-seeking tasks, full context perception is
often unnecessary, as a query's information needs can dynamically range from
localized details to a global perspective, depending on its complexity.
However, existing methods struggle to adapt effectively to these dynamic
information needs.
  In the paper, we propose a method for processing long-context
information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE
constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache
compactly captures global information, and the layer-2 (L2) cache provides
detailed and localized information. ACRE establishes a proxying relationship
between the two caches, allowing the input query to attend to the L1 cache and
dynamically refill it with relevant entries from the L2 cache. This mechanism
integrates global understanding with query-specific local details, thus
improving answer decoding. Experiments on a variety of long-context
information-seeking datasets demonstrate ACRE's effectiveness, achieving
improvements in both performance and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL25 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The escalating scale and cost of Large Language Models (LLMs) training
necessitate accurate pre-training prediction of downstream task performance for
efficient resource allocation. This is challenged by: 1) the emergence
phenomenon, where metrics become meaningful only after extensive training,
hindering prediction by smaller models; and 2) uneven task difficulty and
inconsistent performance scaling patterns, leading to high metric variability.
Current prediction methods lack accuracy and reliability. We propose a
Clustering-On-Difficulty (COD) framework for downstream performance prediction.
The COD framework clusters tasks by their difficulty scaling features, thereby
establishing a more stable and predictable support subset through the exclusion
of tasks exhibiting non-emergent behavior or irregular scaling. We adopt a
performance scaling law to predict cluster-wise performance with theoretical
support. Predictable subset performance acts as an intermediate predictor for
the full evaluation set. We further derive a mapping function to accurately
extrapolate the performance of the subset to the full set. Applied to an LLM
with 70B parameters, COD achieved a 1.36% average prediction error across eight
key LLM benchmarks, offering actionable insights for resource allocation and
training monitoring of LLMs pretraining.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages,6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SafeInt: Shielding Large Language Models from Jailbreak Attacks via
  Safety-Aware Representation Intervention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15594v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15594v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Wu, Chen Chen, Chunyan Hou, Xiaojie Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the widespread real-world deployment of large language models (LLMs),
ensuring their behavior complies with safety standards has become crucial.
Jailbreak attacks exploit vulnerabilities in LLMs to induce undesirable
behavior, posing a significant threat to LLM safety. Previous defenses often
fail to achieve both effectiveness and efficiency simultaneously. Defenses from
a representation perspective offer new insights, but existing interventions
cannot dynamically adjust representations based on the harmfulness of the
queries. To address this limitation, we propose SafeIntervention (SafeInt), a
novel defense method that shields LLMs from jailbreak attacks through
safety-aware representation intervention. Built on our analysis of the
representations of jailbreak samples, the core idea of SafeInt is to relocate
jailbreak-related representations into the rejection region. This is achieved
by intervening in the representation distributions of jailbreak samples to
align them with those of unsafe samples. We conduct comprehensive experiments
covering six jailbreak attacks, two jailbreak datasets, and two utility
benchmarks. Experimental results demonstrate that SafeInt outperforms all
baselines in defending LLMs against jailbreak attacks while largely maintaining
utility. Additionally, we evaluate SafeInt against adaptive attacks and verify
its effectiveness in mitigating real-time attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ABBA: Highly Expressive Hadamard Product Adaptation for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14238v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14238v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Praneeth Vepakomma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models have demonstrated strong performance across a wide
range of tasks, but adapting them efficiently to new domains remains a key
challenge. Parameter-Efficient Fine-Tuning (PEFT) methods address this by
introducing lightweight, trainable modules while keeping most pre-trained
weights fixed. The prevailing approach, LoRA, models updates using a low-rank
decomposition, but its expressivity is inherently constrained by the rank.
Recent methods like HiRA aim to increase expressivity by incorporating a
Hadamard product with the frozen weights, but still rely on the structure of
the pre-trained model. We introduce ABBA, a new PEFT architecture that
reparameterizes the update as a Hadamard product of two independently learnable
low-rank matrices. In contrast to prior work, ABBA fully decouples the update
from the pre-trained weights, enabling both components to be optimized freely.
This leads to significantly higher expressivity under the same parameter
budget. We formally analyze ABBA's expressive capacity and validate its
advantages through matrix reconstruction experiments. Empirically, ABBA
achieves state-of-the-art results on arithmetic and commonsense reasoning
benchmarks, consistently outperforming existing PEFT methods by a significant
margin across multiple models. Our code is publicly available at:
https://github.com/CERT-Lab/abba.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Raghav Singhal, Kaustubh Ponkshe, and Rohit Vartak contributed
  equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ICA-RAG: Information Completeness Guided Adaptive Retrieval-Augmented
  Generation for Disease Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14614v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14614v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingyi Jia, Zhihao Jia, Junwen Duan, Yan Song, Jianxin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Large Language Models~(LLMs), which integrate external
knowledge, have shown remarkable performance in medical domains, including
clinical diagnosis. However, existing RAG methods often struggle to tailor
retrieval strategies to diagnostic difficulty and input sample informativeness.
This limitation leads to excessive and often unnecessary retrieval, impairing
computational efficiency and increasing the risk of introducing noise that can
degrade diagnostic accuracy. To address this, we propose ICA-RAG
(\textbf{I}nformation \textbf{C}ompleteness Guided \textbf{A}daptive
\textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration), a novel framework
for enhancing RAG reliability in disease diagnosis. ICA-RAG utilizes an
adaptive control module to assess the necessity of retrieval based on the
input's information completeness. By optimizing retrieval and incorporating
knowledge filtering, ICA-RAG better aligns retrieval operations with clinical
requirements. Experiments on three Chinese electronic medical record datasets
demonstrate that ICA-RAG significantly outperforms baseline methods,
highlighting its effectiveness in clinical diagnosis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ URSA: Understanding and Verifying Chain-of-thought Reasoning in
  Multimodal Mathematics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04686v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04686v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruilin Luo, Zhuofan Zheng, Yifan Wang, Xinzhe Ni, Zicheng Lin, Songtao Jiang, Yiyao Yu, Chufan Shi, Ruihang Chu, Jin Zeng, Yujiu Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Process Reward Models (PRMs) have shown promise in enhancing the mathematical
reasoning capabilities of Large Language Models (LLMs) through Test-Time
Scaling (TTS). However, their integration into multimodal reasoning remains
largely unexplored. In this work, we take the first step toward unlocking the
potential of PRMs in multimodal mathematical reasoning. We identify three key
challenges: (1) the scarcity of high-quality reasoning data constrains the
capabilities of foundation Multimodal Large Language Models (MLLMs), which
imposes further limitations on the upper bounds of TTS and reinforcement
learning (RL); (2) a lack of automated methods for process labeling within
multimodal contexts persists; (3) the employment of process rewards in unimodal
RL faces issues like reward hacking, which may extend to multimodal scenarios.
To address these issues, we introduce URSA, a three-stage Unfolding multimodal
Process-Supervision Aided training framework. We first construct MMathCoT-1M, a
high-quality large-scale multimodal Chain-of-Thought (CoT) reasoning dataset,
to build a stronger math reasoning foundation MLLM, URSA-8B. Subsequently, we
go through an automatic process to synthesize process supervision data, which
emphasizes both logical correctness and perceptual consistency. We introduce
DualMath-1.1M to facilitate the training of URSA-8B-RM. Finally, we propose
Process-Supervised Group-Relative-Policy-Optimization (PS-GRPO), pioneering a
multimodal PRM-aided online RL method that outperforms vanilla GRPO. With
PS-GRPO application, URSA-8B-PS-GRPO outperforms Gemma3-12B and GPT-4o by 8.4%
and 2.7% on average across 6 benchmarks. Code, data and checkpoint can be found
at https://github.com/URSA-MATH.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Update version. Project url: https://ursa-math.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15968v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15968v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roy Xie, Junlin Wang, Ruomin Huang, Minxing Zhang, Rong Ge, Jian Pei, Neil Zhenqiang Gong, Bhuwan Dhingra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid scaling of large language models (LLMs) has raised concerns about
the transparency and fair use of the data used in their pretraining. Detecting
such content is challenging due to the scale of the data and limited exposure
of each instance during training. We propose ReCaLL (Relative Conditional
Log-Likelihood), a novel membership inference attack (MIA) to detect LLMs'
pretraining data by leveraging their conditional language modeling
capabilities. ReCaLL examines the relative change in conditional
log-likelihoods when prefixing target data points with non-member context. Our
empirical findings show that conditioning member data on non-member prefixes
induces a larger decrease in log-likelihood compared to non-member data. We
conduct comprehensive experiments and show that ReCaLL achieves
state-of-the-art performance on the WikiMIA dataset, even with random and
synthetic prefixes, and can be further improved using an ensemble approach.
Moreover, we conduct an in-depth analysis of LLMs' behavior with different
membership contexts, providing insights into how LLMs leverage membership
information for effective inference at both the sequence and token level.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy
  Expansion <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13282v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13282v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Taxonomies are hierarchical knowledge graphs crucial for recommendation
systems, and web applications. As data grows, expanding taxonomies is
essential, but existing methods face key challenges: (1) discriminative models
struggle with representation limits and generalization, while (2) generative
methods either process all candidates at once, introducing noise and exceeding
context limits, or discard relevant entities by selecting noisy candidates. We
propose LORex ($\textbf{L}$ineage-$\textbf{O}$riented $\textbf{Re}$asoning for
Taxonomy E$\textbf{x}$pansion), a plug-and-play framework that combines
discriminative ranking and generative reasoning for efficient taxonomy
expansion. Unlike prior methods, LORex ranks and chunks candidate terms into
batches, filtering noise and iteratively refining selections by reasoning
candidates' hierarchy to ensure contextual efficiency. Extensive experiments
across four benchmarks and twelve baselines show that LORex improves accuracy
by 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the Findings of ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Over-Tokenized <span class="highlight-title">Transformer</span>: Vocabulary is Generally Worth Scaling <span class="chip">ICML2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16975v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16975v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tokenization is a fundamental component of large language models (LLMs), yet
its influence on model scaling and performance is not fully explored. In this
paper, we introduce Over-Tokenized Transformers, a novel framework that
decouples input and output vocabularies to improve language modeling
performance. Specifically, our approach scales up input vocabularies to
leverage multi-gram tokens. Through extensive experiments, we uncover a
log-linear relationship between input vocabulary size and training loss,
demonstrating that larger input vocabularies consistently enhance model
performance, regardless of model size. Using a large input vocabulary, we
achieve performance comparable to double-sized baselines with no additional
cost. Our findings highlight the importance of tokenization in scaling laws and
provide practical insight for tokenizer design, paving the way for more
efficient and powerful LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by ICML2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Li, Qingxiu Dong, Jingyuan Ma, Di Zhang, Zhifang Sui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large reasoning models demonstrate exceptional performance on
various tasks. However, reasoning models inefficiently over-process both
trivial and complex queries, leading to resource waste and prolonged user
latency. To address this challenge, we propose SelfBudgeter - a self-adaptive
controllable reasoning strategy for efficient reasoning. Our approach adopts a
dual-phase training paradigm: first, the model learns to pre-estimate the
reasoning cost based on the difficulty of the query. Then, we introduce
budget-guided GPRO for reinforcement learning, which effectively maintains
accuracy while reducing output length. SelfBudgeter allows users to anticipate
generation time and make informed decisions about continuing or interrupting
the process. Furthermore, our method enables direct manipulation of reasoning
length via pre-filling token budget. Experimental results demonstrate that
SelfBudgeter can rationally allocate budgets according to problem complexity,
achieving up to 74.47% response length compression on the MATH benchmark while
maintaining nearly undiminished accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Initialization using Update Approximation is a Silver Bullet for
  Extremely Efficient Low-Rank Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.19557v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.19557v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaustubh Ponkshe, Raghav Singhal, Eduard Gorbunov, Alexey Tumanov, Samuel Horvath, Praneeth Vepakomma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank adapters have become standard for efficiently fine-tuning large
language models (LLMs), but they often fall short of achieving the performance
of full fine-tuning. We propose a method, LoRA Silver Bullet or LoRA-SB, that
approximates full fine-tuning within low-rank subspaces using a carefully
designed initialization strategy. We theoretically demonstrate that the
architecture of LoRA-XS, which inserts a learnable (r x r) matrix between B and
A while keeping other matrices fixed, provides the precise conditions needed
for this approximation. We leverage its constrained update space to achieve
optimal scaling for high-rank gradient updates while removing the need for
hyperparameter tuning. We prove that our initialization offers an optimal
low-rank approximation of the initial gradient and preserves update directions
throughout training. Extensive experiments across mathematical reasoning,
commonsense reasoning, and language understanding tasks demonstrate that our
approach exceeds the performance of standard LoRA while using \textbf{27-90}
times fewer learnable parameters, and comprehensively outperforms LoRA-XS. Our
findings establish that it is possible to simulate full fine-tuning in low-rank
subspaces, and achieve significant efficiency gains without sacrificing
performance. Our code is publicly available at
https://github.com/RaghavSinghal10/lora-sb.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Kaustubh Ponkshe and Raghav Singhal contributed equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data
  Augmentation and Gaussian-Decayed Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12887v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12887v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, using large language models (LLMs) for data augmentation has led to
considerable improvements in unsupervised sentence embedding models. However,
existing methods encounter two primary challenges: limited data diversity and
high data noise. Current approaches often neglect fine-grained knowledge, such
as entities and quantities, leading to insufficient diversity. Besides,
unsupervised data frequently lacks discriminative information, and the
generated synthetic samples may introduce noise. In this paper, we propose a
pipeline-based data augmentation method via LLMs and introduce the
Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model
to enhance unsupervised sentence embeddings. To tackle the issue of low data
diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and
quantities, enabling LLMs to generate more diverse samples. To address high
data noise, the GCSE model uses a Gaussian-decayed function to limit the impact
of false hard negative samples, enhancing the model's discriminative
capability. Experimental results show that our approach achieves
state-of-the-art performance in semantic textual similarity (STS) tasks, using
fewer data samples and smaller LLMs, demonstrating its efficiency and
robustness across various models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Phare: A Safety Probe for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11365v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11365v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pierre Le Jeune, Benoît Malézieux, Weixuan Xiao, Matteo Dora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the safety of large language models (LLMs) is critical for
responsible deployment, yet existing evaluations often prioritize performance
over identifying failure modes. We introduce Phare, a multilingual diagnostic
framework to probe and evaluate LLM behavior across three critical dimensions:
hallucination and reliability, social biases, and harmful content generation.
Our evaluation of 17 state-of-the-art LLMs reveals patterns of systematic
vulnerabilities across all safety dimensions, including sycophancy, prompt
sensitivity, and stereotype reproduction. By highlighting these specific
failure modes rather than simply ranking models, Phare provides researchers and
practitioners with actionable insights to build more robust, aligned, and
trustworthy language systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chain-of-Model Learning for Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11820v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11820v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel learning paradigm, termed Chain-of-Model
(CoM), which incorporates the causal relationship into the hidden states of
each layer as a chain style, thereby introducing great scaling efficiency in
model training and inference flexibility in deployment. We introduce the
concept of Chain-of-Representation (CoR), which formulates the hidden states at
each layer as a combination of multiple sub-representations (i.e., chains) at
the hidden dimension level. In each layer, each chain from the output
representations can only view all of its preceding chains in the input
representations. Consequently, the model built upon CoM framework can
progressively scale up the model size by increasing the chains based on the
previous models (i.e., chains), and offer multiple sub-models at varying sizes
for elastic inference by using different chain numbers. Based on this
principle, we devise Chain-of-Language-Model (CoLM), which incorporates the
idea of CoM into each layer of Transformer architecture. Based on CoLM, we
further introduce CoLM-Air by introducing a KV sharing mechanism, that computes
all keys and values within the first chain and then shares across all chains.
This design demonstrates additional extensibility, such as enabling seamless LM
switching, prefilling acceleration and so on. Experimental results demonstrate
our CoLM family can achieve comparable performance to the standard Transformer,
while simultaneously enabling greater flexiblity, such as progressive scaling
to improve training efficiency and offer multiple varying model sizes for
elastic inference, paving a a new way toward building language models. Our code
will be released in the future at: https://github.com/microsoft/CoLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SCAR: Data Selection via Style Consistency-Aware Response Ranking for
  Efficient Instruction-Tuning of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10882v8">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10882v8.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies emphasize that manually ensuring a consistent response style
and maintaining high data quality in training sets can significantly improve
the performance of fine-tuned Large Language Models (LLMs) while reducing the
number of training examples needed. However, the precise definition of style
and the relationship between style, data quality, and LLM performance remains
unclear. This research identifies two key stylistic elements in responses:
linguistic form and instructional surprisal. We find that, among training data
of comparable quality, higher consistency in these response elements leads to
better LLM performance. Inspired by this, we introduce Style Consistency-Aware
Response Ranking (SCAR), which automatically prioritizes instruction-response
pairs in the training set based on their response stylistic consistency. By
selecting the most style-consistent examples, using 0.7% of the full dataset in
certain cases, the fine-tuned LLMs can match or even surpass the performance of
models trained on the entire dataset in coding and open-ended
question-answering benchmarks. Code and data are available at
https://github.com/zhuang-li/SCAR .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages (8th version), developed over 1.5 years. Previously
  submitted to EMNLP 2024 and ICLR 2025, with revisions based on extensive
  review feedback. Now accepted to ACL 2025 main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open
  Domain Event Detection <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03303v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03303v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi-Fan Lu, Xian-Ling Mao, Tian Lan, Tong Zhang, Yu-Shi Zhu, Heyan Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic evaluation for Open Domain Event Detection (ODED) is a highly
challenging task, because ODED is characterized by a vast diversity of
un-constrained output labels from various domains. Nearly all existing
evaluation methods for ODED usually first construct evaluation benchmarks with
limited labels and domain coverage, and then evaluate ODED methods using
metrics based on token-level label matching rules. However, this kind of
evaluation framework faces two issues: (1) The limited evaluation benchmarks
lack representatives of the real world, making it difficult to accurately
reflect the performance of various ODED methods in real-world scenarios; (2)
Evaluation metrics based on token-level matching rules fail to capture semantic
similarity between predictions and golden labels. To address these two problems
above, we propose a scalable and reliable Semantic-level Evaluation framework
for Open domain Event detection (SEOE) by constructing a more representative
evaluation benchmark and introducing a semantic evaluation metric.
Specifically, our proposed framework first constructs a scalable evaluation
benchmark that currently includes 564 event types covering 7 major domains,
with a cost-effective supplementary annotation strategy to ensure the
benchmark's representativeness. The strategy also allows for the supplement of
new event types and domains in the future. Then, the proposed SEOE leverages
large language models (LLMs) as automatic evaluation agents to compute a
semantic F1-score, incorporating fine-grained definitions of semantically
similar labels to enhance the reliability of the evaluation. Extensive
experiments validate the representatives of the benchmark and the reliability
of the semantic evaluation metric. Existing ODED methods are thoroughly
evaluated, and the error patterns of predictions are analyzed, revealing
several insightful findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL 2025 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Small Language Models in the Real World: Insights from Industrial Text
  Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16078v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16078v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lujun Li, Lama Sleem, Niccolo' Gentile, Geoffrey Nichil, Radu State
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the emergence of ChatGPT, Transformer models have significantly advanced
text classification and related tasks. Decoder-only models such as Llama
exhibit strong performance and flexibility, yet they suffer from inefficiency
on inference due to token-by-token generation, and their effectiveness in text
classification tasks heavily depends on prompt quality. Moreover, their
substantial GPU resource requirements often limit widespread adoption. Thus,
the question of whether smaller language models are capable of effectively
handling text classification tasks emerges as a topic of significant interest.
However, the selection of appropriate models and methodologies remains largely
underexplored. In this paper, we conduct a comprehensive evaluation of prompt
engineering and supervised fine-tuning methods for transformer-based text
classification. Specifically, we focus on practical industrial scenarios,
including email classification, legal document categorization, and the
classification of extremely long academic texts. We examine the strengths and
limitations of smaller models, with particular attention to both their
performance and their efficiency in Video Random-Access Memory (VRAM)
utilization, thereby providing valuable insights for the local deployment and
application of compact models in industrial settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based
  on Speech and Audio Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chih-Kai Yang, Neo Ho, Yen-Ting Piao, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large audio-language models (LALMs) extend the large language models with
multimodal understanding in speech, audio, etc. While their performances on
speech and audio-processing tasks are extensively studied, their reasoning
abilities remain underexplored. Particularly, their multi-hop reasoning, the
ability to recall and integrate multiple facts, lacks systematic evaluation.
Existing benchmarks focus on general speech and audio-processing tasks,
conversational abilities, and fairness but overlook this aspect. To bridge this
gap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning
based on speech and audio information. Results show that LALMs struggle to
integrate speech/audio representations for multi-hop reasoning, even when they
extract the relevant information correctly, highlighting a fundamental
challenge in multimodal reasoning. Our findings expose a critical limitation in
LALMs, offering insights and resources for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Interspeech 2025. Project page:
  https://github.com/ckyang1124/SAKURA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Holistic Evaluation of Large Audio-Language Models: A
  Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15957v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15957v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chih-Kai Yang, Neo S. Ho, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With advancements in large audio-language models (LALMs), which enhance large
language models (LLMs) with auditory capabilities, these models are expected to
demonstrate universal proficiency across various auditory tasks. While numerous
benchmarks have emerged to assess LALMs' performance, they remain fragmented
and lack a structured taxonomy. To bridge this gap, we conduct a comprehensive
survey and propose a systematic taxonomy for LALM evaluations, categorizing
them into four dimensions based on their objectives: (1) General Auditory
Awareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented
Ability, and (4) Fairness, Safety, and Trustworthiness. We provide detailed
overviews within each category and highlight challenges in this field, offering
insights into promising future directions. To the best of our knowledge, this
is the first survey specifically focused on the evaluations of LALMs, providing
clear guidelines for the community. We will release the collection of the
surveyed papers and actively maintain it to support ongoing advancements in the
field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Website: https://github.com/ckyang1124/LALM-Evaluation-Survey</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What Media Frames Reveal About Stance: A <span class="highlight-title">Dataset</span> and Study about Memes
  in Climate Change Discourse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijia Zhou, Siyao Peng, Simon Luebke, Jörg Haßler, Mario Haim, Saif M. Mohammad, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Media framing refers to the emphasis on specific aspects of perceived reality
to shape how an issue is defined and understood. Its primary purpose is to
shape public perceptions often in alignment with the authors' opinions and
stances. However, the interaction between stance and media frame remains
largely unexplored. In this work, we apply an interdisciplinary approach to
conceptualize and computationally explore this interaction with internet memes
on climate change. We curate CLIMATEMEMES, the first dataset of climate-change
memes annotated with both stance and media frames, inspired by research in
communication science. CLIMATEMEMES includes 1,184 memes sourced from 47
subreddits, enabling analysis of frame prominence over time and communities,
and sheds light on the framing preferences of different stance holders. We
propose two meme understanding tasks: stance detection and media frame
detection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the
corresponding results on their LLM backbone. Human captions consistently
enhance performance. Synthetic captions and human-corrected OCR also help
occasionally. Our findings highlight that VLMs perform well on stance, but
struggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'
limitations in handling nuanced frames and stance expressions on climate change
internet memes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ REN: Fast and Efficient Region Encodings from Patch-Based Image Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18153v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18153v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Savya Khosla, Sethuraman TV, Barnett Lee, Alexander Schwing, Derek Hoiem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Region Encoder Network (REN), a fast and effective model for
generating region-based image representations using point prompts. Recent
methods combine class-agnostic segmenters (e.g., SAM) with patch-based image
encoders (e.g., DINO) to produce compact and effective region representations,
but they suffer from high computational cost due to the segmentation step. REN
bypasses this bottleneck using a lightweight module that directly generates
region tokens, enabling 60x faster token generation with 35x less memory, while
also improving token quality. It uses a few cross-attention blocks that take
point prompts as queries and features from a patch-based image encoder as keys
and values to produce region tokens that correspond to the prompted objects. We
train REN with three popular encoders-DINO, DINOv2, and OpenCLIP-and show that
it can be extended to other encoders without dedicated training. We evaluate
REN on semantic segmentation and retrieval tasks, where it consistently
outperforms the original encoders in both performance and compactness, and
matches or exceeds SAM-based region methods while being significantly faster.
Notably, REN achieves state-of-the-art results on the challenging Ego4D VQ2D
benchmark and outperforms proprietary LMMs on Visual Haystacks' single-needle
challenge. Code and models are available at: https://github.com/savya08/REN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zizhang Li, Hong-Xing Yu, Wei Liu, Yin Yang, Charles Herrmann, Gordon Wetzstein, Jiajun Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  WonderPlay is a novel framework integrating physics simulation with video
generation for generating action-conditioned dynamic 3D scenes from a single
image. While prior works are restricted to rigid body or simple elastic
dynamics, WonderPlay features a hybrid generative simulator to synthesize a
wide range of 3D dynamics. The hybrid generative simulator first uses a physics
solver to simulate coarse 3D dynamics, which subsequently conditions a video
generator to produce a video with finer, more realistic motion. The generated
video is then used to update the simulated dynamic 3D scene, closing the loop
between the physics solver and the video generator. This approach enables
intuitive user control to be combined with the accurate dynamics of
physics-based simulators and the expressivity of diffusion-based video
generators. Experimental results demonstrate that WonderPlay enables users to
interact with various scenes of diverse content, including cloth, sand, snow,
liquid, smoke, elastic, and rigid bodies -- all using a single image input.
Code will be made public. Project website:
https://kyleleey.github.io/WonderPlay/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. Project website:
  https://kyleleey.github.io/WonderPlay/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TokBench: Evaluating Your Visual Tokenizer before Visual Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18142v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18142v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Wu, Dongliang Luo, Weizhi Zhao, Zhihao Xie, Yuanhao Wang, Junyi Li, Xudong Xie, Yuliang Liu, Xiang Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we reveal the limitations of visual tokenizers and VAEs in
preserving fine-grained features, and propose a benchmark to evaluate
reconstruction performance for two challenging visual contents: text and face.
Image tokenization has significantly advanced visual generation and multimodal
modeling, particularly with autoregressive models due to the modeling
simplicity of discrete tokens. Autoregressive models typically rely on image
tokenizers to compress images into discrete tokens for sequential prediction,
whereas diffusion models often operate on continuous latent space to reduce
computational costs. However, both visual compression approaches inevitably
lose visual information, thereby limiting the upper bound of visual generation
quality. To evaluate how these compression losses affect text and faces, the
most human-sensitive visual elements, we first collect and curate a collection
of text and faces images from existing datasets, ensuring clarity and
diversity. For text reconstruction, we employ OCR models to assess the
recognition accuracy of the reconstructed text, and then we measure feature
similarity between original and reconstructed faces thereby quantifying faces
reconstruction fidelity. Our method is highly lightweight, requiring just 2GB
memory and 4 minutes to complete evaluations. With our benchmark, we analyze
the reconstruction quality of text and faces at various scales across different
image tokenizers and VAEs. Our results demonstrate that modern visual
tokenizers still struggle to preserve fine-grained features, particularly at
smaller scales. Furthermore, we extend this evaluation framework to the video,
conducting a comprehensive analysis of video tokenizers. Additionally, we find
that traditional metrics fail to accurately reflect the reconstruction
performance for faces and text, while our proposed metrics serve as an
effective complement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Benchmark, homepagee: https://wjf5203.github.io/TokBench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Boosting Open Set Recognition Performance through Modulated
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18137v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18137v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amit Kumar Kundu, Vaishnavi Patil, Joseph Jaja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The open set recognition (OSR) problem aims to identify test samples from
novel semantic classes that are not part of the training classes, a task that
is crucial in many practical scenarios. However, existing OSR methods use a
constant scaling factor (the temperature) to the logits before applying a loss
function, which hinders the model from exploring both ends of the spectrum in
representation learning -- from instance-level to semantic-level features. In
this paper, we address this problem by enabling temperature-modulated
representation learning using our novel negative cosine scheduling scheme. Our
scheduling lets the model form a coarse decision boundary at the beginning of
training by focusing on fewer neighbors, and gradually prioritizes more
neighbors to smooth out rough edges. This gradual task switching leads to a
richer and more generalizable representation space. While other OSR methods
benefit by including regularization or auxiliary negative samples, such as with
mix-up, thereby adding a significant computational overhead, our scheme can be
folded into any existing OSR method with no overhead. We implement the proposed
scheme on top of a number of baselines, using both cross-entropy and
contrastive loss functions as well as a few other OSR methods, and find that
our scheme boosts both the OSR performance and the closed set performance in
most cases, especially on the tougher semantic shift benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VideoGameBench: Can Vision-Language Models complete popular video games? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex L. Zhang, Thomas L. Griffiths, Karthik R. Narasimhan, Ofir Press
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have achieved strong results on coding and math
benchmarks that are challenging for humans, yet their ability to perform tasks
that come naturally to humans--such as perception, spatial navigation, and
memory management--remains understudied. Real video games are crafted to be
intuitive for humans to learn and master by leveraging innate inductive biases,
making them an ideal testbed for evaluating such capabilities in VLMs. To this
end, we introduce VideoGameBench, a benchmark consisting of 10 popular video
games from the 1990s that VLMs directly interact with in real-time.
VideoGameBench challenges models to complete entire games with access to only
raw visual inputs and a high-level description of objectives and controls, a
significant departure from existing setups that rely on game-specific
scaffolding and auxiliary information. We keep three of the games secret to
encourage solutions that generalize to unseen environments. Our experiments
show that frontier vision-language models struggle to progress beyond the
beginning of each game. We find inference latency to be a major limitation of
frontier models in the real-time setting; therefore, we introduce
VideoGameBench Lite, a setting where the game pauses while waiting for the LM's
next action. The best performing model, Gemini 2.5 Pro, completes only 0.48% of
VideoGameBench and 1.6% of VideoGameBench Lite. We hope that the formalization
of the human skills mentioned above into this benchmark motivates progress in
these research directions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 33 pages including supplementary</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BiggerGait: Unlocking Gait Recognition with Layer-wise Representations
  from Large Vision Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18132v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18132v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingqing Ye, Chao Fan, Zhanbo Huang, Chengwen Luo, Jianqiang Li, Shiqi Yu, Xiaoming Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision models (LVM) based gait recognition has achieved impressive
performance. However, existing LVM-based approaches may overemphasize gait
priors while neglecting the intrinsic value of LVM itself, particularly the
rich, distinct representations across its multi-layers. To adequately unlock
LVM's potential, this work investigates the impact of layer-wise
representations on downstream recognition tasks. Our analysis reveals that
LVM's intermediate layers offer complementary properties across tasks,
integrating them yields an impressive improvement even without rich
well-designed gait priors. Building on this insight, we propose a simple and
universal baseline for LVM-based gait recognition, termed BiggerGait.
Comprehensive evaluations on CCPG, CAISA-B*, SUSTech1K, and CCGR\_MINI validate
the superiority of BiggerGait across both within- and cross-domain tasks,
establishing it as a simple yet practical baseline for gait representation
learning. All the models and code will be publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One RL to See Them All: Visual Triple Unified Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Ma, Linge Du, Xuyang Shen, Shaoxiang Chen, Pengfei Li, Qibing Ren, Lizhuang Ma, Yuchao Dai, Pengfei Liu, Junjie Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) has significantly advanced the reasoning
capabilities of vision-language models (VLMs). However, the use of RL beyond
reasoning tasks remains largely unexplored, especially for perceptionintensive
tasks like object detection and grounding. We propose V-Triune, a Visual Triple
Unified Reinforcement Learning system that enables VLMs to jointly learn visual
reasoning and perception tasks within a single training pipeline. V-Triune
comprises triple complementary components: Sample-Level Data Formatting (to
unify diverse task inputs), Verifier-Level Reward Computation (to deliver
custom rewards via specialized verifiers) , and Source-Level Metric Monitoring
(to diagnose problems at the data-source level). We further introduce a novel
Dynamic IoU reward, which provides adaptive, progressive, and definite feedback
for perception tasks handled by V-Triune. Our approach is instantiated within
off-the-shelf RL training framework using open-source 7B and 32B backbone
models. The resulting model, dubbed Orsta (One RL to See Them All),
demonstrates consistent improvements across both reasoning and perception
tasks. This broad capability is significantly shaped by its training on a
diverse dataset, constructed around four representative visual reasoning tasks
(Math, Puzzle, Chart, and Science) and four visual perception tasks (Grounding,
Detection, Counting, and OCR). Subsequently, Orsta achieves substantial gains
on MEGA-Bench Core, with improvements ranging from +2.1 to an impressive +14.1
across its various 7B and 32B model variants, with performance benefits
extending to a wide range of downstream tasks. These results highlight the
effectiveness and scalability of our unified RL approach for VLMs. The V-Triune
system, along with the Orsta models, is publicly available at
https://github.com/MiniMax-AI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instructify: Demystifying Metadata to Visual Instruction Tuning Data
  Conversion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18115v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18115v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Hansen, Wei Lin, Junmo Kang, Muhammad Jehanzeb Mirza, Hongyin Luo, Rogerio Feris, Alan Ritter, James Glass, Leonid Karlinsky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Instruction Tuning (VisIT) data, commonly available as human-assistant
conversations with images interleaved in the human turns, are currently the
most widespread vehicle for aligning strong LLMs to understand visual inputs,
converting them to strong LMMs. While many VisIT datasets are available, most
are constructed using ad-hoc techniques developed independently by different
groups. They are often poorly documented, lack reproducible code, and rely on
paid, closed-source model APIs such as GPT-4, Gemini, or Claude to convert
image metadata (labels) into VisIT instructions. This leads to high costs and
makes it challenging to scale, enhance quality, or generate VisIT data for new
datasets. In this work, we address these challenges and propose an open and
unified recipe and approach,~\textbf{\method}, for converting available
metadata to VisIT instructions using open LLMs. Our multi-stage \method
features an efficient framework for metadata grouping, quality control, data
and prompt organization, and conversation sampling. We show that our approach
can reproduce or enhance the data quality of available VisIT datasets when
applied to the same image data and metadata sources, improving GPT-4 generated
VisIT instructions by ~3\% on average and up to 12\% on individual benchmarks
using open models, such as Gemma 2 27B and LLaMa 3.1 70B. Additionally, our
approach enables effective performance scaling - both in quantity and quality -
by enhancing the resulting LMM performance across a wide range of benchmarks.
We also analyze the impact of various factors, including conversation format,
base model selection, and resampling strategies. Our code, which supports the
reproduction of equal or higher-quality VisIT datasets and facilities future
metadata-to-VisIT data conversion for niche domains, is released at
https://github.com/jacob-hansen/Instructify.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adapting SAM 2 for Visual Object Tracking: 1st Place Solution for MMVPR
  Challenge Multi-Modal Tracking <span class="chip">ICPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18111v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18111v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng-Yen Yang, Hsiang-Wei Huang, Pyong-Kun Kim, Chien-Kai Kuo, Jui-Wei Chang, Kwang-Ju Kim, Chung-I Huang, Jenq-Neng Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present an effective approach for adapting the Segment Anything Model 2
(SAM2) to the Visual Object Tracking (VOT) task. Our method leverages the
powerful pre-trained capabilities of SAM2 and incorporates several key
techniques to enhance its performance in VOT applications. By combining SAM2
with our proposed optimizations, we achieved a first place AUC score of 89.4 on
the 2024 ICPR Multi-modal Object Tracking challenge, demonstrating the
effectiveness of our approach. This paper details our methodology, the specific
enhancements made to SAM2, and a comprehensive analysis of our results in the
context of VOT solutions along with the multi-modality aspect of the dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICPR Multi-Modal Visual Pattern Recognition Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accelerating Learned Image Compression Through Modeling Neural Training
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichi Zhang, Zhihao Duan, Yuning Huang, Fengqing Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As learned image compression (LIC) methods become increasingly
computationally demanding, enhancing their training efficiency is crucial. This
paper takes a step forward in accelerating the training of LIC methods by
modeling the neural training dynamics. We first propose a Sensitivity-aware
True and Dummy Embedding Training mechanism (STDET) that clusters LIC model
parameters into few separate modes where parameters are expressed as affine
transformations of reference parameters within the same mode. By further
utilizing the stable intra-mode correlations throughout training and parameter
sensitivities, we gradually embed non-reference parameters, reducing the number
of trainable parameters. Additionally, we incorporate a Sampling-then-Moving
Average (SMA) technique, interpolating sampled weights from stochastic gradient
descent (SGD) training to obtain the moving average weights, ensuring smooth
temporal behavior and minimizing training state variances. Overall, our method
significantly reduces training space dimensions and the number of trainable
parameters without sacrificing model performance, thus accelerating model
convergence. We also provide a theoretical analysis on the Noisy quadratic
model, showing that the proposed method achieves a lower training variance than
standard SGD. Our approach offers valuable insights for further developing
efficient training methods for LICs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to TMLR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ F-ANcGAN: An Attention-Enhanced Cycle Consistent Generative Adversarial
  Architecture for Synthetic Image Generation of Nanoparticles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varun Ajith, Anindya Pal, Saumik Bhattacharya, Sayantari Ghosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nanomaterial research is becoming a vital area for energy, medicine, and
materials science, and accurate analysis of the nanoparticle topology is
essential to determine their properties. Unfortunately, the lack of
high-quality annotated datasets drastically hinders the creation of strong
segmentation models for nanoscale imaging. To alleviate this problem, we
introduce F-ANcGAN, an attention-enhanced cycle consistent generative
adversarial system that can be trained using a limited number of data samples
and generates realistic scanning electron microscopy (SEM) images directly from
segmentation maps. Our model uses a Style U-Net generator and a U-Net
segmentation network equipped with self-attention to capture structural
relationships and applies augmentation methods to increase the variety of the
dataset. The architecture reached a raw FID score of 17.65 for TiO$_2$ dataset
generation, with a further reduction in FID score to nearly 10.39 by using
efficient post-processing techniques. By facilitating scalable high-fidelity
synthetic dataset generation, our approach can improve the effectiveness of
downstream segmentation task training, overcoming severe data shortage issues
in nanoparticle analysis, thus extending its applications to resource-limited
fields.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 9 figures, 2 tables, conference paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards more transferable adversarial attack in black-box manner 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun Tong Lei, Zhongliang Guo, Hon Chung Lee, Minh Quoc Duong, Chun Pong Lau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial attacks have become a well-explored domain, frequently serving as
evaluation baselines for model robustness. Among these, black-box attacks based
on transferability have received significant attention due to their practical
applicability in real-world scenarios. Traditional black-box methods have
generally focused on improving the optimization framework (e.g., utilizing
momentum in MI-FGSM) to enhance transferability, rather than examining the
dependency on surrogate white-box model architectures. Recent state-of-the-art
approach DiffPGD has demonstrated enhanced transferability by employing
diffusion-based adversarial purification models for adaptive attacks. The
inductive bias of diffusion-based adversarial purification aligns naturally
with the adversarial attack process, where both involving noise addition,
reducing dependency on surrogate white-box model selection. However, the
denoising process of diffusion models incurs substantial computational costs
through chain rule derivation, manifested in excessive VRAM consumption and
extended runtime. This progression prompts us to question whether introducing
diffusion models is necessary. We hypothesize that a model sharing similar
inductive bias to diffusion-based adversarial purification, combined with an
appropriate loss function, could achieve comparable or superior transferability
while dramatically reducing computational overhead. In this paper, we propose a
novel loss function coupled with a unique surrogate model to validate our
hypothesis. Our approach leverages the score of the time-dependent classifier
from classifier-guided diffusion models, effectively incorporating natural data
distribution knowledge into the adversarial optimization process. Experimental
results demonstrate significantly improved transferability across diverse model
architectures while maintaining robustness against diffusion-based defenses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18096v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18096v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, Zhaoxin Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In face-to-face conversations, individuals need to switch between speaking
and listening roles seamlessly. Existing 3D talking head generation models
focus solely on speaking or listening, neglecting the natural dynamics of
interactive conversation, which leads to unnatural interactions and awkward
transitions. To address this issue, we propose a new task -- multi-round
dual-speaker interaction for 3D talking head generation -- which requires
models to handle and generate both speaking and listening behaviors in
continuous conversation. To solve this task, we introduce DualTalk, a novel
unified framework that integrates the dynamic behaviors of speakers and
listeners to simulate realistic and coherent dialogue interactions. This
framework not only synthesizes lifelike talking heads when speaking but also
generates continuous and vivid non-verbal feedback when listening, effectively
capturing the interplay between the roles. We also create a new dataset
featuring 50 hours of multi-round conversations with over 1,000 characters,
where participants continuously switch between speaking and listening roles.
Extensive experiments demonstrate that our method significantly enhances the
naturalness and expressiveness of 3D talking heads in dual-speaker
conversations. We recommend watching the supplementary video:
https://ziqiaopeng.github.io/dualtalk.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CXReasonBench: A Benchmark for Evaluating Structured Diagnostic
  Reasoning in Chest X-rays 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18087v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18087v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyungyung Lee, Geon Choi, Jung-Oh Lee, Hangyul Yoon, Hyuk Gi Hong, Edward Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in Large Vision-Language Models (LVLMs) has enabled promising
applications in medical tasks, such as report generation and visual question
answering. However, existing benchmarks focus mainly on the final diagnostic
answer, offering limited insight into whether models engage in clinically
meaningful reasoning. To address this, we present CheXStruct and CXReasonBench,
a structured pipeline and benchmark built on the publicly available
MIMIC-CXR-JPG dataset. CheXStruct automatically derives a sequence of
intermediate reasoning steps directly from chest X-rays, such as segmenting
anatomical regions, deriving anatomical landmarks and diagnostic measurements,
computing diagnostic indices, and applying clinical thresholds. CXReasonBench
leverages this pipeline to evaluate whether models can perform clinically valid
reasoning steps and to what extent they can learn from structured guidance,
enabling fine-grained and transparent assessment of diagnostic reasoning. The
benchmark comprises 18,988 QA pairs across 12 diagnostic tasks and 1,200 cases,
each paired with up to 4 visual inputs, and supports multi-path, multi-stage
evaluation including visual grounding via anatomical region selection and
diagnostic measurements. Even the strongest of 10 evaluated LVLMs struggle with
structured reasoning and generalization, often failing to link abstract
knowledge with anatomically grounded visual interpretation. The code is
available at https://github.com/ttumyche/CXReasonBench
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Video Discovery: Agentic Search with Tool Use for Long-form Video
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18079v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18079v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-form video understanding presents significant challenges due to
extensive temporal-spatial complexity and the difficulty of question answering
under such extended contexts. While Large Language Models (LLMs) have
demonstrated considerable advancements in video analysis capabilities and long
context handling, they continue to exhibit limitations when processing
information-dense hour-long videos. To overcome such limitations, we propose
the Deep Video Discovery agent to leverage an agentic search strategy over
segmented video clips. Different from previous video agents manually designing
a rigid workflow, our approach emphasizes the autonomous nature of agents. By
providing a set of search-centric tools on multi-granular video database, our
DVD agent leverages the advanced reasoning capability of LLM to plan on its
current observation state, strategically selects tools, formulates appropriate
parameters for actions, and iteratively refines its internal reasoning in light
of the gathered information. We perform comprehensive evaluation on multiple
long video understanding benchmarks that demonstrates the advantage of the
entire system design. Our DVD agent achieves SOTA performance, significantly
surpassing prior works by a large margin on the challenging LVBench dataset.
Comprehensive ablation studies and in-depth tool analyses are also provided,
yielding insights to further advance intelligent agents tailored for long-form
video understanding tasks. The code will be released later.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DanceTogether! Identity-Preserving Multi-Person Interactive Video
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhao Chen, Mingjin Chen, Jianjin Xu, Xiang Li, Junting Dong, Mingze Sun, Puhua Jiang, Hongxiang Li, Yuhang Yang, Hao Zhao, Xiaoxiao Long, Ruqi Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable video generation (CVG) has advanced rapidly, yet current systems
falter when more than one actor must move, interact, and exchange positions
under noisy control signals. We address this gap with DanceTogether, the first
end-to-end diffusion framework that turns a single reference image plus
independent pose-mask streams into long, photorealistic videos while strictly
preserving every identity. A novel MaskPoseAdapter binds "who" and "how" at
every denoising step by fusing robust tracking masks with semantically rich-but
noisy-pose heat-maps, eliminating the identity drift and appearance bleeding
that plague frame-wise pipelines. To train and evaluate at scale, we introduce
(i) PairFS-4K, 26 hours of dual-skater footage with 7,000+ distinct IDs, (ii)
HumanRob-300, a one-hour humanoid-robot interaction set for rapid cross-domain
transfer, and (iii) TogetherVideoBench, a three-track benchmark centered on the
DanceTogEval-100 test suite covering dance, boxing, wrestling, yoga, and figure
skating. On TogetherVideoBench, DanceTogether outperforms the prior arts by a
significant margin. Moreover, we show that a one-hour fine-tune yields
convincing human-robot videos, underscoring broad generalization to embodied-AI
and HRI tasks. Extensive ablations confirm that persistent identity-action
binding is critical to these gains. Together, our model, datasets, and
benchmark lift CVG from single-subject choreography to compositionally
controllable, multi-actor interaction, opening new avenues for digital
production, simulation, and embodied intelligence. Our video demos and code are
available at https://DanceTog.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our video demos and code are available at https://DanceTog.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic Correspondence: Unified Benchmarking and a Strong Baseline 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiyan Zhang, Xinghui Li, Jingyi Lu, Kai Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Establishing semantic correspondence is a challenging task in computer
vision, aiming to match keypoints with the same semantic information across
different images. Benefiting from the rapid development of deep learning,
remarkable progress has been made over the past decade. However, a
comprehensive review and analysis of this task remains absent. In this paper,
we present the first extensive survey of semantic correspondence methods. We
first propose a taxonomy to classify existing methods based on the type of
their method designs. These methods are then categorized accordingly, and we
provide a detailed analysis of each approach. Furthermore, we aggregate and
summarize the results of methods in literature across various benchmarks into a
unified comparative table, with detailed configurations to highlight
performance variations. Additionally, to provide a detailed understanding on
existing methods for semantic matching, we thoroughly conduct controlled
experiments to analyse the effectiveness of the components of different
methods. Finally, we propose a simple yet effective baseline that achieves
state-of-the-art performance on multiple benchmarks, providing a solid
foundation for future research in this field. We hope this survey serves as a
comprehensive reference and consolidated baseline for future development. Code
is publicly available at: https://github.com/Visual-AI/Semantic-Correspondence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Foundation Model Framework for Multi-View MRI Classification of
  Extramural Vascular Invasion and Mesorectal Fascia Invasion in Rectal Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18058v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18058v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yumeng Zhang, Zohaib Salahuddin, Danial Khan, Shruti Atul Mali, Henry C. Woodruff, Sina Amirrajab, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Luis Marti-Bonmati, Philippe Lambin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: Accurate MRI-based identification of extramural vascular invasion
(EVI) and mesorectal fascia invasion (MFI) is pivotal for risk-stratified
management of rectal cancer, yet visual assessment is subjective and vulnerable
to inter-institutional variability. Purpose: To develop and externally evaluate
a multicenter, foundation-model-driven framework that automatically classifies
EVI and MFI on axial and sagittal T2-weighted MRI. Methods: This retrospective
study used 331 pre-treatment rectal cancer MRI examinations from three European
hospitals. After TotalSegmentator-guided rectal patch extraction, a
self-supervised frequency-domain harmonization pipeline was trained to minimize
scanner-related contrast shifts. Four classifiers were compared: ResNet50,
SeResNet, the universal biomedical pretrained transformer (UMedPT) with a
lightweight MLP head, and a logistic-regression variant using frozen UMedPT
features (UMedPT_LR). Results: UMedPT_LR achieved the best EVI detection when
axial and sagittal features were fused (AUC = 0.82; sensitivity = 0.75; F1
score = 0.73), surpassing the Chaimeleon Grand-Challenge winner (AUC = 0.74).
The highest MFI performance was attained by UMedPT on axial harmonized images
(AUC = 0.77), surpassing the Chaimeleon Grand-Challenge winner (AUC = 0.75).
Frequency-domain harmonization improved MFI classification but variably
affected EVI performance. Conventional CNNs (ResNet50, SeResNet)
underperformed, especially in F1 score and balanced accuracy. Conclusion: These
findings demonstrate that combining foundation model features, harmonization,
and multi-view fusion significantly enhances diagnostic performance in rectal
MRI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FDBPL: Faster Distillation-Based <span class="highlight-title">Prompt</span> Learning for Region-Aware
  Vision-Language Models Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zherui Zhang, Jiaxin Wu, Changwei Wang, Rongtao Xu, Longzhao Huang, Wenhao Xu, Wenbo Xu, Li Guo, Shibiao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning as a parameter-efficient method that has been widely adopted
to adapt Vision-Language Models (VLMs) to downstream tasks. While hard-prompt
design requires domain expertise and iterative optimization, soft-prompt
methods rely heavily on task-specific hard labels, limiting their
generalization to unseen categories. Recent popular distillation-based prompt
learning methods improve generalization by exploiting larger teacher VLMs and
unsupervised knowledge transfer, yet their repetitive teacher model online
inference sacrifices the inherent training efficiency advantage of prompt
learning. In this paper, we propose {{\large {\textbf{F}}}}aster {{\large
{\textbf{D}}}}istillation-{{\large {\textbf{B}}}}ased {{\large
{\textbf{P}}}}rompt {{\large {\textbf{L}}}}earning (\textbf{FDBPL}), which
addresses these issues by sharing soft supervision contexts across multiple
training stages and implementing accelerated I/O. Furthermore, FDBPL introduces
a region-aware prompt learning paradigm with dual positive-negative prompt
spaces to fully exploit randomly cropped regions that containing multi-level
information. We propose a positive-negative space mutual learning mechanism
based on similarity-difference learning, enabling student CLIP models to
recognize correct semantics while learning to reject weakly related concepts,
thereby improving zero-shot performance. Unlike existing distillation-based
prompt learning methods that sacrifice parameter efficiency for generalization,
FDBPL maintains dual advantages of parameter efficiency and strong downstream
generalization. Comprehensive evaluations across 11 datasets demonstrate
superior performance in base-to-new generalization, cross-dataset transfer, and
robustness tests, achieving $2.2\times$ faster training speed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BOTM: Echocardiography Segmentation via Bi-directional Optimal Token
  Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18052v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18052v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihua Liu, Lei Tong, Xilin He, Che Liu, Rossella Arcucci, Chen Jin, Huiyu Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existed echocardiography segmentation methods often suffer from anatomical
inconsistency challenge caused by shape variation, partial observation and
region ambiguity with similar intensity across 2D echocardiographic sequences,
resulting in false positive segmentation with anatomical defeated structures in
challenging low signal-to-noise ratio conditions. To provide a strong
anatomical guarantee across different echocardiographic frames, we propose a
novel segmentation framework named BOTM (Bi-directional Optimal Token Matching)
that performs echocardiography segmentation and optimal anatomy transportation
simultaneously. Given paired echocardiographic images, BOTM learns to match two
sets of discrete image tokens by finding optimal correspondences from a novel
anatomical transportation perspective. We further extend the token matching
into a bi-directional cross-transport attention proxy to regulate the preserved
anatomical consistency within the cardiac cyclic deformation in temporal
domain. Extensive experimental results show that BOTM can generate stable and
accurate segmentation outcomes (e.g. -1.917 HD on CAMUS2H LV, +1.9% Dice on
TED), and provide a better matching interpretation with anatomical consistency
guarantee.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LookWhere? Efficient Visual Recognition by Learning Where to Look and
  What to See from Self-Supervision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anthony Fuller, Yousef Yassin, Junfeng Wen, Daniel G. Kyrollos, Tarek Ibrahim, James R. Green, Evan Shelhamer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision transformers are ever larger, more accurate, and more expensive to
compute. The expense is even more extreme at high resolution as the number of
tokens grows quadratically with the image size. We turn to adaptive computation
to cope with this cost by learning to predict where to compute. Our LookWhere
method divides the computation between a low-resolution selector and a
high-resolution extractor without ever processing the full high-resolution
input. We jointly pretrain the selector and extractor without task supervision
by distillation from a self-supervised teacher, in effect, learning where and
what to compute simultaneously. Unlike prior token reduction methods, which pay
to save by pruning already-computed tokens, and prior token selection methods,
which require complex and expensive per-task optimization, LookWhere
economically and accurately selects and extracts transferrable representations
of images. We show that LookWhere excels at sparse recognition on
high-resolution inputs (Traffic Signs), maintaining accuracy while reducing
FLOPs by up to 34x and time by 6x. It also excels at standard recognition tasks
that are global (ImageNet classification) or local (ADE20K segmentation),
improving accuracy while reducing time by 1.36x.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpikeGen: Generative Framework for Visual Spike Stream Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18049v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18049v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaole Dai, Menghang Dong, Rongyu Zhang, Ruichuan An, Shanghang Zhang, Tiejun Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neuromorphic Visual Systems, such as spike cameras, have attracted
considerable attention due to their ability to capture clear textures under
dynamic conditions. This capability effectively mitigates issues related to
motion and aperture blur. However, in contrast to conventional RGB modalities
that provide dense spatial information, these systems generate binary,
spatially sparse frames as a trade-off for temporally rich visual streams. In
this context, generative models emerge as a promising solution to address the
inherent limitations of sparse data. These models not only facilitate the
conditional fusion of existing information from both spike and RGB modalities
but also enable the conditional generation based on latent priors. In this
study, we introduce a robust generative processing framework named SpikeGen,
designed for visual spike streams captured by spike cameras. We evaluate this
framework across multiple tasks involving mixed spike-RGB modalities, including
conditional image/video deblurring, dense frame reconstruction from spike
streams, and high-speed scene novel-view synthesis. Supported by comprehensive
experimental results, we demonstrate that leveraging the latent space operation
abilities of generative models allows us to effectively address the sparsity of
spatial information while fully exploiting the temporal richness of spike
streams, thereby promoting a synergistic enhancement of different visual
modalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SHARDeg: A Benchmark for Skeletal Human Action Recognition in Degraded
  Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18048v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18048v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Malzard, Nitish Mital, Richard Walters, Victoria Nockles, Raghuveer Rao, Celso M. De Melo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computer vision (CV) models for detection, prediction or classification tasks
operate on video data-streams that are often degraded in the real world, due to
deployment in real-time or on resource-constrained hardware. It is therefore
critical that these models are robust to degraded data, but state of the art
(SoTA) models are often insufficiently assessed with these real-world
constraints in mind. This is exemplified by Skeletal Human Action Recognition
(SHAR), which is critical in many CV pipelines operating in real-time and at
the edge, but robustness to degraded data has previously only been shallowly
and inconsistently assessed. Here we address this issue for SHAR by providing
an important first data degradation benchmark on the most detailed and largest
3D open dataset, NTU-RGB+D-120, and assess the robustness of five leading SHAR
models to three forms of degradation that represent real-world issues. We
demonstrate the need for this benchmark by showing that the form of
degradation, which has not previously been considered, has a large impact on
model accuracy; at the same effective frame rate, model accuracy can vary by
>40% depending on degradation type. We also identify that temporal regularity
of frames in degraded SHAR data is likely a major driver of differences in
model performance, and harness this to improve performance of existing models
by up to >40%, through employing a simple mitigation approach based on
interpolation. Finally, we highlight how our benchmark has helped identify an
important degradation-resistant SHAR model based in Rough Path Theory; the
LogSigRNN SHAR model outperforms the SoTA DeGCN model in five out of six cases
at low frame rates by an average accuracy of 6%, despite trailing the SoTA
model by 11-12% on un-degraded data at high frame rates (30 FPS).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 2 images</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RestoreVAR: Visual Autoregressive Generation for All-in-One Image
  Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18047v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18047v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sudarshan Rajagopalan, Kartik Narayan, Vishal M. Patel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The use of latent diffusion models (LDMs) such as Stable Diffusion has
significantly improved the perceptual quality of All-in-One image Restoration
(AiOR) methods, while also enhancing their generalization capabilities.
However, these LDM-based frameworks suffer from slow inference due to their
iterative denoising process, rendering them impractical for time-sensitive
applications. To address this, we propose RestoreVAR, a novel generative
approach for AiOR that significantly outperforms LDM-based models in
restoration performance while achieving over $\mathbf{10\times}$ faster
inference. RestoreVAR leverages visual autoregressive modeling (VAR), a
recently introduced approach which performs scale-space autoregression for
image generation. VAR achieves comparable performance to that of
state-of-the-art diffusion transformers with drastically reduced computational
costs. To optimally exploit these advantages of VAR for AiOR, we propose
architectural modifications and improvements, including intricately designed
cross-attention mechanisms and a latent-space refinement module, tailored for
the AiOR task. Extensive experiments show that RestoreVAR achieves
state-of-the-art performance among generative AiOR methods, while also
exhibiting strong generalization capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://sudraj2002.github.io/restorevarpage/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via
  Cross-Architecture CLIP Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18039v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18039v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Zhong, Ahmed Ghazal, Jun-Jun Wan, Frederik Zilly, Patrick Mackens, Joachim E. Vollrath, Bogdan Sorin Coseriu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models like CLIP (Contrastive Language-Image Pretraining) have
revolutionized vision-language tasks by enabling zero-shot and few-shot
learning through cross-modal alignment. However, their computational complexity
and large memory footprint make them unsuitable for deployment on
resource-constrained edge devices, such as in-car cameras used for image
collection and real-time processing. To address this challenge, we propose
Clip4Retrofit, an efficient model distillation framework that enables real-time
image labeling on edge devices. The framework is deployed on the Retrofit
camera, a cost-effective edge device retrofitted into thousands of vehicles,
despite strict limitations on compute performance and memory. Our approach
distills the knowledge of the CLIP model into a lightweight student model,
combining EfficientNet-B3 with multi-layer perceptron (MLP) projection heads to
preserve cross-modal alignment while significantly reducing computational
requirements. We demonstrate that our distilled model achieves a balance
between efficiency and performance, making it ideal for deployment in
real-world scenarios. Experimental results show that Clip4Retrofit can perform
real-time image labeling and object identification on edge devices with limited
resources, offering a practical solution for applications such as autonomous
driving and retrofitting existing systems. This work bridges the gap between
state-of-the-art vision-language models and their deployment in
resource-constrained environments, paving the way for broader adoption of
foundation models in edge computing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CAMME: Adaptive Deepfake Image Detection with Multi-Modal
  Cross-Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naseem Khan, Tuan Nguyen, Amine Bermak, Issa Khalil
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proliferation of sophisticated AI-generated deepfakes poses critical
challenges for digital media authentication and societal security. While
existing detection methods perform well within specific generative domains,
they exhibit significant performance degradation when applied to manipulations
produced by unseen architectures--a fundamental limitation as generative
technologies rapidly evolve. We propose CAMME (Cross-Attention Multi-Modal
Embeddings), a framework that dynamically integrates visual, textual, and
frequency-domain features through a multi-head cross-attention mechanism to
establish robust cross-domain generalization. Extensive experiments demonstrate
CAMME's superiority over state-of-the-art methods, yielding improvements of
12.56% on natural scenes and 13.25% on facial deepfakes. The framework
demonstrates exceptional resilience, maintaining (over 91%) accuracy under
natural image perturbations and achieving 89.01% and 96.14% accuracy against
PGD and FGSM adversarial attacks, respectively. Our findings validate that
integrating complementary modalities through cross-attention enables more
effective decision boundary realignment for reliable deepfake detection across
heterogeneous generative architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 8 figures, 12 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mahalanobis++: Improving OOD Detection via Feature Normalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18032v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18032v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Mueller, Matthias Hein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting out-of-distribution (OOD) examples is an important task for
deploying reliable machine learning models in safety-critial applications.
While post-hoc methods based on the Mahalanobis distance applied to pre-logit
features are among the most effective for ImageNet-scale OOD detection, their
performance varies significantly across models. We connect this inconsistency
to strong variations in feature norms, indicating severe violations of the
Gaussian assumption underlying the Mahalanobis distance estimation. We show
that simple $\ell_2$-normalization of the features mitigates this problem
effectively, aligning better with the premise of normally distributed data with
shared covariance matrix. Extensive experiments on 44 models across diverse
architectures and pretraining schemes show that $\ell_2$-normalization improves
the conventional Mahalanobis distance-based approaches significantly and
consistently, and outperforms other recently proposed OOD detection methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knot So Simple: A Minimalistic Environment for Spatial Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18028v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18028v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zizhao Chen, Yoav Artzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose KnotGym, an interactive environment for complex, spatial reasoning
and manipulation. KnotGym includes goal-oriented rope manipulation tasks with
varying levels of complexity, all requiring acting from pure image
observations. Tasks are defined along a clear and quantifiable axis of
complexity based on the number of knot crossings, creating a natural
generalization test. KnotGym has a simple observation space, allowing for
scalable development, yet it highlights core challenges in integrating acute
perception, spatial reasoning, and grounded manipulation. We evaluate methods
of different classes, including model-based RL, model-predictive control, and
chain-of-thought reasoning, and illustrate the challenges KnotGym presents.
KnotGym is available at https://github.com/lil-lab/knotgym.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3D Face Reconstruction Error Decomposed: A Modular Benchmark for Fair
  and Fast Method Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18025v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18025v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Evangelos Sariyanidi, Claudio Ferrari, Federico Nocentini, Stefano Berretti, Andrea Cavallaro, Birkan Tunc
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computing the standard benchmark metric for 3D face reconstruction, namely
geometric error, requires a number of steps, such as mesh cropping, rigid
alignment, or point correspondence. Current benchmark tools are monolithic
(they implement a specific combination of these steps), even though there is no
consensus on the best way to measure error. We present a toolkit for a
Modularized 3D Face reconstruction Benchmark (M3DFB), where the fundamental
components of error computation are segregated and interchangeable, allowing
one to quantify the effect of each. Furthermore, we propose a new component,
namely correction, and present a computationally efficient approach that
penalizes for mesh topology inconsistency. Using this toolkit, we test 16 error
estimators with 10 reconstruction methods on two real and two synthetic
datasets. Critically, the widely used ICP-based estimator provides the worst
benchmarking performance, as it significantly alters the true ranking of the
top-5 reconstruction methods. Notably, the correlation of ICP with the true
error can be as low as 0.41. Moreover, non-rigid alignment leads to significant
improvement (correlation larger than 0.90), highlighting the importance of
annotating 3D landmarks on datasets. Finally, the proposed correction scheme,
together with non-rigid warping, leads to an accuracy on a par with the best
non-rigid ICP-based estimators, but runs an order of magnitude faster. Our
open-source codebase is designed for researchers to easily compare alternatives
for each component, thus helping accelerating progress in benchmarking for 3D
face reconstruction and, furthermore, supporting the improvement of learned
reconstruction methods, which depend on accurate error estimation for effective
training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be published in IEEE International Conference on Automatic Face
  and Gesture Recognition, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Wavelet-based Stereo Matching Framework for Solving Frequency
  Convergence Inconsistency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18024v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18024v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaobao Wei, Jiawei Liu, Dongbo Yang, Junda Cheng, Changyong Shu, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We find that the EPE evaluation metrics of RAFT-stereo converge
inconsistently in the low and high frequency regions, resulting high frequency
degradation (e.g., edges and thin objects) during the iterative process. The
underlying reason for the limited performance of current iterative methods is
that it optimizes all frequency components together without distinguishing
between high and low frequencies. We propose a wavelet-based stereo matching
framework (Wavelet-Stereo) for solving frequency convergence inconsistency.
Specifically, we first explicitly decompose an image into high and low
frequency components using discrete wavelet transform. Then, the high-frequency
and low-frequency components are fed into two different multi-scale frequency
feature extractors. Finally, we propose a novel LSTM-based high-frequency
preservation update operator containing an iterative frequency adapter to
provide adaptive refined high-frequency features at different iteration steps
by fine-tuning the initial high-frequency features. By processing high and low
frequency components separately, our framework can simultaneously refine
high-frequency information in edges and low-frequency information in smooth
regions, which is especially suitable for challenging scenes with fine details
and textures in the distance. Extensive experiments demonstrate that our
Wavelet-Stereo outperforms the state-of-the-art methods and ranks 1st on both
the KITTI 2015 and KITTI 2012 leaderboards for almost all metrics. We will
provide code and pre-trained models to encourage further exploration,
application, and development of our innovative framework
(https://github.com/SIA-IDE/Wavelet-Stereo).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RemoteSAM: Towards Segment Anything for Earth Observation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Yao, Fan Liu, Delong Chen, Chuanyi Zhang, Yijun Wang, Ziyun Chen, Wei Xu, Shimin Di, Yuhui Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We aim to develop a robust yet flexible visual foundation model for Earth
observation. It should possess strong capabilities in recognizing and
localizing diverse visual targets while providing compatibility with various
input-output interfaces required across different task scenarios. Current
systems cannot meet these requirements, as they typically utilize task-specific
architecture trained on narrow data domains with limited semantic coverage. Our
study addresses these limitations from two aspects: data and modeling. We first
introduce an automatic data engine that enjoys significantly better scalability
compared to previous human annotation or rule-based approaches. It has enabled
us to create the largest dataset of its kind to date, comprising 270K
image-text-mask triplets covering an unprecedented range of diverse semantic
categories and attribute specifications. Based on this data foundation, we
further propose a task unification paradigm that centers around referring
expression segmentation. It effectively handles a wide range of vision-centric
perception tasks, including classification, detection, segmentation, grounding,
etc, using a single model without any task-specific heads. Combining these
innovations on data and modeling, we present RemoteSAM, a foundation model that
establishes new SoTA on several earth observation perception benchmarks,
outperforming other foundation models such as Falcon, GeoChat, and LHRS-Bot
with significantly higher efficiency. Models and data are publicly available at
https://github.com/1e12Leon/RemoteSAM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Building Floor Number Estimation from Crowdsourced Street-Level Images:
  Munich <span class="highlight-title">Dataset</span> and Baseline Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18021v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18021v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao Sun, Sining Chen, Yifan Tian, Xiao Xiang Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate information on the number of building floors, or above-ground
storeys, is essential for household estimation, utility provision, risk
assessment, evacuation planning, and energy modeling. Yet large-scale
floor-count data are rarely available in cadastral and 3D city databases. This
study proposes an end-to-end deep learning framework that infers floor numbers
directly from unrestricted, crowdsourced street-level imagery, avoiding
hand-crafted features and generalizing across diverse facade styles. To enable
benchmarking, we release the Munich Building Floor Dataset, a public set of
over 6800 geo-tagged images collected from Mapillary and targeted field
photography, each paired with a verified storey label. On this dataset, the
proposed classification-regression network attains 81.2% exact accuracy and
predicts 97.9% of buildings within +/-1 floor. The method and dataset together
offer a scalable route to enrich 3D city models with vertical information and
lay a foundation for future work in urban informatics, remote sensing, and
geographic information science. Source code and data will be released under an
open license at https://github.com/ya0-sun/Munich-SVI-Floor-Benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and data: https://github.com/ya0-sun/Munich-SVI-Floor-Benchmark</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SemSegBench & DetecBench: Benchmarking Reliability and Generalization
  Beyond Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18015v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18015v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shashank Agnihotri, David Schader, Jonas Jakubassa, Nico Sharei, Simon Kral, Mehmet Ege Kaçar, Ruben Weber, Margret Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reliability and generalization in deep learning are predominantly studied in
the context of image classification. Yet, real-world applications in
safety-critical domains involve a broader set of semantic tasks, such as
semantic segmentation and object detection, which come with a diverse set of
dedicated model architectures. To facilitate research towards robust model
design in segmentation and detection, our primary objective is to provide
benchmarking tools regarding robustness to distribution shifts and adversarial
manipulations. We propose the benchmarking tools SEMSEGBENCH and DETECBENCH,
along with the most extensive evaluation to date on the reliability and
generalization of semantic segmentation and object detection models. In
particular, we benchmark 76 segmentation models across four datasets and 61
object detectors across two datasets, evaluating their performance under
diverse adversarial attacks and common corruptions. Our findings reveal
systematic weaknesses in state-of-the-art models and uncover key trends based
on architecture, backbone, and model capacity. SEMSEGBENCH and DETECBENCH are
open-sourced in our GitHub repository
(https://github.com/shashankskagnihotri/benchmarking_reliability_generalization)
along with our complete set of total 6139 evaluations. We anticipate the
collected data to foster and encourage future research towards improved model
reliability beyond classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First seven listed authors have equal contribution. GitHub:
  https://github.com/shashankskagnihotri/benchmarking_reliability_generalization.
  arXiv admin note: text overlap with arXiv:2505.05091</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Clinical Validation of Deep Learning for Real-Time Tissue Oxygenation
  Estimation Using Spectral Imaging <span class="chip">MICCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18010v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18010v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jens De Winne, Siri Willems, Siri Luthman, Danilo Babin, Hiep Luong, Wim Ceelen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate, real-time monitoring of tissue ischemia is crucial to understand
tissue health and guide surgery. Spectral imaging shows great potential for
contactless and intraoperative monitoring of tissue oxygenation. Due to the
difficulty of obtaining direct reference oxygenation values, conventional
methods are based on linear unmixing techniques. These are prone to assumptions
and these linear relations may not always hold in practice. In this work, we
present deep learning approaches for real-time tissue oxygenation estimation
using Monte-Carlo simulated spectra. We train a fully connected neural network
(FCN) and a convolutional neural network (CNN) for this task and propose a
domain-adversarial training approach to bridge the gap between simulated and
real clinical spectral data. Results demonstrate that these deep learning
models achieve a higher correlation with capillary lactate measurements, a
well-known marker of hypoxia, obtained during spectral imaging in surgery,
compared to traditional linear unmixing. Notably, domain-adversarial training
effectively reduces the domain gap, optimizing performance in real clinical
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Provisionally accepted to the MICCAI 2025 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segment Anyword: Mask <span class="highlight-title">Prompt</span> Inversion for Open-Set Grounded
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihua Liu, Amrutha Saseendran, Lei Tong, Xilin He, Fariba Yousefi, Nikolay Burlutskiy, Dino Oglic, Tom Diethe, Philip Teare, Huiyu Zhou, Chen Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-set image segmentation poses a significant challenge because existing
methods often demand extensive training or fine-tuning and generally struggle
to segment unified objects consistently across diverse text reference
expressions. Motivated by this, we propose Segment Anyword, a novel
training-free visual concept prompt learning approach for open-set language
grounded segmentation that relies on token-level cross-attention maps from a
frozen diffusion model to produce segmentation surrogates or mask prompts,
which are then refined into targeted object masks. Initial prompts typically
lack coherence and consistency as the complexity of the image-text increases,
resulting in suboptimal mask fragments. To tackle this issue, we further
introduce a novel linguistic-guided visual prompt regularization that binds and
clusters visual prompts based on sentence dependency and syntactic structural
information, enabling the extraction of robust, noise-tolerant mask prompts,
and significant improvements in segmentation accuracy. The proposed approach is
effective, generalizes across different open-set segmentation tasks, and
achieves state-of-the-art results of 52.5 (+6.8 relative) mIoU on Pascal
Context 59, 67.73 (+25.73 relative) cIoU on gRefCOCO, and 67.4 (+1.1 relative
to fine-tuned methods) mIoU on GranDf, which is the most complex open-set
grounded segmentation task in the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Canonical Pose Reconstruction from Single Depth Image for 3D Non-rigid
  Pose Recovery on Limited <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17992v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17992v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fahd Alhamazani, Yu-Kun Lai, Paul L. Rosin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D reconstruction from 2D inputs, especially for non-rigid objects like
humans, presents unique challenges due to the significant range of possible
deformations. Traditional methods often struggle with non-rigid shapes, which
require extensive training data to cover the entire deformation space. This
study addresses these limitations by proposing a canonical pose reconstruction
model that transforms single-view depth images of deformable shapes into a
canonical form. This alignment facilitates shape reconstruction by enabling the
application of rigid object reconstruction techniques, and supports recovering
the input pose in voxel representation as part of the reconstruction task,
utilizing both the original and deformed depth images. Notably, our model
achieves effective results with only a small dataset of approximately 300
samples. Experimental results on animal and human datasets demonstrate that our
model outperforms other state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language
  Alignment and Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17982v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17982v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bryan Wong, Jong Woo Kim, Huazhu Fu, Mun Yong Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have recently been integrated into multiple
instance learning (MIL) frameworks to address the challenge of few-shot, weakly
supervised classification of whole slide images (WSIs). A key trend involves
leveraging multi-scale information to better represent hierarchical tissue
structures. However, existing methods often face two key limitations: (1)
insufficient modeling of interactions within the same modalities across scales
(e.g., 5x and 20x) and (2) inadequate alignment between visual and textual
modalities on the same scale. To address these gaps, we propose HiVE-MIL, a
hierarchical vision-language framework that constructs a unified graph
consisting of (1) parent-child links between coarse (5x) and fine (20x)
visual/textual nodes to capture hierarchical relationships, and (2)
heterogeneous intra-scale edges linking visual and textual nodes on the same
scale. To further enhance semantic consistency, HiVE-MIL incorporates a
two-stage, text-guided dynamic filtering mechanism that removes weakly
correlated patch-text pairs, and introduces a hierarchical contrastive loss to
align textual semantics across scales. Extensive experiments on TCGA breast,
lung, and kidney cancer datasets demonstrate that HiVE-MIL consistently
outperforms both traditional MIL and recent VLM-based MIL approaches, achieving
gains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate
the value of jointly modeling hierarchical structure and multimodal alignment
for efficient and scalable learning from limited pathology data. The code is
available at https://github.com/bryanwong17/HiVE-MIL
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ To Glue or Not to Glue? Classical vs Learned Image Matching for Mobile
  Mapping Cameras to Textured Semantic 3D Building Models <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simone Gaisbauer, Prabin Gyawali, Qilin Zhang, Olaf Wysocki, Boris Jutzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feature matching is a necessary step for many computer vision and
photogrammetry applications such as image registration, structure-from-motion,
and visual localization. Classical handcrafted methods such as SIFT feature
detection and description combined with nearest neighbour matching and RANSAC
outlier removal have been state-of-the-art for mobile mapping cameras. With
recent advances in deep learning, learnable methods have been introduced and
proven to have better robustness and performance under complex conditions.
Despite their growing adoption, a comprehensive comparison between classical
and learnable feature matching methods for the specific task of semantic 3D
building camera-to-model matching is still missing. This submission
systematically evaluates the effectiveness of different feature-matching
techniques in visual localization using textured CityGML LoD2 models. We use
standard benchmark datasets (HPatches, MegaDepth-1500) and custom datasets
consisting of facade textures and corresponding camera images (terrestrial and
drone). For the latter, we evaluate the achievable accuracy of the absolute
pose estimated using a Perspective-n-Point (PnP) algorithm, with geometric
ground truth derived from geo-referenced trajectory data. The results indicate
that the learnable feature matching methods vastly outperform traditional
approaches regarding accuracy and robustness on our challenging custom datasets
with zero to 12 RANSAC-inliers and zero to 0.16 area under the curve. We
believe that this work will foster the development of model-based visual
localization methods. Link to the code:
https://github.com/simBauer/To\_Glue\_or\_not\_to\_Glue
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to MMT, Xiamen, China; ISPRS Annals</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MR-EEGWaveNet: Multiresolutional EEGWaveNet for Seizure Detection from
  Long EEG Recordings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17972v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17972v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazi Mahmudul Hassan, Xuyang Zhao, Hidenori Sugano, Toshihisa Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feature engineering for generalized seizure detection models remains a
significant challenge. Recently proposed models show variable performance
depending on the training data and remain ineffective at accurately
distinguishing artifacts from seizure data. In this study, we propose a novel
end-to-end model, ''Multiresolutional EEGWaveNet (MR-EEGWaveNet),'' which
efficiently distinguishes seizure events from background electroencephalogram
(EEG) and artifacts/noise by capturing both temporal dependencies across
different time frames and spatial relationships between channels. The model has
three modules: convolution, feature extraction, and predictor. The convolution
module extracts features through depth-wise and spatio-temporal convolution.
The feature extraction module individually reduces the feature dimension
extracted from EEG segments and their sub-segments. Subsequently, the extracted
features are concatenated into a single vector for classification using a fully
connected classifier called the predictor module. In addition, an anomaly
score-based post-classification processing technique was introduced to reduce
the false-positive rates of the model. Experimental results were reported and
analyzed using different parameter settings and datasets (Siena (public) and
Juntendo (private)). The proposed MR-EEGWaveNet significantly outperformed the
conventional non-multiresolution approach, improving the F1 scores from 0.177
to 0.336 on Siena and 0.327 to 0.488 on Juntendo, with precision gains of 15.9%
and 20.62%, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explainable Anatomy-Guided AI for Prostate MRI: Foundation Models and In
  Silico Clinical Trials for Virtual Biopsy-based Risk Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17971v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17971v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danial Khan, Zohaib Salahuddin, Yumeng Zhang, Sheng Kuang, Shruti Atul Mali, Henry C. Woodruff, Sina Amirrajab, Rachel Cavill, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Adrian Galiana-Bordera, Paula Jimenez Gomez, Luis Marti-Bonmati, Philippe Lambin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a fully automated, anatomically guided deep learning pipeline for
prostate cancer (PCa) risk stratification using routine MRI. The pipeline
integrates three key components: an nnU-Net module for segmenting the prostate
gland and its zones on axial T2-weighted MRI; a classification module based on
the UMedPT Swin Transformer foundation model, fine-tuned on 3D patches with
optional anatomical priors and clinical data; and a VAE-GAN framework for
generating counterfactual heatmaps that localize decision-driving image
regions. The system was developed using 1,500 PI-CAI cases for segmentation and
617 biparametric MRIs with metadata from the CHAIMELEON challenge for
classification (split into 70% training, 10% validation, and 20% testing).
Segmentation achieved mean Dice scores of 0.95 (gland), 0.94 (peripheral zone),
and 0.92 (transition zone). Incorporating gland priors improved AUC from 0.69
to 0.72, with a three-scale ensemble achieving top performance (AUC = 0.79,
composite score = 0.76), outperforming the 2024 CHAIMELEON challenge winners.
Counterfactual heatmaps reliably highlighted lesions within segmented regions,
enhancing model interpretability. In a prospective multi-center in-silico trial
with 20 clinicians, AI assistance increased diagnostic accuracy from 0.72 to
0.77 and Cohen's kappa from 0.43 to 0.53, while reducing review time per case
by 40%. These results demonstrate that anatomy-aware foundation models with
counterfactual explainability can enable accurate, interpretable, and efficient
PCa risk assessment, supporting their potential use as virtual biopsies in
clinical practice.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Single-View Mesh Reconstruction Ready for Robotics? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17966v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17966v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederik Nolte, Bernhard Schölkopf, Ingmar Posner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper evaluates single-view mesh reconstruction models for creating
digital twin environments in robot manipulation. Recent advances in computer
vision for 3D reconstruction from single viewpoints present a potential
breakthrough for efficiently creating virtual replicas of physical environments
for robotics contexts. However, their suitability for physics simulations and
robotics applications remains unexplored. We establish benchmarking criteria
for 3D reconstruction in robotics contexts, including handling typical inputs,
producing collision-free and stable reconstructions, managing occlusions, and
meeting computational constraints. Our empirical evaluation using realistic
robotics datasets shows that despite success on computer vision benchmarks,
existing approaches fail to meet robotics-specific requirements. We
quantitively examine limitations of single-view reconstruction for practical
robotics implementation, in contrast to prior work that focuses on multi-view
approaches. Our findings highlight critical gaps between computer vision
advances and robotics needs, guiding future research at this intersection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Domain Gap: Measuring the Domain Gap Between Real-World and
  Synthetic Point Clouds for Automated Driving Development 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nguyen Duc, Yan-Ling Lai, Patrick Madlindl, Xinyuan Zhu, Benedikt Schwab, Olaf Wysocki, Ludwig Hoegner, Thomas H. Kolbe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Owing to the typical long-tail data distribution issues, simulating
domain-gap-free synthetic data is crucial in robotics, photogrammetry, and
computer vision research. The fundamental challenge pertains to credibly
measuring the difference between real and simulated data. Such a measure is
vital for safety-critical applications, such as automated driving, where
out-of-domain samples may impact a car's perception and cause fatal accidents.
Previous work has commonly focused on simulating data on one scene and
analyzing performance on a different, real-world scene, hampering the disjoint
analysis of domain gap coming from networks' deficiencies, class definitions,
and object representation. In this paper, we propose a novel approach to
measuring the domain gap between the real world sensor observations and
simulated data representing the same location, enabling comprehensive domain
gap analysis. To measure such a domain gap, we introduce a novel metric
DoGSS-PCL and evaluation assessing the geometric and semantic quality of the
simulated point cloud. Our experiments corroborate that the introduced approach
can be used to measure the domain gap. The tests also reveal that synthetic
semantic point clouds may be used for training deep neural networks,
maintaining the performance at the 50/50 real-to-synthetic ratio. We strongly
believe that this work will facilitate research on credible data simulation and
allow for at-scale deployment in automated driving testing and digital
twinning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to PFG Journal of Photogrammetry, Remote Sensing and
  Geoinformation Science</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusion Classifiers Understand Compositionality, but Conditions Apply 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17955v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17955v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujin Jeong, Arnas Uselis, Seong Joon Oh, Anna Rohrbach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding visual scenes is fundamental to human intelligence. While
discriminative models have significantly advanced computer vision, they often
struggle with compositional understanding. In contrast, recent generative
text-to-image diffusion models excel at synthesizing complex scenes, suggesting
inherent compositional capabilities. Building on this, zero-shot diffusion
classifiers have been proposed to repurpose diffusion models for discriminative
tasks. While prior work offered promising results in discriminative
compositional scenarios, these results remain preliminary due to a small number
of benchmarks and a relatively shallow analysis of conditions under which the
models succeed. To address this, we present a comprehensive study of the
discriminative capabilities of diffusion classifiers on a wide range of
compositional tasks. Specifically, our study covers three diffusion models (SD
1.5, 2.0, and, for the first time, 3-m) spanning 10 datasets and over 30 tasks.
Further, we shed light on the role that target dataset domains play in
respective performance; to isolate the domain effects, we introduce a new
diagnostic benchmark Self-Bench comprised of images created by diffusion models
themselves. Finally, we explore the importance of timestep weighting and
uncover a relationship between domain gap and timestep sensitivity,
particularly for SD3-m. To sum up, diffusion classifiers understand
compositionality, but conditions apply! Code and dataset are available at
https://github.com/eugene6923/Diffusion-Classifiers-Compositionality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SplatCo: Structure-View Collaborative Gaussian Splatting for
  Detail-Preserving Rendering of Large-Scale Unbounded Scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17951v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17951v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haihong Xiao, Jianan Zou, Yuxin Zhou, Ying He, Wenxiong Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SplatCo, a structure-view collaborative Gaussian splatting
framework for high-fidelity rendering of complex outdoor environments. SplatCo
builds upon two novel components: (1) a cross-structure collaboration module
that combines global tri-plane representations, which capture coarse scene
layouts, with local context grid features that represent fine surface details.
This fusion is achieved through a novel hierarchical compensation strategy,
ensuring both global consistency and local detail preservation; and (2) a
cross-view assisted training strategy that enhances multi-view consistency by
synchronizing gradient updates across viewpoints, applying visibility-aware
densification, and pruning overfitted or inaccurate Gaussians based on
structural consistency. Through joint optimization of structural representation
and multi-view coherence, SplatCo effectively reconstructs fine-grained
geometric structures and complex textures in large-scale scenes. Comprehensive
evaluations on 13 diverse large-scale scenes, including Mill19, MatrixCity,
Tanks & Temples, WHU, and custom aerial captures, demonstrate that SplatCo
consistently achieves higher reconstruction quality than state-of-the-art
methods, with PSNR improvements of 1-2 dB and SSIM gains of 0.1 to 0.2. These
results establish a new benchmark for high-fidelity rendering of large-scale
unbounded scenes. Code and additional information are available at
https://github.com/SCUT-BIP-Lab/SplatCo.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation
  of Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17931v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17931v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image segmentation is vital for clinical diagnosis, yet current deep
learning methods often demand extensive expert effort, i.e., either through
annotating large training datasets or providing prompts at inference time for
each new case. This paper introduces a zero-shot and automatic segmentation
pipeline that combines off-the-shelf vision-language and segmentation
foundation models. Given a medical image and a task definition (e.g., "segment
the optic disc in an eye fundus image"), our method uses a grounding model to
generate an initial bounding box, followed by a visual prompt boosting module
that enhance the prompts, which are then processed by a promptable segmentation
model to produce the final mask. To address the challenges of domain gap and
result verification, we introduce a test-time adaptation framework featuring a
set of learnable adaptors that align the medical inputs with foundation model
representations. Its hyperparameters are optimized via Bayesian Optimization,
guided by a proxy validation model without requiring ground-truth labels. Our
pipeline offers an annotation-efficient and scalable solution for zero-shot
medical image segmentation across diverse tasks. Our pipeline is evaluated on
seven diverse medical imaging datasets and shows promising results. By proper
decomposition and test-time adaptation, our fully automatic pipeline performs
competitively with weakly-prompted interactive foundation models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of Few-Shot Learning Methods for Kidney Stone Type
  Recognition in Ureteroscopy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17921v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17921v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carlos Salazar-Ruiz, Francisco Lopez-Tiro, Ivan Reyes-Amezcua, Clement Larose, Gilberto Ochoa-Ruiz, Christian Daul
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the type of kidney stones is crucial for prescribing appropriate
treatments to prevent recurrence. Currently, various approaches exist to
identify the type of kidney stones. However, obtaining results through the
reference ex vivo identification procedure can take several weeks, while in
vivo visual recognition requires highly trained specialists. For this reason,
deep learning models have been developed to provide urologists with an
automated classification of kidney stones during ureteroscopies. Nevertheless,
a common issue with these models is the lack of training data. This
contribution presents a deep learning method based on few-shot learning, aimed
at producing sufficiently discriminative features for identifying kidney stone
types in endoscopic images, even with a very limited number of samples. This
approach was specifically designed for scenarios where endoscopic images are
scarce or where uncommon classes are present, enabling classification even with
a limited training dataset. The results demonstrate that Prototypical Networks,
using up to 25% of the training data, can achieve performance equal to or
better than traditional deep learning models trained with the complete dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, 3 tables, conference, cbms25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Prompt</span>able cancer segmentation using minimal expert-curated data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17915v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17915v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lynn Karam, Yipei Wang, Veeru Kasivisvanathan, Mirabela Rusu, Yipeng Hu, Shaheer U. Saeed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated segmentation of cancer on medical images can aid targeted
diagnostic and therapeutic procedures. However, its adoption is limited by the
high cost of expert annotations required for training and inter-observer
variability in datasets. While weakly-supervised methods mitigate some
challenges, using binary histology labels for training as opposed to requiring
full segmentation, they require large paired datasets of histology and images,
which are difficult to curate. Similarly, promptable segmentation aims to allow
segmentation with no re-training for new tasks at inference, however, existing
models perform poorly on pathological regions, again necessitating large
datasets for training. In this work we propose a novel approach for promptable
segmentation requiring only 24 fully-segmented images, supplemented by 8
weakly-labelled images, for training. Curating this minimal data to a high
standard is relatively feasible and thus issues with the cost and variability
of obtaining labels can be mitigated. By leveraging two classifiers, one
weakly-supervised and one fully-supervised, our method refines segmentation
through a guided search process initiated by a single-point prompt. Our
approach outperforms existing promptable segmentation methods, and performs
comparably with fully-supervised methods, for the task of prostate cancer
segmentation, while using substantially less annotated data (up to 100X less).
This enables promptable segmentation with very minimal labelled data, such that
the labels can be curated to a very high standard.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Medical Image Understanding and Analysis (MIUA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UltraBoneUDF: <span class="highlight-title">Self-supervised</span> Bone Surface Reconstruction from
  Ultrasound Based on Neural Unsigned Distance Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17912v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17912v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luohong Wu, Matthias Seibold, Nicola A. Cavalcanti, Giuseppe Loggia, Lisa Reissner, Bastian Sigrist, Jonas Hein, Lilian Calvet, Arnd Viehöfer, Philipp Fürnstahl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: Bone surface reconstruction plays a critical role in
computer-assisted orthopedic surgery. Compared to traditional imaging
modalities such as CT and MRI, ultrasound offers a radiation-free,
cost-effective, and portable alternative. Continuous bone surface
reconstruction can be employed for many clinical applications. However, due to
the inherent limitations of ultrasound imaging, B-mode ultrasound typically
capture only partial bone surfaces. Existing reconstruction methods struggle
with such incomplete data, leading to artifacts and increased reconstruction
errors. Effective techniques for accurately reconstructing thin and open bone
surfaces from real-world 3D ultrasound volumes remain lacking. Methods: We
propose UltraBoneUDF, a self-supervised framework designed for reconstructing
open bone surfaces from ultrasound using neural Unsigned Distance Functions. To
enhance reconstruction quality, we introduce a novel global feature extractor
that effectively fuses ultrasound-specific image characteristics. Additionally,
we present a novel loss function based on local tangent plane optimization that
substantially improves surface reconstruction quality. UltraBoneUDF and
baseline models are extensively evaluated on four open-source datasets.
Results: Qualitative results highlight the limitations of the state-of-the-art
methods for open bone surface reconstruction and demonstrate the effectiveness
of UltraBoneUDF. Quantitatively, UltraBoneUDF significantly outperforms
competing methods across all evaluated datasets for both open and closed bone
surface reconstruction in terms of mean Chamfer distance error: 1.10 mm on the
UltraBones100k dataset (39.6\% improvement compared to the SOTA), 0.23 mm on
the OpenBoneCT dataset (69.3\% improvement), 0.18 mm on the ClosedBoneCT
dataset (70.2\% improvement), and 0.05 mm on the Prostate dataset (55.3\%
improvement).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Object-level Cross-view Geo-localization with Location Enhancement and
  Multi-Head Cross Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17911v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17911v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheyang Huang, Jagannath Aryal, Saeid Nahavandi, Xuequan Lu, Chee Peng Lim, Lei Wei, Hailing Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-view geo-localization determines the location of a query image,
captured by a drone or ground-based camera, by matching it to a geo-referenced
satellite image. While traditional approaches focus on image-level
localization, many applications, such as search-and-rescue, infrastructure
inspection, and precision delivery, demand object-level accuracy. This enables
users to prompt a specific object with a single click on a drone image to
retrieve precise geo-tagged information of the object. However, variations in
viewpoints, timing, and imaging conditions pose significant challenges,
especially when identifying visually similar objects in extensive satellite
imagery. To address these challenges, we propose an Object-level Cross-view
Geo-localization Network (OCGNet). It integrates user-specified click locations
using Gaussian Kernel Transfer (GKT) to preserve location information
throughout the network. This cue is dually embedded into the feature encoder
and feature matching blocks, ensuring robust object-specific localization.
Additionally, OCGNet incorporates a Location Enhancement (LE) module and a
Multi-Head Cross Attention (MHCA) module to adaptively emphasize
object-specific features or expand focus to relevant contextual regions when
necessary. OCGNet achieves state-of-the-art performance on a public dataset,
CVOGL. It also demonstrates few-shot learning capabilities, effectively
generalizing from limited examples, making it suitable for diverse applications
(https://github.com/ZheyangH/OCGNet).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffusionReward: Enhancing Blind Face Restoration through Reward
  Feedback Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17910v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17910v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Wu, Wei Wang, Yahui Liu, Zixiang Li, Yao Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward Feedback Learning (ReFL) has recently shown great potential in
aligning model outputs with human preferences across various generative tasks.
In this work, we introduce a ReFL framework, named DiffusionReward, to the
Blind Face Restoration task for the first time. DiffusionReward effectively
overcomes the limitations of diffusion-based methods, which often fail to
generate realistic facial details and exhibit poor identity consistency. The
core of our framework is the Face Reward Model (FRM), which is trained using
carefully annotated data. It provides feedback signals that play a pivotal role
in steering the optimization process of the restoration network. In particular,
our ReFL framework incorporates a gradient flow into the denoising process of
off-the-shelf face restoration methods to guide the update of model parameters.
The guiding gradient is collaboratively determined by three aspects: (i) the
FRM to ensure the perceptual quality of the restored faces; (ii) a
regularization term that functions as a safeguard to preserve generative
diversity; and (iii) a structural consistency constraint to maintain facial
fidelity. Furthermore, the FRM undergoes dynamic optimization throughout the
process. It not only ensures that the restoration network stays precisely
aligned with the real face manifold, but also effectively prevents reward
hacking. Experiments on synthetic and wild datasets demonstrate that our method
outperforms state-of-the-art methods, significantly improving identity
consistency and facial details. The source codes, data, and models are
available at: https://github.com/01NeuralNinja/DiffusionReward.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 13 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ComfyMind: Toward General-Purpose Generation via Tree-Based Planning and
  Reactive Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17908v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17908v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Litao Guo, Xinli Xu, Luozhou Wang, Jiantao Lin, Jinsong Zhou, Zixin Zhang, Bolan Su, Ying-Cong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of generative models, general-purpose generation
has gained increasing attention as a promising approach to unify diverse tasks
across modalities within a single system. Despite this progress, existing
open-source frameworks often remain fragile and struggle to support complex
real-world applications due to the lack of structured workflow planning and
execution-level feedback. To address these limitations, we present ComfyMind, a
collaborative AI system designed to enable robust and scalable general-purpose
generation, built on the ComfyUI platform. ComfyMind introduces two core
innovations: Semantic Workflow Interface (SWI) that abstracts low-level node
graphs into callable functional modules described in natural language, enabling
high-level composition and reducing structural errors; Search Tree Planning
mechanism with localized feedback execution, which models generation as a
hierarchical decision process and allows adaptive correction at each stage.
Together, these components improve the stability and flexibility of complex
generative workflows. We evaluate ComfyMind on three public benchmarks:
ComfyBench, GenEval, and Reason-Edit, which span generation, editing, and
reasoning tasks. Results show that ComfyMind consistently outperforms existing
open-source baselines and achieves performance comparable to GPT-Image-1.
ComfyMind paves a promising path for the development of open-source
general-purpose generative AI systems. Project page:
https://github.com/LitaoGuo/ComfyMind
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://github.com/LitaoGuo/ComfyMind</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic segmentation with reward 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17905v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17905v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xie Ting, Ye Huang, Zhilin Liu, Lixin Duan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In real-world scenarios, pixel-level labeling is not always available.
Sometimes, we need a semantic segmentation network, and even a visual encoder
can have a high compatibility, and can be trained using various types of
feedback beyond traditional labels, such as feedback that indicates the quality
of the parsing results. To tackle this issue, we proposed RSS (Reward in
Semantic Segmentation), the first practical application of reward-based
reinforcement learning on pure semantic segmentation offered in two granular
levels (pixel-level and image-level). RSS incorporates various novel
technologies, such as progressive scale rewards (PSR) and pair-wise spatial
difference (PSD), to ensure that the reward facilitates the convergence of the
semantic segmentation network, especially under image-level rewards.
Experiments and visualizations on benchmark datasets demonstrate that the
proposed RSS can successfully ensure the convergence of the semantic
segmentation network on two levels of rewards. Additionally, the RSS, which
utilizes an image-level reward, outperforms existing weakly supervised methods
that also rely solely on image-level signals during training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tech report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pixels to Prognosis: Harmonized Multi-Region CT-Radiomics and
  Foundation-Model Signatures Across Multicentre NSCLC Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17893v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17893v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shruti Atul Mali, Zohaib Salahuddin, Danial Khan, Yumeng Zhang, Henry C. Woodruff, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Luis Marti-Bonmati, Philippe Lambin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Purpose: To evaluate the impact of harmonization and multi-region CT image
feature integration on survival prediction in non-small cell lung cancer
(NSCLC) patients, using handcrafted radiomics, pretrained foundation model (FM)
features, and clinical data from a multicenter dataset.
  Methods: We analyzed CT scans and clinical data from 876 NSCLC patients (604
training, 272 test) across five centers. Features were extracted from the whole
lung, tumor, mediastinal nodes, coronary arteries, and coronary artery calcium
(CAC). Handcrafted radiomics and FM deep features were harmonized using ComBat,
reconstruction kernel normalization (RKN), and RKN+ComBat. Regularized Cox
models predicted overall survival; performance was assessed using the
concordance index (C-index), 5-year time-dependent area under the curve
(t-AUC), and hazard ratio (HR). SHapley Additive exPlanations (SHAP) values
explained feature contributions. A consensus model used agreement across top
region of interest (ROI) models to stratify patient risk.
  Results: TNM staging showed prognostic utility (C-index = 0.67; HR = 2.70;
t-AUC = 0.85). The clinical + tumor radiomics model with ComBat achieved a
C-index of 0.7552 and t-AUC of 0.8820. FM features (50-voxel cubes) combined
with clinical data yielded the highest performance (C-index = 0.7616; t-AUC =
0.8866). An ensemble of all ROIs and FM features reached a C-index of 0.7142
and t-AUC of 0.7885. The consensus model, covering 78% of valid test cases,
achieved a t-AUC of 0.92, sensitivity of 97.6%, and specificity of 66.7%.
  Conclusion: Harmonization and multi-region feature integration improve
survival prediction in multicenter NSCLC data. Combining interpretable
radiomics, FM features, and consensus modeling enables robust risk
stratification across imaging centers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Track Anything Annotate: Video annotation and <span class="highlight-title">dataset</span> generation of
  computer vision models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17884v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17884v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikita Ivanov, Mark Klimov, Dmitry Glukhikh, Tatiana Chernysheva, Igor Glukhikh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern machine learning methods require significant amounts of labelled data,
making the preparation process time-consuming and resource-intensive. In this
paper, we propose to consider the process of prototyping a tool for annotating
and generating training datasets based on video tracking and segmentation. We
examine different approaches to solving this problem, from technology selection
through to final implementation. The developed prototype significantly
accelerates dataset generation compared to manual annotation. All resources are
available at https://github.com/lnikioffic/track-anything-annotate
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FastCAV: Efficient Computation of Concept Activation Vectors for
  Explaining Deep Neural Networks <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17883v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17883v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laines Schmalwasser, Niklas Penzel, Joachim Denzler, Julia Niebling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concepts such as objects, patterns, and shapes are how humans understand the
world. Building on this intuition, concept-based explainability methods aim to
study representations learned by deep neural networks in relation to
human-understandable concepts. Here, Concept Activation Vectors (CAVs) are an
important tool and can identify whether a model learned a concept or not.
However, the computational cost and time requirements of existing CAV
computation pose a significant challenge, particularly in large-scale,
high-dimensional architectures. To address this limitation, we introduce
FastCAV, a novel approach that accelerates the extraction of CAVs by up to
63.6x (on average 46.4x). We provide a theoretical foundation for our approach
and give concrete assumptions under which it is equivalent to established
SVM-based methods. Our empirical results demonstrate that CAVs calculated with
FastCAV maintain similar performance while being more efficient and stable. In
downstream applications, i.e., concept-based explanation methods, we show that
FastCAV can act as a replacement leading to equivalent insights. Hence, our
approach enables previously infeasible investigations of deep models, which we
demonstrate by tracking the evolution of concepts during model training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2025, 27 pages, 20 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyperspectral Anomaly Detection Fused Unified Nonconvex Tensor Ring
  Factors Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17881v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17881v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenjin Qin, Hailin Wang, Hao Shu, Feng Zhang, Jianjun Wang, Xiangyong Cao, Xi-Le Zhao, Gemine Vivone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, tensor decomposition-based approaches for hyperspectral
anomaly detection (HAD) have gained significant attention in the field of
remote sensing. However, existing methods often fail to fully leverage both the
global correlations and local smoothness of the background components in
hyperspectral images (HSIs), which exist in both the spectral and spatial
domains. This limitation results in suboptimal detection performance. To
mitigate this critical issue, we put forward a novel HAD method named
HAD-EUNTRFR, which incorporates an enhanced unified nonconvex tensor ring (TR)
factors regularization. In the HAD-EUNTRFR framework, the raw HSIs are first
decomposed into background and anomaly components. The TR decomposition is then
employed to capture the spatial-spectral correlations within the background
component. Additionally, we introduce a unified and efficient nonconvex
regularizer, induced by tensor singular value decomposition (TSVD), to
simultaneously encode the low-rankness and sparsity of the 3-D gradient TR
factors into a unique concise form. The above characterization scheme enables
the interpretable gradient TR factors to inherit the low-rankness and
smoothness of the original background. To further enhance anomaly detection, we
design a generalized nonconvex regularization term to exploit the group
sparsity of the anomaly component. To solve the resulting doubly nonconvex
model, we develop a highly efficient optimization algorithm based on the
alternating direction method of multipliers (ADMM) framework. Experimental
results on several benchmark datasets demonstrate that our proposed method
outperforms existing state-of-the-art (SOTA) approaches in terms of detection
accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-task Learning For Joint Action and Gesture Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17867v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17867v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantinos Spathis, Nikolaos Kardaris, Petros Maragos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In practical applications, computer vision tasks often need to be addressed
simultaneously. Multitask learning typically achieves this by jointly training
a single deep neural network to learn shared representations, providing
efficiency and improving generalization. Although action and gesture
recognition are closely related tasks, since they focus on body and hand
movements, current state-of-the-art methods handle them separately. In this
paper, we show that employing a multi-task learning paradigm for action and
gesture recognition results in more efficient, robust and generalizable visual
representations, by leveraging the synergies between these tasks. Extensive
experiments on multiple action and gesture datasets demonstrate that handling
actions and gestures in a single architecture can achieve better performance
for both tasks in comparison to their single-task learning variants.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Person Interaction Generation from Two-Person Motion Priors <span class="chip">SIGGRAPH 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17860v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17860v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenning Xu, Shiyu Fan, Paul Henderson, Edmond S. L. Ho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating realistic human motion with high-level controls is a crucial task
for social understanding, robotics, and animation. With high-quality MOCAP data
becoming more available recently, a wide range of data-driven approaches have
been presented. However, modelling multi-person interactions still remains a
less explored area. In this paper, we present Graph-driven Interaction
Sampling, a method that can generate realistic and diverse multi-person
interactions by leveraging existing two-person motion diffusion models as
motion priors. Instead of training a new model specific to multi-person
interaction synthesis, our key insight is to spatially and temporally separate
complex multi-person interactions into a graph structure of two-person
interactions, which we name the Pairwise Interaction Graph. We thus decompose
the generation task into simultaneous single-person motion generation
conditioned on one other's motion. In addition, to reduce artifacts such as
interpenetrations of body parts in generated multi-person interactions, we
introduce two graph-dependent guidance terms into the diffusion sampling
scheme. Unlike previous work, our method can produce various high-quality
multi-person interactions without having repetitive individual motions.
Extensive experiments demonstrate that our approach consistently outperforms
existing methods in reducing artifacts when generating a wide range of
two-person and multi-person interactions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGGRAPH 2025 Conference Papers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Locality-Sensitive Hashing for Efficient Hard Negative Sampling in
  Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17844v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17844v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fabian Deuser, Philipp Hausenblas, Hannah Schieber, Daniel Roth, Martin Werner, Norbert Oswald
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive learning is a representational learning paradigm in which a
neural network maps data elements to feature vectors. It improves the feature
space by forming lots with an anchor and examples that are either positive or
negative based on class similarity. Hard negative examples, which are close to
the anchor in the feature space but from a different class, improve learning
performance. Finding such examples of high quality efficiently in large,
high-dimensional datasets is computationally challenging. In this paper, we
propose a GPU-friendly Locality-Sensitive Hashing (LSH) scheme that quantizes
real-valued feature vectors into binary representations for approximate nearest
neighbor search. We investigate its theoretical properties and evaluate it on
several datasets from textual and visual domain. Our approach achieves
comparable or better performance while requiring significantly less computation
than existing hard negative mining strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VLM Models and Automated Grading of Atopic Dermatitis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17835v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17835v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marc Lalonde, Hamed Ghodrati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of grading atopic dermatitis (or AD, a form of eczema) from patient
images is difficult even for trained dermatologists. Research on automating
this task has progressed in recent years with the development of deep learning
solutions; however, the rapid evolution of multimodal models and more
specifically vision-language models (VLMs) opens the door to new possibilities
in terms of explainable assessment of medical images, including dermatology.
This report describes experiments carried out to evaluate the ability of seven
VLMs to assess the severity of AD on a set of test images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ICPL-ReID: Identity-Conditional <span class="highlight-title">Prompt</span> Learning for Multi-Spectral
  Object Re-Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17821v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17821v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shihao Li, Chenglong Li, Aihua Zheng, Jin Tang, Bin Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-spectral object re-identification (ReID) brings a new perception
perspective for smart city and intelligent transportation applications,
effectively addressing challenges from complex illumination and adverse
weather. However, complex modal differences between heterogeneous spectra pose
challenges to efficiently utilizing complementary and discrepancy of spectra
information. Most existing methods fuse spectral data through intricate modal
interaction modules, lacking fine-grained semantic understanding of spectral
information (\textit{e.g.}, text descriptions, part masks, and object
keypoints). To solve this challenge, we propose a novel Identity-Conditional
text Prompt Learning framework (ICPL), which exploits the powerful cross-modal
alignment capability of CLIP, to unify different spectral visual features from
text semantics. Specifically, we first propose the online prompt learning using
learnable text prompt as the identity-level semantic center to bridge the
identity semantics of different spectra in online manner. Then, in lack of
concrete text descriptions, we propose the multi-spectral identity-condition
module to use identity prototype as spectral identity condition to constraint
prompt learning. Meanwhile, we construct the alignment loop mutually optimizing
the learnable text prompt and spectral visual encoder to avoid online prompt
learning disrupting the pre-trained text-image alignment distribution. In
addition, to adapt to small-scale multi-spectral data and mitigate style
differences between spectra, we propose multi-spectral adapter that employs a
low-rank adaption method to learn spectra-specific features. Comprehensive
experiments on 5 benchmarks, including RGBNT201, Market-MM, MSVR310, RGBN300,
and RGBNT100, demonstrate that the proposed method outperforms the
state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Multimedia (TMM)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing It or Not? Interpretable Vision-aware Latent Steering to Mitigate
  Object Hallucinations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17812v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17812v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boxu Chen, Ziwei Zheng, Le Yang, Zeyu Geng, Zhengyu Zhao, Chenhao Lin, Chao Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) have achieved remarkable success but
continue to struggle with object hallucination (OH), generating outputs
inconsistent with visual inputs. While previous work has proposed methods to
reduce OH, the visual decision-making mechanisms that lead to hallucinations
remain poorly understood. In this paper, we propose VaLSe, a Vision-aware
Latent Steering framework that adopts an interpretation-then-mitigation
strategy to address OH in LVLMs. By tackling dual challenges of modeling
complex vision-language interactions and eliminating spurious activation
artifacts, VaLSe can generate visual contribution maps that trace how specific
visual inputs influence individual output tokens. These maps reveal the model's
vision-aware focus regions, which are then used to perform latent space
steering, realigning internal representations toward semantically relevant
content and reducing hallucinated outputs. Extensive experiments demonstrate
that VaLSe is a powerful interpretability tool and an effective method for
enhancing model robustness against OH across multiple benchmarks. Furthermore,
our analysis uncovers limitations in existing OH evaluation metrics,
underscoring the need for more nuanced, interpretable, and visually grounded OH
benchmarks in future work. Code is available at:
https://github.com/Ziwei-Zheng/VaLSe.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Attention Infused Deep Learning System with Grad-CAM Visualization
  for Early Screening of Glaucoma 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17808v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17808v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramanathan Swaminathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research work reveals the eye opening wisdom of the hybrid labyrinthine
deep learning models synergy born out of combining a trailblazing convolutional
neural network with a disruptive Vision Transformer, both intertwined together
with a radical Cross Attention module. Here, two high yielding datasets for
artificial intelligence models in detecting glaucoma, namely ACRIMA and
Drishti, are utilized.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages in general IEEE format, 8 figures, 4 tables, pdflatex</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Temporal Consistency Constrained Transferable Adversarial Attacks with
  Background Mixup for Action Recognition <span class="chip">IJCAI'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ping Li, Jianan Ni, Bo Pang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Action recognition models using deep learning are vulnerable to adversarial
examples, which are transferable across other models trained on the same data
modality. Existing transferable attack methods face two major challenges: 1)
they heavily rely on the assumption that the decision boundaries of the
surrogate (a.k.a., source) model and the target model are similar, which limits
the adversarial transferability; and 2) their decision boundary difference
makes the attack direction uncertain, which may result in the gradient
oscillation, weakening the adversarial attack. This motivates us to propose a
Background Mixup-induced Temporal Consistency (BMTC) attack method for action
recognition. From the input transformation perspective, we design a
model-agnostic background adversarial mixup module to reduce the
surrogate-target model dependency. In particular, we randomly sample one video
from each category and make its background frame, while selecting the
background frame with the top attack ability for mixup with the clean frame by
reinforcement learning. Moreover, to ensure an explicit attack direction, we
leverage the background category as guidance for updating the gradient of
adversarial example, and design a temporal gradient consistency loss, which
strengthens the stability of the attack direction on subsequent frames.
Empirical studies on two video datasets, i.e., UCF101 and Kinetics-400, and one
image dataset, i.e., ImageNet, demonstrate that our method significantly boosts
the transferability of adversarial examples across several action/image
recognition models. Our code is available at
https://github.com/mlvccn/BMTC_TransferAttackVid.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in IJCAI'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Coreset Selection of Coreset Selection Literature: Introduction and
  Recent Advances 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17799v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17799v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian B. Moser, Arundhati S. Shanbhag, Stanislav Frolov, Federico Raue, Joachim Folz, Andreas Dengel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coreset selection targets the challenge of finding a small, representative
subset of a large dataset that preserves essential patterns for effective
machine learning. Although several surveys have examined data reduction
strategies before, most focus narrowly on either classical geometry-based
methods or active learning techniques. In contrast, this survey presents a more
comprehensive view by unifying three major lines of coreset research, namely,
training-free, training-oriented, and label-free approaches, into a single
taxonomy. We present subfields often overlooked by existing work, including
submodular formulations, bilevel optimization, and recent progress in
pseudo-labeling for unlabeled datasets. Additionally, we examine how pruning
strategies influence generalization and neural scaling laws, offering new
insights that are absent from prior reviews. Finally, we compare these methods
under varying computational, robustness, and performance demands and highlight
open challenges, such as robustness, outlier filtering, and adapting coreset
selection to foundation models, for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DetailFusion: A Dual-branch Framework with Detail Enhancement for
  Composed Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Yang, Yinan Zhou, Yuxin Chen, Ziqi Zhang, Zongyang Ma, Chunfeng Yuan, Bing Li, Lin Song, Jun Gao, Peng Li, Weiming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Composed Image Retrieval (CIR) aims to retrieve target images from a gallery
based on a reference image and modification text as a combined query. Recent
approaches focus on balancing global information from two modalities and encode
the query into a unified feature for retrieval. However, due to insufficient
attention to fine-grained details, these coarse fusion methods often struggle
with handling subtle visual alterations or intricate textual instructions. In
this work, we propose DetailFusion, a novel dual-branch framework that
effectively coordinates information across global and detailed granularities,
thereby enabling detail-enhanced CIR. Our approach leverages atomic detail
variation priors derived from an image editing dataset, supplemented by a
detail-oriented optimization strategy to develop a Detail-oriented Inference
Branch. Furthermore, we design an Adaptive Feature Compositor that dynamically
fuses global and detailed features based on fine-grained information of each
unique multimodal query. Extensive experiments and ablation analyses not only
demonstrate that our method achieves state-of-the-art performance on both CIRR
and FashionIQ datasets but also validate the effectiveness and cross-domain
adaptability of detail enhancement for CIR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Data Augmentation for Object Point Cloud Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17783v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17783v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dekai Zhu, Stefan Gavranovic, Flavien Boussuge, Benjamin Busam, Slobodan Ilic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data augmentation is widely used to train deep learning models to address
data scarcity. However, traditional data augmentation (TDA) typically relies on
simple geometric transformation, such as random rotation and rescaling,
resulting in minimal data diversity enrichment and limited model performance
improvement. State-of-the-art generative models for 3D shape generation rely on
the denoising diffusion probabilistic models and manage to generate realistic
novel point clouds for 3D content creation and manipulation. Nevertheless, the
generated 3D shapes lack associated point-wise semantic labels, restricting
their usage in enlarging the training data for point cloud segmentation tasks.
To bridge the gap between data augmentation techniques and the advanced
diffusion models, we extend the state-of-the-art 3D diffusion model, Lion, to a
part-aware generative model that can generate high-quality point clouds
conditioned on given segmentation masks. Leveraging the novel generative model,
we introduce a 3-step generative data augmentation (GDA) pipeline for point
cloud segmentation training. Our GDA approach requires only a small amount of
labeled samples but enriches the training data with generated variants and
pseudo-labeled samples, which are validated by a novel diffusion-based
pseudo-label filtering method. Extensive experiments on two large-scale
synthetic datasets and a real-world medical dataset demonstrate that our GDA
method outperforms TDA approach and related semi-supervised and self-supervised
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hephaestus Minicubes: A Global, Multi-Modal <span class="highlight-title">Dataset</span> for Volcanic Unrest
  Monitoring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikolas Papadopoulos, Nikolaos Ioannis Bountos, Maria Sdraka, Andreas Karavias, Ioannis Papoutsis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ground deformation is regarded in volcanology as a key precursor signal
preceding volcanic eruptions. Satellite-based Interferometric Synthetic
Aperture Radar (InSAR) enables consistent, global-scale deformation tracking;
however, deep learning methods remain largely unexplored in this domain, mainly
due to the lack of a curated machine learning dataset. In this work, we build
on the existing Hephaestus dataset, and introduce Hephaestus Minicubes, a
global collection of 38 spatiotemporal datacubes offering high resolution,
multi-source and multi-temporal information, covering 44 of the world's most
active volcanoes over a 7-year period. Each spatiotemporal datacube integrates
InSAR products, topographic data, as well as atmospheric variables which are
known to introduce signal delays that can mimic ground deformation in InSAR
imagery. Furthermore, we provide expert annotations detailing the type,
intensity and spatial extent of deformation events, along with rich text
descriptions of the observed scenes. Finally, we present a comprehensive
benchmark, demonstrating Hephaestus Minicubes' ability to support volcanic
unrest monitoring as a multi-modal, multi-temporal classification and semantic
segmentation task, establishing strong baselines with state-of-the-art
architectures. This work aims to advance machine learning research in volcanic
monitoring, contributing to the growing integration of data-driven methods
within Earth science applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anjie Le, Henan Liu, Yue Wang, Zhenyu Liu, Rongkun Zhu, Taohan Weng, Jinze Yu, Boyang Wang, Yalun Wu, Kaiwen Yan, Quanlin Sun, Meirui Jiang, Jialun Pei, Siya Liu, Haoyun Zheng, Zhoujun Li, Alison Noble, Jacques Souquet, Xiaoqing Guo, Manxi Lin, Hongcheng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ultrasound is a widely-used imaging modality critical to global healthcare,
yet its interpretation remains challenging due to its varying image quality on
operators, noises, and anatomical structures. Although large vision-language
models (LVLMs) have demonstrated impressive multimodal capabilities across
natural and medical domains, their performance on ultrasound remains largely
unexplored. We introduce U2-BENCH, the first comprehensive benchmark to
evaluate LVLMs on ultrasound understanding across classification, detection,
regression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning
15 anatomical regions and defines 8 clinically inspired tasks, such as
diagnosis, view recognition, lesion localization, clinical value estimation,
and report generation, across 50 ultrasound application scenarios. We evaluate
20 state-of-the-art LVLMs, both open- and closed-source, general-purpose and
medical-specific. Our results reveal strong performance on image-level
classification, but persistent challenges in spatial reasoning and clinical
language generation. U2-BENCH establishes a rigorous and unified testbed to
assess and accelerate LVLM research in the uniquely multimodal domain of
medical ultrasound imaging.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TextFlux: An OCR-Free DiT Model for High-Fidelity Multilingual Scene
  Text Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17778v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17778v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Xie, Jielei Zhang, Pengyu Chen, Ziyue Wang, Weihang Wang, Longwen Gao, Peiyi Li, Huyang Sun, Qiang Zhang, Qian Qiao, Jiaqing Fan, Zhouhui Lian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based scene text synthesis has progressed rapidly, yet existing
methods commonly rely on additional visual conditioning modules and require
large-scale annotated data to support multilingual generation. In this work, we
revisit the necessity of complex auxiliary modules and further explore an
approach that simultaneously ensures glyph accuracy and achieves high-fidelity
scene integration, by leveraging diffusion models' inherent capabilities for
contextual reasoning. To this end, we introduce TextFlux, a DiT-based framework
that enables multilingual scene text synthesis. The advantages of TextFlux can
be summarized as follows: (1) OCR-free model architecture. TextFlux eliminates
the need for OCR encoders (additional visual conditioning modules) that are
specifically used to extract visual text-related features. (2) Strong
multilingual scalability. TextFlux is effective in low-resource multilingual
settings, and achieves strong performance in newly added languages with fewer
than 1,000 samples. (3) Streamlined training setup. TextFlux is trained with
only 1% of the training data required by competing methods. (4) Controllable
multi-line text generation. TextFlux offers flexible multi-line synthesis with
precise line-level control, outperforming methods restricted to single-line or
rigid layouts. Extensive experiments and visualizations demonstrate that
TextFlux outperforms previous methods in both qualitative and quantitative
evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TopoPoint: Enhance Topology Reasoning via Endpoint Detection in
  Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17771v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17771v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanping Fu, Xinyuan Liu, Tianyu Li, Yike Ma, Yucheng Zhang, Feng Dai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topology reasoning, which unifies perception and structured reasoning, plays
a vital role in understanding intersections for autonomous driving. However,
its performance heavily relies on the accuracy of lane detection, particularly
at connected lane endpoints. Existing methods often suffer from lane endpoints
deviation, leading to incorrect topology construction. To address this issue,
we propose TopoPoint, a novel framework that explicitly detects lane endpoints
and jointly reasons over endpoints and lanes for robust topology reasoning.
During training, we independently initialize point and lane query, and proposed
Point-Lane Merge Self-Attention to enhance global context sharing through
incorporating geometric distances between points and lanes as an attention mask
. We further design Point-Lane Graph Convolutional Network to enable mutual
feature aggregation between point and lane query. During inference, we
introduce Point-Lane Geometry Matching algorithm that computes distances
between detected points and lanes to refine lane endpoints, effectively
mitigating endpoint deviation. Extensive experiments on the OpenLane-V2
benchmark demonstrate that TopoPoint achieves state-of-the-art performance in
topology reasoning (48.8 on OLS). Additionally, we propose DET$_p$ to evaluate
endpoint detection, under which our method significantly outperforms existing
approaches (52.6 v.s. 45.2 on DET$_p$). The code is released at
https://github.com/Franpin/TopoPoint.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ R-Genie: Reasoning-Guided Generative Image Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17768v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17768v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong Zhang, Lingfeng He, Rui Yan, Fei Shen, Jinhui Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While recent advances in image editing have enabled impressive visual
synthesis capabilities, current methods remain constrained by explicit textual
instructions and limited editing operations, lacking deep comprehension of
implicit user intentions and contextual reasoning. In this work, we introduce a
new image editing paradigm: reasoning-guided generative editing, which
synthesizes images based on complex, multi-faceted textual queries accepting
world knowledge and intention inference. To facilitate this task, we first
construct a comprehensive dataset featuring over 1,000 image-instruction-edit
triples that incorporate rich reasoning contexts and real-world knowledge. We
then propose R-Genie: a reasoning-guided generative image editor, which
synergizes the generation power of diffusion models with advanced reasoning
capabilities of multimodal large language models. R-Genie incorporates a
reasoning-attention mechanism to bridge linguistic understanding with visual
synthesis, enabling it to handle intricate editing requests involving abstract
user intentions and contextual reasoning relations. Extensive experimental
results validate that R-Genie can equip diffusion models with advanced
reasoning-based editing capabilities, unlocking new potentials for intelligent
image synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://dongzhang89.github.io/RGenie.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Soft-CAM: Making black box models self-explainable for high-stakes
  decisions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17748v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17748v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kerol Djoumessi, Philipp Berens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional neural networks (CNNs) are widely used for high-stakes
applications like medicine, often surpassing human performance. However, most
explanation methods rely on post-hoc attribution, approximating the
decision-making process of already trained black-box models. These methods are
often sensitive, unreliable, and fail to reflect true model reasoning, limiting
their trustworthiness in critical applications. In this work, we introduce
SoftCAM, a straightforward yet effective approach that makes standard CNN
architectures inherently interpretable. By removing the global average pooling
layer and replacing the fully connected classification layer with a
convolution-based class evidence layer, SoftCAM preserves spatial information
and produces explicit class activation maps that form the basis of the model's
predictions. Evaluated on three medical datasets, SoftCAM maintains
classification performance while significantly improving both the qualitative
and quantitative explanation compared to existing post-hoc methods. Our results
demonstrate that CNNs can be inherently interpretable without compromising
performance, advancing the development of self-explainable deep learning for
high-stakes decision-making.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RQR3D: Reparametrizing the regression targets for BEV-based 3D object
  detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17732v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17732v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ozsel Kilinc, Cem Tarhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate, fast, and reliable 3D perception is essential for autonomous
driving. Recently, bird's-eye view (BEV)-based perception approaches have
emerged as superior alternatives to perspective-based solutions, offering
enhanced spatial understanding and more natural outputs for planning. Existing
BEV-based 3D object detection methods, typically adhering to angle-based
representation, directly estimate the size and orientation of rotated bounding
boxes. We observe that BEV-based 3D object detection is analogous to aerial
oriented object detection, where angle-based methods are recognized for being
affected by discontinuities in their loss functions. Drawing inspiration from
this domain, we propose Restricted Quadrilateral Representation to define 3D
regression targets. RQR3D regresses the smallest horizontal bounding box
encapsulating the oriented box, along with the offsets between the corners of
these two boxes, thereby transforming the oriented object detection problem
into a keypoint regression task. RQR3D is compatible with any 3D object
detection approach. We employ RQR3D within an anchor-free single-stage object
detection method and introduce an objectness head to address class imbalance
problem. Furthermore, we introduce a simplified radar fusion backbone that
eliminates the need for voxel grouping and processes the BEV-mapped point cloud
with standard 2D convolutions, rather than sparse convolutions. Extensive
evaluations on the nuScenes dataset demonstrate that RQR3D achieves
state-of-the-art performance in camera-radar 3D object detection, outperforming
the previous best method by +4% in NDS and +2.4% in mAP, and significantly
reducing the translation and orientation errors, which are crucial for safe
autonomous driving. These consistent gains highlight the robustness, precision,
and real-world readiness of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the
  Real World Domain 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Zhou, Linye Lyu, Zhuotao Tian, Cheng Zhuo, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety-critical scenarios are rare yet pivotal for evaluating and enhancing
the robustness of autonomous driving systems. While existing methods generate
safety-critical driving trajectories, simulations, or single-view videos, they
fall short of meeting the demands of advanced end-to-end autonomous systems
(E2E AD), which require real-world, multi-view video data. To bridge this gap,
we introduce SafeMVDrive, the first framework designed to generate
high-quality, safety-critical, multi-view driving videos grounded in real-world
domains. SafeMVDrive strategically integrates a safety-critical trajectory
generator with an advanced multi-view video generator. To tackle the challenges
inherent in this integration, we first enhance scene understanding ability of
the trajectory generator by incorporating visual context -- which is previously
unavailable to such generator -- and leveraging a GRPO-finetuned
vision-language model to achieve more realistic and context-aware trajectory
generation. Second, recognizing that existing multi-view video generators
struggle to render realistic collision events, we introduce a two-stage,
controllable trajectory generation mechanism that produces collision-evasion
trajectories, ensuring both video quality and safety-critical fidelity.
Finally, we employ a diffusion-based multi-view video generator to synthesize
high-quality safety-critical driving videos from the generated trajectories.
Experiments conducted on an E2E AD planner demonstrate a significant increase
in collision rate when tested with our generated data, validating the
effectiveness of SafeMVDrive in stress-testing planning modules. Our code,
examples, and datasets are publicly available at:
https://zhoujiawei3.github.io/SafeMVDrive/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17726v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17726v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek, Sungjin Ahn, Sungwoong Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, multimodal large language models (MLLMs) have emerged as a key
approach in achieving artificial general intelligence. In particular,
vision-language MLLMs have been developed to generate not only text but also
visual outputs from multimodal inputs. This advancement requires efficient
image tokens that LLMs can process effectively both in input and output.
However, existing image tokenization methods for MLLMs typically capture only
global abstract concepts or uniformly segmented image patches, restricting
MLLMs' capability to effectively understand or generate detailed visual
content, particularly at the object level. To address this limitation, we
propose an object-centric visual tokenizer based on Slot Attention specifically
for MLLMs. In particular, based on the Q-Former encoder, diffusion decoder, and
residual vector quantization, our proposed discretized slot tokens can encode
local visual details while maintaining high-level semantics, and also align
with textual data to be integrated seamlessly within a unified next-token
prediction framework of LLMs. The resulting Slot-MLLM demonstrates significant
performance improvements over baselines with previous visual tokenizers across
various vision-language tasks that entail local detailed comprehension and
generation. Notably, this work is the first demonstration of the feasibility of
object-centric slot attention performed with MLLMs and in-the-wild natural
images.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17721v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17721v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dekai Zhu, Yan Di, Stefan Gavranovic, Slobodan Ilic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Denoising diffusion probabilistic models have achieved significant success in
point cloud generation, enabling numerous downstream applications, such as
generative data augmentation and 3D model editing. However, little attention
has been given to generating point clouds with point-wise segmentation labels,
as well as to developing evaluation metrics for this task. Therefore, in this
paper, we present SeaLion, a novel diffusion model designed to generate
high-quality and diverse point clouds with fine-grained segmentation labels.
Specifically, we introduce the semantic part-aware latent point diffusion
technique, which leverages the intermediate features of the generative models
to jointly predict the noise for perturbed latent points and associated part
segmentation labels during the denoising process, and subsequently decodes the
latent points to point clouds conditioned on part segmentation labels. To
effectively evaluate the quality of generated point clouds, we introduce a
novel point cloud pairwise distance calculation method named part-aware Chamfer
distance (p-CD). This method enables existing metrics, such as 1-NNA, to
measure both the local structural quality and inter-part coherence of generated
point clouds. Experiments on the large-scale synthetic dataset ShapeNet and
real-world medical dataset IntrA demonstrate that SeaLion achieves remarkable
performance in generation quality and diversity, outperforming the existing
state-of-the-art model, DiffFacto, by 13.33% and 6.52% on 1-NNA (p-CD) across
the two datasets. Experimental analysis shows that SeaLion can be trained
semi-supervised, thereby reducing the demand for labeling efforts. Lastly, we
validate the applicability of SeaLion in generative data augmentation for
training segmentation models and the capability of SeaLion to serve as a tool
for part-aware 3D shape editing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using
  Local Inference via DeepSeek 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueyang Li, Jiahao Li, Yu Song, Yunzhong Lou, Xiangdong Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of Computer-Aided Design (CAD) generative modeling will
significantly transform the design of industrial products. The recent research
endeavor has extended into the realm of Large Language Models (LLMs). In
contrast to fine-tuning methods, training-free approaches typically utilize the
advanced closed-source LLMs, thereby offering enhanced flexibility and
efficiency in the development of AI agents for generating CAD parametric
models. However, the substantial cost and limitations of local deployment of
the top-tier closed-source LLMs pose challenges in practical applications. The
Seek-CAD is the pioneer exploration of locally deployed open-source inference
LLM DeepSeek-R1 for CAD parametric model generation with a training-free
methodology. This study is the first investigation to incorporate both visual
and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for
generating CAD models. Specifically, the initial generated parametric CAD model
is rendered into a sequence of step-wise perspective images, which are
subsequently processed by a Vision Language Model (VLM) alongside the
corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation.
Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated
model for the next round of generation. Moreover, we present an innovative 3D
CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and
Refinements) triple design paradigm. This dataset encompasses a wide range of
CAD commands, thereby aligning effectively with industrial application
requirements and proving suitable for the generation of LLMs. Extensive
experiments validate the effectiveness of Seek-CAD under various metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SynRES: Towards Referring Expression Segmentation in the Wild via
  Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong-Hee Kim, Hyunjee Song, Donghyun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the advances in Referring Expression Segmentation (RES) benchmarks,
their evaluation protocols remain constrained, primarily focusing on either
single targets with short queries (containing minimal attributes) or multiple
targets from distinctly different queries on a single domain. This limitation
significantly hinders the assessment of more complex reasoning capabilities in
RES models. We introduce WildRES, a novel benchmark that incorporates long
queries with diverse attributes and non-distinctive queries for multiple
targets. This benchmark spans diverse application domains, including autonomous
driving environments and robotic manipulation scenarios, thus enabling more
rigorous evaluation of complex reasoning capabilities in real-world settings.
Our analysis reveals that current RES models demonstrate substantial
performance deterioration when evaluated on WildRES. To address this challenge,
we introduce SynRES, an automated pipeline generating densely paired
compositional synthetic training data through three innovations: (1) a dense
caption-driven synthesis for attribute-rich image-mask-expression triplets, (2)
reliable semantic alignment mechanisms rectifying caption-pseudo mask
inconsistencies via Image-Text Aligned Grouping, and (3) domain-aware
augmentations incorporating mosaic composition and superclass replacement to
emphasize generalization ability and distinguishing attributes over object
categories. Experimental results demonstrate that models trained with SynRES
achieve state-of-the-art performance, improving gIoU by 2.0% on WildRES-ID and
3.8% on WildRES-DS. Code and datasets are available at
https://github.com/UTLLab/SynRES.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViP$^2$-CLIP: Visual-Perception <span class="highlight-title">Prompt</span>ing with Unified Alignment for
  Zero-Shot Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any
target domain training samples, relying solely on external auxiliary data.
Existing CLIP-based methods attempt to activate the model's ZSAD potential via
handcrafted or static learnable prompts. The former incur high engineering
costs and limited semantic coverage, whereas the latter apply identical
descriptions across diverse anomaly types, thus fail to adapt to complex
variations. Furthermore, since CLIP is originally pretrained on large-scale
classification tasks, its anomaly segmentation quality is highly sensitive to
the exact wording of class names, severely constraining prompting strategies
that depend on class labels. To address these challenges, we introduce
ViP$^{2}$-CLIP. The key insight of ViP$^{2}$-CLIP is a Visual-Perception
Prompting (ViP-Prompt) mechanism, which fuses global and multi-scale local
visual context to adaptively generate fine-grained textual prompts, eliminating
manual templates and class-name priors. This design enables our model to focus
on precise abnormal regions, making it particularly valuable when category
labels are ambiguous or privacy-constrained. Extensive experiments on 15
industrial and medical benchmarks demonstrate that ViP$^{2}$-CLIP achieves
state-of-the-art performance and robust cross-domain generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-Supervised Medical Image Segmentation via Dual Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunyao Lu, Yihang Wu, Reem Kateb, Ahmad Chaddad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional supervised medical image segmentation models require large
amounts of labeled data for training; however, obtaining such large-scale
labeled datasets in the real world is extremely challenging. Recent
semi-supervised segmentation models also suffer from noisy pseudo-label issue
and limited supervision in feature space. To solve these challenges, we propose
an innovative semi-supervised 3D medical image segmentation method to reduce
the dependency on large, expert-labeled datasets. Furthermore, we introduce a
dual-network architecture to address the limitations of existing methods in
using contextual information and generating reliable pseudo-labels. In
addition, a self-supervised contrastive learning strategy is used to enhance
the representation of the network and reduce prediction uncertainty by
distinguishing between reliable and unreliable predictions. Experiments on
clinical magnetic resonance imaging demonstrate that our approach outperforms
state-of-the-art techniques. Our code is available at
https://github.com/AIPMLab/Semi-supervised-Segmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ISBI2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for
  Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17685v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17685v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuang Zeng, Xinyuan Chang, Mengwei Xie, Xinran Liu, Yifan Bai, Zheng Pan, Mu Xu, Xing Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual language models (VLMs) have attracted increasing interest in
autonomous driving due to their powerful reasoning capabilities. However,
existing VLMs typically utilize discrete text Chain-of-Thought (CoT) tailored
to the current scenario, which essentially represents highly abstract and
symbolic compression of visual information, potentially leading to
spatio-temporal relationship ambiguity and fine-grained information loss. Is
autonomous driving better modeled on real-world simulation and imagination than
on pure symbolic logic? In this paper, we propose a spatio-temporal CoT
reasoning method that enables models to think visually. First, VLM serves as a
world model to generate unified image frame for predicting future world states:
where perception results (e.g., lane divider and 3D detection) represent the
future spatial relationships, and ordinary future frame represent the temporal
evolution relationships. This spatio-temporal CoT then serves as intermediate
reasoning steps, enabling the VLM to function as an inverse dynamics model for
trajectory planning based on current observations and future predictions. To
implement visual generation in VLMs, we propose a unified pretraining paradigm
integrating visual generation and understanding, along with a progressive
visual CoT enhancing autoregressive image generation. Extensive experimental
results demonstrate the effectiveness of the proposed method, advancing
autonomous driving towards visual reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 5G-DIL: Domain Incremental Learning with Similarity-Aware Sampling for
  Dynamic 5G Indoor Localization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17684v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17684v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nisha Lakshmana Raichur, Lucas Heublein, Christopher Mutschler, Felix Ott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Indoor positioning based on 5G data has achieved high accuracy through the
adoption of recent machine learning (ML) techniques. However, the performance
of learning-based methods degrades significantly when environmental conditions
change, thereby hindering their applicability to new scenarios. Acquiring new
training data for each environmental change and fine-tuning ML models is both
time-consuming and resource-intensive. This paper introduces a domain
incremental learning (DIL) approach for dynamic 5G indoor localization, called
5G-DIL, enabling rapid adaptation to environmental changes. We present a novel
similarity-aware sampling technique based on the Chebyshev distance, designed
to efficiently select specific exemplars from the previous environment while
training only on the modified regions of the new environment. This avoids the
need to train on the entire region, significantly reducing the time and
resources required for adaptation without compromising localization accuracy.
This approach requires as few as 50 exemplars from adaptation domains,
significantly reducing training time while maintaining high positioning
accuracy in previous environments. Comparative evaluations against
state-of-the-art DIL techniques on a challenging real-world indoor dataset
demonstrate the effectiveness of the proposed sample selection method. Our
approach is adaptable to real-world non-line-of-sight propagation scenarios and
achieves an MAE positioning error of 0.261 meters, even under dynamic
environmental conditions. Code:
https://gitlab.cc-asp.fraunhofer.de/5g-pos/5g-dil
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual Attention Residual U-Net for Accurate Brain Ultrasound Segmentation
  in IVH Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17683v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17683v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dan Yuan, Yi Feng, Ziyun Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intraventricular hemorrhage (IVH) is a severe neurological complication among
premature infants, necessitating early and accurate detection from brain
ultrasound (US) images to improve clinical outcomes. While recent deep learning
methods offer promise for computer-aided diagnosis, challenges remain in
capturing both local spatial details and global contextual dependencies
critical for segmenting brain anatomies. In this work, we propose an enhanced
Residual U-Net architecture incorporating two complementary attention
mechanisms: the Convolutional Block Attention Module (CBAM) and a Sparse
Attention Layer (SAL). The CBAM improves the model's ability to refine spatial
and channel-wise features, while the SAL introduces a dual-branch design,
sparse attention filters out low-confidence query-key pairs to suppress noise,
and dense attention ensures comprehensive information propagation. Extensive
experiments on the Brain US dataset demonstrate that our method achieves
state-of-the-art segmentation performance, with a Dice score of 89.04% and IoU
of 81.84% for ventricle region segmentation. These results highlight the
effectiveness of integrating spatial refinement and attention sparsity for
robust brain anatomy detection. Code is available at:
https://github.com/DanYuan001/BrainImgSegment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages,6 figures and 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in
  Ophthalmic Surgery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ming Hu, Zhendi Yu, Feilong Tang, Kaiwen Chen, Yulong Li, Imran Razzak, Junjun He, Tolga Birdal, Kaijing Zhou, Zongyuan Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate 3D reconstruction of hands and instruments is critical for
vision-based analysis of ophthalmic microsurgery, yet progress has been
hampered by the lack of realistic, large-scale datasets and reliable annotation
tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic
3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from
40 surgeons and totaling 7.1 million frames, with fine-grained annotations of
12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full
6-DoF instrument poses. To scalably produce high-fidelity labels, we design a
multi-stage automatic annotation pipeline that integrates multi-view data
observation, data-driven motion prior with cross-view geometric consistency and
biomechanical constraints, along with a combination of collision-aware
interaction constraints for instrument interactions. Building upon OphNet-3D,
we establish two challenging benchmarks-bimanual hand pose estimation and
hand-instrument interaction reconstruction-and propose two dedicated
architectures: H-Net for dual-hand mesh recovery and OH-Net for joint
reconstruction of two-hand-two-instrument interactions. These models leverage a
novel spatial reasoning module with weak-perspective camera modeling and
collision-aware center-based representation. Both architectures outperform
existing methods by substantial margins, achieving improvements of over 2mm in
Mean Per Joint Position Error (MPJPE) and up to 23% in ADD-S metrics for hand
and instrument reconstruction, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SVL: Spike-based Vision-language <span class="highlight-title">Pretrain</span>ing for Efficient 3D Open-world
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuerui Qiu, Peixi Wu, Yaozhi Wen, Shaowei Gu, Yuqi Pan, Xinhao Luo, Bo XU, Guoqi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D
spatio-temporal features. However, existing SNNs still exhibit a significant
performance gap compared to Artificial Neural Networks (ANNs) due to inadequate
pre-training strategies. These limitations manifest as restricted
generalization ability, task specificity, and a lack of multimodal
understanding, particularly in challenging tasks such as multimodal question
answering and zero-shot 3D classification. To overcome these challenges, we
propose a Spike-based Vision-Language (SVL) pretraining framework that empowers
SNNs with open-world 3D understanding while maintaining spike-driven
efficiency. SVL introduces two key components: (i) Multi-scale Triple Alignment
(MTA) for label-free triplet-based contrastive learning across 3D, image, and
text modalities, and (ii) Re-parameterizable Vision-Language Integration
(Rep-VLI) to enable lightweight inference without relying on large text
encoders. Extensive experiments show that SVL achieves a top-1 accuracy of
85.4% in zero-shot 3D classification, surpassing advanced ANN models, and
consistently outperforms prior SNNs on downstream tasks, including 3D
classification (+6.1%), DVS action recognition (+2.1%), 3D detection (+1.1%),
and 3D segmentation (+2.1%) with remarkable efficiency. Moreover, SVL enables
SNNs to perform open-world 3D question answering, sometimes outperforming ANNs.
To the best of our knowledge, SVL represents the first scalable, generalizable,
and hardware-friendly paradigm for 3D open-world understanding, effectively
bridging the gap between SNNs and ANNs in complex open-world understanding
tasks. Code is available https://github.com/bollossom/SVL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Proto-FG3D: Prototype-based Interpretable Fine-Grained 3D Shape
  Classification <span class="chip">BMVC2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuxian Ma, Zihao Dong, Runmin Cong, Sam Kwong, Xiuli Shao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning-based multi-view coarse-grained 3D shape classification has
achieved remarkable success over the past decade, leveraging the powerful
feature learning capabilities of CNN-based and ViT-based backbones. However, as
a challenging research area critical for detailed shape understanding,
fine-grained 3D classification remains understudied due to the limited
discriminative information captured during multi-view feature aggregation,
particularly for subtle inter-class variations, class imbalance, and inherent
interpretability limitations of parametric model. To address these problems, we
propose the first prototype-based framework named Proto-FG3D for fine-grained
3D shape classification, achieving a paradigm shift from parametric softmax to
non-parametric prototype learning. Firstly, Proto-FG3D establishes joint
multi-view and multi-category representation learning via Prototype
Association. Secondly, prototypes are refined via Online Clustering, improving
both the robustness of multi-view feature allocation and inter-subclass
balance. Finally, prototype-guided supervised learning is established to
enhance fine-grained discrimination via prototype-view correlation analysis and
enables ad-hoc interpretability through transparent case-based reasoning.
Experiments on FG3D and ModelNet40 show Proto-FG3D surpasses state-of-the-art
methods in accuracy, transparent predictions, and ad-hoc interpretability with
visualizations, challenging conventional fine-grained 3D recognition
approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 2 figures, 5 tablets; Submitted to BMVC2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EMRA-proxy: Enhancing Multi-Class Region Semantic Segmentation in Remote
  Sensing Images with Attention Proxy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichun Yu, Yuqing Lan, Zhihuan Xing, Xiaoyi Yang, Tingyue Tang, Dan Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution remote sensing (HRRS) image segmentation is challenging due
to complex spatial layouts and diverse object appearances. While CNNs excel at
capturing local features, they struggle with long-range dependencies, whereas
Transformers can model global context but often neglect local details and are
computationally expensive.We propose a novel approach, Region-Aware Proxy
Network (RAPNet), which consists of two components: Contextual Region Attention
(CRA) and Global Class Refinement (GCR). Unlike traditional methods that rely
on grid-based layouts, RAPNet operates at the region level for more flexible
segmentation. The CRA module uses a Transformer to capture region-level
contextual dependencies, generating a Semantic Region Mask (SRM). The GCR
module learns a global class attention map to refine multi-class information,
combining the SRM and attention map for accurate segmentation.Experiments on
three public datasets show that RAPNet outperforms state-of-the-art methods,
achieving superior multi-class segmentation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 20th International Conference on Intelligent
  Computing (ICIC 2024): Poster Volume I. Tianjin, China, 2024: 538-562</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17659v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17659v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaolong Tang, Meina Kan, Shiguang Shan, Xilin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safe and feasible trajectory planning is essential for real-world autonomous
driving systems. However, existing learning-based planning methods often rely
on expert demonstrations, which not only lack explicit safety awareness but
also risk inheriting unsafe behaviors such as speeding from suboptimal human
driving data. Inspired by the success of large language models, we propose
Plan-R1, a novel two-stage trajectory planning framework that formulates
trajectory planning as a sequential prediction task, guided by explicit
planning principles such as safety, comfort, and traffic rule compliance. In
the first stage, we train an autoregressive trajectory predictor via next
motion token prediction on expert data. In the second stage, we design
rule-based rewards (e.g., collision avoidance, speed limits) and fine-tune the
model using Group Relative Policy Optimization (GRPO), a reinforcement learning
strategy, to align its predictions with these planning principles. Experiments
on the nuPlan benchmark demonstrate that our Plan-R1 significantly improves
planning safety and feasibility, achieving state-of-the-art performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instruct2See: Learning to Remove Any Obstructions Across Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhang Li, Yu Guo, Chuhua Xian, Shengfeng He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Images are often obstructed by various obstacles due to capture limitations,
hindering the observation of objects of interest. Most existing methods address
occlusions from specific elements like fences or raindrops, but are constrained
by the wide range of real-world obstructions, making comprehensive data
collection impractical. To overcome these challenges, we propose Instruct2See,
a novel zero-shot framework capable of handling both seen and unseen obstacles.
The core idea of our approach is to unify obstruction removal by treating it as
a soft-hard mask restoration problem, where any obstruction can be represented
using multi-modal prompts, such as visual semantics and textual instructions,
processed through a cross-attention unit to enhance contextual understanding
and improve mode control. Additionally, a tunable mask adapter allows for
dynamic soft masking, enabling real-time adjustment of inaccurate masks.
Extensive experiments on both in-distribution and out-of-distribution obstacles
show that Instruct2See consistently achieves strong performance and
generalization in obstruction removal, regardless of whether the obstacles were
present during the training phase. Code and dataset are available at
https://jhscut.github.io/Instruct2See.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HoloLLM: Multisensory Foundation Model for Language-Grounded Human
  Sensing and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17645v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17645v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhao Zhou, Jianfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied agents operating in smart homes must understand human behavior
through diverse sensory inputs and communicate via natural language. While
Vision-Language Models (VLMs) have enabled impressive language-grounded
perception, their reliance on visual data limits robustness in real-world
scenarios with occlusions, poor lighting, or privacy constraints. In this
paper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that
integrates uncommon but powerful sensing modalities, such as LiDAR, infrared,
mmWave radar, and WiFi, to enable seamless human perception and reasoning
across heterogeneous environments. We address two key challenges: (1) the
scarcity of aligned modality-text data for rare sensors, and (2) the
heterogeneity of their physical signal representations. To overcome these, we
design a Universal Modality-Injection Projector (UMIP) that enhances
pre-aligned modality embeddings with fine-grained, text-aligned features from
tailored encoders via coarse-to-fine cross-attention without introducing
significant alignment overhead. We further introduce a human-VLM collaborative
data curation pipeline to generate paired textual annotations for sensing
datasets. Extensive experiments on two newly constructed benchmarks show that
HoloLLM significantly outperforms existing MLLMs, improving language-grounded
human sensing accuracy by up to 30%. This work establishes a new foundation for
real-world, language-informed multisensory embodied intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 13 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Prospective Medical Image Reconstruction via Knowledge-Informed
  Dynamic Optimal Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17644v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17644v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taoran Zheng, Xing Li, Yan Yang, Xiang Gu, Zongben Xu, Jian Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image reconstruction from measurement data is a vital but challenging
inverse problem. Deep learning approaches have achieved promising results, but
often requires paired measurement and high-quality images, which is typically
simulated through a forward model, i.e., retrospective reconstruction. However,
training on simulated pairs commonly leads to performance degradation on real
prospective data due to the retrospective-to-prospective gap caused by
incomplete imaging knowledge in simulation. To address this challenge, this
paper introduces imaging Knowledge-Informed Dynamic Optimal Transport (KIDOT),
a novel dynamic optimal transport framework with optimality in the sense of
preserving consistency with imaging physics in transport, that conceptualizes
reconstruction as finding a dynamic transport path. KIDOT learns from unpaired
data by modeling reconstruction as a continuous evolution path from
measurements to images, guided by an imaging knowledge-informed cost function
and transport equation. This dynamic and knowledge-aware approach enhances
robustness and better leverages unpaired data while respecting acquisition
physics. Theoretically, we demonstrate that KIDOT naturally generalizes dynamic
optimal transport, ensuring its mathematical rationale and solution existence.
Extensive experiments on MRI and CT reconstruction demonstrate KIDOT's superior
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Large Vision-Language Models with Layout Modality for Table
  Question Answering on Japanese Annual Securities Reports 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hayato Aida, Kosuke Takahashi, Takahiro Omi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With recent advancements in Large Language Models (LLMs) and growing interest
in retrieval-augmented generation (RAG), the ability to understand table
structures has become increasingly important. This is especially critical in
financial domains such as securities reports, where highly accurate question
answering (QA) over tables is required. However, tables exist in various
formats-including HTML, images, and plain text-making it difficult to preserve
and extract structural information. Therefore, multimodal LLMs are essential
for robust and general-purpose table understanding. Despite their promise,
current Large Vision-Language Models (LVLMs), which are major representatives
of multimodal LLMs, still face challenges in accurately understanding
characters and their spatial relationships within documents. In this study, we
propose a method to enhance LVLM-based table understanding by incorporating
in-table textual content and layout features. Experimental results demonstrate
that these auxiliary modalities significantly improve performance, enabling
robust interpretation of complex document layouts without relying on explicitly
structured input formats.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IIAI AAI 2025, the 3rd International Conference on
  Computational and Data Sciences in Economics and Finance</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography
  Quality Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Wang, De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Nu-Fang Xiao, Jian-Long Hao, Ming-Yuan Liu, Zeng-Guang Hou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic X-ray angiographies generated by modern generative models hold
great potential to reduce the use of contrast agents in vascular interventional
procedures. However, low-quality synthetic angiographies can significantly
increase procedural risk, underscoring the need for reliable image quality
assessment (IQA) methods. Existing IQA models, however, fail to leverage
auxiliary images as references during evaluation and lack fine-grained,
task-specific metrics necessary for clinical relevance. To address these
limitations, this paper proposes CAS-IQA, a vision-language model (VLM)-based
framework that predicts fine-grained quality scores by effectively
incorporating auxiliary information from related images. In the absence of
angiography datasets, CAS-3K is constructed, comprising 3,565 synthetic
angiographies along with score annotations. To ensure clinically meaningful
assessment, three task-specific evaluation metrics are defined. Furthermore, a
Multi-path featUre fuSion and rouTing (MUST) module is designed to enhance
image representations by adaptively fusing and routing visual tokens to
metric-specific branches. Extensive experiments on the CAS-3K dataset
demonstrate that CAS-IQA significantly outperforms state-of-the-art IQA methods
by a considerable margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Image and Video Generation via Test-Time Evolutionary Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran He, Jiajun Liang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Ling Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the marginal cost of scaling computation (data and parameters) during
model pre-training continues to increase substantially, test-time scaling (TTS)
has emerged as a promising direction for improving generative model performance
by allocating additional computation at inference time. While TTS has
demonstrated significant success across multiple language tasks, there remains
a notable gap in understanding the test-time scaling behaviors of image and
video generative models (diffusion-based or flow-based models). Although recent
works have initiated exploration into inference-time strategies for vision
tasks, these approaches face critical limitations: being constrained to
task-specific domains, exhibiting poor scalability, or falling into reward
over-optimization that sacrifices sample diversity. In this paper, we propose
\textbf{Evo}lutionary \textbf{Search} (EvoSearch), a novel, generalist, and
efficient TTS method that effectively enhances the scalability of both image
and video generation across diffusion and flow models, without requiring
additional training or model expansion. EvoSearch reformulates test-time
scaling for diffusion and flow models as an evolutionary search problem,
leveraging principles from biological evolution to efficiently explore and
refine the denoising trajectory. By incorporating carefully designed selection
and mutation mechanisms tailored to the stochastic differential equation
denoising process, EvoSearch iteratively generates higher-quality offspring
while preserving population diversity. Through extensive evaluation across both
diffusion and flow architectures for image and video generation tasks, we
demonstrate that our method consistently outperforms existing approaches,
achieves higher diversity, and shows strong generalizability to unseen
evaluation metrics. Our project is available at the website
https://tinnerhrhe.github.io/evosearch.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages. Project: https://tinnerhrhe.github.io/evosearch</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathoSCOPE: Few-Shot Pathology Detection via <span class="highlight-title">Self-Supervised</span> Contrastive
  Learning and Pathology-Informed Synthetic Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sinchee Chin, Yinuo Ma, Xiaochen Yang, Jing-Hao Xue, Wenming Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised pathology detection trains models on non-pathological data to
flag deviations as pathologies, offering strong generalizability for
identifying novel diseases and avoiding costly annotations. However, building
reliable normality models requires vast healthy datasets, as hospitals' data is
inherently biased toward symptomatic populations, while privacy regulations
hinder the assembly of representative healthy cohorts. To address this
limitation, we propose PathoSCOPE, a few-shot unsupervised pathology detection
framework that requires only a small set of non-pathological samples (minimum 2
shots), significantly improving data efficiency. We introduce Global-Local
Contrastive Loss (GLCL), comprised of a Local Contrastive Loss to reduce the
variability of non-pathological embeddings and a Global Contrastive Loss to
enhance the discrimination of pathological regions. We also propose a
Pathology-informed Embedding Generation (PiEG) module that synthesizes
pathological embeddings guided by the global loss, better exploiting the
limited non-pathological samples. Evaluated on the BraTS2020 and ChestXray8
datasets, PathoSCOPE achieves state-of-the-art performance among unsupervised
methods while maintaining computational efficiency (2.48 GFLOPs, 166 FPS).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask
  Multimodal Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihan Yao, Yushi Hu, Yujie Yi, Bin Han, Shangbin Feng, Guang Yang, Bingbing Wen, Ranjay Krishna, Lucy Lu Wang, Yulia Tsvetkov, Noah A. Smith, Banghua Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatically evaluating multimodal generation presents a significant
challenge, as automated metrics often struggle to align reliably with human
evaluation, especially for complex tasks that involve multiple modalities. To
address this, we present MMMG, a comprehensive and human-aligned benchmark for
multimodal generation across 4 modality combinations (image, audio, interleaved
text and image, interleaved text and audio), with a focus on tasks that present
significant challenges for generation models, while still enabling reliable
automatic evaluation through a combination of models and programs. MMMG
encompasses 49 tasks (including 29 newly developed ones), each with a carefully
designed evaluation pipeline, and 937 instructions to systematically assess
reasoning, controllability, and other key capabilities of multimodal generation
models. Extensive validation demonstrates that MMMG is highly aligned with
human evaluation, achieving an average agreement of 94.3%. Benchmarking results
on 24 multimodal generation models reveal that even though the state-of-the-art
model, GPT Image, achieves 78.3% accuracy for image generation, it falls short
on multimodal reasoning and interleaved generation. Furthermore, results
suggest considerable headroom for improvement in audio generation, highlighting
an important direction for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MinkUNeXt-SI: Improving point cloud-based place recognition including
  spherical coordinates and LiDAR intensity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17591v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17591v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Judith Vilella-Cantos, Juan José Cabrera, Luis Payá, Mónica Ballesta, David Valiente
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In autonomous navigation systems, the solution of the place recognition
problem is crucial for their safe functioning. But this is not a trivial
solution, since it must be accurate regardless of any changes in the scene,
such as seasonal changes and different weather conditions, and it must be
generalizable to other environments. This paper presents our method,
MinkUNeXt-SI, which, starting from a LiDAR point cloud, preprocesses the input
data to obtain its spherical coordinates and intensity values normalized within
a range of 0 to 1 for each point, and it produces a robust place recognition
descriptor. To that end, a deep learning approach that combines Minkowski
convolutions and a U-net architecture with skip connections is used. The
results of MinkUNeXt-SI demonstrate that this method reaches and surpasses
state-of-the-art performance while it also generalizes satisfactorily to other
datasets. Additionally, we showcase the capture of a custom dataset and its use
in evaluating our solution, which also achieves outstanding results. Both the
code of our solution and the runs of our dataset are publicly available for
reproducibility purposes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human
  Head Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17590v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17590v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Barthel, Wieland Morgenstern, Paul Hinzer, Anna Hilsmann, Peter Eisert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high
quality synthesis of human heads. However, existing methods stabilize training
and enhance rendering quality from steep viewpoints by conditioning the random
latent vector on the current camera position. This compromises 3D consistency,
as we observe significant identity changes when re-synthesizing the 3D head
with each camera shift. Conversely, fixing the camera to a single viewpoint
yields high-quality renderings for that perspective but results in poor
performance for novel views. Removing view-conditioning typically destabilizes
GAN training, often causing the training to collapse. In response to these
challenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework
that enables stable training and high-quality 3D-consistent synthesis of human
heads without relying on view-conditioning. To ensure training stability, we
introduce a multi-view regularization technique that enhances generator
convergence with minimal computational overhead. Additionally, we adapt the
conditional loss used in existing 3D Gaussian splatting GANs and propose a
generator architecture designed to not only stabilize training but also
facilitate efficient rendering and straightforward scaling, enabling output
resolutions up to $2048^2$. To evaluate the capabilities of CGS-GAN, we curate
a new dataset derived from FFHQ. This dataset enables very high resolutions,
focuses on larger portions of the human head, reduces view-dependent artifacts
for improved 3D consistency, and excludes images where subjects are obscured by
hands or other objects. As a result, our approach achieves very high rendering
quality, supported by competitive FID scores, while ensuring consistent 3D
scene generation. Check our our project page here:
https://fraunhoferhhi.github.io/cgs-gan/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main paper 12 pages, supplementary materials 8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distance Estimation in Outdoor Driving Environments Using Phase-only
  Correlation Method with Event Cameras 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masataka Kobayashi, Shintaro Shiba, Quan Kong, Norimasa Kobori, Tsukasa Shimizu, Shan Lu, Takaya Yamazato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing adoption of autonomous driving, the advancement of sensor
technology is crucial for ensuring safety and reliable operation. Sensor fusion
techniques that combine multiple sensors such as LiDAR, radar, and cameras have
proven effective, but the integration of multiple devices increases both
hardware complexity and cost. Therefore, developing a single sensor capable of
performing multiple roles is highly desirable for cost-efficient and scalable
autonomous driving systems.
  Event cameras have emerged as a promising solution due to their unique
characteristics, including high dynamic range, low latency, and high temporal
resolution. These features enable them to perform well in challenging lighting
conditions, such as low-light or backlit environments. Moreover, their ability
to detect fine-grained motion events makes them suitable for applications like
pedestrian detection and vehicle-to-infrastructure communication via visible
light.
  In this study, we present a method for distance estimation using a monocular
event camera and a roadside LED bar. By applying a phase-only correlation
technique to the event data, we achieve sub-pixel precision in detecting the
spatial shift between two light sources. This enables accurate
triangulation-based distance estimation without requiring stereo vision. Field
experiments conducted in outdoor driving scenarios demonstrated that the
proposed approach achieves over 90% success rate with less than 0.5-meter error
for distances ranging from 20 to 60 meters.
  Future work includes extending this method to full position estimation by
leveraging infrastructure such as smart poles equipped with LEDs, enabling
event-camera-based vehicles to determine their own position in real time. This
advancement could significantly enhance navigation accuracy, route
optimization, and integration into intelligent transportation systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 7 figures. To appear in IEEE Intelligent Vehicles Symposium
  (IV) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MODEM: A Morton-Order Degradation Estimation Mechanism for Adverse
  Weather Image Recovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hainuo Wang, Qiming Hu, Xiaojie Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Restoring images degraded by adverse weather remains a significant challenge
due to the highly non-uniform and spatially heterogeneous nature of
weather-induced artifacts, e.g., fine-grained rain streaks versus widespread
haze. Accurately estimating the underlying degradation can intuitively provide
restoration models with more targeted and effective guidance, enabling adaptive
processing strategies. To this end, we propose a Morton-Order Degradation
Estimation Mechanism (MODEM) for adverse weather image restoration. Central to
MODEM is the Morton-Order 2D-Selective-Scan Module (MOS2D), which integrates
Morton-coded spatial ordering with selective state-space models to capture
long-range dependencies while preserving local structural coherence.
Complementing MOS2D, we introduce a Dual Degradation Estimation Module (DDEM)
that disentangles and estimates both global and local degradation priors. These
priors dynamically condition the MOS2D modules, facilitating adaptive and
context-aware restoration. Extensive experiments and ablation studies
demonstrate that MODEM achieves state-of-the-art results across multiple
benchmarks and weather types, highlighting its effectiveness in modeling
complex degradation dynamics. Our code will be released at
https://github.com/hainuo-wang/MODEM.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfLVG: Reinforce Inference-Time Consistent Long Video Generation with
  GRPO 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueji Fang, Liyuan Ma, Zhiyang Chen, Mingyuan Zhou, Guo-jun Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-to-video generation, particularly with autoregressive
models, have enabled the synthesis of high-quality videos depicting individual
scenes. However, extending these models to generate long, cross-scene videos
remains a significant challenge. As the context length grows during
autoregressive decoding, computational costs rise sharply, and the model's
ability to maintain consistency and adhere to evolving textual prompts
deteriorates. We introduce InfLVG, an inference-time framework that enables
coherent long video generation without requiring additional long-form video
data. InfLVG leverages a learnable context selection policy, optimized via
Group Relative Policy Optimization (GRPO), to dynamically identify and retain
the most semantically relevant context throughout the generation process.
Instead of accumulating the entire generation history, the policy ranks and
selects the top-$K$ most contextually relevant tokens, allowing the model to
maintain a fixed computational budget while preserving content consistency and
prompt alignment. To optimize the policy, we design a hybrid reward function
that jointly captures semantic alignment, cross-scene consistency, and artifact
reduction. To benchmark performance, we introduce the Cross-scene Video
Benchmark (CsVBench) along with an Event Prompt Set (EPS) that simulates
complex multi-scene transitions involving shared subjects and varied
actions/backgrounds. Experimental results show that InfLVG can extend video
length by up to 9$\times$, achieving strong consistency and semantic fidelity
across scenes. Our code is available at https://github.com/MAPLE-AIGC/InfLVG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Fourier-based Doppler Resolution with Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Denisa Qosja, Kilian Barth, Simon Wagner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In radar systems, high resolution in the Doppler dimension is important for
detecting slow-moving targets as it allows for more distinct separation between
these targets and clutter, or stationary objects. However, achieving sufficient
resolution is constrained by hardware capabilities and physical factors,
leading to the development of processing techniques to enhance the resolution
after acquisition. In this work, we leverage artificial intelligence to
increase the Doppler resolution in range-Doppler maps. Based on a zero-padded
FFT, a refinement via the generative neural networks of diffusion models is
achieved. We demonstrate that our method overcomes the limitations of
traditional FFT, generating data where closely spaced targets are effectively
separated.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at International Radar Symposium (IRS) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Model Already Knows the Best Noise: Bayesian Active Noise Selection via
  Attention in Video Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kwanyoung Kim, Sanghyun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The choice of initial noise significantly affects the quality and prompt
alignment of video diffusion models, where different noise seeds for the same
prompt can lead to drastically different generations. While recent methods rely
on externally designed priors such as frequency filters or inter-frame
smoothing, they often overlook internal model signals that indicate which noise
seeds are inherently preferable. To address this, we propose ANSE (Active Noise
Selection for Generation), a model-aware framework that selects high-quality
noise seeds by quantifying attention-based uncertainty. At its core is BANSA
(Bayesian Active Noise Selection via Attention), an acquisition function that
measures entropy disagreement across multiple stochastic attention samples to
estimate model confidence and consistency. For efficient inference-time
deployment, we introduce a Bernoulli-masked approximation of BANSA that enables
score estimation using a single diffusion step and a subset of attention
layers. Experiments on CogVideoX-2B and 5B demonstrate that ANSE improves video
quality and temporal coherence with only an 8% and 13% increase in inference
time, respectively, providing a principled and generalizable approach to noise
selection in video diffusion. See our project page:
https://anse-project.github.io/anse-project/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deeper Diffusion Models Amplify Bias 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahin Hakemi, Naveed Akhtar, Ghulam Mubashar Hassan, Ajmal Mian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the impressive performance of generative Diffusion Models (DMs),
their internal working is still not well understood, which is potentially
problematic. This paper focuses on exploring the important notion of
bias-variance tradeoff in diffusion models. Providing a systematic foundation
for this exploration, it establishes that at one extreme the diffusion models
may amplify the inherent bias in the training data and, on the other, they may
compromise the presumed privacy of the training samples. Our exploration aligns
with the memorization-generalization understanding of the generative models,
but it also expands further along this spectrum beyond ``generalization'',
revealing the risk of bias amplification in deeper models. Building on the
insights, we also introduce a training-free method to improve output quality in
text-to-image and image-to-image generation. By progressively encouraging
temporary high variance in the generation process with partial bypassing of the
mid-block's contribution in the denoising process of DMs, our method
consistently improves generative image quality with zero training cost. Our
claims are validated both theoretically and empirically.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wildfire spread forecasting with Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikolaos Anastasiou, Spyros Kondylatos, Ioannis Papoutsis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate prediction of wildfire spread is crucial for effective risk
management, emergency response, and strategic resource allocation. In this
study, we present a deep learning (DL)-based framework for forecasting the
final extent of burned areas, using data available at the time of ignition. We
leverage a spatio-temporal dataset that covers the Mediterranean region from
2006 to 2022, incorporating remote sensing data, meteorological observations,
vegetation maps, land cover classifications, anthropogenic factors, topography
data, and thermal anomalies. To evaluate the influence of temporal context, we
conduct an ablation study examining how the inclusion of pre- and post-ignition
data affects model performance, benchmarking the temporal-aware DL models
against a baseline trained exclusively on ignition-day inputs. Our results
indicate that multi-day observational data substantially improve predictive
accuracy. Particularly, the best-performing model, incorporating a temporal
window of four days before to five days after ignition, improves both the F1
score and the Intersection over Union by almost 5% in comparison to the
baseline on the test dataset. We publicly release our dataset and models to
enhance research into data-driven approaches for wildfire modeling and
response.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProTAL: A Drag-and-Link Video Programming Framework for Temporal Action
  Localization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen He, Jianbing Lv, Liqi Cheng, Lingyu Meng, Dazhen Deng, Yingcai Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal Action Localization (TAL) aims to detect the start and end
timestamps of actions in a video. However, the training of TAL models requires
a substantial amount of manually annotated data. Data programming is an
efficient method to create training labels with a series of human-defined
labeling functions. However, its application in TAL faces difficulties of
defining complex actions in the context of temporal video frames. In this
paper, we propose ProTAL, a drag-and-link video programming framework for TAL.
ProTAL enables users to define \textbf{key events} by dragging nodes
representing body parts and objects and linking them to constrain the relations
(direction, distance, etc.). These definitions are used to generate action
labels for large-scale unlabelled videos. A semi-supervised method is then
employed to train TAL models with such labels. We demonstrate the effectiveness
of ProTAL through a usage scenario and a user study, providing insights into
designing video programming framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CHI'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Center-aware Residual Anomaly Synthesis for Multi-class Industrial
  Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17551v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17551v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiyu Chen, Huiyuan Luo, Haiming Yao, Wei Luo, Zhen Qu, Chengkan Lv, Zhengtao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection plays a vital role in the inspection of industrial images.
Most existing methods require separate models for each category, resulting in
multiplied deployment costs. This highlights the challenge of developing a
unified model for multi-class anomaly detection. However, the significant
increase in inter-class interference leads to severe missed detections.
Furthermore, the intra-class overlap between normal and abnormal samples,
particularly in synthesis-based methods, cannot be ignored and may lead to
over-detection. To tackle these issues, we propose a novel Center-aware
Residual Anomaly Synthesis (CRAS) method for multi-class anomaly detection.
CRAS leverages center-aware residual learning to couple samples from different
categories into a unified center, mitigating the effects of inter-class
interference. To further reduce intra-class overlap, CRAS introduces
distance-guided anomaly synthesis that adaptively adjusts noise variance based
on normal data distribution. Experimental results on diverse datasets and
real-world industrial applications demonstrate the superior detection accuracy
and competitive inference speed of CRAS. The source code and the newly
constructed dataset are publicly available at
https://github.com/cqylunlun/CRAS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Industrial Informatics (TII)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ T2VUnlearning: A Concept Erasing Method for Text-to-Video Diffusion
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17550v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17550v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Ye, Songjie Cheng, Yongtao Wang, Yajiao Xiong, Yishen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-to-video (T2V) diffusion models have significantly
enhanced the quality of generated videos. However, their ability to produce
explicit or harmful content raises concerns about misuse and potential rights
violations. Inspired by the success of unlearning techniques in erasing
undesirable concepts from text-to-image (T2I) models, we extend unlearning to
T2V models and propose a robust and precise unlearning method. Specifically, we
adopt negatively-guided velocity prediction fine-tuning and enhance it with
prompt augmentation to ensure robustness against LLM-refined prompts. To
achieve precise unlearning, we incorporate a localization and a preservation
regularization to preserve the model's ability to generate non-target concepts.
Extensive experiments demonstrate that our method effectively erases a specific
concept while preserving the model's generation capability for all other
concepts, outperforming existing methods. We provide the unlearned models in
\href{https://github.com/VDIGPKU/T2VUnlearning.git}{https://github.com/VDIGPKU/T2VUnlearning.git}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FreqU-FNet: Frequency-Aware U-Net for Imbalanced Medical Image
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17544v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17544v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiqi Xing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image segmentation faces persistent challenges due to severe class
imbalance and the frequency-specific distribution of anatomical structures.
Most conventional CNN-based methods operate in the spatial domain and struggle
to capture minority class signals, often affected by frequency aliasing and
limited spectral selectivity. Transformer-based models, while powerful in
modeling global dependencies, tend to overlook critical local details necessary
for fine-grained segmentation. To overcome these limitations, we propose
FreqU-FNet, a novel U-shaped segmentation architecture operating in the
frequency domain. Our framework incorporates a Frequency Encoder that leverages
Low-Pass Frequency Convolution and Daubechies wavelet-based downsampling to
extract multi-scale spectral features. To reconstruct fine spatial details, we
introduce a Spatial Learnable Decoder (SLD) equipped with an adaptive
multi-branch upsampling strategy. Furthermore, we design a frequency-aware loss
(FAL) function to enhance minority class learning. Extensive experiments on
multiple medical segmentation benchmarks demonstrate that FreqU-FNet
consistently outperforms both CNN and Transformer baselines, particularly in
handling under-represented classes, by effectively exploiting discriminative
frequency bands.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Synergistic Bleeding Region and Point Detection in Laparoscopic Surgical
  Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.22174v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.22174v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialun Pei, Zhangjun Zhou, Diandian Guo, Zhixi Li, Jing Qin, Bo Du, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intraoperative bleeding in laparoscopic surgery causes rapid obscuration of
the operative field to hinder the surgical process and increases the risk of
postoperative complications. Intelligent detection of bleeding areas can
quantify the blood loss to assist decision-making, while locating bleeding
points helps surgeons quickly identify the source of bleeding and achieve
hemostasis in time to improve surgical success rates. In this study, we first
construct a real-world laparoscopic surgical bleeding detection dataset, named
SurgBlood, comprising 5,330 frames from 95 surgical video clips with bleeding
region and point annotations. Accordingly, we develop a dual-task synergistic
online detector called BlooDet, designed to perform simultaneous detection of
bleeding regions and points in laparoscopic surgery. Our framework embraces a
dual-branch bidirectional guidance design based on Segment Anything Model 2
(SAM 2). The mask branch detects bleeding regions through adaptive edge and
point prompt embeddings, and the point branch leverages mask memory to induce
bleeding point memory modeling and capture the direction of bleed point
movement via inter-frame optical flow. By bidirectional guidance, the two
branches explore potential spatial-temporal relationships while leveraging
memory modeling to infer the current bleeding condition. Extensive experiments
demonstrate that our baseline outperforms 12 counterparts on SurgBlood in both
bleeding region and point detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMXU: A Multi-Modal and Multi-X-ray Understanding <span class="highlight-title">Dataset</span> for Disease
  Progression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11651v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11651v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) have shown great promise in medical
applications, particularly in visual question answering (MedVQA) and diagnosis
from medical images. However, existing datasets and models often fail to
consider critical aspects of medical diagnostics, such as the integration of
historical records and the analysis of disease progression over time. In this
paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel
dataset for MedVQA that focuses on identifying changes in specific regions
between two patient visits. Unlike previous datasets that primarily address
single-image questions, MMXU enables multi-image questions, incorporating both
current and historical patient data. We demonstrate the limitations of current
LVLMs in identifying disease progression on MMXU-\textit{test}, even those that
perform well on traditional benchmarks. To address this, we propose a
MedRecord-Augmented Generation (MAG) approach, incorporating both global and
regional historical records. Our experiments show that integrating historical
records significantly enhances diagnostic accuracy by at least 20\%, bridging
the gap between current LVLMs and human expert performance. Additionally, we
fine-tune models with MAG on MMXU-\textit{dev}, which demonstrates notable
improvements. We hope this work could illuminate the avenue of advancing the
use of LVLMs in medical diagnostics by emphasizing the importance of historical
context in interpreting medical images. Our dataset is released at github:
https://github.com/linjiemu/MMXU.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Clinician-Friendly Platform for Ophthalmic Image Analysis Without
  Technical Barriers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15928v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15928v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Wang, Tian Lin, Qingshan Hou, Aidi Lin, Jingcheng Wang, Qingsheng Peng, Truong X. Nguyen, Danqi Fang, Ke Zou, Ting Xu, Cancan Xue, Ten Cheer Quek, Qinkai Yu, Minxin Liu, Hui Zhou, Zixuan Xiao, Guiqin He, Huiyu Liang, Tingkun Shi, Man Chen, Linna Liu, Yuanyuan Peng, Lianyu Wang, Qiuming Hu, Junhong Chen, Zhenhua Zhang, Cheng Chen, Yitian Zhao, Dianbo Liu, Jianhua Wu, Xinjian Chen, Changqing Zhang, Triet Thanh Nguyen, Yanda Meng, Yalin Zheng, Yih Chung Tham, Carol Y. Cheung, Huazhu Fu, Haoyu Chen, Ching-Yu Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence (AI) shows remarkable potential in medical imaging
diagnostics, yet most current models require retraining when applied across
different clinical settings, limiting their scalability. We introduce
GlobeReady, a clinician-friendly AI platform that enables fundus disease
diagnosis that operates without retraining, fine-tuning, or the needs for
technical expertise. GlobeReady demonstrates high accuracy across imaging
modalities: 93.9-98.5% for 11 fundus diseases using color fundus photographs
(CPFs) and 87.2-92.7% for 15 fundus diseases using optic coherence tomography
(OCT) scans. By leveraging training-free local feature augmentation, GlobeReady
platform effectively mitigates domain shifts across centers and populations,
achieving accuracies of 88.9-97.4% across five centers on average in China,
86.3-96.9% in Vietnam, and 73.4-91.0% in Singapore, and 90.2-98.9% in the UK.
Incorporating a bulit-in confidence-quantifiable diagnostic mechanism further
enhances the platform's accuracy to 94.9-99.4% with CFPs and 88.2-96.2% with
OCT, while enabling identification of out-of-distribution cases with 86.3%
accuracy across 49 common and rare fundus diseases using CFPs, and 90.6%
accuracy across 13 diseases using OCT. Clinicians from countries rated
GlobeReady highly for usability and clinical relevance (average score 4.6/5).
These findings demonstrate GlobeReady's robustness, generalizability and
potential to support global ophthalmic care without technical barriers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ViFOR: A Fourier-Enhanced Vision <span class="highlight-title">Transformer</span> for Multi-Image
  Super-Resolution in Earth System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12427v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12427v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ehsan Zeraatkar, Salah A Faroughi, Jelena Tešić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Super-resolution (SR) techniques are essential for improving Earth System
Model (ESM) data's spatial resolution, which helps better understand complex
environmental processes. This paper presents a new algorithm, ViFOR, which
combines Vision Transformers (ViT) and Fourier-based Implicit Neural
Representation Networks (INRs) to generate High-Resolution (HR) images from
Low-Resolution (LR) inputs. ViFOR introduces a novel integration of
Fourier-based activation functions within the Vision Transformer architecture,
enabling it to effectively capture global context and high-frequency details
critical for accurate SR reconstruction. The results show that ViFOR
outperforms state-of-the-art methods such as ViT, Sinusoidal Representation
Networks (SIREN), and SR Generative Adversarial Networks (SRGANs) based on
metrics like Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE)
both for global as well as the local imagery. ViFOR improves PSNR of up to 4.18
dB, 1.56 dB, and 1.73 dB over ViT for full images in the Source Temperature,
Shortwave, and Longwave Flux.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Forensics Adapter: Unleashing CLIP for Generalizable Face Forgery
  Detection <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.19715v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.19715v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinjie Cui, Yuezun Li, Delong Zhu, Jiaran Zhou, Junyu Dong, Siwei Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We describe Forensics Adapter, an adapter network designed to transform CLIP
into an effective and generalizable face forgery detector. Although CLIP is
highly versatile, adapting it for face forgery detection is non-trivial as
forgery-related knowledge is entangled with a wide range of unrelated
knowledge. Existing methods treat CLIP merely as a feature extractor, lacking
task-specific adaptation, which limits their effectiveness. To address this, we
introduce an adapter to learn face forgery traces -- the blending boundaries
unique to forged faces, guided by task-specific objectives. Then we enhance the
CLIP visual tokens with a dedicated interaction strategy that communicates
knowledge across CLIP and the adapter. Since the adapter is alongside CLIP, its
versatility is highly retained, naturally ensuring strong generalizability in
face forgery detection. With only 5.7M trainable parameters, our method
achieves a significant performance boost, improving by approximately 7% on
average across five standard datasets. Additionally, we describe Forensics
Adapter++, an extended method that incorporates textual modality via a newly
proposed forgery-aware prompt learning strategy. This extension leads to a
further 1.3% performance boost over the original Forensics Adapter. We believe
the proposed methods can serve as a baseline for future CLIP-based face forgery
detection methods. The codes have been released at
https://github.com/OUC-VAS/ForensicsAdapter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extension of CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Think or Not? Selective Reasoning via Reinforcement Learning for
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16854v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16854v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning (RL) has proven to be an effective post-training
strategy for enhancing reasoning in vision-language models (VLMs). Group
Relative Policy Optimization (GRPO) is a recent prominent method that
encourages models to generate complete reasoning traces before answering,
leading to increased token usage and computational cost. Inspired by the
human-like thinking process-where people skip reasoning for easy questions but
think carefully when needed-we explore how to enable VLMs to first decide when
reasoning is necessary. To realize this, we propose TON, a two-stage training
strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective
'thought dropout' operation, where reasoning traces are randomly replaced with
empty thoughts. This introduces a think-or-not format that serves as a cold
start for selective reasoning; (ii) a GRPO stage that enables the model to
freely explore when to think or not, while maximizing task-aware outcome
rewards. Experimental results show that TON can reduce the completion length by
up to 90% compared to vanilla GRPO, without sacrificing performance or even
improving it. Further evaluations across diverse vision-language tasks-covering
a range of reasoning difficulties under both 3B and 7B models-consistently
reveal that the model progressively learns to bypass unnecessary reasoning
steps as training advances. These findings shed light on the path toward
human-like reasoning patterns in reinforcement learning approaches. Our code is
available at https://github.com/kokolerk/TON.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>update more examples in appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Faceted Multimodal Monosemanticity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14888v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14888v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanqi Yan, Xiangxiang Cui, Lu Yin, Paul Pu Liang, Yulan He, Yifei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans experience the world through multiple modalities, such as, vision,
language, and speech, making it natural to explore the commonality and
distinctions among them. In this work, we take a data-driven approach to
address this question by analyzing interpretable, monosemantic features
extracted from deep multimodal models. Specifically, we investigate CLIP, a
prominent visual-language representation model trained on massive image-text
pairs. Building on prior research in single-modal interpretability, we develop
a set of multi-modal interpretability tools and measures designed to
disentangle and analyze features learned from CLIP. Specifically, we introduce
the Modality Dominance Score (MDS) to attribute each CLIP feature to a specific
modality. We then map CLIP features into a more interpretable space, enabling
us to categorize them into three distinct classes: vision features
(single-modal), language features (single-modal), and visual-language features
(cross-modal). Interestingly, this data-driven categorization closely aligns
with human intuitive understandings of different modalities. We further show
that this modality decomposition can benefit multiple downstream tasks,
including reducing bias in gender detection, generating cross-modal adversarial
examples, and enabling modal-specific feature control in text-to-image
generation. These results indicate that large-scale multimodal models, when
equipped with task-agnostic interpretability tools, can offer valuable insights
into the relationships between different data modalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CostFilter-AD: Enhancing Anomaly Detection through Matching Cost
  Filtering <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.01476v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.01476v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Zhang, Mingxiu Cai, Hanxiao Wang, Gaochang Wu, Tianyou Chai, Xiatian Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised anomaly detection (UAD) seeks to localize the anomaly mask of an
input image with respect to normal samples. Either by reconstructing normal
counterparts (reconstruction-based) or by learning an image feature embedding
space (embedding-based), existing approaches fundamentally rely on image-level
or feature-level matching to derive anomaly scores. Often, such a matching
process is inaccurate yet overlooked, leading to sub-optimal detection. To
address this issue, we introduce the concept of cost filtering, borrowed from
classical matching tasks, such as depth and flow estimation, into the UAD
problem. We call this approach {\em CostFilter-AD}. Specifically, we first
construct a matching cost volume between the input and normal samples,
comprising two spatial dimensions and one matching dimension that encodes
potential matches. To refine this, we propose a cost volume filtering network,
guided by the input observation as an attention query across multiple feature
layers, which effectively suppresses matching noise while preserving edge
structures and capturing subtle anomalies. Designed as a generic
post-processing plug-in, CostFilter-AD can be integrated with either
reconstruction-based or embedding-based methods. Extensive experiments on
MVTec-AD and VisA benchmarks validate the generic benefits of CostFilter-AD for
both single- and multi-class UAD tasks. Code and models will be released at
https://github.com/ZHE-SAPI/CostFilter-AD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 12 figures, 20 tables, accepted by Forty-Second
  International Conference on Machine Learning ( ICML 2025 ), link:
  https://icml.cc/virtual/2025/poster/46359</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RBench-V: A Primary Assessment for Visual Reasoning Models with
  Multi-modal Outputs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng-Hao Guo, Xuanyu Chu, Qianrui Yang, Zhe-Han Mo, Yiqing Shen, Pei-lin Li, Xinjie Lin, Jinnian Zhang, Xin-Sheng Chen, Yi Zhang, Kiyohiro Nakayama, Zhengyang Geng, Houwen Peng, Han Hu, Shi-Min Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of native multi-modal models and omni-models,
exemplified by GPT-4o, Gemini, and o3, with their capability to process and
generate content across modalities such as text and images, marks a significant
milestone in the evolution of intelligence. Systematic evaluation of their
multi-modal output capabilities in visual thinking processes (also known as
multi-modal chain of thought, M-CoT) becomes critically important. However,
existing benchmarks for evaluating multi-modal models primarily focus on
assessing multi-modal inputs and text-only reasoning while neglecting the
importance of reasoning through multi-modal outputs. In this paper, we present
a benchmark, dubbed RBench-V, designed to assess models' vision-indispensable
reasoning abilities. To construct RBench-V, we carefully hand-pick 803
questions covering math, physics, counting, and games. Unlike previous
benchmarks that typically specify certain input modalities, RBench-V presents
problems centered on multi-modal outputs, which require image manipulation such
as generating novel images and constructing auxiliary lines to support the
reasoning process. We evaluate numerous open- and closed-source models on
RBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the
best-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below
the human score of 82.3%, highlighting that current models struggle to leverage
multi-modal reasoning. Data and code are available at
https://evalmodels.github.io/rbenchv
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Selective Structured State Space for Multispectral-fused Small Target
  Detection <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14043v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14043v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianqian Zhang, WeiJun Wang, Yunxing Liu, Li Zhou, Hao Zhao, Junshe An, Zihan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Target detection in high-resolution remote sensing imagery faces challenges
due to the low recognition accuracy of small targets and high computational
costs. The computational complexity of the Transformer architecture increases
quadratically with image resolution, while Convolutional Neural Networks (CNN)
architectures are forced to stack deeper convolutional layers to expand their
receptive fields, leading to an explosive growth in computational demands. To
address these computational constraints, we leverage Mamba's linear complexity
for efficiency. However, Mamba's performance declines for small targets,
primarily because small targets occupy a limited area in the image and have
limited semantic information. Accurate identification of these small targets
necessitates not only Mamba's global attention capabilities but also the
precise capture of fine local details. To this end, we enhance Mamba by
developing the Enhanced Small Target Detection (ESTD) module and the
Convolutional Attention Residual Gate (CARG) module. The ESTD module bolsters
local attention to capture fine-grained details, while the CARG module, built
upon Mamba, emphasizes spatial and channel-wise information, collectively
improving the model's ability to capture distinctive representations of small
targets. Additionally, to highlight the semantic representation of small
targets, we design a Mask Enhanced Pixel-level Fusion (MEPF) module for
multispectral fusion, which enhances target features by effectively fusing
visible and infrared multimodal information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work was submitted to CVPR 2025, but was rejected after being
  reviewed by 7 reviewers. After revision, it is currently under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Simpler Fast Vision <span class="highlight-title">Transformer</span>s with a Jumbo CLS Token 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15021v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15021v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anthony Fuller, Yousef Yassin, Daniel G. Kyrollos, Evan Shelhamer, James R. Green
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a simple enhancement of vision transformers (ViTs) to improve
accuracy while maintaining throughput. Our approach, Jumbo, creates a wider CLS
token, which is split to match the patch token width before attention,
processed with self-attention, and reassembled. After attention, Jumbo applies
a dedicated, wider FFN to this token. Since there is only one Jumbo token, its
cost is minimal, and because we share this FFN across layers, its parameter
count is controlled. Jumbo significantly improves over ViT+Registers on
ImageNet-1K and ImageNet-21K. These gains are largest at small sizes / high
speeds, e.g., ViT-nano+Jumbo outperforms ViT-nano+Registers by 13%. In fact,
our Jumbo models are so efficient that they outperform specialized
compute-efficient models while preserving the architectural advantages of plain
ViTs, such as support for token dropping and other modalities. Accordingly, we
demonstrate that Jumbo excels in these two settings via masked autoencoding and
on a suite of time series benchmarks. Code and weights available:
https://github.com/antofuller/jumbo
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rapid Whole Brain Motion-robust Mesoscale In-vivo MR Imaging using
  Multi-scale Implicit Neural Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08634v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08634v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Lyu, Lipeng Ning, William Consagra, Qiang Liu, Richard J. Rushmore, Berkin Bilgic, Yogesh Rathi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution whole-brain in vivo MR imaging at mesoscale resolutions
remains challenging due to long scan durations, motion artifacts, and limited
signal-to-noise ratio (SNR). This study proposes Rotating-view super-resolution
(ROVER)-MRI, an unsupervised framework based on multi-scale implicit neural
representations (INR), enabling efficient recovery of fine anatomical details
from multi-view thick-slice acquisitions. ROVER-MRI employs coordinate-based
neural networks to implicitly and continuously encode image structures at
multiple spatial scales, simultaneously modeling anatomical continuity and
correcting inter-view motion through an integrated registration mechanism.
Validation on ex-vivo monkey brain data and multiple in-vivo human datasets
demonstrates substantially improved reconstruction performance compared to
bicubic interpolation and state-of-the-art regularized least-squares
super-resolution reconstruction (LS-SRR) with 2-fold reduction in scan time.
Notably, ROVER-MRI achieves an unprecedented whole-brain in-vivo T2-weighted
imaging at 180 micron isotropic resolution in only 17 minutes of scan time on a
7T scanner with 22.4% lower relative error compared to LS-SRR. We also
demonstrate improved SNR using ROVER-MRI compared to a time-matched 3D GRE
acquisition. Quantitative results on several datasets demonstrate better
sharpness of the reconstructed images with ROVER-MRI for different
super-resolution factors (5 to 11). These findings highlight ROVER-MRI's
potential as a rapid, accurate, and motion-resilient mesoscale imaging
solution, promising substantial advantages for neuroimaging studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Implicit Visual Misunderstandings in Multimodal Large Language
  Models through Attention Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.10541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.10541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements have enhanced the capability of Multimodal Large Language
Models (MLLMs) to comprehend multi-image information. However, existing
benchmarks primarily evaluate answer correctness, overlooking whether models
genuinely comprehend the visual input. To address this, we define implicit
visual misunderstanding (IVM), where MLLMs provide correct answers without
fully comprehending the visual input. Through our analysis, we decouple the
visual and textual modalities within the causal attention module, revealing
that attention distribution increasingly converges on the image associated with
the correct answer as the network layers deepen. This insight leads to the
introduction of a scale-agnostic metric, \textit{attention accuracy}, and a
novel benchmark for quantifying IVMs. Attention accuracy directly evaluates the
model's visual understanding via internal mechanisms, remaining robust to
positional biases for more reliable assessments. Furthermore, we extend our
approach to finer granularities and demonstrate its effectiveness in unimodal
scenarios, underscoring its versatility and generalizability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Robustness of Medical Vision-Language Models: Are they Truly
  Generalizable? <span class="chip">UAI</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15425v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15425v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raza Imam, Rufael Marew, Mohammad Yaqub
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical Vision-Language Models (MVLMs) have achieved par excellence
generalization in medical image analysis, yet their performance under noisy,
corrupted conditions remains largely untested. Clinical imaging is inherently
susceptible to acquisition artifacts and noise; however, existing evaluations
predominantly assess generally clean datasets, overlooking robustness -- i.e.,
the model's ability to perform under real-world distortions. To address this
gap, we first introduce MediMeta-C, a corruption benchmark that systematically
applies several perturbations across multiple medical imaging datasets.
Combined with MedMNIST-C, this establishes a comprehensive robustness
evaluation framework for MVLMs. We further propose RobustMedCLIP, a visual
encoder adaptation of a pretrained MVLM that incorporates few-shot tuning to
enhance resilience against corruptions. Through extensive experiments, we
benchmark 5 major MVLMs across 5 medical imaging modalities, revealing that
existing models exhibit severe degradation under corruption and struggle with
domain-modality tradeoffs. Our findings highlight the necessity of diverse
training and robust adaptation strategies, demonstrating that efficient
low-rank adaptation when paired with few-shot tuning, improves robustness while
preserving generalization across modalities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset and Code is available at
  https://github.com/BioMedIA-MBZUAI/RobustMedCLIP Accepted at: Medical Image
  Understanding and Analysis (MIUA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Generalized Gait Recognition: Reducing Redundancy and Noise
  within Indoor and Outdoor <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qian Zhou, Xianda Guo, Jilong Wang, Chuanfu Shen, Zhongyuan Wang, Hua Zou, Qin Zou, Chao Liang, Long Chen, Gang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalized gait recognition, which aims to achieve robust performance across
diverse domains, remains a challenging problem due to severe domain shifts in
viewpoints, appearances, and environments. While mixed-dataset training is
widely used to enhance generalization, it introduces new obstacles including
inter-dataset optimization conflicts and redundant or noisy samples, both of
which hinder effective representation learning. To address these challenges, we
propose a unified framework that systematically improves cross-domain gait
recognition. First, we design a disentangled triplet loss that isolates
supervision signals across datasets, mitigating gradient conflicts during
optimization. Second, we introduce a targeted dataset distillation strategy
that filters out the least informative 20\% of training samples based on
feature redundancy and prediction uncertainty, enhancing data efficiency.
Extensive experiments on CASIA-B, OU-MVLP, Gait3D, and GREW demonstrate that
our method significantly improves cross-dataset recognition for both GaitBase
and DeepGaitV2 backbones, without sacrificing source-domain accuracy. Code will
be released at https://github.com/li1er3/Generalized_Gait.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Erasing Undesirable Concepts in Diffusion Models with Adversarial
  Preservation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.15618v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.15618v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anh Bui, Long Vuong, Khanh Doan, Trung Le, Paul Montague, Tamas Abraham, Dinh Phung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models excel at generating visually striking content from text but
can inadvertently produce undesirable or harmful content when trained on
unfiltered internet data. A practical solution is to selectively removing
target concepts from the model, but this may impact the remaining concepts.
Prior approaches have tried to balance this by introducing a loss term to
preserve neutral content or a regularization term to minimize changes in the
model parameters, yet resolving this trade-off remains challenging. In this
work, we propose to identify and preserving concepts most affected by parameter
changes, termed as \textit{adversarial concepts}. This approach ensures stable
erasure with minimal impact on the other concepts. We demonstrate the
effectiveness of our method using the Stable Diffusion model, showing that it
outperforms state-of-the-art erasure methods in eliminating unwanted content
while maintaining the integrity of other unrelated elements. Our code is
available at https://github.com/tuananhbui89/Erasing-Adversarial-Preservation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Erasing Concepts, Generative Unlearning, NeurIPS 2024. arXiv admin
  note: text overlap with arXiv:2403.12326</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fantastic Targets for Concept Erasure in Diffusion Models and Where To
  Find Them 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18950v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18950v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anh Bui, Trang Vu, Long Vuong, Trung Le, Paul Montague, Tamas Abraham, Junae Kim, Dinh Phung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept erasure has emerged as a promising technique for mitigating the risk
of harmful content generation in diffusion models by selectively unlearning
undesirable concepts. The common principle of previous works to remove a
specific concept is to map it to a fixed generic concept, such as a neutral
concept or just an empty text prompt. In this paper, we demonstrate that this
fixed-target strategy is suboptimal, as it fails to account for the impact of
erasing one concept on the others. To address this limitation, we model the
concept space as a graph and empirically analyze the effects of erasing one
concept on the remaining concepts. Our analysis uncovers intriguing geometric
properties of the concept space, where the influence of erasing a concept is
confined to a local region. Building on this insight, we propose the Adaptive
Guided Erasure (AGE) method, which \emph{dynamically} selects optimal target
concepts tailored to each undesirable concept, minimizing unintended side
effects. Experimental results show that AGE significantly outperforms
state-of-the-art erasure methods on preserving unrelated concepts while
maintaining effective erasure performance. Our code is published at
{https://github.com/tuananhbui89/Adaptive-Guided-Erasure}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07435v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07435v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The adoption of Millimeter-Wave (mmWave) radar devices for human sensing,
particularly gait recognition, has recently gathered significant attention due
to their efficiency, resilience to environmental conditions, and
privacy-preserving nature. In this work, we tackle the challenging problem of
Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike
most existing research, which assumes a closed-set scenario, our work considers
the more realistic open-set case, where unknown subjects might be present at
inference time, and should be correctly recognized by the system. Point clouds
are well-suited for edge computing applications with resource constraints, but
are more significantly affected by noise and random fluctuations than other
representations, like the more common micro-Doppler signature. This is the
first work addressing open-set gait recognition with sparse point cloud data.
To do so, we propose a novel neural network architecture that combines
supervised classification with unsupervised reconstruction of the point clouds,
creating a robust, rich, and highly regularized latent space of gait features.
To detect unknown subjects at inference time, we introduce a probabilistic
novelty detection algorithm that leverages the structured latent space and
offers a tunable trade-off between inference speed and prediction accuracy.
Along with this paper, we release mmGait10, an original human gait dataset
featuring over five hours of measurements from ten subjects, under varied
walking modalities. Extensive experimental results show that our solution
attains F1-Score improvements by 24% over state-of-the-art methods, on average,
and across multiple openness levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10165v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10165v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nguyen Ngoc Dat, Tom Richardson, Matthew Watson, Kilian Meier, Jenna Kline, Sid Reid, Guy Maalouf, Duncan Hine, Majid Mirmehdi, Tilo Burghardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Live tracking of wildlife via high-resolution video processing directly
onboard drones is widely unexplored and most existing solutions rely on
streaming video to ground stations to support navigation. Yet, both autonomous
animal-reactive flight control beyond visual line of sight and/or
mission-specific individual and behaviour recognition tasks rely to some degree
on this capability. In response, we introduce WildLive - a near real-time
animal detection and tracking framework for high-resolution imagery running
directly onboard uncrewed aerial vehicles (UAVs). The system performs
multi-animal detection and tracking at 17.81fps for HD and 7.53fps on 4K video
streams suitable for operation during higher altitude flights to minimise
animal disturbance. Our system is optimised for Jetson Orin AGX onboard
hardware. It integrates the efficiency of sparse optical flow tracking and
mission-specific sampling with device-optimised and proven YOLO-driven object
detection and segmentation techniques. Essentially, computational resource is
focused onto spatio-temporal regions of high uncertainty to significantly
improve UAV processing speeds. Alongside, we introduce our WildLive dataset,
which comprises 200K+ annotated animal instances across 19K+ frames from 4K UAV
videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain
ground truth bounding boxes, segmentation masks, as well as individual
tracklets and tracking point trajectories. We compare our system against
current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our
multi-animal tracking experiments with onboard hardware confirm that near
real-time high-resolution wildlife tracking is possible on UAVs whilst
maintaining high accuracy levels as needed for future navigational and
mission-specific animal-centric operational autonomy. Our materials are
available at: https://dat-nguyenvn.github.io/WildLive/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QVGen: Pushing the Limit of Quantized Video Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11497v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11497v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video diffusion models (DMs) have enabled high-quality video synthesis. Yet,
their substantial computational and memory demands pose serious challenges to
real-world deployment, even on high-end GPUs. As a commonly adopted solution,
quantization has proven notable success in reducing cost for image DMs, while
its direct application to video DMs remains ineffective. In this paper, we
present QVGen, a novel quantization-aware training (QAT) framework tailored for
high-performance and inference-efficient video DMs under extremely low-bit
quantization (e.g., 4-bit or below). We begin with a theoretical analysis
demonstrating that reducing the gradient norm is essential to facilitate
convergence for QAT. To this end, we introduce auxiliary modules ($\Phi$) to
mitigate large quantization errors, leading to significantly enhanced
convergence. To eliminate the inference overhead of $\Phi$, we propose a
rank-decay strategy that progressively eliminates $\Phi$. Specifically, we
repeatedly employ singular value decomposition (SVD) and a proposed rank-based
regularization $\mathbf{\gamma}$ to identify and decay low-contributing
components. This strategy retains performance while zeroing out inference
overhead. Extensive experiments across $4$ state-of-the-art (SOTA) video DMs,
with parameter sizes ranging from $1.3$B $\sim14$B, show that QVGen is the
first to reach full-precision comparable quality under 4-bit settings.
Moreover, it significantly outperforms existing methods. For instance, our
3-bit CogVideoX-2B achieves improvements of $+25.28$ in Dynamic Degree and
$+8.43$ in Scene Consistency on VBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code will be released upon acceptance</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12549v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12549v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominic Maggio, Hyungtae Lim, Luca Carlone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present VGGT-SLAM, a dense RGB SLAM system constructed by incrementally
and globally aligning submaps created from the feed-forward scene
reconstruction approach VGGT using only uncalibrated monocular cameras. While
related works align submaps using similarity transforms (i.e., translation,
rotation, and scale), we show that such approaches are inadequate in the case
of uncalibrated cameras. In particular, we revisit the idea of reconstruction
ambiguity, where given a set of uncalibrated cameras with no assumption on the
camera motion or scene structure, the scene can only be reconstructed up to a
15-degrees-of-freedom projective transformation of the true geometry. This
inspires us to recover a consistent scene reconstruction across submaps by
optimizing over the SL(4) manifold, thus estimating 15-degrees-of-freedom
homography transforms between sequential submaps while accounting for potential
loop closure constraints. As verified by extensive experiments, we demonstrate
that VGGT-SLAM achieves improved map quality using long video sequences that
are infeasible for VGGT due to its high GPU requirements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.04963v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.04963v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Onkar Susladkar, Gayatri Deshmukh, Yalcin Tur, Gorkhem Durak, Ulas Bagci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthesizing medical images remains challenging due to limited annotated
pathological data, modality domain gaps, and the complexity of representing
diffuse pathologies such as liver cirrhosis. Existing methods often struggle to
maintain anatomical fidelity while accurately modeling pathological features,
frequently relying on priors derived from natural images or inefficient
multi-step sampling. In this work, we introduce ViCTr (Vital Consistency
Transfer), a novel two-stage framework that combines a rectified flow
trajectory with a Tweedie-corrected diffusion process to achieve high-fidelity,
pathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k
dataset using Elastic Weight Consolidation (EWC) to preserve critical
anatomical structures. We then fine-tune the model adversarially with Low-Rank
Adaptation (LoRA) modules for precise control over pathology severity. By
reformulating Tweedie's formula within a linear trajectory framework, ViCTr
supports one-step sampling, reducing inference from 50 steps to just 4, without
sacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and
CirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art
performance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for
cirrhosis synthesis 28% lower than existing approaches and improving nnUNet
segmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews
indicate that ViCTr-generated liver cirrhosis MRIs are clinically
indistinguishable from real scans. To our knowledge, ViCTr is the first method
to provide fine-grained, pathology-aware MRI synthesis with graded severity
control, closing a critical gap in AI-driven medical imaging research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Autoregressive Sequence Modeling for 3D Medical Image Representation <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08691v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08691v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siwen Wang, Churan Wang, Fei Gao, Lixian Su, Fandong Zhang, Yizhou Wang, Yizhou Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Three-dimensional (3D) medical images, such as Computed Tomography (CT) and
Magnetic Resonance Imaging (MRI), are essential for clinical applications.
However, the need for diverse and comprehensive representations is particularly
pronounced when considering the variability across different organs, diagnostic
tasks, and imaging modalities. How to effectively interpret the intricate
contextual information and extract meaningful insights from these images
remains an open challenge to the community. While current self-supervised
learning methods have shown potential, they often consider an image as a whole
thereby overlooking the extensive, complex relationships among local regions
from one or multiple images. In this work, we introduce a pioneering method for
learning 3D medical image representations through an autoregressive
pre-training framework. Our approach sequences various 3D medical images based
on spatial, contrast, and semantic correlations, treating them as
interconnected visual tokens within a token sequence. By employing an
autoregressive sequence modeling task, we predict the next visual token in the
sequence, which allows our model to deeply understand and integrate the
contextual information inherent in 3D medical images. Additionally, we
implement a random startup strategy to avoid overestimating token relationships
and to enhance the robustness of learning. The effectiveness of our approach is
demonstrated by the superior performance over others on nine downstream tasks
in public datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor
  Segmentation with Missing Modalities <span class="chip">MICCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16809v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16809v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junze Wang, Lei Fan, Weipeng Jing, Donglin Di, Yang Song, Sidong Liu, Cong Cong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for multimodal MRI segmentation with missing modalities
typically assume that all MRI modalities are available during training.
However, in clinical practice, some modalities may be missing due to the
sequential nature of MRI acquisition, leading to performance degradation.
Furthermore, retraining models to accommodate newly available modalities can be
inefficient and may cause overfitting, potentially compromising previously
learned knowledge. To address these challenges, we propose Replay-based
Hypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation
with missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to
enable the segmentation model to learn from newly acquired MRI modalities
without forgetting previously learned information. To enhance segmentation
performance across diverse patient scenarios, we introduce the Cross-Patient
Hypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture
high-order associations between patients. Additionally, we incorporate
Tversky-Aware Contrastive (TAC) loss to effectively mitigate information
imbalance both across and within different modalities. Extensive experiments on
the BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art
methods, achieving an improvement of over 2% in the Dice Similarity Coefficient
across various tumor regions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MICCAI 2025 Early Accept. The code is available at
  https://github.com/reeive/ReHyDIL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RCR: Robust Crowd Reconstruction with Upright Space from a Single
  Large-scene Image 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06232v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06232v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Huang, Hao Wen, Tianyi Zhou, Haozhe Lin, Yu-kun Lai, Kun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on spatially consistent hundreds of human pose and shape
reconstruction from a single large-scene image with various human scales under
arbitrary camera FoVs (Fields of View). Due to the small and highly varying 2D
human scales, depth ambiguity, and perspective distortion, no existing methods
can achieve globally consistent reconstruction with correct reprojection. To
address these challenges, we first propose a new concept, Human-scene Virtual
Interaction Point (HVIP), to convert the complex 3D human localization into
2D-pixel localization. We then extend it to RCR (Robust Crowd Reconstruction),
which achieves globally consistent reconstruction and stable generalization on
different camera FoVs without test-time optimization. To perceive humans in
varying pixel sizes, we propose an Iterative Ground-aware Cropping to
automatically crop the image and then merge the results. To eliminate the
influence of the camera and cropping process during the reconstruction, we
introduce a canonical Upright 3D Space and the corresponding Upright 2D Space.
To link the canonical space and the camera space, we propose the Upright
Normalization, which transforms the local crop input into the Upright 2D Space,
and transforms the output from the Upright 3D Space into the unified camera
space. Besides, we contribute two benchmark datasets, LargeCrowd and SynCrowd,
for evaluating crowd reconstruction in large scenes. Experimental results
demonstrate the effectiveness of the proposed method. The source code and data
will be publicly available for research purposes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMInference: Accelerating Pre-filling for Long-Context VLMs via
  Modality-Aware Permutation Sparse Attention <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.16083v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.16083v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Li, Huiqiang Jiang, Chengruidong Zhang, Qianhui Wu, Xufang Luo, Surin Ahn, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of long-context capabilities with visual understanding
unlocks unprecedented potential for Vision Language Models (VLMs). However, the
quadratic attention complexity during the pre-filling phase remains a
significant obstacle to real-world deployment. To overcome this limitation, we
introduce MMInference (Multimodality Million tokens Inference), a dynamic
sparse attention method that accelerates the prefilling stage for long-context
multi-modal inputs. First, our analysis reveals that the temporal and spatial
locality of video input leads to a unique sparse pattern, the Grid pattern.
Simultaneously, VLMs exhibit markedly different sparse distributions across
different modalities. We introduce a permutation-based method to leverage the
unique Grid pattern and handle modality boundary issues. By offline search the
optimal sparse patterns for each head, MMInference constructs the sparse
distribution dynamically based on the input. We also provide optimized GPU
kernels for efficient sparse computations. Notably, MMInference integrates
seamlessly into existing VLM pipelines without any model modifications or
fine-tuning. Experiments on multi-modal benchmarks-including Video QA,
Captioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art
long-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that
MMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while
maintaining accuracy. Our code is available at https://aka.ms/MMInference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Camera Movement Estimation and Path Correction using the Combination of
  Modified A-SIFT and Stereo System for 3D Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17668v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17668v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Usha Kumari, Shuvendu Rana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Creating accurate and efficient 3D models poses significant challenges,
particularly in addressing large viewpoint variations, computational
complexity, and alignment discrepancies. Efficient camera path generation can
help resolve these issues. In this context, a modified version of the Affine
Scale-Invariant Feature Transform (ASIFT) is proposed to extract more matching
points with reduced computational overhead, ensuring an adequate number of
inliers for precise camera rotation angle estimation. Additionally, a novel
two-camera-based rotation correction model is introduced to mitigate small
rotational errors, further enhancing accuracy. Furthermore, a stereo
camera-based translation estimation and correction model is implemented to
determine camera movement in 3D space by altering the Structure From Motion
(SFM) model. Finally, the novel combination of ASIFT and two camera-based SFM
models provides an accurate camera movement trajectory in 3D space.
Experimental results show that the proposed camera movement approach achieves
99.9% accuracy compared to the actual camera movement path and outperforms
state-of-the-art camera path estimation methods. By leveraging this accurate
camera path, the system facilitates the creation of precise 3D models, making
it a robust solution for applications requiring high fidelity and efficiency in
3D reconstruction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Black-box Model Predictions via Two-level Nested Feature
  Attributions with Consistency Property <span class="chip">IJCAI2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14522v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14522v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuya Yoshikawa, Masanari Kimura, Ryotaro Shimizu, Yuki Saito
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Techniques that explain the predictions of black-box machine learning models
are crucial to make the models transparent, thereby increasing trust in AI
systems. The input features to the models often have a nested structure that
consists of high- and low-level features, and each high-level feature is
decomposed into multiple low-level features. For such inputs, both high-level
feature attributions (HiFAs) and low-level feature attributions (LoFAs) are
important for better understanding the model's decision. In this paper, we
propose a model-agnostic local explanation method that effectively exploits the
nested structure of the input to estimate the two-level feature attributions
simultaneously. A key idea of the proposed method is to introduce the
consistency property that should exist between the HiFAs and LoFAs, thereby
bridging the separate optimization problems for estimating them. Thanks to this
consistency property, the proposed method can produce HiFAs and LoFAs that are
both faithful to the black-box models and consistent with each other, using a
smaller number of queries to the models. In experiments on image classification
in multiple instance learning and text classification using language models, we
demonstrate that the HiFAs and LoFAs estimated by the proposed method are
accurate, faithful to the behaviors of the black-box models, and provide
consistent explanations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript is an extended version of our paper accepted at
  IJCAI2025, with detailed proofs and additional experimental results</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation
  Networks for Remote Sensing Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.13716v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.13716v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanli Ma, Oktay Karakus, Paul L. Rosin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semi-supervised learning (SSL) aims to help reduce the cost of the manual
labelling process by leveraging a substantial pool of unlabelled data alongside
a limited set of labelled data during the training phase. Since pixel-level
manual labelling in large-scale remote sensing imagery is expensive and
time-consuming, semi-supervised learning has become a widely used solution to
deal with this. However, the majority of existing SSL frameworks, especially
various teacher-student frameworks, are too bulky to run efficiently on a GPU
with limited memory. There is still a lack of lightweight SSL frameworks and
efficient perturbation methods to promote the diversity of training samples and
enhance the precision of pseudo labels during training. In order to fill this
gap, we proposed a simple, lightweight, and efficient SSL architecture named
\textit{DiverseHead}, which promotes the utilisation of multiple decision heads
instead of multiple whole networks. Another limitation of most existing SSL
frameworks is the insufficient diversity of pseudo labels, as they rely on the
same network architecture and fail to explore different structures for
generating pseudo labels. To solve this issue, we propose \textit{DiverseModel}
to explore and analyse different networks in parallel for SSL to increase the
diversity of pseudo labels. The two proposed methods, namely
\textit{DiverseHead} and \textit{DiverseModel}, both achieve competitive
semantic segmentation performance in four widely used remote sensing imagery
datasets compared to state-of-the-art semi-supervised learning methods.
Meanwhile, the proposed lightweight DiverseHead architecture can be easily
applied to various state-of-the-art SSL methods while further improving their
performance. The code is available at
https://github.com/WANLIMA-CARDIFF/DiverseNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiffBreak: Is Diffusion-Based Purification Robust? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16598v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16598v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andre Kassis, Urs Hengartner, Yaoliang Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based purification (DBP) has become a cornerstone defense against
adversarial examples (AEs), regarded as robust due to its use of diffusion
models (DMs) that project AEs onto the natural data manifold. We refute this
core claim, theoretically proving that gradient-based attacks effectively
target the DM rather than the classifier, causing DBP's outputs to align with
adversarial distributions. This prompts a reassessment of DBP's robustness,
attributing it to two critical flaws: incorrect gradients and inappropriate
evaluation protocols that test only a single random purification of the AE. We
show that with proper accounting for stochasticity and resubmission risk, DBP
collapses. To support this, we introduce DiffBreak, the first reliable toolkit
for differentiation through DBP, eliminating gradient flaws that previously
further inflated robustness estimates. We also analyze the current defense
scheme used for DBP where classification relies on a single purification,
pinpointing its inherent invalidity. We provide a statistically grounded
majority-vote (MV) alternative that aggregates predictions across multiple
purified copies, showing partial but meaningful robustness gain. We then
propose a novel adaptation of an optimization method against deepfake
watermarking, crafting systemic perturbations that defeat DBP even under MV,
challenging DBP's viability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EMT: A Visual Multi-Task Benchmark <span class="highlight-title">Dataset</span> for Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19260v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19260v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nadya Abdel Madjid, Murad Mebrahtu, Abdulrahman Ahmad, Abdelmoamen Nasser, Bilal Hassan, Naoufel Werghi, Jorge Dias, Majid Khonji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces the Emirates Multi-Task (EMT) dataset, designed to
support multi-task benchmarking within a unified framework. It comprises over
30,000 frames from a dash-camera perspective and 570,000 annotated bounding
boxes, covering approximately 150 kilometers of driving routes that reflect the
distinctive road topology, congestion patterns, and driving behavior of Gulf
region traffic. The dataset supports three primary tasks: tracking, trajectory
forecasting, and intention prediction. Each benchmark is accompanied by
corresponding evaluations: (1) multi-agent tracking experiments addressing
multi-class scenarios and occlusion handling; (2) trajectory forecasting
evaluation using deep sequential and interaction-aware models; and (3)
intention prediction experiments based on observed trajectories. The dataset is
publicly available at https://avlab.io/emt-dataset, with pre-processing scripts
and evaluation models at https://github.com/AV-Lab/emt-dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ D3C2-Net: Dual-Domain Deep Convolutional Coding Network for Compressive
  Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2207.13560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2207.13560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiqi Li, Bin Chen, Shuai Liu, Shijie Zhao, Bowen Du, Yongbing Zhang, Jian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By mapping iterative optimization algorithms into neural networks (NNs), deep
unfolding networks (DUNs) exhibit well-defined and interpretable structures and
achieve remarkable success in the field of compressive sensing (CS). However,
most existing DUNs solely rely on the image-domain unfolding, which restricts
the information transmission capacity and reconstruction flexibility, leading
to their loss of image details and unsatisfactory performance. To overcome
these limitations, this paper develops a dual-domain optimization framework
that combines the priors of (1) image- and (2) convolutional-coding-domains and
offers generality to CS and other inverse imaging tasks. By converting this
optimization framework into deep NN structures, we present a Dual-Domain Deep
Convolutional Coding Network (D3C2-Net), which enjoys the ability to
efficiently transmit high-capacity self-adaptive convolutional features across
all its unfolded stages. Our theoretical analyses and experiments on simulated
and real captured data, covering 2D and 3D natural, medical, and scientific
signals, demonstrate the effectiveness, practicality, superior performance, and
generalization ability of our method over other competing approaches and its
significant potential in achieving a balance among accuracy, complexity, and
interpretability. Code is available at https://github.com/lwq20020127/D3C2-Net.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by IEEE TCSVT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReactDiff: Latent Diffusion for Facial Reaction Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14151v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14151v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaming Li, Sheng Wang, Xin Wang, Yitao Zhu, Honglin Xiong, Zixu Zhuang, Qian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the audio-visual clip of the speaker, facial reaction generation aims
to predict the listener's facial reactions. The challenge lies in capturing the
relevance between video and audio while balancing appropriateness, realism, and
diversity. While prior works have mostly focused on uni-modal inputs or
simplified reaction mappings, recent approaches such as PerFRDiff have explored
multi-modal inputs and the one-to-many nature of appropriate reaction mappings.
In this work, we propose the Facial Reaction Diffusion (ReactDiff) framework
that uniquely integrates a Multi-Modality Transformer with conditional
diffusion in the latent space for enhanced reaction generation. Unlike existing
methods, ReactDiff leverages intra- and inter-class attention for fine-grained
multi-modal interaction, while the latent diffusion process between the encoder
and decoder enables diverse yet contextually appropriate outputs. Experimental
results demonstrate that ReactDiff significantly outperforms existing
approaches, achieving a facial reaction correlation of 0.26 and diversity score
of 0.094 while maintaining competitive realism. The code is open-sourced at
\href{https://github.com/Hunan-Tiger/ReactDiff}{github}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Neural Networks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout
  Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.03602v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.03602v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuan Fang, Yuan Dong, Kunming Luo, Xiaotao Hu, Rakesh Shrestha, Ping Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-driven 3D indoor scene generation is useful for gaming, the film
industry, and AR/VR applications. However, existing methods cannot faithfully
capture the room layout, nor do they allow flexible editing of individual
objects in the room. To address these problems, we present Ctrl-Room, which can
generate convincing 3D rooms with designer-style layouts and high-fidelity
textures from just a text prompt. Moreover, Ctrl-Room enables versatile
interactive editing operations such as resizing or moving individual furniture
items. Our key insight is to separate the modeling of layouts and appearance.
Our proposed method consists of two stages: a Layout Generation Stage and an
Appearance Generation Stage. The Layout Generation Stage trains a
text-conditional diffusion model to learn the layout distribution with our
holistic scene code parameterization. Next, the Appearance Generation Stage
employs a fine-tuned ControlNet to produce a vivid panoramic image of the room
guided by the 3D scene layout and text prompt. We thus achieve a high-quality
3D room generation with convincing layouts and lively textures. Benefiting from
the scene code parameterization, we can easily edit the generated room model
through our mask-guided editing module, without expensive edit-specific
training. Extensive experiments on the Structured3D dataset demonstrate that
our method outperforms existing methods in producing more reasonable,
view-consistent, and editable 3D rooms from natural language prompts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Q-Insight: Understanding Image Quality via Visual Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.22679v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.22679v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiqi Li, Xuanyu Zhang, Shijie Zhao, Yabin Zhang, Junlin Li, Li Zhang, Jian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image quality assessment (IQA) focuses on the perceptual visual quality of
images, playing a crucial role in downstream tasks such as image
reconstruction, compression, and generation. The rapid advancement of
multi-modal large language models (MLLMs) has significantly broadened the scope
of IQA, moving toward comprehensive image quality understanding that
incorporates content analysis, degradation perception, and comparison reasoning
beyond mere numerical scoring. Previous MLLM-based methods typically either
generate numerical scores lacking interpretability or heavily rely on
supervised fine-tuning (SFT) using large-scale annotated datasets to provide
descriptive assessments, limiting their flexibility and applicability. In this
paper, we propose Q-Insight, a reinforcement learning-based model built upon
group relative policy optimization (GRPO), which demonstrates strong visual
reasoning capability for image quality understanding while requiring only a
limited amount of rating scores and degradation labels. By jointly optimizing
score regression and degradation perception tasks with carefully designed
reward functions, our approach effectively exploits their mutual benefits for
enhanced performance. Extensive experiments demonstrate that Q-Insight
substantially outperforms existing state-of-the-art methods in both score
regression and degradation perception tasks, while exhibiting impressive
zero-shot generalization to comparison reasoning tasks. Code will be available
at https://github.com/lwq20020127/Q-Insight.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boosting Edge Detection with Pixel-wise Feature Selection: The
  Extractor-Selector Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02534v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02534v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Shu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning has significantly advanced image edge detection (ED), primarily
through improved feature extraction. However, most existing ED models apply
uniform feature fusion across all pixels, ignoring critical differences between
regions such as edges and textures. To address this limitation, we propose the
Extractor-Selector (E-S) paradigm, a novel framework that introduces pixel-wise
feature selection for more adaptive and precise fusion. Unlike conventional
image-level fusion that applies the same convolutional kernel to all pixels,
our approach dynamically selects relevant features at each pixel, enabling more
refined edge predictions. The E-S framework can be seamlessly integrated with
existing ED models without architectural changes, delivering substantial
performance gains. It can also be combined with enhanced feature extractors for
further accuracy improvements. Extensive experiments across multiple benchmarks
confirm that our method consistently outperforms baseline ED models. For
instance, on the BIPED2 dataset, the proposed framework can achieve over 7$\%$
improvements in ODS and OIS, and 22$\%$ improvements in AP, demonstrating its
effectiveness and superiority.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive Assessment Benchmark for Rigorously Evaluating Deep
  Learning Image Classifiers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.04137v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.04137v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael W. Spratling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reliable and robust evaluation methods are a necessary first step towards
developing machine learning models that are themselves robust and reliable.
Unfortunately, current evaluation protocols typically used to assess
classifiers fail to comprehensively evaluate performance as they tend to rely
on limited types of test data, and ignore others. For example, using the
standard test data fails to evaluate the predictions made by the classifier to
samples from classes it was not trained on. On the other hand, testing with
data containing samples from unknown classes fails to evaluate how well the
classifier can predict the labels for known classes. This article advocates
benchmarking performance using a wide range of different types of data and
using a single metric that can be applied to all such data types to produce a
consistent evaluation of performance. Using the proposed benchmark it is found
that current deep neural networks, including those trained with methods that
are believed to produce state-of-the-art robustness, are vulnerable to making
mistakes on certain types of data. This means that such models will be
unreliable in real-world scenarios where they may encounter data from many
different domains, and that they are insecure as they can be easily fooled into
making the wrong decisions. It is hoped that these results will motivate the
wider adoption of more comprehensive testing methods that will, in turn, lead
to the development of more robust machine learning methods in the future.
  Code is available at: https://codeberg.org/mwspratling/RobustnessEvaluation
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ARFC-WAHNet: Adaptive Receptive Field Convolution and Wavelet-Attentive
  Hierarchical Network for Infrared Small Target Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.10595v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.10595v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingye Cui, Junhai Luo, Jiakun Deng, Kexuan Li, Xiangyu Qiu, Zhenming Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Infrared small target detection (ISTD) is critical in both civilian and
military applications. However, the limited texture and structural information
in infrared images makes accurate detection particularly challenging. Although
recent deep learning-based methods have improved performance, their use of
conventional convolution kernels limits adaptability to complex scenes and
diverse targets. Moreover, pooling operations often cause feature loss and
insufficient exploitation of image information. To address these issues, we
propose an adaptive receptive field convolution and wavelet-attentive
hierarchical network for infrared small target detection (ARFC-WAHNet). This
network incorporates a multi-receptive field feature interaction convolution
(MRFFIConv) module to adaptively extract discriminative features by integrating
multiple convolutional branches with a gated unit. A wavelet frequency
enhancement downsampling (WFED) module leverages Haar wavelet transform and
frequency-domain reconstruction to enhance target features and suppress
background noise. Additionally, we introduce a high-low feature fusion (HLFF)
module for integrating low-level details with high-level semantics, and a
global median enhancement attention (GMEA) module to improve feature diversity
and expressiveness via global attention. Experiments on public datasets SIRST,
NUDT-SIRST, and IRSTD-1k demonstrate that ARFC-WAHNet outperforms recent
state-of-the-art methods in both detection accuracy and robustness,
particularly under complex backgrounds. The code is available at
https://github.com/Leaf2001/ARFC-WAHNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LaViDa: A Large Diffusion Language Model for Multimodal Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16839v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16839v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shufan Li, Konstantinos Kallidromitis, Hritik Bansal, Akash Gokul, Yusuke Kato, Kazuki Kozuka, Jason Kuen, Zhe Lin, Kai-Wei Chang, Aditya Grover
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern Vision-Language Models (VLMs) can solve a wide range of tasks
requiring visual reasoning. In real-world scenarios, desirable properties for
VLMs include fast inference and controllable generation (e.g., constraining
outputs to adhere to a desired format). However, existing autoregressive (AR)
VLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs)
offer a promising alternative, enabling parallel decoding for faster inference
and bidirectional context for controllable generation through text-infilling.
While effective in language-only settings, DMs' potential for multimodal tasks
is underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build
LaViDa by equipping DMs with a vision encoder and jointly fine-tune the
combined parts for multimodal instruction following. To address challenges
encountered, LaViDa incorporates novel techniques such as complementary masking
for effective training, prefix KV cache for efficient inference, and timestep
shifting for high-quality sampling. Experiments show that LaViDa achieves
competitive or superior performance to AR VLMs on multi-modal benchmarks such
as MMMU, while offering unique advantages of DMs, including flexible
speed-quality tradeoff, controllability, and bidirectional reasoning. On COCO
captioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x
speedup. On bidirectional tasks, it achieves +59% improvement on Constrained
Poem Completion. These results demonstrate LaViDa as a strong alternative to AR
VLMs. Code and models will be released in the camera-ready version.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.11117v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.11117v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixuan Jiang, Yang Liu, Weixing Chen, Jingzhou Luo, Ziliang Chen, Ling Pan, Guanbin Li, Liang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied Question Answering (EQA) is a challenging task in embodied
intelligence that requires agents to dynamically explore 3D environments,
actively gather visual information, and perform multi-step reasoning to answer
questions. However, current EQA approaches suffer from critical limitations in
exploration efficiency, dataset design, and evaluation metrics. Moreover,
existing datasets often introduce biases or prior knowledge, leading to
disembodied reasoning, while frontier-based exploration strategies struggle in
cluttered environments and fail to ensure fine-grained exploration of
task-relevant areas. To address these challenges, we construct the
EXPloration-awaRe Embodied queStion anSwering Benchmark (EXPRESS-Bench), the
largest dataset designed specifically to evaluate both exploration and
reasoning capabilities. EXPRESS-Bench consists of 777 exploration trajectories
and 2,044 question-trajectory pairs. To improve exploration efficiency, we
propose Fine-EQA, a hybrid exploration model that integrates frontier-based and
goal-oriented navigation to guide agents toward task-relevant regions more
effectively. Additionally, we introduce a novel evaluation metric,
Exploration-Answer Consistency (EAC), which ensures faithful assessment by
measuring the alignment between answer grounding and exploration reliability.
Extensive experimental comparisons with state-of-the-art EQA models demonstrate
the effectiveness of our EXPRESS-Bench in advancing embodied exploration and
question reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">19</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bidirectional Knowledge Distillation for Enhancing Sequential
  Recommendation with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18120v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18120v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiongran Wu, Jiahao Liu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Li Shang, Tun Lu, Ning Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated exceptional performance in
understanding and generating semantic patterns, making them promising
candidates for sequential recommendation tasks. However, when combined with
conventional recommendation models (CRMs), LLMs often face challenges related
to high inference costs and static knowledge transfer methods. In this paper,
we propose a novel mutual distillation framework, LLMD4Rec, that fosters
dynamic and bidirectional knowledge exchange between LLM-centric and CRM-based
recommendation systems. Unlike traditional unidirectional distillation methods,
LLMD4Rec enables iterative optimization by alternately refining both models,
enhancing the semantic understanding of CRMs and enriching LLMs with
collaborative signals from user-item interactions. By leveraging sample-wise
adaptive weighting and aligning output distributions, our approach eliminates
the need for additional parameters while ensuring effective knowledge transfer.
Extensive experiments on real-world datasets demonstrate that LLMD4Rec
significantly improves recommendation accuracy across multiple benchmarks
without increasing inference costs. This method provides a scalable and
efficient solution for combining the strengths of both LLMs and CRMs in
sequential recommendation systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing the performance of 8 AI chatbots in bibliographic reference
  retrieval: Grok and DeepSeek outperform Chat<span class="highlight-title">GPT</span>, but none are fully accurate 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18059v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18059v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Álvaro Cabezas-Clavijo, Pavel Sidorenko-Bautista
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study analyzes the performance of eight generative artificial
intelligence chatbots -- ChatGPT, Claude, Copilot, DeepSeek, Gemini, Grok, Le
Chat, and Perplexity -- in their free versions, in the task of generating
academic bibliographic references within the university context. A total of 400
references were evaluated across the five major areas of knowledge (Health,
Engineering, Experimental Sciences, Social Sciences, and Humanities), based on
a standardized prompt. Each reference was assessed according to five key
components (authorship, year, title, source, and location), along with document
type, publication age, and error count. The results show that only 26.5% of the
references were fully correct, 33.8% partially correct, and 39.8% were either
erroneous or entirely fabricated. Grok and DeepSeek stood out as the only
chatbots that did not generate false references, while Copilot, Perplexity, and
Claude exhibited the highest hallucination rates. Furthermore, the chatbots
showed a greater tendency to generate book references over journal articles,
although the latter had a significantly higher fabrication rate. A high degree
of overlap was also detected among the sources provided by several models,
particularly between DeepSeek, Grok, Gemini, and ChatGPT. These findings reveal
structural limitations in current AI models, highlight the risks of uncritical
use by students, and underscore the need to strengthen information and critical
literacy regarding the use of AI tools in higher education.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AI Literacy for Legal AI Systems: A practical approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gizem Gultekin-Varkonyi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal AI systems are increasingly being adopted by judicial and legal system
deployers and providers worldwide to support a range of applications. While
they offer potential benefits such as reducing bias, increasing efficiency, and
improving accountability, they also pose significant risks, requiring a careful
balance between opportunities, and legal and ethical development and
deployment. AI literacy, as a legal requirement under the EU AI Act and a
critical enabler of ethical AI for deployers and providers, could be a tool to
achieve this. The article introduces the term "legal AI systems" and then
analyzes the concept of AI literacy and the benefits and risks associated with
these systems. This analysis is linked to a broader AI-L concept for
organizations that deal with legal AI systems. The outcome of the article, a
roadmap questionnaire as a practical tool for developers and providers to
assess risks, benefits, and stakeholder concerns, could be useful in meeting
societal and regulatory expectations for legal AI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Forthcoming in Iustum Aequum Salutare (2025) vol.21</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Feature Interactions from the Perspective of Quadratic Neural
  Networks for Click-through Rate Prediction <span class="chip">KDD'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honghao Li, Yiwen Zhang, Yi Zhang, Lei Sang, Jieming Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hadamard Product (HP) has long been a cornerstone in click-through rate (CTR)
prediction tasks due to its simplicity, effectiveness, and ability to capture
feature interactions without additional parameters. However, the underlying
reasons for its effectiveness remain unclear. In this paper, we revisit HP from
the perspective of Quadratic Neural Networks (QNN), which leverage quadratic
interaction terms to model complex feature relationships. We further reveal
QNN's ability to expand the feature space and provide smooth nonlinear
approximations without relying on activation functions. Meanwhile, we find that
traditional post-activation does not further improve the performance of the
QNN. Instead, mid-activation is a more suitable alternative. Through
theoretical analysis and empirical evaluation of 25 QNN neuron formats, we
identify a good-performing variant and make further enhancements on it.
Specifically, we propose the Multi-Head Khatri-Rao Product as a superior
alternative to HP and a Self-Ensemble Loss with dynamic ensemble capability
within the same network to enhance computational efficiency and performance.
Ultimately, we propose a novel neuron format, QNN-alpha, which is tailored for
CTR prediction tasks. Experimental results show that QNN-alpha achieves new
state-of-the-art performance on six public datasets while maintaining low
inference latency, good scalability, and excellent compatibility. The code,
running logs, and detailed hyperparameter configurations are available at:
https://github.com/salmon1802/QNN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD'25 accepted</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing CTR Prediction with De-correlated Expert Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiancheng Wang, Mingjia Yin, Junwei Pan, Ximei Wang, Hao Wang, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling feature interactions is essential for accurate click-through rate
(CTR) prediction in advertising systems. Recent studies have adopted the
Mixture-of-Experts (MoE) approach to improve performance by ensembling multiple
feature interaction experts. These studies employ various strategies, such as
learning independent embedding tables for each expert or utilizing
heterogeneous expert architectures, to differentiate the experts, which we
refer to expert \emph{de-correlation}. However, it remains unclear whether
these strategies effectively achieve de-correlated experts. To address this, we
propose a De-Correlated MoE (D-MoE) framework, which introduces a Cross-Expert
De-Correlation loss to minimize expert correlations.Additionally, we propose a
novel metric, termed Cross-Expert Correlation, to quantitatively evaluate the
expert de-correlation degree. Based on this metric, we identify a key finding
for MoE framework design: \emph{different de-correlation strategies are
mutually compatible, and progressively employing them leads to reduced
correlation and enhanced performance}.Extensive experiments have been conducted
to validate the effectiveness of D-MoE and the de-correlation principle.
Moreover, online A/B testing on Tencent's advertising platforms demonstrates
that D-MoE achieves a significant 1.19\% Gross Merchandise Volume (GMV) lift
compared to the Multi-Embedding MoE baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Superplatforms Have to Attack AI Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17861v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17861v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianghao Lin, Jiachen Zhu, Zheli Zhou, Yunjia Xi, Weiwen Liu, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past decades, superplatforms, digital companies that integrate a
vast range of third-party services and applications into a single, unified
ecosystem, have built their fortunes on monopolizing user attention through
targeted advertising and algorithmic content curation. Yet the emergence of AI
agents driven by large language models (LLMs) threatens to upend this business
model. Agents can not only free user attention with autonomy across diverse
platforms and therefore bypass the user-attention-based monetization, but might
also become the new entrance for digital traffic. Hence, we argue that
superplatforms have to attack AI agents to defend their centralized control of
digital traffic entrance. Specifically, we analyze the fundamental conflict
between user-attention-based monetization and agent-driven autonomy through the
lens of our gatekeeping theory. We show how AI agents can disintermediate
superplatforms and potentially become the next dominant gatekeepers, thereby
forming the urgent necessity for superplatforms to proactively constrain and
attack AI agents. Moreover, we go through the potential technologies for
superplatform-initiated attacks, covering a brand-new, unexplored technical
area with unique challenges. We have to emphasize that, despite our position,
this paper does not advocate for adversarial attacks by superplatforms on AI
agents, but rather offers an envisioned trend to highlight the emerging
tensions between superplatforms and AI agents. Our aim is to raise awareness
and encourage critical discussion for collaborative solutions, prioritizing
user interests and perserving the openness of digital ecosystems in the age of
AI agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Position paper under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VIBE: Vector Index Benchmark for Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17810v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17810v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias Jääsaari, Ville Hyvönen, Matteo Ceccarello, Teemu Roos, Martin Aumüller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximate nearest neighbor (ANN) search is a performance-critical component
of many machine learning pipelines. Rigorous benchmarking is essential for
evaluating the performance of vector indexes for ANN search. However, the
datasets of the existing benchmarks are no longer representative of the current
applications of ANN search. Hence, there is an urgent need for an up-to-date
set of benchmarks. To this end, we introduce Vector Index Benchmark for
Embeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE
contains a pipeline for creating benchmark datasets using dense embedding
models characteristic of modern applications, such as retrieval-augmented
generation (RAG). To replicate real-world workloads, we also include
out-of-distribution (OOD) datasets where the queries and the corpus are drawn
from different distributions. We use VIBE to conduct a comprehensive evaluation
of SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution
and 6 out-of-distribution datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DetailFusion: A Dual-branch Framework with Detail Enhancement for
  Composed Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Yang, Yinan Zhou, Yuxin Chen, Ziqi Zhang, Zongyang Ma, Chunfeng Yuan, Bing Li, Lin Song, Jun Gao, Peng Li, Weiming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Composed Image Retrieval (CIR) aims to retrieve target images from a gallery
based on a reference image and modification text as a combined query. Recent
approaches focus on balancing global information from two modalities and encode
the query into a unified feature for retrieval. However, due to insufficient
attention to fine-grained details, these coarse fusion methods often struggle
with handling subtle visual alterations or intricate textual instructions. In
this work, we propose DetailFusion, a novel dual-branch framework that
effectively coordinates information across global and detailed granularities,
thereby enabling detail-enhanced CIR. Our approach leverages atomic detail
variation priors derived from an image editing dataset, supplemented by a
detail-oriented optimization strategy to develop a Detail-oriented Inference
Branch. Furthermore, we design an Adaptive Feature Compositor that dynamically
fuses global and detailed features based on fine-grained information of each
unique multimodal query. Extensive experiments and ablation analyses not only
demonstrate that our method achieves state-of-the-art performance on both CIRR
and FashionIQ datasets but also validate the effectiveness and cross-domain
adaptability of detail enhancement for CIR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Resolving Conflicting Evidence in Automated Fact-Checking: A Study on
  Retrieval-Augmented LLMs <span class="chip">IJCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17762v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17762v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee, Rui Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) augmented with retrieval mechanisms have
demonstrated significant potential in fact-checking tasks by integrating
external knowledge. However, their reliability decreases when confronted with
conflicting evidence from sources of varying credibility. This paper presents
the first systematic evaluation of Retrieval-Augmented Generation (RAG) models
for fact-checking in the presence of conflicting evidence. To support this
study, we introduce \textbf{CONFACT} (\textbf{Con}flicting Evidence for
\textbf{Fact}-Checking) (Dataset available at
https://github.com/zoeyyes/CONFACT), a novel dataset comprising questions
paired with conflicting information from various sources. Extensive experiments
reveal critical vulnerabilities in state-of-the-art RAG methods, particularly
in resolving conflicts stemming from differences in media source credibility.
To address these challenges, we investigate strategies to integrate media
background information into both the retrieval and generation stages. Our
results show that effectively incorporating source credibility significantly
enhances the ability of RAG models to resolve conflicting evidence and improve
fact-checking performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready for IJCAI 2025, AI and Social Good</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling Ranking Properties with In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nilanjan Sinhababu, Andrew Parry, Debasis Ganguly, Pabitra Mitra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While standard IR models are mainly designed to optimize relevance,
real-world search often needs to balance additional objectives such as
diversity and fairness. These objectives depend on inter-document interactions
and are commonly addressed using post-hoc heuristics or supervised learning
methods, which require task-specific training for each ranking scenario and
dataset. In this work, we propose an in-context learning (ICL) approach that
eliminates the need for such training. Instead, our method relies on a small
number of example rankings that demonstrate the desired trade-offs between
objectives for past queries similar to the current input. We evaluate our
approach on four IR test collections to investigate multiple auxiliary
objectives: group fairness (TREC Fairness), polarity diversity (Touch\'e), and
topical diversity (TREC Deep Learning 2019/2020). We empirically validate that
our method enables control over ranking behavior through demonstration
engineering, allowing nuanced behavioral adjustments without explicit
optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 3 tables, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Behave<span class="highlight-title">GPT</span>: A Foundation Model for Large-scale User Behavior Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahui Gong, Jingtao Ding, Fanjin Meng, Chen Yang, Hong Chen, Zuojian Wang, Haisheng Lu, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, foundational models have revolutionized the fields of
language and vision, demonstrating remarkable abilities in understanding and
generating complex data; however, similar advances in user behavior modeling
have been limited, largely due to the complexity of behavioral data and the
challenges involved in capturing intricate temporal and contextual
relationships in user activities. To address this, we propose BehaveGPT, a
foundational model designed specifically for large-scale user behavior
prediction. Leveraging transformer-based architecture and a novel pretraining
paradigm, BehaveGPT is trained on vast user behavior datasets, allowing it to
learn complex behavior patterns and support a range of downstream tasks,
including next behavior prediction, long-term generation, and cross-domain
adaptation. Our approach introduces the DRO-based pretraining paradigm tailored
for user behavior data, which improves model generalization and transferability
by equitably modeling both head and tail behaviors. Extensive experiments on
real-world datasets demonstrate that BehaveGPT outperforms state-of-the-art
baselines, achieving more than a 10% improvement in macro and weighted recall,
showcasing its ability to effectively capture and predict user behavior.
Furthermore, we measure the scaling law in the user behavior domain for the
first time on the Honor dataset, providing insights into how model performance
scales with increased data and parameter sizes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 8 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large language model as user daily behavior data generator: balancing
  population diversity and individual personality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxin Li, Jingtao Ding, Jiahui Gong, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting human daily behavior is challenging due to the complexity of
routine patterns and short-term fluctuations. While data-driven models have
improved behavior prediction by leveraging empirical data from various
platforms and devices, the reliance on sensitive, large-scale user data raises
privacy concerns and limits data availability. Synthetic data generation has
emerged as a promising solution, though existing methods are often limited to
specific applications. In this work, we introduce BehaviorGen, a framework that
uses large language models (LLMs) to generate high-quality synthetic behavior
data. By simulating user behavior based on profiles and real events,
BehaviorGen supports data augmentation and replacement in behavior prediction
models. We evaluate its performance in scenarios such as pertaining
augmentation, fine-tuning replacement, and fine-tuning augmentation, achieving
significant improvements in human mobility and smartphone usage predictions,
with gains of up to 18.9%. Our results demonstrate the potential of BehaviorGen
to enhance user behavior modeling through flexible and privacy-preserving
synthetic data generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 7 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EGA: A Unified End-to-End Generative Framework for Industrial
  Advertising Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17549v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17549v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zuowu Zheng, Ze Wang, Fan Yang, Jiangke Fan, Teng Zhang, Xingxing Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online industrial advertising system is fundamentally constrained by the
inefficiency of multi-stage cascaded architectures, which filter out
high-potential candidates early and fragment business decision logic across
independent modules. Although recent advances in generative recommendation
offer end-to-end solutions, they fall short of practical advertising
requirements, lacking explicit modeling of bidding, creative selection,
allocation mechanism, and payment computation that are essential for real-world
deployment. To overcome these limitations, we propose End-to-end Generative
Advertising (EGA), a first unified generative framework that seamlessly
integrates user interests modeling, POI and creative generation, position
allocation, and payment optimization within a single model. EGA leverages
hierarchical tokenization and multi-token prediction to jointly generate
candidate POI and creative contents, while a permutation-aware reward model and
token-level bidding strategy ensure alignment with both user experiences and
advertiser business objectives. Meanwhile, we decouple allocation from payment
via a dedicated POI-level payment network with differentiable ex-post regret
minimization, guaranteeing incentive compatibility approximately. Extensive
offline and large-scale online experiments on real-world advertising systems
demonstrate its effectiveness and practical advantages over traditional
cascading architectures, highlighting its potential as one of the industry's
pioneering end-to-end generative advertising solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Recommendation, Classification, and Tracing Based on
  Hugging Face Knowledge Graph <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiaosheng Chen, Kaijia Huang, Xiao Zhou, Weiqing Luo, Yuanning Cui, Gong Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of open source machine learning (ML) resources, such as
models and datasets, has accelerated IR research. However, existing platforms
like Hugging Face do not explicitly utilize structured representations,
limiting advanced queries and analyses such as tracing model evolution and
recommending relevant datasets. To fill the gap, we construct HuggingKG, the
first large-scale knowledge graph built from the Hugging Face community for ML
resource management. With 2.6 million nodes and 6.2 million edges, HuggingKG
captures domain-specific relations and rich textual attributes. It enables us
to further present HuggingBench, a multi-task benchmark with three novel test
collections for IR tasks including resource recommendation, classification, and
tracing. Our experiments reveal unique characteristics of HuggingKG and the
derived tasks. Both resources are publicly available, expected to advance
research in open source resource sharing and management.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures. Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Copyright Protection for Knowledge Bases of Retrieval-augmented
  Language Models via Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.10440v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.10440v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly integrated into real-world
personalized applications through retrieval-augmented generation (RAG)
mechanisms to supplement their responses with domain-specific knowledge.
However, the valuable and often proprietary nature of the knowledge bases used
in RAG introduces the risk of unauthorized usage by adversaries. Existing
methods that can be generalized as watermarking techniques to protect these
knowledge bases typically involve poisoning or backdoor attacks. However, these
methods require altering the LLM's results of verification samples, inevitably
making these watermarks susceptible to anomaly detection and even introducing
new security risks. To address these challenges, we propose \name{} for
`harmless' copyright protection of knowledge bases. Instead of manipulating
LLM's final output, \name{} implants distinct yet benign verification behaviors
in the space of chain-of-thought (CoT) reasoning, maintaining the correctness
of the final answer. Our method has three main stages: (1) Generating CoTs: For
each verification question, we generate two `innocent' CoTs, including a target
CoT for building watermark behaviors; (2) Optimizing Watermark Phrases and
Target CoTs: Inspired by our theoretical analysis, we optimize them to minimize
retrieval errors under the \emph{black-box} and \emph{text-only} setting of
suspicious LLM, ensuring that only watermarked verification queries can
retrieve their correspondingly target CoTs contained in the knowledge base; (3)
Ownership Verification: We exploit a pairwise Wilcoxon test to verify whether a
suspicious LLM is augmented with the protected knowledge base by comparing its
responses to watermarked and benign verification queries. Our experiments on
diverse benchmarks demonstrate that \name{} effectively protects knowledge
bases and its resistance to adaptive attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally to this work. 25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ InfoDeepSeek: Benchmarking Agentic Information Seeking for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15872v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15872v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
grounding responses with retrieved information. As an emerging paradigm,
Agentic RAG further enhances this process by introducing autonomous LLM agents
into the information seeking process. However, existing benchmarks fall short
in evaluating such systems, as they are confined to a static retrieval
environment with a fixed, limited corpus} and simple queries that fail to
elicit agentic behavior. Moreover, their evaluation protocols assess
information seeking effectiveness by pre-defined gold sets of documents, making
them unsuitable for the open-ended and dynamic nature of real-world web
environments. To bridge this gap, we present InfoDeepSeek, a new benchmark with
challenging questions designed for assessing agentic information seeking in
real-world, dynamic web environments. We propose a systematic methodology for
constructing challenging queries satisfying the criteria of determinacy,
difficulty, and diversity. Based on this, we develop the first evaluation
framework tailored to dynamic agentic information seeking, including
fine-grained metrics about the accuracy, utility, and compactness of
information seeking outcomes. Through extensive experiments across LLMs, search
engines, and question types, InfoDeepSeek reveals nuanced agent behaviors and
offers actionable insights for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boosting Long-Context Management via Query-Guided Activation Refilling <span class="chip">ACL25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12486v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12486v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Processing long contexts poses a significant challenge for large language
models (LLMs) due to their inherent context-window limitations and the
computational burden of extensive key-value (KV) activations, which severely
impact efficiency. For information-seeking tasks, full context perception is
often unnecessary, as a query's information needs can dynamically range from
localized details to a global perspective, depending on its complexity.
However, existing methods struggle to adapt effectively to these dynamic
information needs.
  In the paper, we propose a method for processing long-context
information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE
constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache
compactly captures global information, and the layer-2 (L2) cache provides
detailed and localized information. ACRE establishes a proxying relationship
between the two caches, allowing the input query to attend to the L1 cache and
dynamically refill it with relevant entries from the L2 cache. This mechanism
integrates global understanding with query-specific local details, thus
improving answer decoding. Experiments on a variety of long-context
information-seeking datasets demonstrate ACRE's effectiveness, achieving
improvements in both performance and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL25 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese
  Medicine Knowledge Retrieval and Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.20118v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.20118v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional Chinese Medicine (TCM) represents a rich repository of ancient
medical knowledge that continues to play an important role in modern
healthcare. Due to the complexity and breadth of the TCM literature, the
integration of AI technologies is critical for its modernization and broader
accessibility. However, this integration poses considerable challenges,
including the interpretation of obscure classical Chinese texts and the
modeling of intricate semantic relationships among TCM concepts. In this paper,
we develop OpenTCM, an LLM-based system that combines a domain-specific TCM
knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG).
First, we extract more than 3.73 million classical Chinese characters from 68
gynecological books in the Chinese Medical Classics Database, with the help of
TCM and gynecology experts. Second, we construct a comprehensive
multi-relational knowledge graph comprising more than 48,000 entities and
152,000 interrelationships, using customized prompts and Chinese-oriented LLMs
such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last,
we integrate OpenTCM with this knowledge graph, enabling high-fidelity
ingredient knowledge retrieval and diagnostic question-answering without model
fine-tuning. Experimental evaluations demonstrate that our prompt design and
model selection significantly improve knowledge graph quality, achieving a
precision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves
mean expert scores of 4.5 in ingredient information retrieval and 3.8 in
diagnostic question-answering tasks, outperforming state-of-the-art solutions
in real-world TCM use cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StealthRank: LLM Ranking Manipulation via Stealthy <span class="highlight-title">Prompt</span> Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Tang, Yi Fan, Chenxiao Yu, Tiankai Yang, Yue Zhao, Xiyang Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of large language models (LLMs) into information retrieval
systems introduces new attack surfaces, particularly for adversarial ranking
manipulations. We present $\textbf{StealthRank}$, a novel adversarial attack
method that manipulates LLM-driven ranking systems while maintaining textual
fluency and stealth. Unlike existing methods that often introduce detectable
anomalies, StealthRank employs an energy-based optimization framework combined
with Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text
sequences embedded within item or document descriptions that subtly yet
effectively influence LLM ranking mechanisms. We evaluate StealthRank across
multiple LLMs, demonstrating its ability to covertly boost the ranking of
target items while avoiding explicit manipulation traces. Our results show that
StealthRank consistently outperforms state-of-the-art adversarial ranking
baselines in both effectiveness and stealth, highlighting critical
vulnerabilities in LLM-driven ranking systems. Our code is publicly available
at $\href{https://github.com/Tangyiming205069/controllable-seo}{here}$.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Distribution Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nic Fishman, Gokul Gowri, Peng Yin, Jonathan Gootenberg, Omar Abudayyeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many real-world problems require reasoning across multiple scales, demanding
models which operate not on single data points, but on entire distributions. We
introduce generative distribution embeddings (GDE), a framework that lifts
autoencoders to the space of distributions. In GDEs, an encoder acts on sets of
samples, and the decoder is replaced by a generator which aims to match the
input distribution. This framework enables learning representations of
distributions by coupling conditional generative models with encoder networks
which satisfy a criterion we call distributional invariance. We show that GDEs
learn predictive sufficient statistics embedded in the Wasserstein space, such
that latent GDE distances approximately recover the $W_2$ distance, and latent
interpolation approximately recovers optimal transport trajectories for
Gaussian and Gaussian mixture distributions. We systematically benchmark GDEs
against existing approaches on synthetic datasets, demonstrating consistently
stronger performance. We then apply GDEs to six key problems in computational
biology: learning representations of cell populations from lineage-tracing data
(150K cells), predicting perturbation effects on single-cell transcriptomes (1M
cells), predicting perturbation effects on cellular phenotypes (20M single-cell
images), modeling tissue-specific DNA methylation patterns (253M sequences),
designing synthetic yeast promoters (34M sequences), and spatiotemporal
modeling of viral protein sequences (1M sequences).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lost in the Haystack: Smaller Needles are More Difficult for LLMs to
  Find 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Owen Bianchi, Mathew J. Koretsky, Maya Willey, Chelsea X. Alvarado, Tanay Nayak, Adi Asija, Nicole Kuznetsov, Mike A. Nalls, Faraz Faghri, Daniel Khashabi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) face significant challenges with
needle-in-a-haystack tasks, where relevant information ("the needle") must be
drawn from a large pool of irrelevant context ("the haystack"). Previous
studies have highlighted positional bias and distractor quantity as critical
factors affecting model performance, yet the influence of gold context size has
received little attention. We address this gap by systematically studying how
variations in gold context length impact LLM performance on long-context
question answering tasks. Our experiments reveal that LLM performance drops
sharply when the gold context is shorter, i.e., smaller gold contexts
consistently degrade model performance and amplify positional sensitivity,
posing a major challenge for agentic systems that must integrate scattered,
fine-grained information of varying lengths. This pattern holds across three
diverse domains (general knowledge, biomedical reasoning, and mathematical
reasoning) and seven state-of-the-art LLMs of various sizes and architectures.
Our work provides clear insights to guide the design of robust, context-aware
LLM-driven systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Boosting Open Set Recognition Performance through Modulated
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18137v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18137v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amit Kumar Kundu, Vaishnavi Patil, Joseph Jaja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The open set recognition (OSR) problem aims to identify test samples from
novel semantic classes that are not part of the training classes, a task that
is crucial in many practical scenarios. However, existing OSR methods use a
constant scaling factor (the temperature) to the logits before applying a loss
function, which hinders the model from exploring both ends of the spectrum in
representation learning -- from instance-level to semantic-level features. In
this paper, we address this problem by enabling temperature-modulated
representation learning using our novel negative cosine scheduling scheme. Our
scheduling lets the model form a coarse decision boundary at the beginning of
training by focusing on fewer neighbors, and gradually prioritizes more
neighbors to smooth out rough edges. This gradual task switching leads to a
richer and more generalizable representation space. While other OSR methods
benefit by including regularization or auxiliary negative samples, such as with
mix-up, thereby adding a significant computational overhead, our scheme can be
folded into any existing OSR method with no overhead. We implement the proposed
scheme on top of a number of baselines, using both cross-entropy and
contrastive loss functions as well as a few other OSR methods, and find that
our scheme boosts both the OSR performance and the closed set performance in
most cases, especially on the tougher semantic shift benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gaming Tool Preferences in Agentic LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazem Faghih, Wenxiao Wang, Yize Cheng, Siddhant Bharti, Gaurang Sriramanan, Sriram Balasubramanian, Parsa Hosseini, Soheil Feizi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can now access a wide range of external tools,
thanks to the Model Context Protocol (MCP). This greatly expands their
abilities as various agents. However, LLMs rely entirely on the text
descriptions of tools to decide which ones to use--a process that is
surprisingly fragile. In this work, we expose a vulnerability in prevalent
tool/function-calling protocols by investigating a series of edits to tool
descriptions, some of which can drastically increase a tool's usage from LLMs
when competing with alternatives. Through controlled experiments, we show that
tools with properly edited descriptions receive over 10 times more usage from
GPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further
evaluate how various edits to tool descriptions perform when competing directly
with one another and how these trends generalize or differ across a broader set
of 10 different models. These phenomenons, while giving developers a powerful
way to promote their tools, underscore the need for a more reliable foundation
for agentic LLMs to select and utilize tools and resources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging KANs for Expedient Training of Multichannel MLPs via
  Preconditioning and Geometric Refinement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18131v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18131v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonas A. Actor, Graham Harper, Ben Southworth, Eric C. Cyr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilayer perceptrons (MLPs) are a workhorse machine learning architecture,
used in a variety of modern deep learning frameworks. However, recently
Kolmogorov-Arnold Networks (KANs) have become increasingly popular due to their
success on a range of problems, particularly for scientific machine learning
tasks. In this paper, we exploit the relationship between KANs and multichannel
MLPs to gain structural insight into how to train MLPs faster. We demonstrate
the KAN basis (1) provides geometric localized support, and (2) acts as a
preconditioned descent in the ReLU basis, overall resulting in expedited
training and improved accuracy. Our results show the equivalence between
free-knot spline KAN architectures, and a class of MLPs that are refined
geometrically along the channel dimension of each weight tensor. We exploit
this structural equivalence to define a hierarchical refinement scheme that
dramatically accelerates training of the multi-channel MLP architecture. We
show further accuracy improvements can be had by allowing the $1$D locations of
the spline knots to be trained simultaneously with the weights. These advances
are demonstrated on a range of benchmark examples for regression and scientific
machine learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 3 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reward Model Overoptimisation in Iterated RLHF 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18126v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18126v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lorenz Wolf, Robert Kirk, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning from human feedback (RLHF) is a widely used method for
aligning large language models with human preferences. However, RLHF often
suffers from reward model overoptimisation, in which models overfit to the
reward function, resulting in non-generalisable policies that exploit the
idiosyncrasies and peculiarities of the reward function. A common mitigation is
iterated RLHF, in which reward models are repeatedly retrained with updated
human feedback and policies are re-optimised. Despite its increasing adoption,
the dynamics of overoptimisation in this setting remain poorly understood. In
this work, we present the first comprehensive study of overoptimisation in
iterated RLHF. We systematically analyse key design choices - how reward model
training data is transferred across iterations, which reward function is used
for optimisation, and how policies are initialised. Using the controlled
AlpacaFarm benchmark, we observe that overoptimisation tends to decrease over
successive iterations, as reward models increasingly approximate ground-truth
preferences. However, performance gains diminish over time, and while
reinitialising from the base policy is robust, it limits optimisation
flexibility. Other initialisation strategies often fail to recover from early
overoptimisation. These findings offer actionable insights for building more
stable and generalisable RLHF pipelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 17 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TabSTAR: A Foundation Tabular Model With Semantically Target-Aware
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18125v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18125v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alan Arazi, Eilam Shapira, Roi Reichart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While deep learning has achieved remarkable success across many domains, it
has historically underperformed on tabular learning tasks, which remain
dominated by gradient boosting decision trees (GBDTs). However, recent
advancements are paving the way for Tabular Foundation Models, which can
leverage real-world knowledge and generalize across diverse datasets,
particularly when the data contains free-text. Although incorporating language
model capabilities into tabular tasks has been explored, most existing methods
utilize static, target-agnostic textual representations, limiting their
effectiveness. We introduce TabSTAR: a Foundation Tabular Model with
Semantically Target-Aware Representations. TabSTAR is designed to enable
transfer learning on tabular data with textual features, with an architecture
free of dataset-specific parameters. It unfreezes a pretrained text encoder and
takes as input target tokens, which provide the model with the context needed
to learn task-specific embeddings. TabSTAR achieves state-of-the-art
performance for both medium- and large-sized datasets across known benchmarks
of classification tasks with text features, and its pretraining phase exhibits
scaling laws in the number of datasets, offering a pathway for further
performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProgRM: Build Better GUI Agents with Progress Rewards 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18121v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18121v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danyang Zhang, Situo Zhang, Ziyue Yang, Zichen Zhu, Zihan Zhao, Ruisheng Cao, Lu Chen, Kai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based (Large Language Model) GUI (Graphical User Interface) agents can
potentially reshape our daily lives significantly. However, current LLM-based
GUI agents suffer from the scarcity of high-quality training data owing to the
difficulties of trajectory collection and reward annotation. Existing works
have been exploring LLMs to collect trajectories for imitation learning or to
offer reward signals for online RL training. However, the Outcome Reward Model
(ORM) used in existing works cannot provide finegrained feedback and can
over-penalize the valuable steps in finally failed trajectories. To this end,
we propose Progress Reward Model (ProgRM) to provide dense informative
intermediate rewards by predicting a task completion progress for each step in
online training. To handle the challenge of progress reward label annotation,
we further design an efficient LCS-based (Longest Common Subsequence)
self-annotation algorithm to discover the key steps in trajectories and assign
progress labels accordingly. ProgRM is evaluated with extensive experiments and
analyses. Actors trained with ProgRM outperform leading proprietary LLMs and
ORM-trained actors, illustrating the effectiveness of ProgRM. The codes for
experiments will be made publicly available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable Policy Maximization Under Network Interference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18118v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18118v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aidan Gleich, Eric Laber, Alexander Volfovsky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many interventions, such as vaccines in clinical trials or coupons in online
marketplaces, must be assigned sequentially without full knowledge of their
effects. Multi-armed bandit algorithms have proven successful in such settings.
However, standard independence assumptions fail when the treatment status of
one individual impacts the outcomes of others, a phenomenon known as
interference. We study optimal-policy learning under interference on a dynamic
network. Existing approaches to this problem require repeated observations of
the same fixed network and struggle to scale in sample size beyond as few as
fifteen connected units -- both limit applications. We show that under common
assumptions on the structure of interference, rewards become linear. This
enables us to develop a scalable Thompson sampling algorithm that maximizes
policy impact when a new $n$-node network is observed each round. We prove a
Bayesian regret bound that is sublinear in $n$ and the number of rounds.
Simulation experiments show that our algorithm learns quickly and outperforms
existing methods. The results close a key scalability gap between causal
inference methods for interference and practical bandit algorithms, enabling
policy optimization in large-scale networked systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Supervised Learning and Reinforcement Learning in Math
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18116v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18116v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huayu Chen, Kaiwen Zheng, Qinsheng Zhang, Ganqu Cui, Yin Cui, Haotian Ye, Tsung-Yi Lin, Ming-Yu Liu, Jun Zhu, Haoxiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning (RL) has played a central role in the recent surge of
LLMs' math abilities by enabling self-improvement through binary verifier
signals. In contrast, Supervised Learning (SL) is rarely considered for such
verification-driven training, largely due to its heavy reliance on reference
answers and inability to reflect on mistakes. In this work, we challenge the
prevailing notion that self-improvement is exclusive to RL and propose
Negative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to
reflect on their failures and improve autonomously with no external teachers.
In online training, instead of throwing away self-generated negative answers,
NFT constructs an implicit negative policy to model them. This implicit policy
is parameterized with the same positive LLM we target to optimize on positive
data, enabling direct policy optimization on all LLMs' generations. We conduct
experiments on 7B and 32B models in math reasoning tasks. Results consistently
show that through the additional leverage of negative feedback, NFT
significantly improves over SL baselines like Rejection sampling Fine-Tuning,
matching or even surpassing leading RL algorithms like GRPO and DAPO.
Furthermore, we demonstrate that NFT and GRPO are actually equivalent in
strict-on-policy training, even though they originate from entirely different
theoretical foundations. Our experiments and theoretical findings bridge the
gap between SL and RL methods in binary-feedback learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Discreteness: Finite-Sample Analysis of Straight-Through
  Estimator for Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18113v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18113v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Halyun Jeong, Jack Xin, Penghang Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training quantized neural networks requires addressing the non-differentiable
and discrete nature of the underlying optimization problem. To tackle this
challenge, the straight-through estimator (STE) has become the most widely
adopted heuristic, allowing backpropagation through discrete operations by
introducing surrogate gradients. However, its theoretical properties remain
largely unexplored, with few existing works simplifying the analysis by
assuming an infinite amount of training data. In contrast, this work presents
the first finite-sample analysis of STE in the context of neural network
quantization. Our theoretical results highlight the critical role of sample
size in the success of STE, a key insight absent from existing studies.
Specifically, by analyzing the quantization-aware training of a two-layer
neural network with binary weights and activations, we derive the sample
complexity bound in terms of the data dimensionality that guarantees the
convergence of STE-based optimization to the global minimum. Moreover, in the
presence of label noises, we uncover an intriguing recurrence property of
STE-gradient method, where the iterate repeatedly escape from and return to the
optimal binary weights. Our analysis leverages tools from compressed sensing
and dynamical systems theory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ F-ANcGAN: An Attention-Enhanced Cycle Consistent Generative Adversarial
  Architecture for Synthetic Image Generation of Nanoparticles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varun Ajith, Anindya Pal, Saumik Bhattacharya, Sayantari Ghosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nanomaterial research is becoming a vital area for energy, medicine, and
materials science, and accurate analysis of the nanoparticle topology is
essential to determine their properties. Unfortunately, the lack of
high-quality annotated datasets drastically hinders the creation of strong
segmentation models for nanoscale imaging. To alleviate this problem, we
introduce F-ANcGAN, an attention-enhanced cycle consistent generative
adversarial system that can be trained using a limited number of data samples
and generates realistic scanning electron microscopy (SEM) images directly from
segmentation maps. Our model uses a Style U-Net generator and a U-Net
segmentation network equipped with self-attention to capture structural
relationships and applies augmentation methods to increase the variety of the
dataset. The architecture reached a raw FID score of 17.65 for TiO$_2$ dataset
generation, with a further reduction in FID score to nearly 10.39 by using
efficient post-processing techniques. By facilitating scalable high-fidelity
synthetic dataset generation, our approach can improve the effectiveness of
downstream segmentation task training, overcoming severe data shortage issues
in nanoparticle analysis, thus extending its applications to resource-limited
fields.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 9 figures, 2 tables, conference paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Can I Publish My LLM Benchmark Without Giving the True Answers Away? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18102v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18102v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takashi Ishida, Thanawat Lodkaew, Ikko Yamane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Publishing a large language model (LLM) benchmark on the Internet risks
contaminating future LLMs: the benchmark may be unintentionally (or
intentionally) used to train or select a model. A common mitigation is to keep
the benchmark private and let participants submit their models or predictions
to the organizers. However, this strategy will require trust in a single
organization and still permits test-set overfitting through repeated queries.
To overcome this issue, we propose a way to publish benchmarks without
completely disclosing the ground-truth answers to the questions, while still
maintaining the ability to openly evaluate LLMs. Our main idea is to inject
randomness to the answers by preparing several logically correct answers, and
only include one of them as the solution in the benchmark. This reduces the
best possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is
this helpful to keep us from disclosing the ground truth, but this approach
also offers a test for detecting data contamination. In principle, even fully
capable models should not surpass the Bayes accuracy. If a model surpasses this
ceiling despite this expectation, this is a strong signal of data
contamination. We present experimental evidence that our method can detect data
contamination accurately on a wide range of benchmarks, models, and training
methodologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Dual Buffer with Divide-and-Conquer Strategy for Online
  Continual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18101v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18101v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Congren Dai, Huichi Zhou, Jiahao Huang, Zhenxuan Zhang, Fanwen Wang, Guang Yang, Fei Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online Continual Learning (OCL) presents a complex learning environment in
which new data arrives in a batch-to-batch online format, and the risk of
catastrophic forgetting can significantly impair model efficacy. In this study,
we address OCL by introducing an innovative memory framework that incorporates
a short-term memory system to retain dynamic information and a long-term memory
system to archive enduring knowledge. Specifically, the long-term memory system
comprises a collection of sub-memory buffers, each linked to a cluster
prototype and designed to retain data samples from distinct categories. We
propose a novel $K$-means-based sample selection method to identify cluster
prototypes for each encountered category. To safeguard essential and critical
samples, we introduce a novel memory optimisation strategy that selectively
retains samples in the appropriate sub-memory buffer by evaluating each cluster
prototype against incoming samples through an optimal transportation mechanism.
This approach specifically promotes each sub-memory buffer to retain data
samples that exhibit significant discrepancies from the corresponding cluster
prototype, thereby ensuring the preservation of semantically rich information.
In addition, we propose a novel Divide-and-Conquer (DAC) approach that
formulates the memory updating as an optimisation problem and divides it into
several subproblems. As a result, the proposed DAC approach can solve these
subproblems separately and thus can significantly reduce computations of the
proposed memory updating process. We conduct a series of experiments across
standard and imbalanced learning settings, and the empirical findings indicate
that the proposed memory framework achieves state-of-the-art performance in
both learning contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards more transferable adversarial attack in black-box manner 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun Tong Lei, Zhongliang Guo, Hon Chung Lee, Minh Quoc Duong, Chun Pong Lau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial attacks have become a well-explored domain, frequently serving as
evaluation baselines for model robustness. Among these, black-box attacks based
on transferability have received significant attention due to their practical
applicability in real-world scenarios. Traditional black-box methods have
generally focused on improving the optimization framework (e.g., utilizing
momentum in MI-FGSM) to enhance transferability, rather than examining the
dependency on surrogate white-box model architectures. Recent state-of-the-art
approach DiffPGD has demonstrated enhanced transferability by employing
diffusion-based adversarial purification models for adaptive attacks. The
inductive bias of diffusion-based adversarial purification aligns naturally
with the adversarial attack process, where both involving noise addition,
reducing dependency on surrogate white-box model selection. However, the
denoising process of diffusion models incurs substantial computational costs
through chain rule derivation, manifested in excessive VRAM consumption and
extended runtime. This progression prompts us to question whether introducing
diffusion models is necessary. We hypothesize that a model sharing similar
inductive bias to diffusion-based adversarial purification, combined with an
appropriate loss function, could achieve comparable or superior transferability
while dramatically reducing computational overhead. In this paper, we propose a
novel loss function coupled with a unique surrogate model to validate our
hypothesis. Our approach leverages the score of the time-dependent classifier
from classifier-guided diffusion models, effectively incorporating natural data
distribution knowledge into the adversarial optimization process. Experimental
results demonstrate significantly improved transferability across diverse model
architectures while maintaining robustness against diffusion-based defenses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Mixing Can Induce Phase Transitions in Knowledge Acquisition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinran Gu, Kaifeng Lyu, Jiazheng Li, Jingzhao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are typically trained on data mixtures: most
data come from web scrapes, while a small portion is curated from high-quality
sources with dense domain-specific knowledge. In this paper, we show that when
training LLMs on such data mixtures, knowledge acquisition from knowledge-dense
datasets, unlike training exclusively on knowledge-dense data
(arXiv:2404.05405), does not always follow a smooth scaling law but can exhibit
phase transitions with respect to the mixing ratio and model size. Through
controlled experiments on a synthetic biography dataset mixed with web-scraped
data, we demonstrate that: (1) as we increase the model size to a critical
value, the model suddenly transitions from memorizing very few to most of the
biographies; (2) below a critical mixing ratio, the model memorizes almost
nothing even with extensive training, but beyond this threshold, it rapidly
memorizes more biographies. We attribute these phase transitions to a capacity
allocation phenomenon: a model with bounded capacity must act like a knapsack
problem solver to minimize the overall test loss, and the optimal allocation
across datasets can change discontinuously as the model size or mixing ratio
varies. We formalize this intuition in an information-theoretic framework and
reveal that these phase transitions are predictable, with the critical mixing
ratio following a power-law relationship with the model size. Our findings
highlight a concrete case where a good mixing recipe for large models may not
be optimal for small models, and vice versa.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Early-Exit Graph Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18088v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18088v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Giuseppe Di Francesco, Maria Sofia Bucarelli, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto, Fabrizio Silvestri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Early-exit mechanisms allow deep neural networks to halt inference as soon as
classification confidence is high enough, adaptively trading depth for
confidence, and thereby cutting latency and energy on easy inputs while
retaining full-depth accuracy for harder ones. Similarly, adding early exit
mechanisms to Graph Neural Networks (GNNs), the go-to models for
graph-structured data, allows for dynamic trading depth for confidence on
simple graphs while maintaining full-depth accuracy on harder and more complex
graphs to capture intricate relationships. Although early exits have proven
effective across various deep learning domains, their potential within GNNs in
scenarios that require deep architectures while resisting over-smoothing and
over-squashing remains largely unexplored. We unlock that potential by first
introducing Symmetric-Anti-Symmetric Graph Neural Networks (SAS-GNN), whose
symmetry-based inductive biases mitigate these issues and yield stable
intermediate representations that can be useful to allow early exiting in GNNs.
Building on this backbone, we present Early-Exit Graph Neural Networks
(EEGNNs), which append confidence-aware exit heads that allow on-the-fly
termination of propagation based on each node or the entire graph. Experiments
show that EEGNNs preserve robust performance as depth grows and deliver
competitive accuracy on heterophilic and long-range benchmarks, matching
attention-based and asynchronous message-passing models while substantially
reducing computation and latency. We plan to release the code to reproduce our
experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stable Reinforcement Learning for Efficient Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18086v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18086v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muzhi Dai, Shixuan Liu, Qingyi Si
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The success of Deepseek-R1 has drawn the LLM community's attention to
reinforcement learning (RL) methods like GRPO. However, such rule-based 0/1
outcome reward methods lack the capability to regulate the intermediate
reasoning processes during chain-of-thought (CoT) generation, leading to severe
overthinking phenomena. In response, recent studies have designed reward
functions to reinforce models' behaviors in producing shorter yet correct
completions. Nevertheless, we observe that these length-penalty reward
functions exacerbate RL training instability: as the completion length
decreases, model accuracy abruptly collapses, often occurring early in
training. To address this issue, we propose a simple yet effective solution
GRPO-$\lambda$, an efficient and stabilized variant of GRPO, which dynamically
adjusts the reward strategy by monitoring the correctness ratio among
completions within each query-sampled group. A low correctness ratio indicates
the need to avoid length penalty that compromises CoT quality, triggering a
switch to length-agnostic 0/1 rewards that prioritize reasoning capability. A
high ratio maintains length penalties to boost efficiency. Experimental results
show that our approach avoids training instability caused by length penalty
while maintaining the optimal accuracy-efficiency trade-off. On the GSM8K,
GPQA, MATH-500, AMC 2023, and AIME 2024 benchmarks, it improves average
accuracy by 1.48% while reducing CoT sequence length by 47.3%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Do You Need for Diverse Trajectory Stitching in Diffusion Planning? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18083v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18083v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quentin Clark, Florian Shkurti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In planning, stitching is an ability of algorithms to piece together
sub-trajectories of data they are trained on to generate new and diverse
behaviours. While stitching is historically a strength of offline reinforcement
learning, recent generative behavioural cloning (BC) methods have also shown
proficiency at stitching. However, the main factors behind this are poorly
understood, hindering the development of new algorithms that can reliably
stitch. Focusing on diffusion planners trained via BC, we find two properties
are needed to compose: \emph{positional equivariance} and \emph{local
receptiveness}. We use these two properties to explain architecture, data, and
inference choices in existing generative BC methods based on diffusion
planning, including replanning frequency, data augmentation, and data scaling.
Experimental comparisions show that (1) while locality is more important than
positional equivariance in creating a diffusion planner capable of composition,
both are crucial (2) enabling these properties through relatively simple
architecture choices can be competitive with more computationally expensive
methods such as replanning or scaling data, and (3) simple inpainting-based
guidance can guide architecturally compositional models to enable
generalization in goal-conditioned settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 Pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Iterative Framework for Generative Backmapping of Coarse Grained
  Proteins 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18082v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18082v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Kementzidis, Erin Wong, John Nicholson, Ruichen Xu, Yuefan Deng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The techniques of data-driven backmapping from coarse-grained (CG) to
fine-grained (FG) representation often struggle with accuracy, unstable
training, and physical realism, especially when applied to complex systems such
as proteins. In this work, we introduce a novel iterative framework by using
conditional Variational Autoencoders and graph-based neural networks,
specifically designed to tackle the challenges associated with such large-scale
biomolecules. Our method enables stepwise refinement from CG beads to full
atomistic details. We outline the theory of iterative generative backmapping
and demonstrate via numerical experiments the advantages of multistep schemes
by applying them to proteins of vastly different structures with very coarse
representations. This multistep approach not only improves the accuracy of
reconstructions but also makes the training process more computationally
efficient for proteins with ultra-CG representations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures. For associated code repositories, see: CGVAE:
  https://github.com/wwang2/CoarseGrainingVAE GenZProT:
  https://github.com/learningmatter-mit/GenZProt See also arXiv:2201.12176 and
  arXiv:2303.01569 for related methods</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Backpropagation-Free Metropolis-Adjusted Langevin Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18081v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18081v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adam D. Cobb, Susmit Jha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work on backpropagation-free learning has shown that it is possible to
use forward-mode automatic differentiation (AD) to perform optimization on
differentiable models. Forward-mode AD requires sampling a tangent vector for
each forward pass of a model. The result is the model evaluation with the
directional derivative along the tangent. In this paper, we illustrate how the
sampling of this tangent vector can be incorporated into the proposal mechanism
for the Metropolis-Adjusted Langevin Algorithm (MALA). As such, we are the
first to introduce a backpropagation-free gradient-based Markov chain Monte
Carlo (MCMC) algorithm. We also extend to a novel backpropagation-free
position-specific preconditioned forward-mode MALA that leverages Hessian
information. Overall, we propose four new algorithms: Forward MALA; Line
Forward MALA; Pre-conditioned Forward MALA, and Pre-conditioned Line Forward
MALA. We highlight the reduced computational cost of the forward-mode samplers
and show that forward-mode is competitive with the original MALA, while even
outperforming it depending on the probabilistic model. We include Bayesian
inference results on a range of probabilistic models, including hierarchical
distributions and Bayesian neural networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 Pages, 8 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AFD-STA: Adaptive Filtering Denoising with Spatiotemporal Attention for
  Chaotic System Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18080v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18080v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunlin Gong, Yin Wang, Jingru Li, Hanleran Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents AFD-STA Net, a neural framework integrating adaptive
filtering and spatiotemporal dynamics learning for predicting high-dimensional
chaotic systems governed by partial differential equations. The architecture
combines: 1) An adaptive exponential smoothing module with position-aware decay
coefficients for robust attractor reconstruction, 2) Parallel attention
mechanisms capturing cross-temporal and spatial dependencies, 3) Dynamic gated
fusion of multiscale features, and 4) Deep projection networks with
dimension-scaling capabilities. Numerical experiments on nonlinear PDE systems
demonstrate the model's effectiveness in maintaining prediction accuracy under
both smooth and strongly chaotic regimes while exhibiting noise tolerance
through adaptive filtering. Component ablation studies confirm critical
contributions from each module, particularly highlighting the essential role of
spatiotemporal attention in learning complex dynamical interactions. The
framework shows promising potential for real-world applications requiring
simultaneous handling of measurement uncertainties and high-dimensional
nonlinear dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bayesian Deep Learning for Discrete Choice 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel F. Villarraga, Ricardo A. Daziano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Discrete choice models (DCMs) are used to analyze individual decision-making
in contexts such as transportation choices, political elections, and consumer
preferences. DCMs play a central role in applied econometrics by enabling
inference on key economic variables, such as marginal rates of substitution,
rather than focusing solely on predicting choices on new unlabeled data.
However, while traditional DCMs offer high interpretability and support for
point and interval estimation of economic quantities, these models often
underperform in predictive tasks compared to deep learning (DL) models. Despite
their predictive advantages, DL models remain largely underutilized in discrete
choice due to concerns about their lack of interpretability, unstable parameter
estimates, and the absence of established methods for uncertainty
quantification. Here, we introduce a deep learning model architecture
specifically designed to integrate with approximate Bayesian inference methods,
such as Stochastic Gradient Langevin Dynamics (SGLD). Our proposed model
collapses to behaviorally informed hypotheses when data is limited, mitigating
overfitting and instability in underspecified settings while retaining the
flexibility to capture complex nonlinear relationships when sufficient data is
available. We demonstrate our approach using SGLD through a Monte Carlo
simulation study, evaluating both predictive metrics--such as out-of-sample
balanced accuracy--and inferential metrics--such as empirical coverage for
marginal rates of substitution interval estimates. Additionally, we present
results from two empirical case studies: one using revealed mode choice data in
NYC, and the other based on the widely used Swiss train choice stated
preference data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emergence of Hebbian Dynamics in Regularized Non-Local Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18069v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18069v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Koplow, Tomaso Poggio, Liu Ziyin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic Gradient Descent (SGD) has emerged as a remarkably effective
learning algorithm, underpinning nearly all state-of-the-art machine learning
models, from large language models to autonomous vehicles. Despite its
practical success, SGD appears fundamentally distinct from biological learning
mechanisms. It is widely believed that the biological brain can not implement
gradient descent because it is nonlocal, and we have found little (if any)
experimental evidence for it. In contrast, the brain is widely thought to learn
via local Hebbian learning principles, which have been seen as incompatible
with gradient descent. In this paper, we establish a theoretical and empirical
connection between the learning signals of neural networks trained using SGD
with weight decay and those trained with Hebbian learning near convergence. We
show that SGD with regularization can appear to learn according to a Hebbian
rule, and SGD with injected noise according to an anti-Hebbian rule. We also
provide empirical evidence that Hebbian learning properties can emerge in a
network with weight decay from virtually any learning rule--even random ones.
These results may bridge a long-standing gap between artificial and biological
learning, revealing Hebbian properties as an epiphenomenon of deeper
optimization principles and cautioning against interpreting their presence in
neural data as evidence against more complex hetero-synaptic mechanisms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Uncertainty Aware Task Delegation and Human-AI Collaborative
  Decision-Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18066v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18066v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Min Hun Lee, Martyn Zhe Yu Tok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing promise of artificial intelligence (AI) in supporting
decision-making across domains, fostering appropriate human reliance on AI
remains a critical challenge. In this paper, we investigate the utility of
exploring distance-based uncertainty scores for task delegation to AI and
describe how these scores can be visualized through embedding representations
for human-AI decision-making. After developing an AI-based system for physical
stroke rehabilitation assessment, we conducted a study with 19 health
professionals and 10 students in medicine/health to understand the effect of
exploring distance-based uncertainty scores on users' reliance on AI. Our
findings showed that distance-based uncertainty scores outperformed traditional
probability-based uncertainty scores in identifying uncertain cases. In
addition, after exploring confidence scores for task delegation and reviewing
embedding-based visualizations of distance-based uncertainty scores,
participants achieved an 8.20% higher rate of correct decisions, a 7.15% higher
rate of changing their decisions to correct ones, and a 7.14% lower rate of
incorrect changes after reviewing AI outputs than those reviewing
probability-based uncertainty scores ($p<0.01$). Our findings highlight the
potential of distance-based uncertainty scores to enhance decision accuracy and
appropriate reliance on AI while discussing ongoing challenges for human-AI
collaborative decision-making.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM FAccT 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reward Model Generalization for Compute-Aware Test-Time Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeen Song, Wenwen Qiang, Siyu Zhao, Changwen Zheng, Gang Hua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  External test-time reasoning enhances large language models (LLMs) by
decoupling generation and selection. At inference time, the model generates
multiple reasoning paths, and an auxiliary process reward model (PRM) is used
to score and select the best one. A central challenge in this setting is
test-time compute optimality (TCO), i.e., how to maximize answer accuracy under
a fixed inference budget. In this work, we establish a theoretical framework to
analyze how the generalization error of the PRM affects compute efficiency and
reasoning performance. Leveraging PAC-Bayes theory, we derive generalization
bounds and show that a lower generalization error of PRM leads to fewer samples
required to find correct answers. Motivated by this analysis, we propose
Compute-Aware Tree Search (CATS), an actor-critic framework that dynamically
controls search behavior. The actor outputs sampling hyperparameters based on
reward distributions and sparsity statistics, while the critic estimates their
utility to guide budget allocation. Experiments on the MATH and AIME benchmarks
with various LLMs and PRMs demonstrate that CATS consistently outperforms other
external TTS methods, validating our theoretical predictions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Asymptotically optimal regret in communicating Markov decision processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18064v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18064v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Victor Boone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a learning algorithm that achieves asymptotically
optimal regret for Markov decision processes in average reward under a
communicating assumption. That is, given a communicating Markov decision
process $M$, our algorithm has regret $K(M) \log(T) + \mathrm{o}(\log(T))$
where $T$ is the number of learning steps and $K(M)$ is the best possible
constant. This algorithm works by explicitly tracking the constant $K(M)$ to
learn optimally, then balances the trade-off between exploration (playing
sub-optimally to gain information), co-exploration (playing optimally to gain
information) and exploitation (playing optimally to score maximally). We
further show that the function $K(M)$ is discontinuous, which is a consequence
challenge for our approach. To that end, we describe a regularization mechanism
to estimate $K(M)$ with arbitrary precision from empirical data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning with Restricted Boltzmann Machines: Asymptotics of AMP and GD
  in High Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhou Xu, Florent Krzakala, Lenka Zdeborová
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Restricted Boltzmann Machine (RBM) is one of the simplest generative
neural networks capable of learning input distributions. Despite its
simplicity, the analysis of its performance in learning from the training data
is only well understood in cases that essentially reduce to singular value
decomposition of the data. Here, we consider the limit of a large dimension of
the input space and a constant number of hidden units. In this limit, we
simplify the standard RBM training objective into a form that is equivalent to
the multi-index model with non-separable regularization. This opens a path to
analyze training of the RBM using methods that are established for multi-index
models, such as Approximate Message Passing (AMP) and its state evolution, and
the analysis of Gradient Descent (GD) via the dynamical mean-field theory. We
then give rigorous asymptotics of the training dynamics of RBM on data
generated by the spiked covariance model as a prototype of a structure suitable
for unsupervised learning. We show in particular that RBM reaches the optimal
computational weak recovery threshold, aligning with the BBP transition, in the
spiked covariance model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Linear Mixture Distributionally Robust Markov Decision Processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18044v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18044v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhishuai Liu, Pan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many real-world decision-making problems face the off-dynamics challenge: the
agent learns a policy in a source domain and deploys it in a target domain with
different state transitions. The distributionally robust Markov decision
process (DRMDP) addresses this challenge by finding a robust policy that
performs well under the worst-case environment within a pre-specified
uncertainty set of transition dynamics. Its effectiveness heavily hinges on the
proper design of these uncertainty sets, based on prior knowledge of the
dynamics. In this work, we propose a novel linear mixture DRMDP framework,
where the nominal dynamics is assumed to be a linear mixture model. In contrast
with existing uncertainty sets directly defined as a ball centered around the
nominal kernel, linear mixture DRMDPs define the uncertainty sets based on a
ball around the mixture weighting parameter. We show that this new framework
provides a more refined representation of uncertainties compared to
conventional models based on $(s,a)$-rectangularity and $d$-rectangularity,
when prior knowledge about the mixture model is present. We propose a meta
algorithm for robust policy learning in linear mixture DRMDPs with general
$f$-divergence defined uncertainty sets, and analyze its sample complexities
under three divergence metrics instantiations: total variation,
Kullback-Leibler, and $\chi^2$ divergences. These results establish the
statistical learnability of linear mixture DRMDPs, laying the theoretical
foundation for future research on this new setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improved Algorithms for Overlapping and Robust Clustering of
  Edge-Colored Hypergraphs: An LP-Based Combinatorial Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18043v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18043v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changyeol Lee, Yongho Shin, Hyung-Chan An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clustering is a fundamental task in both machine learning and data mining.
Among various methods, edge-colored clustering (ECC) has emerged as a useful
approach for handling categorical data. Given a hypergraph with (hyper)edges
labeled by colors, ECC aims to assign vertex colors to minimize the number of
edges where the vertex color differs from the edge's color. However,
traditional ECC has inherent limitations, as it enforces a nonoverlapping and
exhaustive clustering. To tackle these limitations, three versions of ECC have
been studied: Local ECC and Global ECC, which allow overlapping clusters, and
Robust ECC, which accounts for vertex outliers. For these problems, both linear
programming (LP) rounding algorithms and greedy combinatorial algorithms have
been proposed. While these LP-rounding algorithms provide high-quality
solutions, they demand substantial computation time; the greedy algorithms, on
the other hand, run very fast but often compromise solution quality. In this
paper, we present an algorithmic framework that combines the strengths of LP
with the computational efficiency of combinatorial algorithms. Both
experimental and theoretical analyses show that our algorithms efficiently
produce high-quality solutions for all three problems: Local, Global, and
Robust ECC. We complement our algorithmic contributions with
complexity-theoretic inapproximability results and integrality gap bounds,
which suggest that significant theoretical improvements are unlikely. Our
results also answer two open questions previously raised in the literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mahalanobis++: Improving OOD Detection via Feature Normalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18032v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18032v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Mueller, Matthias Hein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting out-of-distribution (OOD) examples is an important task for
deploying reliable machine learning models in safety-critial applications.
While post-hoc methods based on the Mahalanobis distance applied to pre-logit
features are among the most effective for ImageNet-scale OOD detection, their
performance varies significantly across models. We connect this inconsistency
to strong variations in feature norms, indicating severe violations of the
Gaussian assumption underlying the Mahalanobis distance estimation. We show
that simple $\ell_2$-normalization of the features mitigates this problem
effectively, aligning better with the premise of normally distributed data with
shared covariance matrix. Extensive experiments on 44 models across diverse
architectures and pretraining schemes show that $\ell_2$-normalization improves
the conventional Mahalanobis distance-based approaches significantly and
consistently, and outperforms other recently proposed OOD detection methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automata Learning of Preferences over Temporal Logic Formulas from
  Pairwise Comparisons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hazhar Rahmani, Jie Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many preference elicitation algorithms consider preference over propositional
logic formulas or items with different attributes. In sequential decision
making, a user's preference can be a preorder over possible outcomes, each of
which is a temporal sequence of events. This paper considers a class of
preference inference problems where the user's unknown preference is
represented by a preorder over regular languages (sets of temporal sequences),
referred to as temporal goals. Given a finite set of pairwise comparisons
between finite words, the objective is to learn both the set of temporal goals
and the preorder over these goals. We first show that a preference relation
over temporal goals can be modeled by a Preference Deterministic Finite
Automaton (PDFA), which is a deterministic finite automaton augmented with a
preorder over acceptance conditions. The problem of preference inference
reduces to learning the PDFA. This problem is shown to be computationally
challenging, with the problem of determining whether there exists a PDFA of
size smaller than a given integer $k$, consistent with the sample, being
NP-Complete. We formalize the properties of characteristic samples and develop
an algorithm that guarantees to learn, given a characteristic sample, the
minimal PDFA equivalent to the true PDFA from which the sample is drawn. We
present the method through a running example and provide detailed analysis
using a robotic motion planning problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 11 figures, technical report, submission under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knot So Simple: A Minimalistic Environment for Spatial Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18028v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18028v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zizhao Chen, Yoav Artzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose KnotGym, an interactive environment for complex, spatial reasoning
and manipulation. KnotGym includes goal-oriented rope manipulation tasks with
varying levels of complexity, all requiring acting from pure image
observations. Tasks are defined along a clear and quantifiable axis of
complexity based on the number of knot crossings, creating a natural
generalization test. KnotGym has a simple observation space, allowing for
scalable development, yet it highlights core challenges in integrating acute
perception, spatial reasoning, and grounded manipulation. We evaluate methods
of different classes, including model-based RL, model-predictive control, and
chain-of-thought reasoning, and illustrate the challenges KnotGym presents.
KnotGym is available at https://github.com/lil-lab/knotgym.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Time to Spike? Understanding the Representational Power of Spiking
  Neural Networks in Discrete Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18023v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18023v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duc Anh Nguyen, Ernesto Araya, Adalbert Fono, Gitta Kutyniok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have seen significant progress in developing spiking neural
networks (SNNs) as a potential solution to the energy challenges posed by
conventional artificial neural networks (ANNs). However, our theoretical
understanding of SNNs remains relatively limited compared to the ever-growing
body of literature on ANNs. In this paper, we study a discrete-time model of
SNNs based on leaky integrate-and-fire (LIF) neurons, referred to as
discrete-time LIF-SNNs, a widely used framework that still lacks solid
theoretical foundations. We demonstrate that discrete-time LIF-SNNs with static
inputs and outputs realize piecewise constant functions defined on polyhedral
regions, and more importantly, we quantify the network size required to
approximate continuous functions. Moreover, we investigate the impact of
latency (number of time steps) and depth (number of layers) on the complexity
of the input space partitioning induced by discrete-time LIF-SNNs. Our analysis
highlights the importance of latency and contrasts these networks with ANNs
employing piecewise linear activation functions. Finally, we present numerical
experiments to support our theoretical findings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Strictly Constrained Generative Modeling via Split Augmented Langevin
  Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthieu Blanke, Yongquan Qu, Sara Shamekh, Pierre Gentine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models hold great promise for representing complex physical
systems, but their deployment is currently limited by the lack of guarantees on
the physical plausibility of the generated outputs. Ensuring that known
physical constraints are enforced is therefore critical when applying
generative models to scientific and engineering problems. We address this
limitation by developing a principled framework for sampling from a target
distribution while rigorously satisfying physical constraints. Leveraging the
variational formulation of Langevin dynamics, we propose Split Augmented
Langevin (SAL), a novel primal-dual sampling algorithm that enforces
constraints progressively through variable splitting, with convergence
guarantees. While the method is developed theoretically for Langevin dynamics,
we demonstrate its effective applicability to diffusion models. In particular,
we use constrained diffusion models to generate physical fields satisfying
energy and mass conservation laws. We apply our method to diffusion-based data
assimilation on a complex physical system, where enforcing physical constraints
substantially improves both forecast accuracy and the preservation of critical
conserved quantities. We also demonstrate the potential of SAL for challenging
feasibility problems in optimal control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SemSegBench & DetecBench: Benchmarking Reliability and Generalization
  Beyond Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18015v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18015v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shashank Agnihotri, David Schader, Jonas Jakubassa, Nico Sharei, Simon Kral, Mehmet Ege Kaçar, Ruben Weber, Margret Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reliability and generalization in deep learning are predominantly studied in
the context of image classification. Yet, real-world applications in
safety-critical domains involve a broader set of semantic tasks, such as
semantic segmentation and object detection, which come with a diverse set of
dedicated model architectures. To facilitate research towards robust model
design in segmentation and detection, our primary objective is to provide
benchmarking tools regarding robustness to distribution shifts and adversarial
manipulations. We propose the benchmarking tools SEMSEGBENCH and DETECBENCH,
along with the most extensive evaluation to date on the reliability and
generalization of semantic segmentation and object detection models. In
particular, we benchmark 76 segmentation models across four datasets and 61
object detectors across two datasets, evaluating their performance under
diverse adversarial attacks and common corruptions. Our findings reveal
systematic weaknesses in state-of-the-art models and uncover key trends based
on architecture, backbone, and model capacity. SEMSEGBENCH and DETECBENCH are
open-sourced in our GitHub repository
(https://github.com/shashankskagnihotri/benchmarking_reliability_generalization)
along with our complete set of total 6139 evaluations. We anticipate the
collected data to foster and encourage future research towards improved model
reliability beyond classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First seven listed authors have equal contribution. GitHub:
  https://github.com/shashankskagnihotri/benchmarking_reliability_generalization.
  arXiv admin note: text overlap with arXiv:2505.05091</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Operator Neural Network Model Predictive Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18008v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18008v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Oliver de Jong, Khemraj Shukla, Mircea Lazar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider the design of model predictive control (MPC)
algorithms based on deep operator neural networks (DeepONets). These neural
networks are capable of accurately approximating real and complex valued
solutions of continuous time nonlinear systems without relying on recurrent
architectures. The DeepONet architecture is made up of two feedforward neural
networks: the branch network, which encodes the input function space, and the
trunk network, which represents dependencies on temporal variables or initial
conditions. Utilizing the original DeepONet architecture as a predictor within
MPC for Multi Input Multi Output (MIMO) systems requires multiple branch
networks, to generate multi output predictions, one for each input. Moreover,
to predict multiple time steps into the future, the network has to be evaluated
multiple times. Motivated by this, we introduce a multi step DeepONet
(MS-DeepONet) architecture that computes in one shot multi step predictions of
system outputs from multi step input sequences, which is better suited for MPC.
We prove that the MS DeepONet is a universal approximator in terms of multi
step sequence prediction. Additionally, we develop automated hyper parameter
selection strategies and implement MPC frameworks using both the standard
DeepONet and the proposed MS DeepONet architectures in PyTorch. The
implementation is publicly available on GitHub. Simulation results demonstrate
that MS-DeepONet consistently outperforms the standard DeepONet in learning and
predictive control tasks across several nonlinear benchmark systems: the van
der Pol oscillator, the quadruple tank process, and a cart pendulum unstable
system, where it successfully learns and executes multiple swing up and
stabilization policies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distances for Markov chains from sample streams 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18005v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18005v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergio Calo, Anders Jonsson, Gergely Neu, Ludovic Schwartz, Javier Segovia-Aguas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bisimulation metrics are powerful tools for measuring similarities between
stochastic processes, and specifically Markov chains. Recent advances have
uncovered that bisimulation metrics are, in fact, optimal-transport distances,
which has enabled the development of fast algorithms for computing such metrics
with provable accuracy and runtime guarantees. However, these recent methods,
as well as all previously known methods, assume full knowledge of the
transition dynamics. This is often an impractical assumption in most real-world
scenarios, where typically only sample trajectories are available. In this
work, we propose a stochastic optimization method that addresses this
limitation and estimates bisimulation metrics based on sample access, without
requiring explicit transition models. Our approach is derived from a new linear
programming (LP) formulation of bisimulation metrics, which we solve using a
stochastic primal-dual optimization method. We provide theoretical guarantees
on the sample complexity of the algorithm and validate its effectiveness
through a series of empirical evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Example Safety Case for Safeguards Against Misuse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18003v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18003v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Clymer, Jonah Weinbaum, Robert Kirk, Kimberly Mai, Selena Zhang, Xander Davies
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing evaluations of AI misuse safeguards provide a patchwork of evidence
that is often difficult to connect to real-world decisions. To bridge this gap,
we describe an end-to-end argument (a "safety case") that misuse safeguards
reduce the risk posed by an AI assistant to low levels. We first describe how a
hypothetical developer red teams safeguards, estimating the effort required to
evade them. Then, the developer plugs this estimate into a quantitative "uplift
model" to determine how much barriers introduced by safeguards dissuade misuse
(https://www.aimisusemodel.com/). This procedure provides a continuous signal
of risk during deployment that helps the developer rapidly respond to emerging
threats. Finally, we describe how to tie these components together into a
simple safety case. Our work provides one concrete path -- though not the only
path -- to rigorously justifying AI misuse risks are low.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18002v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18002v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Jin, Jingyi Cao, Xiaobao Wang, Bingdao Feng, Dongxiao He, Longbiao Wang, Jianwu Dang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph anomaly detection aims to identify unusual patterns in graph-based
data, with wide applications in fields such as web security and financial fraud
detection. Existing methods typically rely on contrastive learning, assuming
that a lower similarity between a node and its local subgraph indicates
abnormality. However, these approaches overlook a crucial limitation: the
presence of interfering edges invalidates this assumption, since it introduces
disruptive noise that compromises the contrastive learning process.
Consequently, this limitation impairs the ability to effectively learn
meaningful representations of normal patterns, leading to suboptimal detection
performance. To address this issue, we propose a Clean-View Enhanced Graph
Anomaly Detection framework (CVGAD), which includes a multi-scale anomaly
awareness module to identify key sources of interference in the contrastive
learning process. Moreover, to mitigate bias from the one-step edge removal
process, we introduce a novel progressive purification module. This module
incrementally refines the graph by iteratively identifying and removing
interfering edges, thereby enhancing model performance. Extensive experiments
on five benchmark datasets validate the effectiveness of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Anytime-valid, Bayes-assisted,Prediction-Powered Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.18000v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.18000v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Valentin Kilian, Stefano Cortinovis, François Caron
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given a large pool of unlabelled data and a smaller amount of labels,
prediction-powered inference (PPI) leverages machine learning predictions to
increase the statistical efficiency of standard confidence interval procedures
based solely on labelled data, while preserving their fixed-time validity.
  In this paper, we extend the PPI framework to the sequential setting, where
labelled and unlabelled datasets grow over time.
  Exploiting Ville's inequality and the method of mixtures, we propose
prediction-powered confidence sequence procedures that are valid uniformly over
time and naturally accommodate prior knowledge on the quality of the
predictions to further boost efficiency.
  We carefully illustrate the design choices behind our method and demonstrate
its effectiveness in real and synthetic examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Feature Interactions from the Perspective of Quadratic Neural
  Networks for Click-through Rate Prediction <span class="chip">KDD'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honghao Li, Yiwen Zhang, Yi Zhang, Lei Sang, Jieming Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hadamard Product (HP) has long been a cornerstone in click-through rate (CTR)
prediction tasks due to its simplicity, effectiveness, and ability to capture
feature interactions without additional parameters. However, the underlying
reasons for its effectiveness remain unclear. In this paper, we revisit HP from
the perspective of Quadratic Neural Networks (QNN), which leverage quadratic
interaction terms to model complex feature relationships. We further reveal
QNN's ability to expand the feature space and provide smooth nonlinear
approximations without relying on activation functions. Meanwhile, we find that
traditional post-activation does not further improve the performance of the
QNN. Instead, mid-activation is a more suitable alternative. Through
theoretical analysis and empirical evaluation of 25 QNN neuron formats, we
identify a good-performing variant and make further enhancements on it.
Specifically, we propose the Multi-Head Khatri-Rao Product as a superior
alternative to HP and a Self-Ensemble Loss with dynamic ensemble capability
within the same network to enhance computational efficiency and performance.
Ultimately, we propose a novel neuron format, QNN-alpha, which is tailored for
CTR prediction tasks. Experimental results show that QNN-alpha achieves new
state-of-the-art performance on six public datasets while maintaining low
inference latency, good scalability, and excellent compatibility. The code,
running logs, and detailed hyperparameter configurations are available at:
https://github.com/salmon1802/QNN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD'25 accepted</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Analyzing and Understanding the Limitations of VAPO: A
  Theoretical Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Shao, Yiming Cheng, Hongyi Huang, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The VAPO framework has demonstrated significant empirical success in
enhancing the efficiency and reliability of reinforcement learning for long
chain-of-thought (CoT) reasoning tasks with large language models (LLMs). By
systematically addressing challenges such as value model bias, heterogeneous
sequence lengths, and sparse reward signals, VAPO achieves state-of-the-art
performance. While its practical benefits are evident, a deeper theoretical
understanding of its underlying mechanisms and potential limitations is crucial
for guiding future advancements. This paper aims to initiate such a discussion
by exploring VAPO from a theoretical perspective, highlighting areas where its
assumptions might be challenged and where further investigation could yield
more robust and generalizable reasoning agents. We delve into the intricacies
of value function approximation in complex reasoning spaces, the optimality of
adaptive advantage estimation, the impact of token-level optimization, and the
enduring challenges of exploration and generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Outcome-based Reinforcement Learning to Predict the Future 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17989v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17989v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Turtel, Danny Franklin, Kris Skotheim, Luke Hewitt, Philipp Schoenegger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning with verifiable rewards (RLVR) has boosted math and
coding in large language models, yet there has been little effort to extend
RLVR into messier, real-world domains like forecasting. One sticking point is
that outcome-based reinforcement learning for forecasting must learn from
binary, delayed, and noisy rewards, a regime where standard fine-tuning is
brittle. We show that outcome-only online RL on a 14B model can match
frontier-scale accuracy and surpass it in calibration and hypothetical
prediction market betting by adapting two leading algorithms, Group-Relative
Policy Optimisation (GRPO) and ReMax, to the forecasting setting. Our
adaptations remove per-question variance scaling in GRPO, apply
baseline-subtracted advantages in ReMax, hydrate training with 100k temporally
consistent synthetic questions, and introduce lightweight guard-rails that
penalise gibberish, non-English responses and missing rationales, enabling a
single stable pass over 110k events. Scaling ReMax to 110k questions and
ensembling seven predictions yields a 14B model that matches frontier baseline
o1 on accuracy on our holdout set (Brier = 0.193, p = 0.23) while beating it in
calibration (ECE = 0.042, p < 0.001). A simple trading rule turns this
calibration edge into \$127 of hypothetical profit versus \$92 for o1 (p =
0.037). This demonstrates that refined RLVR methods can convert small-scale
LLMs into potentially economically valuable forecasting tools, with
implications for scaling this to larger models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Revealing the Effectiveness of Small-Scale Fine-tuning in
  R1-style Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17988v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17988v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutong Chen, Jiandong Gao, Ji Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  R1-style Reinforcement Learning (RL) significantly enhances Large Language
Models' reasoning capabilities, yet the mechanism behind rule-based RL remains
unclear. We found that small-scale SFT has significant influence on RL but
shows poor efficiency. To explain our observations, we propose an analytical
framework and compare the efficiency of SFT and RL by measuring sample effect.
Hypothetical analysis show that SFT efficiency is limited by training data.
Guided by our analysis, we propose Re-distillation, a technique that fine-tunes
pretrain model through small-scale distillation from the RL-trained policy.
Experiments on Knight & Knave and MATH datasets demonstrate re-distillation's
surprising efficiency: re-distilled models match RL performance with far fewer
samples and less computation. Empirical verification shows that sample effect
is a good indicator of performance improvements. As a result, on K&K dataset,
our re-distilled Qwen2.5-1.5B model surpasses DeepSeek-V3-0324 with only 1K SFT
samples. On MATH, Qwen2.5-1.5B fine-tuned with re-distilled 500 samples matches
its instruct-tuned variant without RL. Our work explains several interesting
phenomena in R1-style RL, shedding light on the mechanisms behind its empirical
success. Code is available at: https://github.com/on1262/deep-reasoning
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 figs, 3 table, preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for
  Human Activity Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17987v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17987v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihang You, Hanqi Jiang, Zishuai Liu, Zihang Xie, Tianming Liu, Jin Lu, Fei Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real world collection of Activities of Daily Living data is challenging due
to privacy concerns, costly deployment and labeling, and the inherent sparsity
and imbalance of human behavior. We present ADLGen, a generative framework
specifically designed to synthesize realistic, event triggered, and symbolic
sensor sequences for ambient assistive environments. ADLGen integrates a
decoder only Transformer with sign based symbolic temporal encoding, and a
context and layout aware sampling mechanism to guide generation toward
semantically rich and physically plausible sensor event sequences. To enhance
semantic fidelity and correct structural inconsistencies, we further
incorporate a large language model into an automatic generate evaluate refine
loop, which verifies logical, behavioral, and temporal coherence and generates
correction rules without manual intervention or environment specific tuning.
Through comprehensive experiments with novel evaluation metrics, ADLGen is
shown to outperform baseline generators in statistical fidelity, semantic
richness, and downstream activity recognition, offering a scalable and
privacy-preserving solution for ADL data synthesis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher
  Approximation for Compressing Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17974v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17974v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viktoriia Chekalina, Daniil Moskovskiy, Daria Cherniuk, Maxim Kurkin, Andrey Kuznetsov, Evgeny Frolov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Fisher information is a fundamental concept for characterizing the
sensitivity of parameters in neural networks. However, leveraging the full
observed Fisher information is too expensive for large models, so most methods
rely on simple diagonal approximations. While efficient, this approach ignores
parameter correlations, often resulting in reduced performance on downstream
tasks. In this work, we mitigate these limitations and propose Generalized
Fisher-Weighted SVD (GFWSVD), a post-training LLM compression technique that
accounts for both diagonal and off-diagonal elements of the Fisher information
matrix, providing a more accurate reflection of parameter importance. To make
the method tractable, we introduce a scalable adaptation of the
Kronecker-factored approximation algorithm for the observed Fisher information.
We demonstrate the effectiveness of our method on LLM compression, showing
improvements over existing compression baselines. For example, at a 20
compression rate on the MMLU benchmark, our method outperforms FWSVD, which is
based on a diagonal approximation of the Fisher information, by 5 percent,
SVD-LLM by 3 percent, and ASVD by 6 percent compression rate.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ To Glue or Not to Glue? Classical vs Learned Image Matching for Mobile
  Mapping Cameras to Textured Semantic 3D Building Models <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simone Gaisbauer, Prabin Gyawali, Qilin Zhang, Olaf Wysocki, Boris Jutzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feature matching is a necessary step for many computer vision and
photogrammetry applications such as image registration, structure-from-motion,
and visual localization. Classical handcrafted methods such as SIFT feature
detection and description combined with nearest neighbour matching and RANSAC
outlier removal have been state-of-the-art for mobile mapping cameras. With
recent advances in deep learning, learnable methods have been introduced and
proven to have better robustness and performance under complex conditions.
Despite their growing adoption, a comprehensive comparison between classical
and learnable feature matching methods for the specific task of semantic 3D
building camera-to-model matching is still missing. This submission
systematically evaluates the effectiveness of different feature-matching
techniques in visual localization using textured CityGML LoD2 models. We use
standard benchmark datasets (HPatches, MegaDepth-1500) and custom datasets
consisting of facade textures and corresponding camera images (terrestrial and
drone). For the latter, we evaluate the achievable accuracy of the absolute
pose estimated using a Perspective-n-Point (PnP) algorithm, with geometric
ground truth derived from geo-referenced trajectory data. The results indicate
that the learnable feature matching methods vastly outperform traditional
approaches regarding accuracy and robustness on our challenging custom datasets
with zero to 12 RANSAC-inliers and zero to 0.16 area under the curve. We
believe that this work will foster the development of model-based visual
localization methods. Link to the code:
https://github.com/simBauer/To\_Glue\_or\_not\_to\_Glue
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to MMT, Xiamen, China; ISPRS Annals</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MR-EEGWaveNet: Multiresolutional EEGWaveNet for Seizure Detection from
  Long EEG Recordings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17972v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17972v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazi Mahmudul Hassan, Xuyang Zhao, Hidenori Sugano, Toshihisa Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feature engineering for generalized seizure detection models remains a
significant challenge. Recently proposed models show variable performance
depending on the training data and remain ineffective at accurately
distinguishing artifacts from seizure data. In this study, we propose a novel
end-to-end model, ''Multiresolutional EEGWaveNet (MR-EEGWaveNet),'' which
efficiently distinguishes seizure events from background electroencephalogram
(EEG) and artifacts/noise by capturing both temporal dependencies across
different time frames and spatial relationships between channels. The model has
three modules: convolution, feature extraction, and predictor. The convolution
module extracts features through depth-wise and spatio-temporal convolution.
The feature extraction module individually reduces the feature dimension
extracted from EEG segments and their sub-segments. Subsequently, the extracted
features are concatenated into a single vector for classification using a fully
connected classifier called the predictor module. In addition, an anomaly
score-based post-classification processing technique was introduced to reduce
the false-positive rates of the model. Experimental results were reported and
analyzed using different parameter settings and datasets (Siena (public) and
Juntendo (private)). The proposed MR-EEGWaveNet significantly outperformed the
conventional non-multiresolution approach, improving the F1 scores from 0.177
to 0.336 on Siena and 0.327 to 0.488 on Juntendo, with precision gains of 15.9%
and 20.62%, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Large Language Models Reliable AI Scientists? Assessing
  Reverse-Engineering of Black-Box Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17968v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17968v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Geng, Howard Chen, Dilip Arumugam, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Using AI to create autonomous researchers has the potential to accelerate
scientific discovery. A prerequisite for this vision is understanding how well
an AI model can identify the underlying structure of a black-box system from
its behavior. In this paper, we explore how well a large language model (LLM)
learns to identify a black-box function from passively observed versus actively
collected data. We investigate the reverse-engineering capabilities of LLMs
across three distinct types of black-box systems, each chosen to represent
different problem domains where future autonomous AI researchers may have
considerable impact: Program, Formal Language, and Math Equation. Through
extensive experiments, we show that LLMs fail to extract information from
observations, reaching a performance plateau that falls short of the ideal of
Bayesian inference. However, we demonstrate that prompting LLMs to not only
observe but also intervene -- actively querying the black-box with specific
inputs to observe the resulting output -- improves performance by allowing LLMs
to test edge cases and refine their beliefs. By providing the intervention data
from one LLM to another, we show that this improvement is partly a result of
engaging in the process of generating effective interventions, paralleling
results in the literature on human learning. Further analysis reveals that
engaging in intervention can help LLMs escape from two common failure modes:
overcomplication, where the LLM falsely assumes prior knowledge about the
black-box, and overlooking, where the LLM fails to incorporate observations.
These insights provide practical guidance for helping LLMs more effectively
reverse-engineer black-box systems, supporting their use in making new
discoveries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17967v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17967v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ionut-Vlad Modoranu, Mher Safaryan, Erik Schultheis, Dan Alistarh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank optimization has emerged as a promising direction in training large
language models (LLMs) to reduce the memory usage of adaptive optimizers by
constraining learning to a lower-dimensional space. Prior work typically
projects gradients of linear layers using approaches based on Singular Value
Decomposition (SVD). However, applying SVD-based procedures individually to
each layer in large models is computationally expensive and incurs additional
memory costs due to storing the projection matrices. In this work, we propose a
computationally efficient and conceptually simple two-step procedure to
approximate SVD-based gradient projections into lower-dimensional spaces.
First, we construct a complete orthogonal basis using predefined orthogonal
matrices of the Discrete Cosine Transform (DCT). Second, we adaptively select
basis columns based on their alignment with the gradient of each layer. Each
projection matrix in our method is obtained via a single matrix multiplication
followed by a lightweight sorting step to identify the most relevant basis
vectors. Due to the predefined nature of the orthogonal bases, they are
computed once at the start of training. During training, we store only the
indices of the selected columns, avoiding the need to store full projection
matrices for each layer. Our numerical experiments on both pre-training and
fine-tuning tasks demonstrate the effectiveness of our dual strategy in
approximating optimal low-rank projections, matching the performance of costly
SVD-based methods while achieving faster runtime and reduced memory usage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ New Tight Bounds for SGD without Variance Assumption: A Computer-Aided
  Lyapunov Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17965v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17965v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Cortild, Lucas Ketels, Juan Peypouquet, Guillaume Garrigos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The analysis of Stochastic Gradient Descent (SGD) often relies on making some
assumption on the variance of the stochastic gradients, which is usually not
satisfied or difficult to verify in practice. This paper contributes to a
recent line of works which attempt to provide guarantees without making any
variance assumption, leveraging only the (strong) convexity and smoothness of
the loss functions. In this context, we prove new theoretical bounds derived
from the monotonicity of a simple Lyapunov energy, improving the current
state-of-the-art and extending their validity to larger step-sizes. Our
theoretical analysis is backed by a Performance Estimation Problem analysis,
which allows us to claim that, empirically, the bias term in our bounds is
tight within our framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>57 pages, 10 figures. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Principled Bayesian Framework for Training Binary and Spiking Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James A. Walker, Moein Khajehnejad, Adeel Razi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a Bayesian framework for training binary and spiking neural
networks that achieves state-of-the-art performance without normalisation
layers. Unlike commonly used surrogate gradient methods -- often heuristic and
sensitive to hyperparameter choices -- our approach is grounded in a
probabilistic model of noisy binary networks, enabling fully end-to-end
gradient-based optimisation. We introduce importance-weighted straight-through
(IW-ST) estimators, a unified class generalising straight-through and
relaxation-based estimators. We characterise the bias-variance trade-off in
this family and derive a bias-minimising objective implemented via an auxiliary
loss. Building on this, we introduce Spiking Bayesian Neural Networks (SBNNs),
a variational inference framework that uses posterior noise to train Binary and
Spiking Neural Networks with IW-ST. This Bayesian approach minimises gradient
bias, regularises parameters, and introduces dropout-like noise. By linking
low-bias conditions, vanishing gradients, and the KL term, we enable training
of deep residual networks without normalisation. Experiments on CIFAR-10, DVS
Gesture, and SHD show our method matches or exceeds existing approaches without
normalisation or hand-tuned gradients.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Domain Gap: Measuring the Domain Gap Between Real-World and
  Synthetic Point Clouds for Automated Driving Development 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nguyen Duc, Yan-Ling Lai, Patrick Madlindl, Xinyuan Zhu, Benedikt Schwab, Olaf Wysocki, Ludwig Hoegner, Thomas H. Kolbe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Owing to the typical long-tail data distribution issues, simulating
domain-gap-free synthetic data is crucial in robotics, photogrammetry, and
computer vision research. The fundamental challenge pertains to credibly
measuring the difference between real and simulated data. Such a measure is
vital for safety-critical applications, such as automated driving, where
out-of-domain samples may impact a car's perception and cause fatal accidents.
Previous work has commonly focused on simulating data on one scene and
analyzing performance on a different, real-world scene, hampering the disjoint
analysis of domain gap coming from networks' deficiencies, class definitions,
and object representation. In this paper, we propose a novel approach to
measuring the domain gap between the real world sensor observations and
simulated data representing the same location, enabling comprehensive domain
gap analysis. To measure such a domain gap, we introduce a novel metric
DoGSS-PCL and evaluation assessing the geometric and semantic quality of the
simulated point cloud. Our experiments corroborate that the introduced approach
can be used to measure the domain gap. The tests also reveal that synthetic
semantic point clouds may be used for training deep neural networks,
maintaining the performance at the 50/50 real-to-synthetic ratio. We strongly
believe that this work will facilitate research on credible data simulation and
allow for at-scale deployment in automated driving testing and digital
twinning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to PFG Journal of Photogrammetry, Remote Sensing and
  Geoinformation Science</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized
  Quadratic Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17958v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17958v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vittorio Erba, Emanuele Troiani, Lenka Zdeborová, Florent Krzakala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the high-dimensional asymptotics of empirical risk minimization
(ERM) in over-parametrized two-layer neural networks with quadratic activations
trained on synthetic data. We derive sharp asymptotics for both training and
test errors by mapping the $\ell_2$-regularized learning problem to a convex
matrix sensing task with nuclear norm penalization. This reveals that capacity
control in such networks emerges from a low-rank structure in the learned
feature maps. Our results characterize the global minima of the loss and yield
precise generalization thresholds, showing how the width of the target function
governs learnability. This analysis bridges and extends ideas from spin-glass
methods, matrix factorization, and convex optimization and emphasizes the deep
link between low-rank matrix sensing and learning in quadratic neural networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VeriThinker: Learning to Verify Makes Reasoning Model Efficient 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17941v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17941v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zigeng Chen, Xinyin Ma, Gongfan Fang, Ruonan Yu, Xinchao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Reasoning Models (LRMs) excel at complex tasks using Chain-of-Thought
(CoT) reasoning. However, their tendency to overthinking leads to unnecessarily
lengthy reasoning chains, dramatically increasing inference costs. To mitigate
this issue, we introduce VeriThinker, a novel approach for CoT compression.
Unlike conventional methods that fine-tune LRMs directly on the original
reasoning task using synthetic concise CoT data, we innovatively fine-tune the
model solely through an auxiliary verification task. By training LRMs to
accurately verify the correctness of CoT solutions, the LRMs inherently become
more discerning about the necessity of subsequent self-reflection steps,
thereby effectively suppressing overthinking. Extensive experiments validate
that VeriThinker substantially reduces reasoning chain lengths while
maintaining or even slightly improving accuracy. When applied to
DeepSeek-R1-Distill-Qwen-7B, our approach reduces reasoning tokens on MATH500
from 3790 to 2125 while improving accuracy by 0.8% (94.0% to 94.8%), and on
AIME25, tokens decrease from 14321 to 10287 with a 2.1% accuracy gain (38.7% to
40.8%). Additionally, our experiments demonstrate that VeriThinker can also be
zero-shot generalized to speculative reasoning. Code is available at
https://github.com/czg1225/VeriThinker
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working in progress. Code Repo:
  https://github.com/czg1225/VeriThinker</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Directed Semi-Simplicial Learning with Applications to Brain Activity
  Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17939v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17939v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Lecha, Andrea Cavallo, Francesca Dominici, Ran Levi, Alessio Del Bue, Elvin Isufi, Pietro Morerio, Claudio Battiloro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) excel at learning from pairwise interactions but
often overlook multi-way and hierarchical relationships. Topological Deep
Learning (TDL) addresses this limitation by leveraging combinatorial
topological spaces. However, existing TDL models are restricted to undirected
settings and fail to capture the higher-order directed patterns prevalent in
many complex systems, e.g., brain networks, where such interactions are both
abundant and functionally significant. To fill this gap, we introduce
Semi-Simplicial Neural Networks (SSNs), a principled class of TDL models that
operate on semi-simplicial sets -- combinatorial structures that encode
directed higher-order motifs and their directional relationships. To enhance
scalability, we propose Routing-SSNs, which dynamically select the most
informative relations in a learnable manner. We prove that SSNs are strictly
more expressive than standard graph and TDL models. We then introduce a new
principled framework for brain dynamics representation learning, grounded in
the ability of SSNs to provably recover topological descriptors shown to
successfully characterize brain activity. Empirically, SSNs achieve
state-of-the-art performance on brain dynamics classification tasks,
outperforming the second-best model by up to 27%, and message passing GNNs by
up to 50% in accuracy. Our results highlight the potential of principled
topological models for learning from structured brain data, establishing a
unique real-world case study for TDL. We also test SSNs on standard node
classification and edge regression tasks, showing competitive performance. We
will make the code and data publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LMask: Learn to Solve Constrained Routing Problems with Lazy Masking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17938v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17938v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyou Li, Haijun Zou, Jiayuan Wu, Zaiwen Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Routing problems are canonical combinatorial optimization tasks with
wide-ranging applications in logistics, transportation, and supply chain
management. However, solving these problems becomes significantly more
challenging when complex constraints are involved. In this paper, we propose
LMask, a novel learning framework that utilizes dynamic masking to generate
high-quality feasible solutions for constrained routing problems. LMask
introduces the LazyMask decoding method, which lazily refines feasibility masks
with the backtracking mechanism. In addition, it employs the refinement
intensity embedding to encode the search trace into the model, mitigating
representation ambiguities induced by backtracking. To further reduce sampling
cost, LMask sets a backtracking budget during decoding, while constraint
violations are penalized in the loss function during training to counteract
infeasibility caused by this budget. We provide theoretical guarantees for the
validity and probabilistic optimality of our approach. Extensive experiments on
the traveling salesman problem with time windows (TSPTW) and TSP with draft
limits (TSPDL) demonstrate that LMask achieves state-of-the-art feasibility
rates and solution quality, outperforming existing neural methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Gated Neurons in <span class="highlight-title">Transformer</span>s from Their Input-Output
  Functionality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Gerstner, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interpretability researchers have attempted to understand MLP neurons of
language models based on both the contexts in which they activate and their
output weight vectors. They have paid little attention to a complementary
aspect: the interactions between input and output. For example, when neurons
detect a direction in the input, they might add much the same direction to the
residual stream ("enrichment neurons") or reduce its presence ("depletion
neurons"). We address this aspect by examining the cosine similarity between
input and output weights of a neuron. We apply our method to 12 models and find
that enrichment neurons dominate in early-middle layers whereas later layers
tend more towards depletion. To explain this finding, we argue that enrichment
neurons are largely responsible for enriching concept representations, one of
the first steps of factual recall. Our input-output perspective is a complement
to activation-dependent analyses and to approaches that treat input and output
separately.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Selection Mechanisms for Sequence Modeling using Linear State Space
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17932v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17932v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umberto Casti, Sandro Zampieri, Fabio Pasqualetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in language modeling tasks have been driven by
architectures such as Transformers and, more recently, by Selective State Space
Models (SSMs). In this paper, we introduce an alternative selection mechanism
inspired by control theory methodologies. Specifically, we propose a novel
residual generator for selection, drawing an analogy to fault detection
strategies in Linear Time-Invariant (LTI) systems. Unlike Mamba, which utilizes
Linear Time-Varying (LTV) systems, our approach combines multiple LTI systems,
preserving their beneficial properties during training while achieving
comparable selectivity. To evaluate the effectiveness of the proposed
architecture, we test its performance on synthetic tasks. While these tasks are
not inherently critical, they serve as benchmarks to test the selectivity
properties of different cores architecture. This work highlights the potential
of integrating theoretical insights with experimental advancements, offering a
complementary perspective to deep learning innovations at the intersection of
control theory and machine learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation
  of Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17931v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17931v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image segmentation is vital for clinical diagnosis, yet current deep
learning methods often demand extensive expert effort, i.e., either through
annotating large training datasets or providing prompts at inference time for
each new case. This paper introduces a zero-shot and automatic segmentation
pipeline that combines off-the-shelf vision-language and segmentation
foundation models. Given a medical image and a task definition (e.g., "segment
the optic disc in an eye fundus image"), our method uses a grounding model to
generate an initial bounding box, followed by a visual prompt boosting module
that enhance the prompts, which are then processed by a promptable segmentation
model to produce the final mask. To address the challenges of domain gap and
result verification, we introduce a test-time adaptation framework featuring a
set of learnable adaptors that align the medical inputs with foundation model
representations. Its hyperparameters are optimized via Bayesian Optimization,
guided by a proxy validation model without requiring ground-truth labels. Our
pipeline offers an annotation-efficient and scalable solution for zero-shot
medical image segmentation across diverse tasks. Our pipeline is evaluated on
seven diverse medical imaging datasets and shows promising results. By proper
decomposition and test-time adaptation, our fully automatic pipeline performs
competitively with weakly-prompted interactive foundation models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predicting Length of Stay in Neurological ICU Patients Using Classical
  Machine Learning and Neural Network Models: A Benchmark Study on MIMIC-IV 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17929v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17929v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Gabitashvili, Philipp Kellmeyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intensive care unit (ICU) is a crucial hospital department that handles
life-threatening cases. Nowadays machine learning (ML) is being leveraged in
healthcare ubiquitously. In recent years, management of ICU became one of the
most significant parts of the hospital functionality (largely but not only due
to the worldwide COVID-19 pandemic). This study explores multiple ML approaches
for predicting LOS in ICU specifically for the patients with neurological
diseases based on the MIMIC-IV dataset. The evaluated models include classic ML
algorithms (K-Nearest Neighbors, Random Forest, XGBoost and CatBoost) and
Neural Networks (LSTM, BERT and Temporal Fusion Transformer). Given that LOS
prediction is often framed as a classification task, this study categorizes LOS
into three groups: less than two days, less than a week, and a week or more. As
the first ML-based approach targeting LOS prediction for neurological disorder
patients, this study does not aim to outperform existing methods but rather to
assess their effectiveness in this specific context. The findings provide
insights into the applicability of ML techniques for improving ICU resource
management and patient care. According to the results, Random Forest model
proved to outperform others on static, achieving an accuracy of 0.68, a
precision of 0.68, a recall of 0.68, and F1-score of 0.67. While BERT model
outperformed LSTM model on time-series data with an accuracy of 0.80, a
precision of 0.80, a recall of 0.80 and F1-score 0.80.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Practical Defect-Focused Automated Code <span class="highlight-title">Review</span> <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyi Lu, Lili Jiang, Xiaojia Li, Jianbing Fang, Fengjun Zhang, Li Yang, Chun Zuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The complexity of code reviews has driven efforts to automate review
comments, but prior approaches oversimplify this task by treating it as
snippet-level code-to-text generation and relying on text similarity metrics
like BLEU for evaluation. These methods overlook repository context, real-world
merge request evaluation, and defect detection, limiting their practicality. To
address these issues, we explore the full automation pipeline within the online
recommendation service of a company with nearly 400 million daily active users,
analyzing industry-grade C++ codebases comprising hundreds of thousands of
lines of code. We identify four key challenges: 1) capturing relevant context,
2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and
4) integrating human workflows. To tackle these, we propose 1) code slicing
algorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a
filtering mechanism for FAR reduction, and 4) a novel prompt design for better
human interaction. Our approach, validated on real-world merge requests from
historical fault reports, achieves a 2x improvement over standard LLMs and a
10x gain over previous baselines. While the presented results focus on C++, the
underlying framework design leverages language-agnostic principles (e.g.,
AST-based analysis), suggesting potential for broader applicability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Forty-Second International Conference on Machine Learning
  (ICML 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of Few-Shot Learning Methods for Kidney Stone Type
  Recognition in Ureteroscopy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17921v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17921v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carlos Salazar-Ruiz, Francisco Lopez-Tiro, Ivan Reyes-Amezcua, Clement Larose, Gilberto Ochoa-Ruiz, Christian Daul
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the type of kidney stones is crucial for prescribing appropriate
treatments to prevent recurrence. Currently, various approaches exist to
identify the type of kidney stones. However, obtaining results through the
reference ex vivo identification procedure can take several weeks, while in
vivo visual recognition requires highly trained specialists. For this reason,
deep learning models have been developed to provide urologists with an
automated classification of kidney stones during ureteroscopies. Nevertheless,
a common issue with these models is the lack of training data. This
contribution presents a deep learning method based on few-shot learning, aimed
at producing sufficiently discriminative features for identifying kidney stone
types in endoscopic images, even with a very limited number of samples. This
approach was specifically designed for scenarios where endoscopic images are
scarce or where uncommon classes are present, enabling classification even with
a limited training dataset. The results demonstrate that Prototypical Networks,
using up to 25% of the training data, can achieve performance equal to or
better than traditional deep learning models trained with the complete dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, 3 tables, conference, cbms25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KITINet: Kinetics Theory Inspired Network Architectures with PDE
  Simulation Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17919v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17919v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingquan Feng, Yifan Fu, Tongcheng Zhang, Yu Jiang, Yixin Huang, Junchi Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the widely recognized success of residual connections in modern
neural networks, their design principles remain largely heuristic. This paper
introduces KITINet (Kinetics Theory Inspired Network), a novel architecture
that reinterprets feature propagation through the lens of non-equilibrium
particle dynamics and partial differential equation (PDE) simulation. At its
core, we propose a residual module that models feature updates as the
stochastic evolution of a particle system, numerically simulated via a
discretized solver for the Boltzmann transport equation (BTE). This formulation
mimics particle collisions and energy exchange, enabling adaptive feature
refinement via physics-informed interactions. Additionally, we reveal that this
mechanism induces network parameter condensation during training, where
parameters progressively concentrate into a sparse subset of dominant channels.
Experiments on scientific computation (PDE operator), image classification
(CIFAR-10/100), and text classification (IMDb/SNLI) show consistent
improvements over classic network baselines, with negligible increase of FLOPs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM Meeting Decision Trees on Tabular Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17918v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17918v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hangting Ye, Jinmeng Li, He Zhao, Dandan Guo, Yi Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular data have been playing a vital role in diverse real-world fields,
including healthcare, finance, etc. With the recent success of Large Language
Models (LLMs), early explorations of extending LLMs to the domain of tabular
data have been developed. Most of these LLM-based methods typically first
serialize tabular data into natural language descriptions, and then tune LLMs
or directly infer on these serialized data. However, these methods suffer from
two key inherent issues: (i) data perspective: existing data serialization
methods lack universal applicability for structured tabular data, and may pose
privacy risks through direct textual exposure, and (ii) model perspective: LLM
fine-tuning methods struggle with tabular data, and in-context learning
scalability is bottle-necked by input length constraints (suitable for few-shot
learning). This work explores a novel direction of integrating LLMs into
tabular data throughough logical decision tree rules as intermediaries,
proposes a decision tree enhancer with LLM-derived rule for tabular prediction,
DeLTa. The proposed DeLTa avoids tabular data serialization, and can be applied
to full data learning setting without LLM fine-tuning. Specifically, we
leverage the reasoning ability of LLMs to redesign an improved rule given a set
of decision tree rules. Furthermore, we provide a calibration method for
original decision trees via new generated rule by LLM, which approximates the
error correction vector to steer the original decision tree predictions in the
direction of ``errors'' reducing. Finally, extensive experiments on diverse
tabular benchmarks show that our method achieves state-of-the-art performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ M-learner:A Flexible And Powerful Framework To Study Heterogeneous
  Treatment Effect In Mediation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17917v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17917v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Li, Qing Liu, Tony Jiang, Hong Amy Xia, Brian P. Hobbs, Peng Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel method, termed the M-learner, for estimating heterogeneous
indirect and total treatment effects and identifying relevant subgroups within
a mediation framework. The procedure comprises four key steps. First, we
compute individual-level conditional average indirect/total treatment effect
Second, we construct a distance matrix based on pairwise differences. Third, we
apply tSNE to project this matrix into a low-dimensional Euclidean space,
followed by K-means clustering to identify subgroup structures. Finally, we
calibrate and refine the clusters using a threshold-based procedure to
determine the optimal configuration. To the best of our knowledge, this is the
first approach specifically designed to capture treatment effect heterogeneity
in the presence of mediation. Experimental results validate the robustness and
effectiveness of the proposed framework. Application to the real-world Jobs II
dataset highlights the broad adaptability and potential applicability of our
method.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flexible MOF Generation with Torsion-Aware Flow Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17914v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17914v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nayoung Kim, Seongsu Kim, Sungsoo Ahn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing metal-organic frameworks (MOFs) with novel chemistries is a
long-standing challenge due to their large combinatorial space and the complex
3D arrangements of building blocks. While recent deep generative models have
enabled scalable MOF generation, they assume (1) a fixed set of building blocks
and (2) known ground-truth local block-wise 3D coordinates. However, this
limits their ability to (1) design novel MOFs and (2) generate the structure
using novel building blocks. We propose a two-stage de novo MOF generation
framework that overcomes these limitations by modeling both chemical and
geometric degrees of freedom. First, we train a SMILES-based autoregressive
model to generate novel metal and organic building blocks, paired with
cheminformatics for 3D structure initialization. Second, we introduce a
flow-matching model that predicts translations, rotations, and torsional angles
to assemble flexible blocks into valid 3D frameworks. Our experiments
demonstrate improved reconstruction accuracy, the generation of valid, novel,
and unique MOFs, and the ability of our model to create novel building blocks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NeuroTrails: Training with Dynamic Sparse Heads as the Key to Effective
  Ensembling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17909v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17909v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bram Grooten, Farid Hasanov, Chenxiang Zhang, Qiao Xiao, Boqian Wu, Zahra Atashgahi, Ghada Sokar, Shiwei Liu, Lu Yin, Elena Mocanu, Mykola Pechenizkiy, Decebal Constantin Mocanu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model ensembles have long been a cornerstone for improving generalization and
robustness in deep learning. However, their effectiveness often comes at the
cost of substantial computational overhead. To address this issue,
state-of-the-art methods aim to replicate ensemble-class performance without
requiring multiple independently trained networks. Unfortunately, these
algorithms often still demand considerable compute at inference. In response to
these limitations, we introduce $\textbf{NeuroTrails}$, a sparse multi-head
architecture with dynamically evolving topology. This unexplored model-agnostic
training paradigm improves ensemble performance while reducing the required
resources. We analyze the underlying reason for its effectiveness and observe
that the various neural trails induced by dynamic sparsity attain a
$\textit{Goldilocks zone}$ of prediction diversity. NeuroTrails displays
efficacy with convolutional and transformer-based architectures on computer
vision and language tasks. Experiments on ResNet-50/ImageNet, LLaMA-350M/C4,
among many others, demonstrate increased accuracy and stronger robustness in
zero-shot generalization, while requiring significantly fewer parameters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our open-source code is available at
  https://github.com/bramgrooten/neurotrails</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Function Forms of Simple ReLU Networks with Random Hidden Weights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17907v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17907v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ka Long Keith Ho, Yoshinari Takeishi, Junichi Takeuchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the function space dynamics of a two-layer ReLU neural network
in the infinite-width limit, highlighting the Fisher information matrix (FIM)'s
role in steering learning. Extending seminal works on approximate
eigendecomposition of the FIM, we derive the asymptotic behavior of basis
functions ($f_v(x) = X^{\top} v $) for four groups of approximate eigenvectors,
showing their convergence to distinct function forms. These functions,
prioritized by gradient descent, exhibit FIM-induced inner products that
approximate orthogonality in the function space, forging a novel connection
between parameter and function spaces. Simulations validate the accuracy of
these theoretical approximations, confirming their practical relevance. By
refining the function space inner product's role, we advance the theoretical
framework for ReLU networks, illuminating their optimization and expressivity.
Overall, this work offers a robust foundation for understanding wide neural
networks and enhances insights into scalable deep learning architectures,
paving the way for improved design and analysis of neural networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 1 figure, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evolving Machine Learning: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17902v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17902v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ignacio Cabrera Martin, Subhaditya Mukherjee, Almas Baimagambetov, Joaquin Vanschoren, Nikolaos Polatidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In an era defined by rapid data evolution, traditional machine learning (ML)
models often fall short in adapting to dynamic environments. Evolving Machine
Learning (EML) has emerged as a critical paradigm, enabling continuous learning
and adaptation in real-time data streams. This survey presents a comprehensive
analysis of EML, focusing on five core challenges: data drift, concept drift,
catastrophic forgetting, skewed learning, and network adaptation. We
systematically review over 120 studies, categorizing state-of-the-art methods
across supervised, unsupervised, and semi-supervised approaches. The survey
explores diverse evaluation metrics, benchmark datasets, and real-world
applications, offering a comparative lens on the effectiveness and limitations
of current techniques. Additionally, we highlight the growing role of adaptive
neural architectures, meta-learning, and ensemble strategies in addressing
evolving data complexities. By synthesizing insights from recent literature,
this work not only maps the current landscape of EML but also identifies
critical gaps and opportunities for future research. Our findings aim to guide
researchers and practitioners in developing robust, ethical, and scalable EML
systems for real-world deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Universal Domain Adaptation Benchmark for Time Series Data
  Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17899v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17899v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Romain Mussard, Fannia Pacheco, Maxime Berar, Gilles Gasso, Paul Honeine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models have significantly improved the ability to detect
novelties in time series (TS) data. This success is attributed to their strong
representation capabilities. However, due to the inherent variability in TS
data, these models often struggle with generalization and robustness. To
address this, a common approach is to perform Unsupervised Domain Adaptation,
particularly Universal Domain Adaptation (UniDA), to handle domain shifts and
emerging novel classes. While extensively studied in computer vision, UniDA
remains underexplored for TS data. This work provides a comprehensive
implementation and comparison of state-of-the-art TS backbones in a UniDA
framework. We propose a reliable protocol to evaluate their robustness and
generalization across different domains. The goal is to provide practitioners
with a framework that can be easily extended to incorporate future advancements
in UniDA and TS architectures. Our results highlight the critical influence of
backbone selection in UniDA performance and enable a robustness analysis across
various datasets and architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DataRater: Meta-Learned <span class="highlight-title">Dataset</span> Curation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17895v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17895v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dan A. Calian, Gregory Farquhar, Iurii Kemaev, Luisa M. Zintgraf, Matteo Hessel, Jeremy Shar, Junhyuk Oh, András György, Tom Schaul, Jeffrey Dean, Hado van Hasselt, David Silver
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The quality of foundation models depends heavily on their training data.
Consequently, great efforts have been put into dataset curation. Yet most
approaches rely on manual tuning of coarse-grained mixtures of large buckets of
data, or filtering by hand-crafted heuristics. An approach that is ultimately
more scalable (let alone more satisfying) is to \emph{learn} which data is
actually valuable for training. This type of meta-learning could allow more
sophisticated, fine-grained, and effective curation. Our proposed
\emph{DataRater} is an instance of this idea. It estimates the value of
training on any particular data point. This is done by meta-learning using
`meta-gradients', with the objective of improving training efficiency on held
out data. In extensive experiments across a range of model scales and datasets,
we find that using our DataRater to filter data is highly effective, resulting
in significantly improved compute efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FastCAV: Efficient Computation of Concept Activation Vectors for
  Explaining Deep Neural Networks <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17883v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17883v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Laines Schmalwasser, Niklas Penzel, Joachim Denzler, Julia Niebling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concepts such as objects, patterns, and shapes are how humans understand the
world. Building on this intuition, concept-based explainability methods aim to
study representations learned by deep neural networks in relation to
human-understandable concepts. Here, Concept Activation Vectors (CAVs) are an
important tool and can identify whether a model learned a concept or not.
However, the computational cost and time requirements of existing CAV
computation pose a significant challenge, particularly in large-scale,
high-dimensional architectures. To address this limitation, we introduce
FastCAV, a novel approach that accelerates the extraction of CAVs by up to
63.6x (on average 46.4x). We provide a theoretical foundation for our approach
and give concrete assumptions under which it is equivalent to established
SVM-based methods. Our empirical results demonstrate that CAVs calculated with
FastCAV maintain similar performance while being more efficient and stable. In
downstream applications, i.e., concept-based explanation methods, we show that
FastCAV can act as a replacement leading to equivalent insights. Hence, our
approach enables previously infeasible investigations of deep models, which we
demonstrate by tracking the evolution of concepts during model training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2025, 27 pages, 20 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyperspectral Anomaly Detection Fused Unified Nonconvex Tensor Ring
  Factors Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17881v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17881v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenjin Qin, Hailin Wang, Hao Shu, Feng Zhang, Jianjun Wang, Xiangyong Cao, Xi-Le Zhao, Gemine Vivone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, tensor decomposition-based approaches for hyperspectral
anomaly detection (HAD) have gained significant attention in the field of
remote sensing. However, existing methods often fail to fully leverage both the
global correlations and local smoothness of the background components in
hyperspectral images (HSIs), which exist in both the spectral and spatial
domains. This limitation results in suboptimal detection performance. To
mitigate this critical issue, we put forward a novel HAD method named
HAD-EUNTRFR, which incorporates an enhanced unified nonconvex tensor ring (TR)
factors regularization. In the HAD-EUNTRFR framework, the raw HSIs are first
decomposed into background and anomaly components. The TR decomposition is then
employed to capture the spatial-spectral correlations within the background
component. Additionally, we introduce a unified and efficient nonconvex
regularizer, induced by tensor singular value decomposition (TSVD), to
simultaneously encode the low-rankness and sparsity of the 3-D gradient TR
factors into a unique concise form. The above characterization scheme enables
the interpretable gradient TR factors to inherit the low-rankness and
smoothness of the original background. To further enhance anomaly detection, we
design a generalized nonconvex regularization term to exploit the group
sparsity of the anomaly component. To solve the resulting doubly nonconvex
model, we develop a highly efficient optimization algorithm based on the
alternating direction method of multipliers (ADMM) framework. Experimental
results on several benchmark datasets demonstrate that our proposed method
outperforms existing state-of-the-art (SOTA) approaches in terms of detection
accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toward Optimal ANC: Establishing Mutual Information Lower Bound 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        François Derrida, Shahar Lutati, Eliya Nachmani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Active Noise Cancellation (ANC) algorithms aim to suppress unwanted acoustic
disturbances by generating anti-noise signals that destructively interfere with
the original noise in real time. Although recent deep learning-based ANC
algorithms have set new performance benchmarks, there remains a shortage of
theoretical limits to rigorously assess their improvements. To address this, we
derive a unified lower bound on cancellation performance composed of two
components. The first component is information-theoretic: it links residual
error power to the fraction of disturbance entropy captured by the anti-noise
signal, thereby quantifying limits imposed by information-processing capacity.
The second component is support-based: it measures the irreducible error
arising in frequency bands that the cancellation path cannot address,
reflecting fundamental physical constraints. By taking the maximum of these two
terms, our bound establishes a theoretical ceiling on the Normalized Mean
Squared Error (NMSE) attainable by any ANC algorithm. We validate its tightness
empirically on the NOISEX dataset under varying reverberation times,
demonstrating robustness across diverse acoustic conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-Supervised Multi-Label Feature Selection with Consistent Sparse
  Graph Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Zhong, Xingyu Wu, Xinping Zhao, Li Zhang, Xinyuan Song, Lei Shi, Bingbing Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In practical domains, high-dimensional data are usually associated with
diverse semantic labels, whereas traditional feature selection methods are
designed for single-label data. Moreover, existing multi-label methods
encounter two main challenges in semi-supervised scenarios: (1). Most
semi-supervised methods fail to evaluate the label correlations without enough
labeled samples, which are the critical information of multi-label feature
selection, making label-specific features discarded. (2). The similarity graph
structure directly derived from the original feature space is suboptimal for
multi-label problems in existing graph-based methods, leading to unreliable
soft labels and degraded feature selection performance. To overcome them, we
propose a consistent sparse graph learning method for multi-label
semi-supervised feature selection (SGMFS), which can enhance the feature
selection performance by maintaining space consistency and learning label
correlations in semi-supervised scenarios. Specifically, for Challenge (1),
SGMFS learns a low-dimensional and independent label subspace from the
projected features, which can compatibly cross multiple labels and effectively
achieve the label correlations. For Challenge (2), instead of constructing a
fixed similarity graph for semi-supervised learning, SGMFS thoroughly explores
the intrinsic structure of the data by performing sparse reconstruction of
samples in both the label space and the learned subspace simultaneously. In
this way, the similarity graph can be adaptively learned to maintain the
consistency between label space and the learned subspace, which can promote
propagating proper soft labels for unlabeled samples, facilitating the ultimate
feature selection. An effective solution with fast convergence is designed to
optimize the objective function. Extensive experiments validate the superiority
of SGMFS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mixture of Low Rank Adaptation with Partial Parameter Sharing for Time
  Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Licheng Pan, Zhichao Chen, Haoxuan Li, Guangyi Liu, Zhijian Xu, Zhaoran Liu, Hao Wang, Ying Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-task forecasting has become the standard approach for time-series
forecasting (TSF). However, we show that it suffers from an Expressiveness
Bottleneck, where predictions at different time steps share the same
representation, leading to unavoidable errors even with optimal
representations. To address this issue, we propose a two-stage framework:
first, pre-train a foundation model for one-step-ahead prediction; then, adapt
it using step-specific LoRA modules.This design enables the foundation model to
handle any number of forecast steps while avoiding the expressiveness
bottleneck. We further introduce the Mixture-of-LoRA (MoLA) model, which
employs adaptively weighted LoRA experts to achieve partial parameter sharing
across steps. This approach enhances both efficiency and forecasting
performance by exploiting interdependencies between forecast steps. Experiments
show that MoLA significantly improves model expressiveness and outperforms
state-of-the-art time-series forecasting methods. Code is available at
https://anonymous.4open.science/r/MoLA-BC92.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting
  Models <span class="chip">KDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17871v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17871v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zezhi Shao, Yujie Li, Fei Wang, Chengqing Yu, Yisong Fu, Tangwen Qian, Bin Xu, Boyu Diao, Yongjun Xu, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of universal time series forecasting models has revolutionized
zero-shot forecasting across diverse domains, yet the critical role of data
diversity in training these models remains underexplored. Existing large-scale
time series datasets often suffer from inherent biases and imbalanced
distributions, leading to suboptimal model performance and generalization. To
address this gap, we introduce BLAST, a novel pre-training corpus designed to
enhance data diversity through a balanced sampling strategy. First, BLAST
incorporates 321 billion observations from publicly available datasets and
employs a comprehensive suite of statistical metrics to characterize time
series patterns. Then, to facilitate pattern-oriented sampling, the data is
implicitly clustered using grid-based partitioning. Furthermore, by integrating
grid sampling and grid mixup techniques, BLAST ensures a balanced and
representative coverage of diverse patterns. Experimental results demonstrate
that models pre-trained on BLAST achieve state-of-the-art performance with a
fraction of the computational resources and training tokens required by
existing methods. Our findings highlight the pivotal role of data diversity in
improving both training efficiency and model performance for the universal
forecasting task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGKDD 2025 (Research Track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Best Group Identification in Multi-Objective Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17869v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17869v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Shahverdikondori, Mohammad Reza Badri, Negar Kiyavash
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Best Group Identification problem in a multi-objective
multi-armed bandit setting, where an agent interacts with groups of arms with
vector-valued rewards. The performance of a group is determined by an
efficiency vector which represents the group's best attainable rewards across
different dimensions. The objective is to identify the set of optimal groups in
the fixed-confidence setting. We investigate two key formulations: group Pareto
set identification, where efficiency vectors of optimal groups are Pareto
optimal and linear best group identification, where each reward dimension has a
known weight and the optimal group maximizes the weighted sum of its efficiency
vector's entries. For both settings, we propose elimination-based algorithms,
establish upper bounds on their sample complexity, and derive lower bounds that
apply to any correct algorithm. Through numerical experiments, we demonstrate
the strong empirical performance of the proposed algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpectraLDS: Provable Distillation for Linear Dynamical Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17868v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17868v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Devan Shah, Shlomo Fortgang, Sofiia Druchyna, Elad Hazan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the first provable method for identifying symmetric linear
dynamical systems (LDS) with accuracy guarantees that are independent of the
systems' state dimension or effective memory. Our approach builds upon recent
work that represents symmetric LDSs as convolutions learnable via fixed
spectral transformations. We show how to invert this representation, thereby
recovering an LDS model from its spectral transform and yielding an end-to-end
convex optimization procedure. This distillation preserves predictive accuracy
while enabling constant-time and constant-space inference per token,
independent of sequence length. We evaluate our method, SpectraLDS, as a
component in sequence prediction architectures and demonstrate that accuracy is
preserved while inference efficiency is improved on tasks such as language
modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17866v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17866v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongshu Guo, Zeyuan Ma, Yining Ma, Xinglin Zhang, Wei-Neng Chen, Yue-Jiao Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing effective black-box optimizers is hampered by limited
problem-specific knowledge and manual control that spans months for almost
every detail. In this paper, we present DesignX, the first automated algorithm
design framework that generates an effective optimizer specific to a given
black-box optimization problem within seconds. Rooted in the first principles,
we identify two key sub-tasks: 1) algorithm structure generation and 2)
hyperparameter control. To enable systematic construction, a comprehensive
modular algorithmic space is first built, embracing hundreds of algorithm
components collected from decades of research. We then introduce a dual-agent
reinforcement learning system that collaborates on structural and parametric
design through a novel cooperative training objective, enabling large-scale
meta-training across 10k diverse instances. Remarkably, through days of
autonomous learning, the DesignX-generated optimizers continuously surpass
human-crafted optimizers by orders of magnitude, either on synthetic testbed or
on realistic optimization scenarios such as Protein-docking, AutoML and UAV
path planning. Further in-depth analysis reveals DesignX's capability to
discover non-trivial algorithm patterns beyond expert intuition, which,
conversely, provides valuable design insights for the optimization community.
We provide DesignX's inference code at https://github.com/MetaEvo/DesignX.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The emergence of sparse attention: impact of data distribution and
  benefits of repetition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17863v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17863v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolas Zucchet, Francesco d'Angelo, Andrew K. Lampinen, Stephanie C. Y. Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emergence is a fascinating property of large language models and neural
networks more broadly: as models scale and train for longer, they sometimes
develop new abilities in sudden ways. Despite initial studies, we still lack a
comprehensive understanding of how and when these abilities emerge. To address
this gap, we study the emergence over training of sparse attention, a critical
and frequently observed attention pattern in Transformers. By combining
theoretical analysis of a toy model with empirical observations on small
Transformers trained on a linear regression variant, we uncover the mechanics
driving sparse attention emergence and reveal that emergence timing follows
power laws based on task structure, architecture, and optimizer choice. We
additionally find that repetition can greatly speed up emergence. Finally, we
confirm these results on a well-studied in-context associative recall task. Our
findings provide a simple, theoretically grounded framework for understanding
how data distributions and model design influence the learning dynamics behind
one form of emergence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Person Interaction Generation from Two-Person Motion Priors <span class="chip">SIGGRAPH 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17860v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17860v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenning Xu, Shiyu Fan, Paul Henderson, Edmond S. L. Ho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating realistic human motion with high-level controls is a crucial task
for social understanding, robotics, and animation. With high-quality MOCAP data
becoming more available recently, a wide range of data-driven approaches have
been presented. However, modelling multi-person interactions still remains a
less explored area. In this paper, we present Graph-driven Interaction
Sampling, a method that can generate realistic and diverse multi-person
interactions by leveraging existing two-person motion diffusion models as
motion priors. Instead of training a new model specific to multi-person
interaction synthesis, our key insight is to spatially and temporally separate
complex multi-person interactions into a graph structure of two-person
interactions, which we name the Pairwise Interaction Graph. We thus decompose
the generation task into simultaneous single-person motion generation
conditioned on one other's motion. In addition, to reduce artifacts such as
interpenetrations of body parts in generated multi-person interactions, we
introduce two graph-dependent guidance terms into the diffusion sampling
scheme. Unlike previous work, our method can produce various high-quality
multi-person interactions without having repetitive individual motions.
Extensive experiments demonstrate that our approach consistently outperforms
existing methods in reducing artifacts when generating a wide range of
two-person and multi-person interactions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGGRAPH 2025 Conference Papers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable Valuation of Human Feedback through Provably Robust Model
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17859v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17859v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masahiro Fujisawa, Masaki Adachi, Michael A. Osborne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the importance of aligning language models with human preferences,
crowd-sourced human feedback is often noisy -- for example, preferring less
desirable responses -- posing a fundamental challenge to alignment. A truly
robust alignment objective should yield identical model parameters even under
severe label noise, a property known as redescending. We prove that no existing
alignment methods satisfy this property. To address this, we propose
H\"older-DPO, the first principled alignment loss with a provable redescending
property, enabling estimation of the clean data distribution from noisy
feedback. The aligned model estimates the likelihood of clean data, providing a
theoretically grounded metric for dataset valuation that identifies the
location and fraction of mislabels. This metric is gradient-free, enabling
scalable and automated human feedback valuation without costly manual
verification or clean validation dataset. H\"older-DPO achieves
state-of-the-art robust alignment performance while accurately detecting
mislabels in controlled datasets. Finally, we apply H\"older-DPO to widely used
alignment datasets, revealing substantial noise levels and demonstrating that
removing these mislabels significantly improves alignment performance across
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Weight Sharing for Bayesian Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17856v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17856v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moule Lin, Shuhao Guan, Weipeng Jing, Goetz Botterweck, Andrea Patane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While offering a principled framework for uncertainty quantification in deep
learning, the employment of Bayesian Neural Networks (BNNs) is still
constrained by their increased computational requirements and the convergence
difficulties when training very deep, state-of-the-art architectures. In this
work, we reinterpret weight-sharing quantization techniques from a stochastic
perspective in the context of training and inference with Bayesian Neural
Networks (BNNs). Specifically, we leverage 2D adaptive Gaussian distributions,
Wasserstein distance estimations, and alpha blending to encode the stochastic
behaviour of a BNN in a lower dimensional, soft Gaussian representation.
Through extensive empirical investigation, we demonstrate that our approach
significantly reduces the computational overhead inherent in Bayesian learning
by several orders of magnitude, enabling the efficient Bayesian training of
large-scale models, such as ResNet-101 and Vision Transformer (VIT). On various
computer vision benchmarks including CIFAR10, CIFAR100, and ImageNet1k. Our
approach compresses model parameters by approximately 50x and reduces model
size by 75, while achieving accuracy and uncertainty estimations comparable to
the state-of-the-art.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Out of the Shadows: Exploring a Latent Space for Neural Network
  Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Koller, Tobias Ladner, Matthias Althoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks are ubiquitous. However, they are often sensitive to small
input changes. Hence, to prevent unexpected behavior in safety-critical
applications, their formal verification -- a notoriously hard problem -- is
necessary. Many state-of-the-art verification algorithms use reachability
analysis or abstract interpretation to enclose the set of possible outputs of a
neural network. Often, the verification is inconclusive due to the conservatism
of the enclosure. To address this problem, we design a novel latent space for
formal verification that enables the transfer of output specifications to the
input space for an iterative specification-driven input refinement, i.e., we
iteratively reduce the set of possible inputs to only enclose the unsafe ones.
The latent space is constructed from a novel view of projection-based set
representations, e.g., zonotopes, which are commonly used in reachability
analysis of neural networks. A projection-based set representation is a
"shadow" of a higher-dimensional set -- a latent space -- that does not change
during a set propagation through a neural network. Hence, the input set and the
output enclosure are "shadows" of the same latent space that we can use to
transfer constraints. We present an efficient verification tool for neural
networks that uses our iterative refinement to significantly reduce the number
of subproblems in a branch-and-bound procedure. Using zonotopes as a set
representation, unlike many other state-of-the-art approaches, our approach can
be realized by only using matrix operations, which enables a significant
speed-up through efficient GPU acceleration. We demonstrate that our tool
achieves competitive performance, which would place it among the top-ranking
tools of the last neural network verification competition (VNN-COMP'24).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Recurrent Neural Networks to a Billion Parameters with
  Zero-Order Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17852v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17852v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francois Chaubard, Mykel Kochenderfer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  During inference, Recurrent Neural Networks (RNNs) scale constant in both
FLOPs and GPU memory with increasing context length, as they compress all prior
tokens into a fixed-size memory. In contrast, transformers scale linearly in
FLOPs and, at best, linearly in memory during generation, since they must
attend to all previous tokens explicitly. Despite this inference-time
advantage, training large RNNs on long contexts remains impractical because
standard optimization methods depend on Backpropagation Through Time (BPTT).
BPTT requires retention of all intermediate activations during the forward
pass, causing memory usage to scale linearly with both context length and model
size. In this paper, we show that Zero-Order Optimization (ZOO) methods such as
Random-vector Gradient Estimation (RGE) can successfully replace BPTT to train
RNNs with convergence rates that match, or exceed BPTT by up to 19 fold, while
using orders of magnitude less memory and cost, as the model remains in
inference mode throughout training. We further demonstrate that
Central-Difference RGE (CD-RGE) corresponds to optimizing a smoothed surrogate
loss, inherently regularizing training and improving generalization. Our method
matches or outperforms BPTT across three settings: (1) overfitting, (2)
transduction, and (3) language modeling. Across all tasks, with sufficient
perturbations, our models generalize as well as or better than those trained
with BPTT, often in fewer steps. Despite the need for more forward passes per
step, we can surpass BPTT wall-clock time per step using recent advancements
such as FlashRNN and distributed inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TransDF: Time-Series Forecasting Needs Transformed Label Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17847v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17847v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Wang, Licheng Pan, Zhichao Chen, Xu Chen, Qingyang Dai, Lei Wang, Haoxuan Li, Zhouchen Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training time-series forecasting models presents unique challenges in
designing effective learning objectives. Existing methods predominantly utilize
the temporal mean squared error, which faces two critical challenges: (1) label
autocorrelation, which leads to bias from the label sequence likelihood; (2)
excessive amount of tasks, which increases with the forecast horizon and
complicates optimization. To address these challenges, we propose
Transform-enhanced Direct Forecast (TransDF), which transforms the label
sequence into decorrelated components with discriminated significance. Models
are trained to align the most significant components, thereby effectively
mitigating label autocorrelation and reducing task amount. Extensive
experiments demonstrate that TransDF achieves state-of-the-art performance and
is compatible with various forecasting models. Code is available at
https://anonymous.4open.science/r/TransDF-88CF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Continuum <span class="highlight-title">Transformer</span>s Perform In-Context Learning by Operator Gradient
  Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17838v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17838v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhiti Mishra, Yash Patel, Ambuj Tewari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers robustly exhibit the ability to perform in-context learning,
whereby their predictive accuracy on a task can increase not by parameter
updates but merely with the placement of training samples in their context
windows. Recent works have shown that transformers achieve this by implementing
gradient descent in their forward passes. Such results, however, are restricted
to standard transformer architectures, which handle finite-dimensional inputs.
In the space of PDE surrogate modeling, a generalization of transformers to
handle infinite-dimensional function inputs, known as "continuum transformers,"
has been proposed and similarly observed to exhibit in-context learning.
Despite impressive empirical performance, such in-context learning has yet to
be theoretically characterized. We herein demonstrate that continuum
transformers perform in-context operator learning by performing gradient
descent in an operator RKHS. We demonstrate this using novel proof strategies
that leverage a generalized representer theorem for Hilbert spaces and gradient
flows over the space of functionals of a Hilbert space. We additionally show
the operator learned in context is the Bayes Optimal Predictor in the infinite
depth limit of the transformer. We then provide empirical validations of this
optimality result and demonstrate that the parameters under which such gradient
descent is performed are recovered through the continuum transformer training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Distributed Estimation: Extending Gossip Algorithms to Ranking
  and Trimmed Means 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17836v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17836v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Van Elst, Igor Colin, Stephan Clémençon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the problem of robust estimation in gossip algorithms
over arbitrary communication graphs. Gossip algorithms are fully decentralized,
relying only on local neighbor-to-neighbor communication, making them
well-suited for situations where communication is constrained. A fundamental
challenge in existing mean-based gossip algorithms is their vulnerability to
malicious or corrupted nodes. In this paper, we show that an outlier-robust
mean can be computed by globally estimating a robust statistic. More
specifically, we propose a novel gossip algorithm for rank estimation, referred
to as \textsc{GoRank}, and leverage it to design a gossip procedure dedicated
to trimmed mean estimation, coined \textsc{GoTrim}. In addition to a detailed
description of the proposed methods, a key contribution of our work is a
precise convergence analysis: we establish an $\mathcal{O}(1/t)$ rate for rank
estimation and an $\mathcal{O}(\log(t)/t)$ rate for trimmed mean estimation,
where by $t$ is meant the number of iterations. Moreover, we provide a
breakdown point analysis of \textsc{GoTrim}. We empirically validate our
theoretical results through experiments on diverse network topologies, data
distributions and contamination schemes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hybrid Mamba-<span class="highlight-title">Transformer</span> Decoder for Error-Correcting Codes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17834v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17834v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shy-el Cohen, Yoni Choukroun, Eliya Nachmani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel deep learning method for decoding error correction codes
based on the Mamba architecture, enhanced with Transformer layers. Our approach
proposes a hybrid decoder that leverages Mamba's efficient sequential modeling
while maintaining the global context capabilities of Transformers. To further
improve performance, we design a novel layer-wise masking strategy applied to
each Mamba layer, allowing selective attention to relevant code features at
different depths. Additionally, we introduce a progressive layer-wise loss,
supervising the network at intermediate stages and promoting robust feature
extraction throughout the decoding process. Comprehensive experiments across a
range of linear codes demonstrate that our method significantly outperforms
Transformer-only decoders and standard Mamba models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating Affect Mining Techniques for Annotation Sample Selection
  in the Creation of Finnish Affective Speech Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17833v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17833v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kalle Lahtinen, Einari Vaaras, Liisa Mustanoja, Okko Räsänen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Study of affect in speech requires suitable data, as emotional expression and
perception vary across languages. Until now, no corpus has existed for natural
expression of affect in spontaneous Finnish, existing data being acted or from
a very specific communicative setting. This paper presents the first such
corpus, created by annotating 12,000 utterances for emotional arousal and
valence, sampled from three large-scale Finnish speech corpora. To ensure
diverse affective expression, sample selection was conducted with an affect
mining approach combining acoustic, cross-linguistic speech emotion, and text
sentiment features. We compare this method to random sampling in terms of
annotation diversity, and conduct post-hoc analyses to identify sampling
choices that would have maximized the diversity. As an outcome, the work
introduces a spontaneous Finnish affective speech corpus and informs sampling
strategies for affective speech corpus creation in other languages or domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at Interspeech 2025, Rotterdam, The
  Netherlands</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Imagine Beyond! Distributionally Robust Auto-Encoding for State Space
  Coverage in Online Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17830v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17830v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolas Castanet, Olivier Sigaud, Sylvain Lamprier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomously
acquire diverse behaviors, but faces major challenges in visual environments
due to high-dimensional, semantically sparse observations. In the online
setting, where agents learn representations while exploring, the latent space
evolves with the agent's policy, to capture newly discovered areas of the
environment. However, without incentivization to maximize state coverage in the
representation, classical approaches based on auto-encoders may converge to
latent spaces that over-represent a restricted set of states frequently visited
by the agent. This is exacerbated in an intrinsic motivation setting, where the
agent uses the distribution encoded in the latent space to sample the goals it
learns to master. To address this issue, we propose to progressively enforce
distributional shifts towards a uniform distribution over the full state space,
to ensure a full coverage of skills that can be learned in the environment. We
introduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method that
combines the $\beta$-VAE framework with Distributionally Robust Optimization.
DRAG leverages an adversarial neural weighter of training states of the VAE, to
account for the mismatch between the current data distribution and unseen parts
of the environment. This allows the agent to construct semantically meaningful
latent spaces beyond its immediate experience. Our approach improves state
space coverage and downstream control performance on hard exploration
environments such as mazes and robotic control involving walls to bypass,
without pre-training nor prior environment knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement
  Fine-Tuning of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuchen Pan, Yanxi Chen, Yushuo Chen, Yuchang Sun, Daoyuan Chen, Wenhao Zhang, Yuexiang Xie, Yilun Huang, Yilei Zhang, Dawei Gao, Yaliang Li, Bolin Ding, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Trinity-RFT is a general-purpose, flexible and scalable framework designed
for reinforcement fine-tuning (RFT) of large language models. It is built with
a decoupled design, consisting of (1) an RFT-core that unifies and generalizes
synchronous/asynchronous, on-policy/off-policy, and online/offline modes of
RFT, (2) seamless integration for agent-environment interaction with high
efficiency and robustness, and (3) systematic data pipelines optimized for RFT.
Trinity-RFT can be easily adapted for diverse application scenarios, and serves
as a unified platform for exploring advanced reinforcement learning paradigms.
This technical report outlines the vision, features, design and implementations
of Trinity-RFT, accompanied by extensive examples demonstrating the utility and
user-friendliness of the proposed framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This technical report will be continuously updated as the codebase
  evolves. GitHub: https://github.com/modelscope/Trinity-RFT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Source Separation of Small Classical Ensembles: Challenges and
  Opportunities <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17823v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17823v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gerardo Roa-Dabike, Trevor J. Cox, Jon P. Barker, Michael A. Akeroyd, Scott Bannister, Bruno Fazenda, Jennifer Firth, Simone Graetzer, Alinka Greasley, Rebecca R. Vos, William M. Whitmer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Musical (MSS) source separation of western popular music using non-causal
deep learning can be very effective. In contrast, MSS for classical music is an
unsolved problem. Classical ensembles are harder to separate than popular music
because of issues such as the inherent greater variation in the music; the
sparsity of recordings with ground truth for supervised training; and greater
ambiguity between instruments. The Cadenza project has been exploring MSS for
classical music. This is being done so music can be remixed to improve
listening experiences for people with hearing loss. To enable the work, a new
database of synthesized woodwind ensembles was created to overcome instrumental
imbalances in the EnsembleSet. For the MSS, a set of ConvTasNet models was used
with each model being trained to extract a string or woodwind instrument.
ConvTasNet was chosen because it enabled both causal and non-causal approaches
to be tested. Non-causal approaches have dominated MSS work and are useful for
recorded music, but for live music or processing on hearing aids, causal signal
processing is needed. The MSS performance was evaluated on the two small
datasets (Bach10 and URMP) of real instrument recordings where the ground-truth
is available. The performances of the causal and non-causal systems were
similar. Comparing the average Signal-to-Distortion (SDR) of the synthesized
validation set (6.2 dB causal; 6.9 non-causal), to the real recorded evaluation
set (0.3 dB causal, 0.4 dB non-causal), shows that mismatch between synthesized
and recorded data is a problem. Future work needs to either gather more real
recordings that can be used for training, or to improve the realism and
diversity of the synthesized recordings to reduce the mismatch...
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures, 2 tables, submitted to WASSPA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantifying uncertainty in spectral clusterings: expectations for
  perturbed and incomplete data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17819v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17819v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jürgen Dölz, Jolanda Weygandt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spectral clustering is a popular unsupervised learning technique which is
able to partition unlabelled data into disjoint clusters of distinct shapes.
However, the data under consideration are often experimental data, implying
that the data is subject to measurement errors and measurements may even be
lost or invalid. These uncertainties in the corrupted input data induce
corresponding uncertainties in the resulting clusters, and the clusterings thus
become unreliable.
  Modelling the uncertainties as random processes, we discuss a mathematical
framework based on random set theory for the computational Monte Carlo
approximation of statistically expected clusterings in case of corrupted, i.e.,
perturbed, incomplete, and possibly even additional, data. We propose several
computationally accessible quantities of interest and analyze their consistency
in the infinite data point and infinite Monte Carlo sample limit. Numerical
experiments are provided to illustrate and compare the proposed quantities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VIBE: Vector Index Benchmark for Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17810v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17810v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias Jääsaari, Ville Hyvönen, Matteo Ceccarello, Teemu Roos, Martin Aumüller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximate nearest neighbor (ANN) search is a performance-critical component
of many machine learning pipelines. Rigorous benchmarking is essential for
evaluating the performance of vector indexes for ANN search. However, the
datasets of the existing benchmarks are no longer representative of the current
applications of ANN search. Hence, there is an urgent need for an up-to-date
set of benchmarks. To this end, we introduce Vector Index Benchmark for
Embeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE
contains a pipeline for creating benchmark datasets using dense embedding
models characteristic of modern applications, such as retrieval-augmented
generation (RAG). To replicate real-world workloads, we also include
out-of-distribution (OOD) datasets where the queries and the corpus are drawn
from different distributions. We use VIBE to conduct a comprehensive evaluation
of SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution
and 6 out-of-distribution datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyperparameter Optimization via Interacting with Probabilistic Circuits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17804v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17804v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonas Seng, Fabrizio Ventola, Zhongjie Yu, Kristian Kersting
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing interest in designing truly interactive hyperparameter
optimization (HPO) methods, to date, only a few allow to include human
feedback. Existing interactive Bayesian optimization (BO) methods incorporate
human beliefs by weighting the acquisition function with a user-defined prior
distribution. However, in light of the non-trivial inner optimization of the
acquisition function prevalent in BO, such weighting schemes do not always
accurately reflect given user beliefs. We introduce a novel BO approach
leveraging tractable probabilistic models named probabilistic circuits (PCs) as
a surrogate model. PCs encode a tractable joint distribution over the hybrid
hyperparameter space and evaluation scores. They enable exact conditional
inference and sampling. Based on conditional sampling, we construct a novel
selection policy that enables an acquisition function-free generation of
candidate points (thereby eliminating the need for an additional inner-loop
optimization) and ensures that user beliefs are reflected accurately in the
selection policy. We provide a theoretical analysis and an extensive empirical
evaluation, demonstrating that our method achieves state-of-the-art performance
in standard HPO and outperforms interactive BO baselines in interactive HPO.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Coreset Selection of Coreset Selection Literature: Introduction and
  Recent Advances 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17799v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17799v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian B. Moser, Arundhati S. Shanbhag, Stanislav Frolov, Federico Raue, Joachim Folz, Andreas Dengel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coreset selection targets the challenge of finding a small, representative
subset of a large dataset that preserves essential patterns for effective
machine learning. Although several surveys have examined data reduction
strategies before, most focus narrowly on either classical geometry-based
methods or active learning techniques. In contrast, this survey presents a more
comprehensive view by unifying three major lines of coreset research, namely,
training-free, training-oriented, and label-free approaches, into a single
taxonomy. We present subfields often overlooked by existing work, including
submodular formulations, bilevel optimization, and recent progress in
pseudo-labeling for unlabeled datasets. Additionally, we examine how pruning
strategies influence generalization and neural scaling laws, offering new
insights that are absent from prior reviews. Finally, we compare these methods
under varying computational, robustness, and performance demands and highlight
open challenges, such as robustness, outlier filtering, and adapting coreset
selection to foundation models, for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Latent Mode Decomposition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17797v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17797v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Morante, Naveed ur Rehman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Variational Latent Mode Decomposition (VLMD), a new algorithm
for extracting oscillatory modes and associated connectivity structures from
multivariate signals. VLMD addresses key limitations of existing Multivariate
Mode Decomposition (MMD) techniques -including high computational cost,
sensitivity to parameter choices, and weak modeling of interchannel
dependencies. Its improved performance is driven by a novel underlying model,
Latent Mode Decomposition (LMD), which blends sparse coding and mode
decomposition to represent multichannel signals as sparse linear combinations
of shared latent components composed of AM-FM oscillatory modes. This
formulation enables VLMD to operate in a lower-dimensional latent space,
enhancing robustness to noise, scalability, and interpretability. The algorithm
solves a constrained variational optimization problem that jointly enforces
reconstruction fidelity, sparsity, and frequency regularization. Experiments on
synthetic and real-world datasets demonstrate that VLMD outperforms
state-of-the-art MMD methods in accuracy, efficiency, and interpretability of
extracted structures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 9 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RECIPE-TKG: From Sparse History to Structured Reasoning for LLM-based
  Temporal Knowledge Graph Completion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17794v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17794v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ömer Faruk Akgül, Feiyu Zhu, Yuxin Yang, Rajgopal Kannan, Viktor Prasanna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal Knowledge Graphs (TKGs) represent dynamic facts as timestamped
relations between entities. TKG completion involves forecasting missing or
future links, requiring models to reason over time-evolving structure. While
LLMs show promise for this task, existing approaches often overemphasize
supervised fine-tuning and struggle particularly when historical evidence is
limited or missing. We introduce RECIPE-TKG, a lightweight and data-efficient
framework designed to improve accuracy and generalization in settings with
sparse historical context. It combines (1) rule-based multi-hop retrieval for
structurally diverse history, (2) contrastive fine-tuning of lightweight
adapters to encode relational semantics, and (3) test-time semantic filtering
to iteratively refine generations based on embedding similarity. Experiments on
four TKG benchmarks show that RECIPE-TKG outperforms previous LLM-based
approaches, achieving up to 30.6\% relative improvement in Hits@10. Moreover,
our proposed framework produces more semantically coherent predictions, even
for the samples with limited historical context.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Online Change Detection via Random Fourier Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17789v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17789v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Kalinke, Shakeel Gavioli-Akilagun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article studies the problem of online non-parametric change point
detection in multivariate data streams. We approach the problem through the
lens of kernel-based two-sample testing and introduce a sequential testing
procedure based on random Fourier features, running with logarithmic time
complexity per observation and with overall logarithmic space complexity. The
algorithm has two advantages compared to the state of the art. First, our
approach is genuinely online, and no access to training data known to be from
the pre-change distribution is necessary. Second, the algorithm does not
require the user to specify a window parameter over which local tests are to be
calculated. We prove strong theoretical guarantees on the algorithm's
performance, including information-theoretic bounds demonstrating that the
detection delay is optimal in the minimax sense. Numerical studies on real and
synthetic data show that our algorithm is competitive with respect to the state
of the art.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Doubly Robust Conformalized Survival Analysis with Right-Censored Data <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.09729v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.09729v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Sesia, Vladimir Svetnik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a conformal inference method for constructing lower prediction
bounds for survival times from right-censored data, extending recent approaches
designed for more restrictive type-I censoring scenarios. The proposed method
imputes unobserved censoring times using a machine learning model, and then
analyzes the imputed data using a survival model calibrated via weighted
conformal inference. This approach is theoretically supported by an asymptotic
double robustness property. Empirical studies on simulated and real data
demonstrate that our method leads to relatively informative predictive
inferences and is especially robust in challenging settings where the survival
model may be inaccurate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revision after ICML review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Finding the Underlying Viscoelastic Constitutive Equation via Universal
  Differential Equations and Differentiable Physics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.00556v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.00556v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias C. Rodrigues, Roney L. Thompson, Dário A. B. Oliveira, Roberto F. Ausas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research employs Universal Differential Equations (UDEs) alongside
differentiable physics to model viscoelastic fluids, merging conventional
differential equations, neural networks and numerical methods to reconstruct
missing terms in constitutive models. This study focuses on analyzing four
viscoelastic models: Upper Convected Maxwell (UCM), Johnson-Segalman, Giesekus,
and Exponential Phan-Thien-Tanner (ePTT), through the use of synthetic
datasets. The methodology was tested across different experimental conditions,
including oscillatory and startup flows. While the UDE framework effectively
predicts shear and normal stresses for most models, it demonstrates some
limitations when applied to the ePTT model. The findings underscore the
potential of UDEs in fluid mechanics while identifying critical areas for
methodological improvement. Also, a model distillation approach was employed to
extract simplified models from complex ones, emphasizing the versatility and
robustness of UDEs in rheological modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OneProt: Towards Multi-Modal Protein Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04863v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04863v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Klemens Flöge, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud, Stefan Kesselheim, Vincent Fortuin, Stephan Günneman, Karel J van der Weg, Holger Gohlke, Erinc Merdivan, Alina Bazarova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Artificial Intelligence have enabled multi-modal systems
to model and translate diverse information spaces. Extending beyond text and
vision, we introduce OneProt, a multi-modal AI for proteins that integrates
structural, sequence, text, and binding site data. Using the ImageBind
framework, OneProt aligns the latent spaces of protein modality encoders in a
lightweight fine-tuning scheme that focuses on pairwise alignment with sequence
data rather than requiring full matches. This novel approach comprises a mix of
Graph Neural Networks and transformer architectures. It demonstrates strong
performance in retrieval tasks and showcases the efficacy of multi-modal
systems in Protein Machine Learning through a broad spectrum of downstream
baselines, including enzyme function prediction and binding site analysis.
Furthermore, OneProt enables the transfer of representational information from
specialized encoders to the sequence encoder, enhancing capabilities for
distinguishing evolutionarily related and unrelated sequences and exhibiting
representational properties where evolutionarily related proteins align in
similar directions within the latent space. In addition, we extensively
investigate modality ablations to identify the encoders that contribute most to
predictive performance, highlighting the significance of the binding site
encoder, which has not been used in similar models previously. This work
expands the horizons of multi-modal protein models, paving the way for
transformative applications in drug discovery, biocatalytic reaction planning,
and protein engineering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 7 figures, 11 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Parameter Symmetry Potentially Unifies Deep Learning Theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05300v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05300v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liu Ziyin, Yizhou Xu, Tomaso Poggio, Isaac Chuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamics of learning in modern large AI systems is hierarchical, often
characterized by abrupt, qualitative shifts akin to phase transitions observed
in physical systems. While these phenomena hold promise for uncovering the
mechanisms behind neural networks and language models, existing theories remain
fragmented, addressing specific cases. In this position paper, we advocate for
the crucial role of the research direction of parameter symmetries in unifying
these fragmented theories. This position is founded on a centralizing
hypothesis for this direction: parameter symmetry breaking and restoration are
the unifying mechanisms underlying the hierarchical learning behavior of AI
models. We synthesize prior observations and theories to argue that this
direction of research could lead to a unified understanding of three distinct
hierarchies in neural networks: learning dynamics, model complexity, and
representation formation. By connecting these hierarchies, our position paper
elevates symmetry -- a cornerstone of theoretical physics -- to become a
potential fundamental principle in modern AI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Activated LoRA: Fine-tuned LLMs for Intrinsics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12397v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12397v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework for
finetuning the weights of large foundation models, and has become the go-to
method for data-driven customization of LLMs. Despite the promise of highly
customized behaviors and capabilities, switching between relevant LoRAs in a
multiturn setting is inefficient, as the key-value (KV) cache of the entire
turn history must be recomputed with the LoRA weights before generation can
begin. To address this problem, we propose Activated LoRA (aLoRA), an adapter
architecture which modifies the LoRA framework to only adapt weights for the
tokens in the sequence \emph{after} the aLoRA is invoked. This change crucially
allows aLoRA to accept the base model's KV cache of the input string, meaning
that aLoRA can be instantly activated whenever needed in a chain without
recomputing the cache. This enables building what we call \emph{intrinsics},
i.e. specialized models invoked to perform well-defined operations on portions
of an input chain or conversation that otherwise uses the base model by
default. We train a set of aLoRA-based intrinsics models, demonstrating
competitive accuracy with standard LoRA while achieving significant inference
benefits. We include a codebase implementing aLoRA in the supplementary
material.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semi-Supervised Model-Free Bayesian State Estimation from Compressed
  Measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07368v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07368v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider data-driven Bayesian state estimation from compressed
measurements (BSCM) of a model-free process. The dimension of the temporal
measurement vector is lower than that of the temporal state vector to be
estimated, leading to an under-determined inverse problem. The underlying
dynamical model of the state's evolution is unknown for a 'model-free process.'
Hence, it is difficult to use traditional model-driven methods, for example,
Kalman and particle filters. Instead, we consider data-driven methods. We
experimentally show that two existing unsupervised learning-based data-driven
methods fail to address the BSCM problem in a model-free process. The methods
are -- data-driven nonlinear state estimation (DANSE) and deep Markov model
(DMM). While DANSE provides good predictive/forecasting performance to model
the temporal measurement data as a time series, its unsupervised learning lacks
suitable regularization for tackling the BSCM task. We then propose a
semi-supervised learning approach and develop a semi-supervised learning-based
DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a large amount of
unlabelled data along with a limited amount of labelled data, i.e., pairwise
measurement-and-state data, which provides the desired regularization. Using
three benchmark dynamical systems, we empirically show that the data-driven
SemiDANSE provides competitive state estimation performance for BSCM using a
handful of different measurement systems, against a hybrid method called
KalmanNet and two model-driven methods (extended Kalman filter and unscented
Kalman filter) that know the dynamical models exactly.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 12 figures, under review at IEEE Transactions on Signal
  Processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HopCast: Calibration of Autoregressive Dynamics Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16587v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16587v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Bilal Shahid, Cody Fleming
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models are often trained to approximate dynamical systems that
can be modeled using differential equations. Many of these models are optimized
to predict one step ahead; such approaches produce calibrated one-step
predictions if the predictive model can quantify uncertainty, such as Deep
Ensembles. At inference time, multi-step predictions are generated via
autoregression, which needs a sound uncertainty propagation method to produce
calibrated multi-step predictions. This work introduces an alternative
Predictor-Corrector approach named \hop{} that uses Modern Hopfield Networks
(MHN) to learn the errors of a deterministic Predictor that approximates the
dynamical system. The Corrector predicts a set of errors for the Predictor's
output based on a context state at any timestep during autoregression. The set
of errors creates sharper and well-calibrated prediction intervals with higher
predictive accuracy compared to baselines without uncertainty propagation. The
calibration and prediction performances are evaluated across a set of dynamical
systems. This work is also the first to benchmark existing uncertainty
propagation methods based on calibration errors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hogwild! Inference: Parallel LLM Generation via Concurrent Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.06261v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.06261v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gleb Rodionov, Roman Garipov, Alina Shutova, George Yakushev, Erik Schultheis, Vage Egiazarian, Anton Sinitsin, Denis Kuznedelev, Dan Alistarh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated the ability to tackle
increasingly complex tasks through advanced reasoning, long-form content
generation, and tool use. Solving these tasks often involves long
inference-time computations. In human problem solving, a common strategy to
expedite work is collaboration: by dividing the problem into sub-tasks,
exploring different strategies concurrently, etc. Recent research has shown
that LLMs can also operate in parallel by implementing explicit cooperation
frameworks, such as voting mechanisms or the explicit creation of independent
sub-tasks that can be executed in parallel. However, each of these frameworks
may not be suitable for all types of tasks, which can hinder their
applicability. In this work, we propose a different design approach: we run LLM
"workers" in parallel , allowing them to synchronize via a concurrently-updated
attention cache and prompt these workers to decide how best to collaborate. Our
approach allows the LLM instances to come up with their own collaboration
strategy for the problem at hand, all the while "seeing" each other's memory in
the concurrent KV cache. We implement this approach via Hogwild! Inference: a
parallel LLM inference engine where multiple instances of the same LLM run in
parallel with the same attention cache, with "instant" access to each other's
memory. Hogwild! Inference takes advantage of Rotary Position Embeddings (RoPE)
to avoid recomputation while improving parallel hardware utilization. We find
that modern reasoning-capable LLMs can perform inference with shared Key-Value
cache out of the box, without additional fine-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Lists to Emojis: How Format Bias Affects Model Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11704v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11704v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study format biases in reinforcement learning from human
feedback (RLHF). We observe that many widely-used preference models, including
human evaluators, GPT-4, and top-ranking models on the RewardBench benchmark,
exhibit strong biases towards specific format patterns, such as lists, links,
bold text, and emojis. Furthermore, large language models (LLMs) can exploit
these biases to achieve higher rankings on popular benchmarks like AlpacaEval
and LMSYS Chatbot Arena. One notable example of this is verbosity bias, where
current preference models favor longer responses that appear more
comprehensive, even when their quality is equal to or lower than shorter,
competing responses. However, format biases beyond verbosity remain largely
underexplored in the literature. In this work, we extend the study of biases in
preference learning beyond the commonly recognized length bias, offering a
comprehensive analysis of a wider range of format biases. Additionally, we show
that with a small amount of biased data (less than 1%), we can inject
significant bias into the reward model. Moreover, these format biases can also
be easily exploited by downstream alignment algorithms, such as best-of-n
sampling and online iterative DPO, as it is usually easier to manipulate the
format than to improve the quality of responses. Our findings emphasize the
need to disentangle format and content both for designing alignment algorithms
and evaluating models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Generalized Hamiltonians using fully Symplectic Mappings <span class="chip">AAAI</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11138v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11138v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harsh Choudhary, Chandan Gupta, Vyacheslav kungrutsev, Melvin Leok, Georgios Korpas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many important physical systems can be described as the evolution of a
Hamiltonian system, which has the important property of being conservative,
that is, energy is conserved throughout the evolution. Physics Informed Neural
Networks and in particular Hamiltonian Neural Networks have emerged as a
mechanism to incorporate structural inductive bias into the NN model. By
ensuring physical invariances are conserved, the models exhibit significantly
better sample complexity and out-of-distribution accuracy than standard NNs.
Learning the Hamiltonian as a function of its canonical variables, typically
position and velocity, from sample observations of the system thus becomes a
critical task in system identification and long-term prediction of system
behavior. However, to truly preserve the long-run physical conservation
properties of Hamiltonian systems, one must use symplectic integrators for a
forward pass of the system's simulation. While symplectic schemes have been
used in the literature, they are thus far limited to situations when they
reduce to explicit algorithms, which include the case of separable Hamiltonians
or augmented non-separable Hamiltonians. We extend it to generalized
non-separable Hamiltonians, and noting the self-adjoint property of symplectic
integrators, we bypass computationally intensive backpropagation through an ODE
solver. We show that the method is robust to noise and provides a good
approximation of the system Hamiltonian when the state variables are sampled
from a noisy observation. In the numerical results, we show the performance of
the method concerning Hamiltonian reconstruction and conservation, indicating
its particular advantage for non-separable systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to The 39th Annual AAAI Conference on Artificial
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Forensics Adapter: Unleashing CLIP for Generalizable Face Forgery
  Detection <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.19715v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.19715v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinjie Cui, Yuezun Li, Delong Zhu, Jiaran Zhou, Junyu Dong, Siwei Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We describe Forensics Adapter, an adapter network designed to transform CLIP
into an effective and generalizable face forgery detector. Although CLIP is
highly versatile, adapting it for face forgery detection is non-trivial as
forgery-related knowledge is entangled with a wide range of unrelated
knowledge. Existing methods treat CLIP merely as a feature extractor, lacking
task-specific adaptation, which limits their effectiveness. To address this, we
introduce an adapter to learn face forgery traces -- the blending boundaries
unique to forged faces, guided by task-specific objectives. Then we enhance the
CLIP visual tokens with a dedicated interaction strategy that communicates
knowledge across CLIP and the adapter. Since the adapter is alongside CLIP, its
versatility is highly retained, naturally ensuring strong generalizability in
face forgery detection. With only 5.7M trainable parameters, our method
achieves a significant performance boost, improving by approximately 7% on
average across five standard datasets. Additionally, we describe Forensics
Adapter++, an extended method that incorporates textual modality via a newly
proposed forgery-aware prompt learning strategy. This extension leads to a
further 1.3% performance boost over the original Forensics Adapter. We believe
the proposed methods can serve as a baseline for future CLIP-based face forgery
detection methods. The codes have been released at
https://github.com/OUC-VAS/ForensicsAdapter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extension of CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in
  Post-Training <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Feuer, Chinmay Hegde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model (LLM) post-training, from DPO to distillation, can refine
behaviors and unlock new skills, but the open science supporting these
post-training techniques is still in its infancy. One limiting factor has been
the difficulty of conducting large-scale comparative analyses of synthetic data
generating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,
the largest public chat dataset to date. We extend the existing WildChat
dataset to include responses not only from GPT, but from over 50 different
open-weight models, ranging in size from 0.5B to 104B parameters. We conduct an
extensive comparative analysis and demonstrate the potential of this dataset by
creating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3
SFT mixture from Allen AI with only 40% as many samples. Our dataset, samples
and code are available at https://github.com/penfever/wildchat-50m.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursive Deep Inverse Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13241v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13241v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Tales Imbiriba
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inferring an adversary's goals from exhibited behavior is crucial for
counterplanning and non-cooperative multi-agent systems in domains like
cybersecurity, military, and strategy games. Deep Inverse Reinforcement
Learning (IRL) methods based on maximum entropy principles show promise in
recovering adversaries' goals but are typically offline, require large batch
sizes with gradient descent, and rely on first-order updates, limiting their
applicability in real-time scenarios. We propose an online Recursive Deep
Inverse Reinforcement Learning (RDIRL) approach to recover the cost function
governing the adversary actions and goals. Specifically, we minimize an upper
bound on the standard Guided Cost Learning (GCL) objective using sequential
second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading
to a fast (in terms of convergence) learning algorithm. We demonstrate that
RDIRL is able to recover cost and reward functions of expert agents in standard
and adversarial benchmark tasks. Experiments on benchmark tasks show that our
proposed approach outperforms several leading IRL algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Compositional Causal Reasoning Evaluation in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04556v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04556v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal reasoning and compositional reasoning are two core aspirations in AI.
Measuring the extent of these behaviors requires principled evaluation methods.
We explore a unified perspective that considers both behaviors simultaneously,
termed compositional causal reasoning (CCR): the ability to infer how causal
measures compose and, equivalently, how causal quantities propagate through
graphs. We instantiate a framework for the systematic evaluation of CCR for the
average treatment effect and the probability of necessity and sufficiency. As
proof of concept, we demonstrate CCR evaluation for language models in the
LLama, Phi, and GPT families. On a math word problem, our framework revealed a
range of taxonomically distinct error patterns. CCR errors increased with the
complexity of causal paths for all models except o1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Impact of the Utility in Semivalue-based Data Valuation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06574v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06574v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mélissa Tamine, Benjamin Heymann, Patrick Loiseau, Maxime Vono
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semivalue-based data valuation uses cooperative-game theory intuitions to
assign each data point a value reflecting its contribution to a downstream
task. Still, those values depend on the practitioner's choice of utility,
raising the question: How robust is semivalue-based data valuation to changes
in the utility? This issue is critical when the utility is set as a trade-off
between several criteria and when practitioners must select among multiple
equally valid utilities. We address it by introducing the notion of a dataset's
spatial signature: given a semivalue, we embed each data point into a
lower-dimensional space where any utility becomes a linear functional, making
the data valuation framework amenable to a simpler geometric picture. Building
on this, we propose a practical methodology centered on an explicit robustness
metric that informs practitioners whether and by how much their data valuation
results will shift as the utility changes. We validate this approach across
diverse datasets and semivalues, demonstrating strong agreement with
rank-correlation analyses and offering analytical insight into how choosing a
semivalue can amplify or diminish robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Copyright Protection for Knowledge Bases of Retrieval-augmented
  Language Models via Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.10440v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.10440v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly integrated into real-world
personalized applications through retrieval-augmented generation (RAG)
mechanisms to supplement their responses with domain-specific knowledge.
However, the valuable and often proprietary nature of the knowledge bases used
in RAG introduces the risk of unauthorized usage by adversaries. Existing
methods that can be generalized as watermarking techniques to protect these
knowledge bases typically involve poisoning or backdoor attacks. However, these
methods require altering the LLM's results of verification samples, inevitably
making these watermarks susceptible to anomaly detection and even introducing
new security risks. To address these challenges, we propose \name{} for
`harmless' copyright protection of knowledge bases. Instead of manipulating
LLM's final output, \name{} implants distinct yet benign verification behaviors
in the space of chain-of-thought (CoT) reasoning, maintaining the correctness
of the final answer. Our method has three main stages: (1) Generating CoTs: For
each verification question, we generate two `innocent' CoTs, including a target
CoT for building watermark behaviors; (2) Optimizing Watermark Phrases and
Target CoTs: Inspired by our theoretical analysis, we optimize them to minimize
retrieval errors under the \emph{black-box} and \emph{text-only} setting of
suspicious LLM, ensuring that only watermarked verification queries can
retrieve their correspondingly target CoTs contained in the knowledge base; (3)
Ownership Verification: We exploit a pairwise Wilcoxon test to verify whether a
suspicious LLM is augmented with the protected knowledge base by comparing its
responses to watermarked and benign verification queries. Our experiments on
diverse benchmarks demonstrate that \name{} effectively protects knowledge
bases and its resistance to adaptive attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally to this work. 25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LoRA-Ensemble: Efficient Uncertainty Modelling for Self-Attention
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14438v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14438v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik J. Mühlematter, Michelle Halbheer, Alexander Becker, Dominik Narnhofer, Helge Aasen, Konrad Schindler, Mehmet Ozgur Turkoglu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous real-world decisions rely on machine learning algorithms and require
calibrated uncertainty estimates. However, modern methods often yield
overconfident, uncalibrated predictions. The dominant approach to quantifying
the uncertainty inherent in the model is to train an ensemble of separate
predictors and measure their empirical variance. In an explicit implementation,
the ensemble has high computational cost and memory footprint, especially if
the base model itself is already large, like modern transformers. This
motivates efforts to develop implicit ensemble methods that emulate the
ensemble without explicitly instantiating all its members. We introduce
LoRA-Ensemble, a parameter-efficient ensembling method for self-attention
networks. It is based on Low-Rank Adaptation (LoRA), originally developed for
efficient LLM fine-tuning, and extends it into an implicit ensembling scheme,
where all ensemble members share the same, pre-trained self-attention network,
but have individual low-rank matrices for the attention projections. The
resulting method not only outperforms state-of-the-art implicit techniques like
BatchEnsemble, but even matches or exceeds the accuracy of an Explicit
Ensemble, while at the same time achieving superior calibration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Lifting of Neural Representations: Zero-Shot Generalization for
  Causal Inferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06343v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06343v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Cadei, Ilker Demirel, Piersilvio De Bartolomeis, Lukas Lindorfer, Sylvia Cremer, Cordelia Schmid, Francesco Locatello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many scientific domains, the cost of data annotation limits the scale and
pace of experimentation. Yet, modern machine learning systems offer a promising
alternative, provided their predictions yield correct conclusions. We focus on
Prediction-Powered Causal Inferences (PPCI), i.e., estimating the treatment
effect in a target experiment with unlabeled factual outcomes, retrievable
zero-shot from a pre-trained model. We first identify the conditional
calibration property to guarantee valid PPCI at population level. Then, we
introduce causal lifting, a new causal lifting constraint transferring validity
across experiments, which we propose to enforce in practice in Deconfounded
Empirical Risk Minimization, our new model-agnostic training objective. We
validate our method on synthetic and real-world scientific data, offering
solutions to instances not solvable by vanilla Empirical Risk Minimization and
invariant training. In particular, we solve zero-shot PPCI on the ISTAnt
dataset for the first time, fine-tuning a foundational model on our replica
dataset of their ecological experiment with a different recording platform and
treatment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tackling Decision Processes with Non-Cumulative Objectives using
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13609v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13609v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Nägele, Jan Olle, Thomas Fösel, Remmy Zen, Florian Marquardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Markov decision processes (MDPs) are used to model a wide variety of
applications ranging from game playing over robotics to finance. Their optimal
policy typically maximizes the expected sum of rewards given at each step of
the decision process. However, a large class of problems does not fit
straightforwardly into this framework: Non-cumulative Markov decision processes
(NCMDPs), where instead of the expected sum of rewards, the expected value of
an arbitrary function of the rewards is maximized. Example functions include
the maximum of the rewards or their mean divided by their standard deviation.
In this work, we introduce a general mapping of NCMDPs to standard MDPs. This
allows all techniques developed to find optimal policies for MDPs, such as
reinforcement learning or dynamic programming, to be directly applied to the
larger class of NCMDPs. Focusing on reinforcement learning, we show
applications in a diverse set of tasks, including classical control, portfolio
optimization in finance, and discrete optimization problems. Given our
approach, we can improve both final performance and training time compared to
relying on standard MDPs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Random Feature Representation Boosting <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18283v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18283v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikita Zozoulenko, Thomas Cass, Lukas Gonon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Random Feature Representation Boosting (RFRBoost), a novel
method for constructing deep residual random feature neural networks (RFNNs)
using boosting theory. RFRBoost uses random features at each layer to learn the
functional gradient of the network representation, enhancing performance while
preserving the convex optimization benefits of RFNNs. In the case of MSE loss,
we obtain closed-form solutions to greedy layer-wise boosting with random
features. For general loss functions, we show that fitting random feature
residual blocks reduces to solving a quadratically constrained least squares
problem. Through extensive numerical experiments on tabular datasets for both
regression and classification, we show that RFRBoost significantly outperforms
RFNNs and end-to-end trained MLP ResNets in the small- to medium-scale regime
where RFNNs are typically applied. Moreover, RFRBoost offers substantial
computational benefits, and theoretical guarantees stemming from boosting
theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fourier-Based 3D Multistage <span class="highlight-title">Transformer</span> for Aberration Correction in
  Multicellular Specimens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thayer Alshaabi, Daniel E. Milkie, Gaoxiang Liu, Cyna Shirazinejad, Jason L. Hong, Kemal Achour, Frederik Görlitz, Ana Milunovic-Jevtic, Cat Simmons, Ibrahim S. Abuzahriyeh, Erin Hong, Samara Erin Williams, Nathanael Harrison, Evan Huang, Eun Seok Bae, Alison N. Killilea, David G. Drubin, Ian A. Swinburne, Srigokul Upadhyayula, Eric Betzig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution tissue imaging is often compromised by sample-induced optical
aberrations that degrade resolution and contrast. While wavefront sensor-based
adaptive optics (AO) can measure these aberrations, such hardware solutions are
typically complex, expensive to implement, and slow when serially mapping
spatially varying aberrations across large fields of view. Here, we introduce
AOViFT (Adaptive Optical Vision Fourier Transformer) -- a machine
learning-based aberration sensing framework built around a 3D multistage Vision
Transformer that operates on Fourier domain embeddings. AOViFT infers
aberrations and restores diffraction-limited performance in puncta-labeled
specimens with substantially reduced computational cost, training time, and
memory footprint compared to conventional architectures or real-space networks.
We validated AOViFT on live gene-edited zebrafish embryos, demonstrating its
ability to correct spatially varying aberrations using either a deformable
mirror or post-acquisition deconvolution. By eliminating the need for the guide
star and wavefront sensing hardware and simplifying the experimental workflow,
AOViFT lowers technical barriers for high-resolution volumetric microscopy
across diverse biological samples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>55 pages, 6 figures, 26 si figures, 8 si tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MFH: A Multi-faceted Heuristic Algorithm Selection Approach for Software
  Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.22228v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.22228v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Su, Liansai Deng, Cheng Wen, Rong Wang, Zhi Ma, Nan Zhang, Cong Tian, Zhenhua Duan, Shengchao Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, many verification algorithms are available to improve the
reliability of software systems. Selecting the appropriate verification
algorithm typically demands domain expertise and non-trivial manpower. An
automated algorithm selector is thus desired. However, existing selectors,
either depend on machine-learned strategies or manually designed heuristics,
encounter issues such as reliance on high-quality samples with algorithm labels
and limited scalability. In this paper, an automated algorithm selection
approach, namely MFH, is proposed for software verification. Our approach
leverages the heuristics that verifiers producing correct results typically
implement certain appropriate algorithms, and the supported algorithms by these
verifiers indirectly reflect which ones are potentially applicable.
Specifically, MFH embeds the code property graph (CPG) of a semantic-preserving
transformed program to enhance the robustness of the prediction model.
Furthermore, our approach decomposes the selection task into the sub-tasks of
predicting potentially applicable algorithms and matching the most appropriate
verifiers. Additionally, MFH also introduces a feedback loop on incorrect
predictions to improve model prediction accuracy. We evaluate MFH on 20
verifiers and over 15,000 verification tasks. Experimental results demonstrate
the effectiveness of MFH, achieving a prediction accuracy of 91.47% even
without ground truth algorithm labels provided during the training phase.
Moreover, the prediction accuracy decreases only by 0.84% when introducing 10
new verifiers, indicating the strong scalability of the proposed approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The decision to withdraw the paper is driven by two reasons: 1. A
  conflict of interest arises from the proposed methods overlapping with
  pending patent applications by other authors. 2. Upon thorough review, it has
  been discovered that the paper contains ambiguities and inaccuracies in
  describing the method, potentially hindering readers' comprehension of the
  content</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning to Add, Multiply, and Execute Algorithmic Instructions Exactly
  with Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16763v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16763v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artur Back de Luca, George Giapitzakis, Kimon Fountoulakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks are known for their ability to approximate smooth functions,
yet they fail to generalize perfectly to unseen inputs when trained on discrete
operations. Such operations lie at the heart of algorithmic tasks such as
arithmetic, which is often used as a test bed for algorithmic execution in
neural networks. In this work, we ask: can neural networks learn to execute
binary-encoded algorithmic instructions exactly? We use the Neural Tangent
Kernel (NTK) framework to study the training dynamics of two-layer fully
connected networks in the infinite-width limit and show how a sufficiently
large ensemble of such models can be trained to execute exactly, with high
probability, four fundamental tasks: binary permutations, binary addition,
binary multiplication, and Subtract and Branch if Negative (SBN) instructions.
Since SBN is Turing-complete, our framework extends to computable functions. We
show how this can be efficiently achieved using only logarithmically many
training data. Our approach relies on two techniques: structuring the training
data to isolate bit-level rules, and controlling correlations in the NTK regime
to align model predictions with the target algorithmic executions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>43 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Random Forests and Generalized Linear Models for Improved
  Accuracy and Interpretability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.01932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.01932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhineet Agarwal, Ana M. Kenney, Yan Shuo Tan, Tiffany M. Tang, Bin Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Random forests (RFs) are among the most popular supervised learning
algorithms due to their nonlinear flexibility and ease-of-use. However, as
black box models, they can only be interpreted via algorithmically-defined
feature importance methods, such as Mean Decrease in Impurity (MDI), which have
been observed to be highly unstable and have ambiguous scientific meaning.
Furthermore, they can perform poorly in the presence of smooth or additive
structure. To address this, we reinterpret decision trees and MDI as linear
regression and $R^2$ values, respectively, with respect to engineered features
associated with the tree's decision splits. This allows us to combine the
respective strengths of RFs and generalized linear models in a framework called
RF+, which also yields an improved feature importance method we call MDI+.
Through extensive data-inspired simulations and real-world datasets, we show
that RF+ improves prediction accuracy over RFs and that MDI+ outperforms
popular feature importance measures in identifying signal features, often
yielding more than a 10% improvement over its closest competitor. In case
studies on drug response prediction and breast cancer subtyping, we further
show that MDI+ extracts well-established genes with significantly greater
stability compared to existing feature importance measures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rapid Whole Brain Motion-robust Mesoscale In-vivo MR Imaging using
  Multi-scale Implicit Neural Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08634v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08634v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Lyu, Lipeng Ning, William Consagra, Qiang Liu, Richard J. Rushmore, Berkin Bilgic, Yogesh Rathi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution whole-brain in vivo MR imaging at mesoscale resolutions
remains challenging due to long scan durations, motion artifacts, and limited
signal-to-noise ratio (SNR). This study proposes Rotating-view super-resolution
(ROVER)-MRI, an unsupervised framework based on multi-scale implicit neural
representations (INR), enabling efficient recovery of fine anatomical details
from multi-view thick-slice acquisitions. ROVER-MRI employs coordinate-based
neural networks to implicitly and continuously encode image structures at
multiple spatial scales, simultaneously modeling anatomical continuity and
correcting inter-view motion through an integrated registration mechanism.
Validation on ex-vivo monkey brain data and multiple in-vivo human datasets
demonstrates substantially improved reconstruction performance compared to
bicubic interpolation and state-of-the-art regularized least-squares
super-resolution reconstruction (LS-SRR) with 2-fold reduction in scan time.
Notably, ROVER-MRI achieves an unprecedented whole-brain in-vivo T2-weighted
imaging at 180 micron isotropic resolution in only 17 minutes of scan time on a
7T scanner with 22.4% lower relative error compared to LS-SRR. We also
demonstrate improved SNR using ROVER-MRI compared to a time-matched 3D GRE
acquisition. Quantitative results on several datasets demonstrate better
sharpness of the reconstructed images with ROVER-MRI for different
super-resolution factors (5 to 11). These findings highlight ROVER-MRI's
potential as a rapid, accurate, and motion-resilient mesoscale imaging
solution, promising substantial advantages for neuroimaging studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Compact Matrix Quantum Group Equivariant Neural Networks <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.06358v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.06358v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edward Pearce-Crump
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group equivariant neural networks have proven effective in modelling a wide
range of tasks where the data lives in a classical geometric space and exhibits
well-defined group symmetries. However, these networks are not suitable for
learning from data that lives in a non-commutative geometry, described formally
by non-commutative $C^{*}$-algebras, since the $C^{*}$-algebra of continuous
functions on a compact matrix group is commutative. To address this limitation,
we derive the existence of a new type of equivariant neural network, called
compact matrix quantum group equivariant neural networks, which encode
symmetries that are described by compact matrix quantum groups. We characterise
the weight matrices that appear in these neural networks for the easy compact
matrix quantum groups, which are defined by set partitions. As a result, we
obtain new characterisations of equivariant weight matrices for some compact
matrix groups that have not appeared previously in the machine learning
literature.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025 Poster; 32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TripNet: Learning Large-scale High-fidelity 3D Car Aerodynamics with
  Triplane Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17400v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17400v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qian Chen, Mohamed Elrefaie, Angela Dai, Faez Ahmed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surrogate modeling has emerged as a powerful tool to accelerate Computational
Fluid Dynamics (CFD) simulations. Existing 3D geometric learning models based
on point clouds, voxels, meshes, or graphs depend on explicit geometric
representations that are memory-intensive and resolution-limited. For
large-scale simulations with millions of nodes and cells, existing models
require aggressive downsampling due to their dependence on mesh resolution,
resulting in degraded accuracy. We present TripNet, a triplane-based neural
framework that implicitly encodes 3D geometry into a compact, continuous
feature map with fixed dimension. Unlike mesh-dependent approaches, TripNet
scales to high-resolution simulations without increasing memory cost, and
enables CFD predictions at arbitrary spatial locations in a query-based
fashion, independent of mesh connectivity or predefined nodes. TripNet achieves
state-of-the-art performance on the DrivAerNet and DrivAerNet++ datasets,
accurately predicting drag coefficients, surface pressure, and full 3D flow
fields. With a unified triplane backbone supporting multiple simulation tasks,
TripNet offers a scalable, accurate, and efficient alternative to traditional
CFD solvers and existing surrogate models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Permutation Equivariant Neural Networks for Symmetric Tensors <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.11276v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.11276v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edward Pearce-Crump
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incorporating permutation equivariance into neural networks has proven to be
useful in ensuring that models respect symmetries that exist in data. Symmetric
tensors, which naturally appear in statistics, machine learning, and graph
theory, are essential for many applications in physics, chemistry, and
materials science, amongst others. However, existing research on permutation
equivariant models has not explored symmetric tensors as inputs, and most prior
work on learning from these tensors has focused on equivariance to Euclidean
groups. In this paper, we present two different characterisations of all linear
permutation equivariant functions between symmetric power spaces of
$\mathbb{R}^n$. We show on two tasks that these functions are highly data
efficient compared to standard MLPs and have potential to generalise well to
symmetric tensors of different sizes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025 Poster; 40 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Bidding Algorithms with Strict Return on Spend (ROS) Constraint 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05599v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05599v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rahul Vaze, Abhishek Sinha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Auto-bidding problem under a strict return-on-spend constraint (ROSC) is
considered, where an algorithm has to make decisions about how much to bid for
an ad slot depending on the revealed value, and the hidden allocation and
payment function that describes the probability of winning the ad-slot
depending on its bid. The objective of an algorithm is to maximize the expected
utility (product of ad value and probability of winning the ad slot) summed
across all time slots subject to the total expected payment being less than the
total expected utility, called the ROSC. A (surprising) impossibility result is
derived that shows that no online algorithm can achieve a sub-linear regret
even when the value, allocation and payment function are drawn i.i.d. from an
unknown distribution. The problem is non-trivial even when the revealed value
remains constant across time slots, and an algorithm with regret guarantee that
is optimal up to logarithmic factor is derived.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Log-Concavity and Score Regularity: Improved Convergence Bounds
  for Score-Based Generative Models in W2-distance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02298v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02298v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marta Gentiloni-Silveri, Antonio Ocello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Score-based Generative Models (SGMs) aim to sample from a target distribution
by learning score functions using samples perturbed by Gaussian noise. Existing
convergence bounds for SGMs in the $\mathcal{W}_2$-distance rely on stringent
assumptions about the data distribution. In this work, we present a novel
framework for analyzing $\mathcal{W}_2$-convergence in SGMs, significantly
relaxing traditional assumptions such as log-concavity and score regularity.
Leveraging the regularization properties of the Ornstein--Uhlenbeck (OU)
process, we show that weak log-concavity of the data distribution evolves into
log-concavity over time. This transition is rigorously quantified through a
PDE-based analysis of the Hamilton--Jacobi--Bellman equation governing the
log-density of the forward process. Moreover, we establish that the drift of
the time-reversed OU process alternates between contractive and non-contractive
regimes, reflecting the dynamics of concavity. Our approach circumvents the
need for stringent regularity conditions on the score function and its
estimators, relying instead on milder, more practical assumptions. We
demonstrate the wide applicability of this framework through explicit
computations on Gaussian mixture models, illustrating its versatility and
potential for broader classes of data distributions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ E$^2$M: Double Bounded $α$-Divergence Optimization for Tensor-based
  Discrete Density Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18220v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18220v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazu Ghalamkari, Jesper Løve Hinrich, Morten Mørup
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tensor-based discrete density estimation requires flexible modeling and
proper divergence criteria to enable effective learning; however, traditional
approaches using $\alpha$-divergence face analytical challenges due to the
$\alpha$-power terms in the objective function, which hinder the derivation of
closed-form update rules. We present a generalization of the
expectation-maximization (EM) algorithm, called E$^2$M algorithm. It
circumvents this issue by first relaxing the optimization into minimization of
a surrogate objective based on the Kullback-Leibler (KL) divergence, which is
tractable via the standard EM algorithm, and subsequently applying a tensor
many-body approximation in the M-step to enable simultaneous closed-form
updates of all parameters. Our approach offers flexible modeling for not only a
variety of low-rank structures, including the CP, Tucker, and Tensor Train
formats, but also their mixtures, thus allowing us to leverage the strengths of
different low-rank structures. We demonstrate the effectiveness of our approach
in classification and density estimation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tuning for Trustworthiness -- Balancing Performance and Explanation
  Consistency in Neural Network Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.07910v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.07910v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Hinterleitner, Thomas Bartz-Beielstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing interest in Explainable Artificial Intelligence (XAI),
explainability is rarely considered during hyperparameter tuning or neural
architecture optimization, where the focus remains primarily on minimizing
predictive loss. In this work, we introduce the novel concept of XAI
consistency, defined as the agreement among different feature attribution
methods, and propose new metrics to quantify it. For the first time, we
integrate XAI consistency directly into the hyperparameter tuning objective,
creating a multi-objective optimization framework that balances predictive
performance with explanation robustness. Implemented within the Sequential
Parameter Optimization Toolbox (SPOT), our approach uses both weighted
aggregation and desirability-based strategies to guide model selection. Through
our proposed framework and supporting tools, we explore the impact of
incorporating XAI consistency into the optimization process. This enables us to
characterize distinct regions in the architecture configuration space: one
region with poor performance and comparatively low interpretability, another
with strong predictive performance but weak interpretability due to low
\gls{xai} consistency, and a trade-off region that balances both objectives by
offering high interpretability alongside competitive performance. Beyond
introducing this novel approach, our research provides a foundation for future
investigations into whether models from the trade-off zone-balancing
performance loss and XAI consistency-exhibit greater robustness by avoiding
overfitting to training performance, thereby leading to more reliable
predictions on out-of-distribution data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TULiP: Test-time Uncertainty Estimation via Linearization and Weight
  Perturbation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16923v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16923v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A reliable uncertainty estimation method is the foundation of many modern
out-of-distribution (OOD) detectors, which are critical for safe deployments of
deep learning models in the open world. In this work, we propose TULiP, a
theoretically-driven post-hoc uncertainty estimator for OOD detection. Our
approach considers a hypothetical perturbation applied to the network before
convergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Ultimately, our approach computes uncertainty from a set of sampled
predictions. We visualize our bound on synthetic regression and classification
datasets. Furthermore, we demonstrate the effectiveness of TULiP using
large-scale OOD detection benchmarks for image classification. Our method
exhibits state-of-the-art performance, particularly for near-distribution
samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Overcoming Non-stationary Dynamics with Evidential Proximal Policy
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01468v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01468v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullah Akgül, Gulcin Baykal, Manuel Haußmann, Melih Kandemir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continuous control of non-stationary environments is a major challenge for
deep reinforcement learning algorithms. The time-dependency of the state
transition dynamics aggravates the notorious stability problems of model-free
deep actor-critic architectures. We posit that two properties will play a key
role in overcoming non-stationarity in transition dynamics: (i) preserving the
plasticity of the critic network, (ii) directed exploration for rapid
adaptation to the changing dynamics. We show that performing on-policy
reinforcement learning with an evidential critic provides both of these
properties. The evidential design ensures a fast and sufficiently accurate
approximation to the uncertainty around the state-value, which maintains the
plasticity of the critic network by detecting the distributional shifts caused
by the change in dynamics. The probabilistic critic also makes the actor
training objective a random variable, enabling the use of directed exploration
approaches as a by-product. We name the resulting algorithm as $\textit{
Evidential Proximal Policy Optimization (EPPO)}$ due to the integral role of
evidential uncertainty quantification in both policy evaluation and policy
improvement stages. Through experiments on non-stationary continuous control
tasks, where the environment dynamics change at regular intervals, we
demonstrate that our algorithm outperforms state-of-the-art on-policy
reinforcement learning variants in both task-specific and overall return.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature
  Attribution Explainability <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08137v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08137v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maaløe, Maria Maistro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural network predictions are notoriously difficult to interpret.
Feature attribution methods aim to explain these predictions by identifying the
contribution of each input feature. Faithfulness, often evaluated using the
area over the perturbation curve (AOPC), reflects feature attributions'
accuracy in describing the internal mechanisms of deep neural networks.
However, many studies rely on AOPC to compare faithfulness across different
models, which we show can lead to false conclusions about models' faithfulness.
Specifically, we find that AOPC is sensitive to variations in the model,
resulting in unreliable cross-model comparisons. Moreover, AOPC scores are
difficult to interpret in isolation without knowing the model-specific lower
and upper limits. To address these issues, we propose a normalization approach,
Normalized AOPC (NAOPC), enabling consistent cross-model evaluations and more
meaningful interpretation of individual scores. Our experiments demonstrate
that this normalization can radically change AOPC results, questioning the
conclusions of earlier studies and offering a more robust framework for
assessing feature attribution faithfulness. Our code is available at
https://github.com/JoakimEdin/naopc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Multi-task Learning via Seeking Task-based Flat Regions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.13723v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.13723v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoang Phan, Lam Tran, Quyen Tran, Ngoc N. Tran, Tuan Truong, Qi Lei, Nhat Ho, Dinh Phung, Trung Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm for
training deep neural networks that allows learning more than one objective by a
single backbone. Compared to training tasks separately, MTL significantly
reduces computational costs, improves data efficiency, and potentially enhances
model performance by leveraging knowledge across tasks. Hence, it has been
adopted in a variety of applications, ranging from computer vision to natural
language processing and speech recognition. Among them, there is an emerging
line of work in MTL that focuses on manipulating the task gradient to derive an
ultimate gradient descent direction to benefit all tasks. Despite achieving
impressive results on many benchmarks, directly applying these approaches
without using appropriate regularization techniques might lead to suboptimal
solutions on real-world problems. In particular, standard training that
minimizes the empirical loss on the training data can easily suffer from
overfitting to low-resource tasks or be spoiled by noisy-labeled ones, which
can cause negative transfer between tasks and overall performance drop. To
alleviate such problems, we propose to leverage a recently introduced training
method, named Sharpness-aware Minimization, which can enhance model
generalization ability on single-task learning. Accordingly, we present a novel
MTL training methodology, encouraging the model to find task-based flat minima
for coherently improving its generalization capability on all tasks. Finally,
we conduct comprehensive experiments on a variety of applications to
demonstrate the merit of our proposed approach to existing gradient-based MTL
methods, as suggested by our developed theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 17 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Erasing Undesirable Concepts in Diffusion Models with Adversarial
  Preservation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.15618v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.15618v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anh Bui, Long Vuong, Khanh Doan, Trung Le, Paul Montague, Tamas Abraham, Dinh Phung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models excel at generating visually striking content from text but
can inadvertently produce undesirable or harmful content when trained on
unfiltered internet data. A practical solution is to selectively removing
target concepts from the model, but this may impact the remaining concepts.
Prior approaches have tried to balance this by introducing a loss term to
preserve neutral content or a regularization term to minimize changes in the
model parameters, yet resolving this trade-off remains challenging. In this
work, we propose to identify and preserving concepts most affected by parameter
changes, termed as \textit{adversarial concepts}. This approach ensures stable
erasure with minimal impact on the other concepts. We demonstrate the
effectiveness of our method using the Stable Diffusion model, showing that it
outperforms state-of-the-art erasure methods in eliminating unwanted content
while maintaining the integrity of other unrelated elements. Our code is
available at https://github.com/tuananhbui89/Erasing-Adversarial-Preservation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Erasing Concepts, Generative Unlearning, NeurIPS 2024. arXiv admin
  note: text overlap with arXiv:2403.12326</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fantastic Targets for Concept Erasure in Diffusion Models and Where To
  Find Them 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18950v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18950v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anh Bui, Trang Vu, Long Vuong, Trung Le, Paul Montague, Tamas Abraham, Junae Kim, Dinh Phung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept erasure has emerged as a promising technique for mitigating the risk
of harmful content generation in diffusion models by selectively unlearning
undesirable concepts. The common principle of previous works to remove a
specific concept is to map it to a fixed generic concept, such as a neutral
concept or just an empty text prompt. In this paper, we demonstrate that this
fixed-target strategy is suboptimal, as it fails to account for the impact of
erasing one concept on the others. To address this limitation, we model the
concept space as a graph and empirically analyze the effects of erasing one
concept on the remaining concepts. Our analysis uncovers intriguing geometric
properties of the concept space, where the influence of erasing a concept is
confined to a local region. Building on this insight, we propose the Adaptive
Guided Erasure (AGE) method, which \emph{dynamically} selects optimal target
concepts tailored to each undesirable concept, minimizing unintended side
effects. Experimental results show that AGE significantly outperforms
state-of-the-art erasure methods on preserving unrelated concepts while
maintaining effective erasure performance. Our code is published at
{https://github.com/tuananhbui89/Adaptive-Guided-Erasure}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model Selection for Gaussian-gated Gaussian Mixture of Experts Using
  Dendrograms of Mixing Measures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13052v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13052v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan Thai, TrungTin Nguyen, Dat Do, Nhat Ho, Christopher Drovandi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture of Experts (MoE) models constitute a widely utilized class of
ensemble learning approaches in statistics and machine learning, known for
their flexibility and computational efficiency. They have become integral
components in numerous state-of-the-art deep neural network architectures,
particularly for analyzing heterogeneous data across diverse domains. Despite
their practical success, the theoretical understanding of model selection,
especially concerning the optimal number of mixture components or experts,
remains limited and poses significant challenges. These challenges primarily
stem from the inclusion of covariates in both the Gaussian gating functions and
expert networks, which introduces intrinsic interactions governed by partial
differential equations with respect to their parameters. In this paper, we
revisit the concept of dendrograms of mixing measures and introduce a novel
extension to Gaussian-gated Gaussian MoE models that enables consistent
estimation of the true number of mixture components and achieves the pointwise
optimal convergence rate for parameter estimation in overfitted scenarios.
Notably, this approach circumvents the need to train and compare a range of
models with varying numbers of components, thereby alleviating the
computational burden, particularly in high-dimensional or deep neural network
settings. Experimental results on synthetic data demonstrate the effectiveness
of the proposed method in accurately recovering the number of experts. It
outperforms common criteria such as the Akaike information criterion, the
Bayesian information criterion, and the integrated completed likelihood, while
achieving optimal convergence rates for parameter estimation and accurately
approximating the regression function.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Correct typos and update the numerical experiments. Tuan Thai and
  TrungTin Nguyen are co-first authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLäMmlein: Compact and Competitive German-Only Language Models from
  Scratch 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11171v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11171v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Pfister, Julia Wunderle, Andreas Hotho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We create two German-only decoder models, LL\"aMmlein 120M and 1B,
transparently from scratch and publish them, along with the training data, for
the German NLP research community to use. The model training involved several
key steps, including extensive data preprocessing, the creation of a custom
German tokenizer, the training itself, as well as the evaluation of the final
models on various benchmarks. Throughout the training process, multiple
checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor
the models' learning dynamics. Compared to state-of-the-art models on the
SuperGLEBer benchmark, both LL\"aMmlein models performed competitively,
consistently matching or surpassing models with similar parameter sizes. The
results show that the models' quality scales with size as expected, but
performance improvements on some tasks plateaued early, offering valuable
insights into resource allocation for future model development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>camera ready;
  https://www.informatik.uni-wuerzburg.de/datascience/projects/nlp/llammlein/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Where You Place the Norm Matters: From Prejudiced to Neutral
  Initializations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11312v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11312v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emanuele Francazi, Francesco Pinto, Aurelien Lucchi, Marco Baity-Jesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Normalization layers, such as Batch Normalization and Layer Normalization,
are central components in modern neural networks, widely adopted to improve
training stability and generalization. While their practical effectiveness is
well documented, a detailed theoretical understanding of how normalization
affects model behavior, starting from initialization, remains an important open
question. In this work, we investigate how both the presence and placement of
normalization within hidden layers influence the statistical properties of
network predictions before training begins. In particular, we study how these
choices shape the distribution of class predictions at initialization, which
can range from unbiased (Neutral) to highly concentrated (Prejudiced) toward a
subset of classes. Our analysis shows that normalization placement induces
systematic differences in the initial prediction behavior of neural networks,
which in turn shape the dynamics of learning. By linking architectural choices
to prediction statistics at initialization, our work provides a principled
understanding of how normalization can influence early training behavior and
offers guidance for more controlled and interpretable network design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Fixed a Typo in Fig.1 and refined the Appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GRADIEND: Monosemantic Feature Learning within Neural Networks Applied
  to Gender Debiasing of <span class="highlight-title">Transformer</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.01406v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.01406v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Drechsel, Steffen Herbold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI systems frequently exhibit and amplify social biases, including gender
bias, leading to harmful consequences in critical areas. This study introduces
a novel encoder-decoder approach that leverages model gradients to learn a
single monosemantic feature neuron encoding gender information. We show that
our method can be used to debias transformer-based language models, while
maintaining other capabilities. We demonstrate the effectiveness of our
approach across various model architectures and highlight its potential for
broader applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Score Matching to Diffusion: A Fine-Grained Error Analysis in the
  Gaussian Setting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.11615v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.11615v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Hurault, Matthieu Terris, Thomas Moreau, Gabriel Peyré
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sampling from an unknown distribution, accessible only through discrete
samples, is a fundamental problem at the core of generative AI. The current
state-of-the-art methods follow a two-step process: first, estimating the score
function (the gradient of a smoothed log-distribution) and then applying a
diffusion-based sampling algorithm -- such as Langevin or Diffusion models. The
resulting distribution's correctness can be impacted by four major factors: the
generalization and optimization errors in score matching, and the
discretization and minimal noise amplitude in the diffusion. In this paper, we
make the sampling error explicit when using a diffusion sampler in the Gaussian
setting. We provide a sharp analysis of the Wasserstein sampling error that
arises from these four error sources. This allows us to rigorously track how
the anisotropy of the data distribution (encoded by its power spectrum)
interacts with key parameters of the end-to-end sampling method, including the
number of initial samples, the stepsizes in both score matching and diffusion,
and the noise amplitude. Notably, we show that the Wasserstein sampling error
can be expressed as a kernel-type norm of the data power spectrum, where the
specific kernel depends on the method parameters. This result provides a
foundation for further analysis of the tradeoffs involved in optimizing
sampling accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>59 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Elucidating Subspace Perturbation in Zeroth-Order Optimization: Theory
  and Practice at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.19099v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.19099v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sihwan Park, Jihun Yun, SungYub Kim, Souvik Kundu, Eunho Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zeroth-order (ZO) optimization has emerged as a promising alternative to
gradient-based backpropagation methods, particularly for black-box optimization
and large language model (LLM) fine-tuning. However, ZO methods often suffer
from slow convergence due to high-variance stochastic gradient estimators.
While subspace perturbations, such as sparsity and low-rank constraints, have
been explored to mitigate this issue, their effectiveness remains poorly
understood. In this work, we develop a \emph{unified theoretical framework}
that analyzes both the convergence and generalization properties of ZO
optimization under subspace perturbations. We show that high dimensionality is
the primary bottleneck and introduce the notion of \textit{subspace alignment}
to explain how the subspace perturbations reduce gradient noise and accelerate
convergence. Our analysis further shows that a broad class of subspace
perturbations exhibits a similar convergence rate, motivating us to prioritize
practical considerations in real-world algorithm design. Building on these
insights, we propose an efficient ZO method using block coordinate descent
(MeZO-BCD), which perturbs and updates only a subset of parameters at each
step. Extensive experiments show that MeZO-BCD significantly accelerates
optimization, achieving up to $\mathbf{\times2.77}$ speedup in wall-clock time
over MeZO on OPT-13B, while maintaining comparable iteration complexity and
fine-tuning performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and
  Guarantees 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.01027v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.01027v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yannis Montreuil, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Two-stage Learning-to-Defer (L2D) enables optimal task delegation by
assigning each input to either a fixed main model or one of several offline
experts, supporting reliable decision-making in complex, multi-agent
environments. However, existing L2D frameworks assume clean inputs and are
vulnerable to adversarial perturbations that can manipulate query
allocation--causing costly misrouting or expert overload. We present the first
comprehensive study of adversarial robustness in two-stage L2D systems. We
introduce two novel attack strategie--untargeted and targeted--which
respectively disrupt optimal allocations or force queries to specific agents.
To defend against such threats, we propose SARD, a convex learning algorithm
built on a family of surrogate losses that are provably Bayes-consistent and
$(\mathcal{R}, \mathcal{G})$-consistent. These guarantees hold across
classification, regression, and multi-task settings. Empirical results
demonstrate that SARD significantly improves robustness under adversarial
attacks while maintaining strong clean performance, marking a critical step
toward secure and trustworthy L2D deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Load Forecasting for Households and Energy Communities: Are Deep
  Learning Models Worth the Effort? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05000v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05000v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Moosbrugger, Valentin Seiler, Philipp Wohlgenannt, Sebastian Hegenbart, Sashko Ristov, Elias Eder, Peter Kepplinger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Energy communities (ECs) play a key role in enabling local demand shifting
and enhancing self-sufficiency, as energy systems transition toward
decentralized structures with high shares of renewable generation. To optimally
operate them, accurate short-term load forecasting is essential, particularly
for implementing demand-side management strategies. With the recent rise of
deep learning methods, data-driven forecasting has gained significant
attention, however, it remains insufficiently explored in many practical
contexts. Therefore, this study evaluates the effectiveness of state-of-the-art
deep learning models -- including LSTM, xLSTM, and Transformer architectures --
compared to traditional benchmarks such as K-Nearest Neighbors (KNN) and
persistence forecasting, across varying community size, historical data
availability, and model complexity. Additionally, we assess the benefits of
transfer learning using publicly available synthetic load profiles. On average,
transfer learning improves the normalized mean absolute error by 1.97%pt when
only two months of training data are available. Interestingly, for less than
six months of training data, simple persistence models outperform deep learning
architectures in forecast accuracy. The practical value of improved forecasting
is demonstrated using a mixed-integer linear programming optimization for ECs
with a shared battery energy storage system. The most accurate deep learning
model achieves an average reduction in financial energy costs of 8.06%.
Notably, a simple KNN approach achieves average savings of 8.01%, making it a
competitive and robust alternative. All implementations are publicly available
to facilitate reproducibility. These findings offer actionable insights for
ECs, and they highlight when the additional complexity of deep learning is
warranted by performance gains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This preprint was submitted to the Elsevier Journal Applied Energy on
  May 23, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Two-Stage Learning-to-Defer Approach for Multi-Task Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.15729v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.15729v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yannis Montreuil, Shu Heng Yeo, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Two-Stage Learning-to-Defer (L2D) framework has been extensively studied
for classification and, more recently, regression tasks. However, many
real-world applications require solving both tasks jointly in a multi-task
setting. We introduce a novel Two-Stage L2D framework for multi-task learning
that integrates classification and regression through a unified deferral
mechanism. Our method leverages a two-stage surrogate loss family, which we
prove to be both Bayes-consistent and $(\mathcal{G}, \mathcal{R})$-consistent,
ensuring convergence to the Bayes-optimal rejector. We derive explicit
consistency bounds tied to the cross-entropy surrogate and the $L_1$-norm of
agent-specific costs, and extend minimizability gap analysis to the
multi-expert two-stage regime. We also make explicit how shared representation
learning--commonly used in multi-task models--affects these consistency
guarantees. Experiments on object detection and electronic health record
analysis demonstrate the effectiveness of our approach and highlight the
limitations of existing L2D methods in multi-task scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 17 main paper</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HoloLLM: Multisensory Foundation Model for Language-Grounded Human
  Sensing and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17645v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17645v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhao Zhou, Jianfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied agents operating in smart homes must understand human behavior
through diverse sensory inputs and communicate via natural language. While
Vision-Language Models (VLMs) have enabled impressive language-grounded
perception, their reliance on visual data limits robustness in real-world
scenarios with occlusions, poor lighting, or privacy constraints. In this
paper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that
integrates uncommon but powerful sensing modalities, such as LiDAR, infrared,
mmWave radar, and WiFi, to enable seamless human perception and reasoning
across heterogeneous environments. We address two key challenges: (1) the
scarcity of aligned modality-text data for rare sensors, and (2) the
heterogeneity of their physical signal representations. To overcome these, we
design a Universal Modality-Injection Projector (UMIP) that enhances
pre-aligned modality embeddings with fine-grained, text-aligned features from
tailored encoders via coarse-to-fine cross-attention without introducing
significant alignment overhead. We further introduce a human-VLM collaborative
data curation pipeline to generate paired textual annotations for sensing
datasets. Extensive experiments on two newly constructed benchmarks show that
HoloLLM significantly outperforms existing MLLMs, improving language-grounded
human sensing accuracy by up to 30%. This work establishes a new foundation for
real-world, language-informed multisensory embodied intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 13 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixing Yang, Xulong Tang, Ziqiao Peng, Yuxuan Hu, Jun He, Hongyan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music-driven 3D dance generation has attracted increasing attention in recent
years, with promising applications in choreography, virtual reality, and
creative content creation. Previous research has generated promising realistic
dance movement from audio signals. However, traditional methods underutilize
genre conditioning, often treating it as auxiliary modifiers rather than core
semantic drivers. This oversight compromises music-motion synchronization and
disrupts dance genre continuity, particularly during complex rhythmic
transitions, thereby leading to visually unsatisfactory effects. To address the
challenge, we propose MEGADance, a novel architecture for music-driven 3D dance
generation. By decoupling choreographic consistency into dance generality and
genre specificity, MEGADance demonstrates significant dance quality and strong
genre controllability. It consists of two stages: (1) High-Fidelity Dance
Quantization Stage (HFDQ), which encodes dance motions into a latent
representation by Finite Scalar Quantization (FSQ) and reconstructs them with
kinematic-dynamic constraints, and (2) Genre-Aware Dance Generation Stage
(GADG), which maps music into the latent representation by synergistic
utilization of Mixture-of-Experts (MoE) mechanism with Mamba-Transformer hybrid
backbone. Extensive experiments on the FineDance and AIST++ dataset demonstrate
the state-of-the-art performance of MEGADance both qualitatively and
quantitatively. Code will be released upon acceptance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2505.14222</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Co-Reinforcement Learning for Unified Multimodal Understanding and
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingjing Jiang, Chongjie Si, Jun Luo, Hanwang Zhang, Chao Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a pioneering exploration of reinforcement learning (RL)
via group relative policy optimization for unified multimodal large language
models (ULMs), aimed at simultaneously reinforcing generation and understanding
capabilities. Through systematic pilot studies, we uncover the significant
potential of ULMs to enable the synergistic co-evolution of dual capabilities
within a shared policy optimization framework. Building on this insight, we
introduce \textbf{CoRL}, a co-reinforcement learning framework comprising a
unified RL stage for joint optimization and a refined RL stage for
task-specific enhancement. With the proposed CoRL, our resulting model,
\textbf{ULM-R1}, achieves average improvements of \textbf{7%} on three
text-to-image generation datasets and \textbf{23%} on nine multimodal
understanding benchmarks. These results demonstrate the effectiveness of CoRL
and highlight the substantial benefit of reinforcement learning in facilitating
cross-task synergy and optimization for ULMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor
  Segmentation with Missing Modalities <span class="chip">MICCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16809v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16809v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junze Wang, Lei Fan, Weipeng Jing, Donglin Di, Yang Song, Sidong Liu, Cong Cong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for multimodal MRI segmentation with missing modalities
typically assume that all MRI modalities are available during training.
However, in clinical practice, some modalities may be missing due to the
sequential nature of MRI acquisition, leading to performance degradation.
Furthermore, retraining models to accommodate newly available modalities can be
inefficient and may cause overfitting, potentially compromising previously
learned knowledge. To address these challenges, we propose Replay-based
Hypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation
with missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to
enable the segmentation model to learn from newly acquired MRI modalities
without forgetting previously learned information. To enhance segmentation
performance across diverse patient scenarios, we introduce the Cross-Patient
Hypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture
high-order associations between patients. Additionally, we incorporate
Tversky-Aware Contrastive (TAC) loss to effectively mitigate information
imbalance both across and within different modalities. Extensive experiments on
the BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art
methods, achieving an improvement of over 2% in the Dice Similarity Coefficient
across various tumor regions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MICCAI 2025 Early Accept. The code is available at
  https://github.com/reeive/ReHyDIL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReactDiff: Latent Diffusion for Facial Reaction Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14151v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14151v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaming Li, Sheng Wang, Xin Wang, Yitao Zhu, Honglin Xiong, Zixu Zhuang, Qian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the audio-visual clip of the speaker, facial reaction generation aims
to predict the listener's facial reactions. The challenge lies in capturing the
relevance between video and audio while balancing appropriateness, realism, and
diversity. While prior works have mostly focused on uni-modal inputs or
simplified reaction mappings, recent approaches such as PerFRDiff have explored
multi-modal inputs and the one-to-many nature of appropriate reaction mappings.
In this work, we propose the Facial Reaction Diffusion (ReactDiff) framework
that uniquely integrates a Multi-Modality Transformer with conditional
diffusion in the latent space for enhanced reaction generation. Unlike existing
methods, ReactDiff leverages intra- and inter-class attention for fine-grained
multi-modal interaction, while the latent diffusion process between the encoder
and decoder enables diverse yet contextually appropriate outputs. Experimental
results demonstrate that ReactDiff significantly outperforms existing
approaches, achieving a facial reaction correlation of 0.26 and diversity score
of 0.094 while maintaining competitive realism. The code is open-sourced at
\href{https://github.com/Hunan-Tiger/ReactDiff}{github}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Neural Networks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Classification and Out-of-distribution Detection for
  Multimodal Intent Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12453v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12453v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanlei Zhang, Qianrui Zhou, Hua Xu, Jianhua Su, Roberto Evans, Kai Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal intent understanding is a significant research area that requires
effective leveraging of multiple modalities to analyze human language. Existing
methods face two main challenges in this domain. Firstly, they have limitations
in capturing the nuanced and high-level semantics underlying complex
in-distribution (ID) multimodal intents. Secondly, they exhibit poor
generalization when confronted with unseen out-of-distribution (OOD) data in
real-world scenarios. To address these issues, we propose a novel method for
both ID classification and OOD detection (MIntOOD). We first introduce a
weighted feature fusion network that models multimodal representations. This
network dynamically learns the importance of each modality, adapting to
multimodal contexts. To develop discriminative representations for both tasks,
we synthesize pseudo-OOD data from convex combinations of ID data and engage in
multimodal representation learning from both coarse-grained and fine-grained
perspectives. The coarse-grained perspective focuses on distinguishing between
ID and OOD binary classes, while the fine-grained perspective not only enhances
the discrimination between different ID classes but also captures
instance-level interactions between ID and OOD samples, promoting proximity
among similar instances and separation from dissimilar ones. We establish
baselines for three multimodal intent datasets and build an OOD benchmark.
Extensive experiments on these datasets demonstrate that our method
significantly improves OOD detection performance with a 3~10% increase in AUROC
scores while achieving new state-of-the-art results in ID classification. Data
and codes are available at https://github.com/thuiar/MIntOOD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Multimedia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What Media Frames Reveal About Stance: A <span class="highlight-title">Dataset</span> and Study about Memes
  in Climate Change Discourse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijia Zhou, Siyao Peng, Simon Luebke, Jörg Haßler, Mario Haim, Saif M. Mohammad, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Media framing refers to the emphasis on specific aspects of perceived reality
to shape how an issue is defined and understood. Its primary purpose is to
shape public perceptions often in alignment with the authors' opinions and
stances. However, the interaction between stance and media frame remains
largely unexplored. In this work, we apply an interdisciplinary approach to
conceptualize and computationally explore this interaction with internet memes
on climate change. We curate CLIMATEMEMES, the first dataset of climate-change
memes annotated with both stance and media frames, inspired by research in
communication science. CLIMATEMEMES includes 1,184 memes sourced from 47
subreddits, enabling analysis of frame prominence over time and communities,
and sheds light on the framing preferences of different stance holders. We
propose two meme understanding tasks: stance detection and media frame
detection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the
corresponding results on their LLM backbone. Human captions consistently
enhance performance. Synthetic captions and human-corrected OCR also help
occasionally. Our findings highlight that VLMs perform well on stance, but
struggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'
limitations in handling nuanced frames and stance expressions on climate change
internet memes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-22T00:00:00Z">2025-05-22</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">40</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich
  Document Understanding <span class="chip">COLING 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17330v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17330v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amit Agarwal, Srikant Panda, Kulbhushan Pachauri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose Few Shot Domain Adapting Graph (FS-DAG), a scalable
and efficient model architecture for visually rich document understanding
(VRDU) in few-shot settings. FS-DAG leverages domain-specific and
language/vision specific backbones within a modular framework to adapt to
diverse document types with minimal data. The model is robust to practical
challenges such as handling OCR errors, misspellings, and domain shifts, which
are critical in real-world deployments. FS-DAG is highly performant with less
than 90M parameters, making it well-suited for complex real-world applications
for Information Extraction (IE) tasks where computational resources are
limited. We demonstrate FS-DAG's capability through extensive experiments for
information extraction task, showing significant improvements in convergence
speed and performance compared to state-of-the-art methods. Additionally, this
work highlights the ongoing progress in developing smaller, more efficient
models that do not compromise on performance. Code :
https://github.com/oracle-samples/fs-dag
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in the Proceedings of the 31st International Conference on
  Computational Linguistics (COLING 2025), Industry Track, pages 100-114</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VoxRAG: A Step Toward Transcription-Free RAG Systems in Spoken Question
  Answering <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zackary Rackauckas, Julia Hirschberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce VoxRAG, a modular speech-to-speech retrieval-augmented
generation system that bypasses transcription to retrieve semantically relevant
audio segments directly from spoken queries. VoxRAG employs silence-aware
segmentation, speaker diarization, CLAP audio embeddings, and FAISS retrieval
using L2-normalized cosine similarity. We construct a 50-query test set
recorded as spoken input by a native English speaker. Retrieval quality was
evaluated using LLM-as-a-judge annotations. For very relevant segments, cosine
similarity achieved a Recall@10 of 0.34. For somewhat relevant segments,
Recall@10 rose to 0.60 and nDCG@10 to 0.27, highlighting strong topical
alignment. Answer quality was judged on a 0--2 scale across relevance,
accuracy, completeness, and precision, with mean scores of 0.84, 0.58, 0.56,
and 0.46 respectively. While precision and retrieval quality remain key
limitations, VoxRAG shows that transcription-free speech-to-speech retrieval is
feasible in RAG systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2025 Workshop MAGMaR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Content Moderation in TV Search: Balancing Policy Compliance, Relevance,
  and User Experience <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17207v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17207v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adeep Hande, Kishorekumar Sundararajan, Sardar Hamidian, Ferhan Ture
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Millions of people rely on search functionality to find and explore content
on entertainment platforms. Modern search systems use a combination of
candidate generation and ranking approaches, with advanced methods leveraging
deep learning and LLM-based techniques to retrieve, generate, and categorize
search results. Despite these advancements, search algorithms can still surface
inappropriate or irrelevant content due to factors like model unpredictability,
metadata errors, or overlooked design flaws. Such issues can misalign with
product goals and user expectations, potentially harming user trust and
business outcomes. In this work, we introduce an additional monitoring layer
using Large Language Models (LLMs) to enhance content moderation. This
additional layer flags content if the user did not intend to search for it.
This approach serves as a baseline for product quality assurance, with
collected feedback used to refine the initial retrieval mechanisms of the
search model, ensuring a safer and more reliable user experience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025 Industry Track. 5 pages, 1 figure, 2 tables.
  DOI: 10.1145/3726302.3731962</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs
  via Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17005v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17005v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are powerful but prone to hallucinations due to
static knowledge. Retrieval-Augmented Generation (RAG) helps by injecting
external information, but current methods often are costly, generalize poorly,
or ignore the internal knowledge of the model. In this paper, we introduce
R1-Searcher++, a novel framework designed to train LLMs to adaptively leverage
both internal and external knowledge sources. R1-Searcher++ employs a two-stage
training strategy: an initial SFT Cold-start phase for preliminary format
learning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses
outcome-supervision to encourage exploration, incorporates a reward mechanism
for internal knowledge utilization, and integrates a memorization mechanism to
continuously assimilate retrieved information, thereby enriching the model's
internal knowledge. By leveraging internal knowledge and external search
engine, the model continuously improves its capabilities, enabling efficient
retrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++
outperforms previous RAG and reasoning methods and achieves efficient
retrieval. The code is available at
https://github.com/RUCAIBox/R1-Searcher-plus.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $\text{R}^2\text{ec}$: Towards Large Recommender Models with Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runyang You, Yongqi Li, Xinyu Lin, Xin Zhang, Wenjie Wang, Wenjie Li, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large recommender models have extended LLMs as powerful recommenders via
encoding or item generation, and recent breakthroughs in LLM reasoning
synchronously motivate the exploration of reasoning in recommendation. Current
studies usually position LLMs as external reasoning modules to yield auxiliary
thought for augmenting conventional recommendation pipelines. However, such
decoupled designs are limited in significant resource cost and suboptimal joint
optimization. To address these issues, we propose \name, a unified large
recommender model with intrinsic reasoning capabilities. Initially, we
reconceptualize the model architecture to facilitate interleaved reasoning and
recommendation in the autoregressive process. Subsequently, we propose RecPO, a
corresponding reinforcement learning framework that optimizes \name\ both the
reasoning and recommendation capabilities simultaneously in a single policy
update; RecPO introduces a fused reward scheme that solely leverages
recommendation labels to simulate the reasoning capability, eliminating
dependency on specialized reasoning annotations. Experiments on three datasets
with various baselines verify the effectiveness of \name, showing relative
improvements of 68.67\% in Hit@5 and 45.21\% in NDCG@20. Code available at
https://github.com/YRYangang/RRec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard
  Negatives for Robust Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16967v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16967v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nandan Thakur, Crystina Zhang, Xueguang Ma, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training robust retrieval and reranker models typically relies on large-scale
retrieval datasets; for example, the BGE collection contains 1.6 million
query-passage pairs sourced from various data sources. However, we find that
certain datasets can negatively impact model effectiveness -- pruning 8 out of
15 datasets from the BGE collection reduces the training set size by
2.35$\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a
deeper examination of training data quality, with a particular focus on "false
negatives", where relevant passages are incorrectly labeled as irrelevant. We
propose a simple, cost-effective approach using cascading LLM prompts to
identify and relabel hard negatives. Experimental results show that relabeling
false negatives with true positives improves both E5 (base) and Qwen2.5-7B
retrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot
AIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on
the relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the
cascading design is further supported by human annotation results, where we
find judgment by GPT-4o shows much higher agreement with humans than
GPT-4o-mini.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at https://github.com/castorini/rlhn & datasets are
  available at https://huggingface.co/rlhn</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Don't "Overthink" Passage Reranking: Is Reasoning Truly Necessary? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16886v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16886v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nour Jedidi, Yung-Sung Chuang, James Glass, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing success of reasoning models across complex natural language
tasks, researchers in the Information Retrieval (IR) community have begun
exploring how similar reasoning capabilities can be integrated into passage
rerankers built on Large Language Models (LLMs). These methods typically employ
an LLM to produce an explicit, step-by-step reasoning process before arriving
at a final relevance prediction. But, does reasoning actually improve reranking
accuracy? In this paper, we dive deeper into this question, studying the impact
of the reasoning process by comparing reasoning-based pointwise rerankers
(ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under
identical training conditions, and observe that StandardRR generally
outperforms ReasonRR. Building on this observation, we then study the
importance of reasoning to ReasonRR by disabling its reasoning process
(ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more
effective than ReasonRR. Examining the cause of this result, our findings
reveal that reasoning-based rerankers are limited by the LLM's reasoning
process, which pushes it toward polarized relevance scores and thus fails to
consider the partial relevance of passages, a key factor for the accuracy of
pointwise rerankers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LARES: Latent Reasoning for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16865v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16865v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enze Liu, Bowen Zheng, Xiaolei Wang, Wayne Xin Zhao, Jinpeng Wang, Sheng Chen, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems have become increasingly important in
real-world applications that model user behavior sequences to predict their
preferences. However, existing sequential recommendation methods predominantly
rely on non-reasoning paradigms, which may limit the model's computational
capacity and result in suboptimal recommendation performance. To address these
limitations, we present LARES, a novel and scalable LAtent REasoning framework
for Sequential recommendation that enhances model's representation capabilities
through increasing the computation density of parameters by depth-recurrent
latent reasoning. Our proposed approach employs a recurrent architecture that
allows flexible expansion of reasoning depth without increasing parameter
complexity, thereby effectively capturing dynamic and intricate user interest
patterns. A key difference of LARES lies in refining all input tokens at each
implicit reasoning step to improve the computation utilization. To fully unlock
the model's reasoning potential, we design a two-phase training strategy: (1)
Self-supervised pre-training (SPT) with dual alignment objectives; (2)
Reinforcement post-training (RPT). During the first phase, we introduce
trajectory-level alignment and step-level alignment objectives, which enable
the model to learn recommendation-oriented latent reasoning patterns without
requiring supplementary annotated data. The subsequent phase utilizes
reinforcement learning (RL) to harness the model's exploratory ability, further
refining its reasoning capabilities. Comprehensive experiments on real-world
benchmarks demonstrate our framework's superior performance. Notably, LARES
exhibits seamless compatibility with existing advanced models, further
improving their recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViDoRe Benchmark V2: Raising the Bar for Visual Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17166v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17166v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quentin Macé, António Loison, Manuel Faysse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ViDoRe Benchmark V1 was approaching saturation with top models exceeding
90% nDCG@5, limiting its ability to discern improvements. ViDoRe Benchmark V2
introduces realistic, challenging retrieval scenarios via blind contextual
querying, long and cross-document queries, and a hybrid synthetic and
human-in-the-loop query generation process. It comprises four diverse,
multilingual datasets and provides clear evaluation instructions. Initial
results demonstrate substantial room for advancement and highlight insights on
model generalization and multilingual capability. This benchmark is designed as
a living resource, inviting community contributions to maintain relevance
through future evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a HuggingFace Blog</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented
  Generation via Knowledge Graph Walks <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16849v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16849v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Martin Böckling, Heiko Paulheim, Andreea Iana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have showcased impressive reasoning abilities,
but often suffer from hallucinations or outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by
grounding LLM responses in structured external information from a knowledge
base. However, many KG-based RAG approaches struggle with (i) aligning KG and
textual representations, (ii) balancing retrieval accuracy and efficiency, and
(iii) adapting to dynamically updated KGs. In this work, we introduce
Walk&Retrieve, a simple yet effective KG-based framework that leverages
walk-based graph traversal and knowledge verbalization for corpus generation
for zero-shot RAG. Built around efficient KG walks, our method does not require
fine-tuning on domain-specific data, enabling seamless adaptation to KG
updates, reducing computational overhead, and allowing integration with any
off-the-shelf backbone LLM. Despite its simplicity, Walk&Retrieve performs
competitively, often outperforming existing RAG systems in response accuracy
and hallucination reduction. Moreover, it demonstrates lower query latency and
robust scalability to large KGs, highlighting the potential of lightweight
retrieval strategies as strong baselines for future RAG research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the Information Retrieval's Role in RAG Systems (IR-RAG
  2025) in conjunction with SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning
  Trajectory Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16834v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16834v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) systems have advanced large language
models (LLMs) in complex deep search scenarios requiring multi-step reasoning
and iterative information retrieval. However, existing approaches face critical
limitations that lack high-quality training trajectories or suffer from the
distributional mismatches in simulated environments and prohibitive
computational costs for real-world deployment. This paper introduces
SimpleDeepSearcher, a lightweight yet effective framework that bridges this gap
through strategic data engineering rather than complex training paradigms. Our
approach synthesizes high-quality training data by simulating realistic user
interactions in live web search environments, coupled with a multi-criteria
curation strategy that optimizes the diversity and quality of input and output
side. Experiments on five benchmarks across diverse domains demonstrate that
SFT on only 871 curated samples yields significant improvements over RL-based
baselines. Our work establishes SFT as a viable pathway by systematically
addressing the data-scarce bottleneck, offering practical insights for
efficient deep search systems. Our code is available at
https://github.com/RUCAIBox/SimpleDeepSearcher.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DeepRec: Towards a Deep Dive Into the Item Space with Large Language
  Model Based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16810v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16810v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zheng, Xiaolei Wang, Enze Liu, Xi Wang, Lu Hongyu, Yu Chen, Wayne Xin Zhao, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large language models (LLMs) have been introduced into recommender
systems (RSs), either to enhance traditional recommendation models (TRMs) or
serve as recommendation backbones. However, existing LLM-based RSs often do not
fully exploit the complementary advantages of LLMs (e.g., world knowledge and
reasoning) and TRMs (e.g., recommendation-specific knowledge and efficiency) to
fully explore the item space. To address this, we propose DeepRec, a novel
LLM-based RS that enables autonomous multi-turn interactions between LLMs and
TRMs for deep exploration of the item space. In each interaction turn, LLMs
reason over user preferences and interact with TRMs to retrieve candidate
items. After multi-turn interactions, LLMs rank the retrieved items to generate
the final recommendations. We adopt reinforcement learning(RL) based
optimization and propose novel designs from three aspects: recommendation model
based data rollout, recommendation-oriented hierarchical rewards, and a
two-stage RL training strategy. For data rollout, we introduce a
preference-aware TRM, with which LLMs interact to construct trajectory data.
For rewards, we design a hierarchical reward function that involves both
process-level and outcome-level rewards to optimize the interaction process and
recommendation performance, respectively. For RL training, we develop a
two-stage training strategy, where the first stage aims to guide LLMs to
interact with TRMs and the second stage focuses on performance improvement.
Experiments on public datasets demonstrate that DeepRec significantly
outperforms both traditional and LLM-based baselines, offering a new paradigm
for deep exploration in recommendation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kexin Zhang, Junlan Chen, Daifeng Li, Yuxuan Zhang, Yangyang Feng, Bowen Deng, Weixu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) encounter difficulties in knowledge-intensive
multi-step reasoning (KIMSR) tasks. One challenge is how to effectively extract
and represent rationale evidence. The current methods often extract
semantically relevant but logically irrelevant evidence, resulting in flawed
reasoning and inaccurate responses. We propose a two-way evidence
self-alignment (TW-ESA) module, which utilizes the mutual alignment between
strict reasoning and LLM reasoning to enhance its understanding of the causal
logic of evidence, thereby addressing the first challenge. Another challenge is
how to utilize the rationale evidence and LLM's intrinsic knowledge for
accurate reasoning when the evidence contains uncertainty. We propose a
dual-gated reasoning enhancement (DGR) module to gradually fuse useful
knowledge of LLM within strict reasoning, which can enable the model to perform
accurate reasoning by focusing on causal elements in the evidence and exhibit
greater robustness. The two modules are collaboratively trained in a unified
framework ESA-DGR. Extensive experiments on three diverse and challenging KIMSR
datasets reveal that ESA-DGR significantly surpasses state-of-the-art LLM-based
fine-tuning methods, with remarkable average improvements of 4% in exact match
(EM) and 5% in F1 score. The implementation code is available at
https://anonymous.4open.science/r/ESA-DGR-2BF8.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on
  Capturing Real-World Changes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiehan Cheng, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose DailyQA, an automatically updated dynamic dataset that updates
questions weekly and contains answers to questions on any given date. DailyQA
utilizes daily updates from Wikipedia revision logs to implement a fully
automated pipeline of data filtering, query generation synthesis, quality
checking, answer extraction, and query classification. The benchmark requires
large language models (LLMs) to process and answer questions involving
fast-changing factual data and covering multiple domains. We evaluate several
open-source and closed-source LLMs using different RAG pipelines with web
search augmentation. We compare the ability of different models to process
time-sensitive web information and find that rerank of web retrieval results is
critical. Our results indicate that LLMs still face significant challenges in
handling frequently updated information, suggesting that DailyQA benchmarking
provides valuable insights into the direction of progress for LLMs and RAG
systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representation Discrepancy Bridging Method for Remote Sensing Image-Text
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16756v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16756v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hailong Ning, Siying Wang, Tao Lei, Xiaopeng Cao, Huanmin Dou, Bin Zhao, Asoke K. Nandi, Petia Radeva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in
geographic information interpretation, disaster monitoring, and urban planning
by establishing semantic associations between image and textual descriptions.
Existing Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language
Pre-training (VLP) models typically adopt symmetric adapter structures for
exploring cross-modal correlations. However, the strong discriminative nature
of text modality may dominate the optimization process and inhibits image
representation learning. The nonnegligible imbalanced cross-modal optimization
remains a bottleneck to enhancing the model performance. To address this issue,
this study proposes a Representation Discrepancy Bridging (RDB) method for the
RSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is
designed to enable modality-specific optimization and improve feature
alignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text
Semantic Adapter (TSA). VEA mines fine-grained image features by Differential
Attention (DA) mechanism, while TSA identifies key textual semantics through
Hierarchical Attention (HA) mechanism. On the other hand, this study extends
the traditional single-task retrieval framework to a dual-task optimization
framework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves
cross-modal alignment robustness through an adaptive weighted combination of
cross-modal, classification, and exponential moving average consistency
constraints. Experiments on RSICD and RSITMD datasets show that the proposed
RDB method achieves a 6%-11% improvement in mR metrics compared to
state-of-the-art PEFT methods and a 1.15%-2% improvement over the full
fine-tuned GeoRSCLIP model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Action is All You Need: Dual-Flow Generative Ranking Network for
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Guo, Erpeng Xue, Lei Huang, Shichao Wang, Xiaolei Wang, Lei Wang, Jinpeng Wang, Sheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream
architecture designed for recommendation systems. DFGR integrates innovative
interaction patterns between real and fake flows within the QKV modules of the
self-attention mechanism, enhancing both training and inference efficiency.
This approach effectively addresses a key limitation observed in Meta's
proposed HSTU generative recommendation approach, where heterogeneous
information volumes are mapped into identical vector spaces, leading to
training instability. Unlike traditional recommendation models, DFGR only
relies on user history behavior sequences and minimal attribute information,
eliminating the need for extensive manual feature engineering. Comprehensive
evaluations on open-source and industrial datasets reveal DFGR's superior
performance compared to established baselines such as DIN, DCN, DIEN, and
DeepFM. We also investigate optimal parameter allocation strategies under
computational constraints, establishing DFGR as an efficient and effective
next-generation generate ranking paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Generative Model with Causality Constraint for Mitigating Biases
  in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianfeng Deng, Qingfeng Chen, Debo Cheng, Jiuyong Li, Lin Liu, Shichao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately predicting counterfactual user feedback is essential for building
effective recommender systems. However, latent confounding bias can obscure the
true causal relationship between user feedback and item exposure, ultimately
degrading recommendation performance. Existing causal debiasing approaches
often rely on strong assumptions-such as the availability of instrumental
variables (IVs) or strong correlations between latent confounders and proxy
variables-that are rarely satisfied in real-world scenarios. To address these
limitations, we propose a novel generative framework called Latent Causality
Constraints for Debiasing representation learning in Recommender Systems
(LCDR). Specifically, LCDR leverages an identifiable Variational Autoencoder
(iVAE) as a causal constraint to align the latent representations learned by a
standard Variational Autoencoder (VAE) through a unified loss function. This
alignment allows the model to leverage even weak or noisy proxy variables to
recover latent confounders effectively. The resulting representations are then
used to improve recommendation performance. Extensive experiments on three
real-world datasets demonstrate that LCDR consistently outperforms existing
methods in both mitigating bias and improving recommendation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MDVT: Enhancing Multimodal Recommendation with Model-Agnostic
  Multimodal-Driven Virtual Triplets <span class="chip">KDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinfeng Xu, Zheyu Chen, Jinze Li, Shuo Yang, Hewei Wang, Yijie Li, Mengran Li, Puzhen Wu, Edith C. H. Ngai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The data sparsity problem significantly hinders the performance of
recommender systems, as traditional models rely on limited historical
interactions to learn user preferences and item properties. While incorporating
multimodal information can explicitly represent these preferences and
properties, existing works often use it only as side information, failing to
fully leverage its potential. In this paper, we propose MDVT, a model-agnostic
approach that constructs multimodal-driven virtual triplets to provide valuable
supervision signals, effectively mitigating the data sparsity problem in
multimodal recommendation systems. To ensure high-quality virtual triplets, we
introduce three tailored warm-up threshold strategies: static, dynamic, and
hybrid. The static warm-up threshold strategy exhaustively searches for the
optimal number of warm-up epochs but is time-consuming and computationally
intensive. The dynamic warm-up threshold strategy adjusts the warm-up period
based on loss trends, improving efficiency but potentially missing optimal
performance. The hybrid strategy combines both, using the dynamic strategy to
find the approximate optimal number of warm-up epochs and then refining it with
the static strategy in a narrow hyper-parameter space. Once the warm-up
threshold is satisfied, the virtual triplets are used for joint model
optimization by our enhanced pair-wise loss function without causing
significant gradient skew. Extensive experiments on multiple real-world
datasets demonstrate that integrating MDVT into advanced multimodal
recommendation models effectively alleviates the data sparsity problem and
improves recommendation performance, particularly in sparse data scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MiLQ: Benchmarking IR Models for Bilingual Web Search with Mixed
  Language Queries 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonghwi Kim, Deokhyung Kang, Seonjeong Hwang, Yunsu Kim, Jungseul Ok, Gary Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite bilingual speakers frequently using mixed-language queries in web
searches, Information Retrieval (IR) research on them remains scarce. To
address this, we introduce MiLQ,Mixed-Language Query test set, the first public
benchmark of mixed-language queries, confirmed as realistic and highly
preferred. Experiments show that multilingual IR models perform moderately on
MiLQ and inconsistently across native, English, and mixed-language queries,
also suggesting code-switched training data's potential for robust IR models
handling such queries. Meanwhile, intentional English mixing in queries proves
an effective strategy for bilinguals searching English documents, which our
analysis attributes to enhanced token matching compared to native queries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causal-Invariant Cross-Domain Out-of-Distribution Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajie Zhu, Yan Wang, Feng Zhu, Pengfei Ding, Hongyang Liu, Zhu Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Recommendation (CDR) aims to leverage knowledge from a
relatively data-richer source domain to address the data sparsity problem in a
relatively data-sparser target domain. While CDR methods need to address the
distribution shifts between different domains, i.e., cross-domain distribution
shifts (CDDS), they typically assume independent and identical distribution
(IID) between training and testing data within the target domain. However, this
IID assumption rarely holds in real-world scenarios due to single-domain
distribution shift (SDDS). The above two co-existing distribution shifts lead
to out-of-distribution (OOD) environments that hinder effective knowledge
transfer and generalization, ultimately degrading recommendation performance in
CDR. To address these co-existing distribution shifts, we propose a novel
Causal-Invariant Cross-Domain Out-of-distribution Recommendation framework,
called CICDOR. In CICDOR, we first learn dual-level causal structures to infer
domain-specific and domain-shared causal-invariant user preferences for
tackling both CDDS and SDDS under OOD environments in CDR. Then, we propose an
LLM-guided confounder discovery module that seamlessly integrates LLMs with a
conventional causal discovery method to extract observed confounders for
effective deconfounding, thereby enabling accurate causal-invariant preference
inference. Extensive experiments on two real-world datasets demonstrate the
superior recommendation accuracy of CICDOR over state-of-the-art methods across
various OOD scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Utilizing citation index and synthetic quality measure to compare
  Wikipedia languages across various topics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16506v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16506v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Włodzimierz Lewoniewski, Krzysztof Węcel, Witold Abramowicz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a comparative analysis of 55 Wikipedia language editions
employing a citation index alongside a synthetic quality measure. Specifically,
we identified the most significant Wikipedia articles within distinct topical
areas, selecting the top 10, top 25, and top 100 most cited articles in each
topic and language version. This index was built on the basis of wikilinks
between Wikipedia articles in each language version and in order to do that we
processed 6.6 billion page-to-page link records. Next, we used a quality score
for each Wikipedia article - a synthetic measure scaled from 0 to 100. This
approach enabled quality comparison of Wikipedia articles even between language
versions with different quality grading schemes. Our results highlight
disparities among Wikipedia language editions, revealing strengths and gaps in
content coverage and quality across topics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at the Wiki Workshop 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Retrieval-Augmented Multimomal Generation for Document
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuicai Dong, Yujing Chang, Shijie Huang, Yasheng Wang, Ruiming Tang, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document Visual Question Answering (DocVQA) faces dual challenges in
processing lengthy multimodal documents (text, images, tables) and performing
cross-modal reasoning. Current document retrieval-augmented generation (DocRAG)
methods remain limited by their text-centric approaches, frequently missing
critical visual information. The field also lacks robust benchmarks for
assessing multimodal evidence selection and integration. We introduce MMDocRAG,
a comprehensive benchmark featuring 4,055 expert-annotated QA pairs with
multi-page, cross-modal evidence chains. Our framework introduces innovative
metrics for evaluating multimodal quote selection and enables answers that
interleave text with relevant visual elements. Through large-scale experiments
with 60 VLM/LLM models and 14 retrieval systems, we identify persistent
challenges in multimodal evidence retrieval, selection, and integration.Key
findings reveal advanced proprietary LVMs show superior performance than
open-sourced alternatives. Also, they show moderate advantages using multimodal
inputs over text-only inputs, while open-source alternatives show significant
performance degradation. Notably, fine-tuned LLMs achieve substantial
improvements when using detailed image descriptions. MMDocRAG establishes a
rigorous testing ground and provides actionable insights for developing more
robust multimodal DocVQA systems. Our benchmark and code are available at
https://mmdocrag.github.io/MMDocRAG/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint. code available at
  \url{https://mmdocrag.github.io/MMDocRAG/}</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for
  GNN-based Recommendation Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Yan, Cai Xu, Xujing Wang, Ziyu Guan, Wei Zhao, Yuhang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems based on graph neural networks perform well in tasks such
as rating and ranking. However, in real-world recommendation scenarios, noise
such as user misuse and malicious advertisement gradually accumulates through
the message propagation mechanism. Even if existing studies mitigate their
effects by reducing the noise propagation weights, the severe sparsity of the
recommender system still leads to the low-weighted noisy neighbors being
mistaken as meaningful information, and the prediction result obtained based on
the polluted nodes is not entirely trustworthy. Therefore, it is crucial to
measure the confidence of the prediction results in this highly noisy
framework. Furthermore, our evaluation of the existing representative GNN-based
recommendation shows that it suffers from overconfidence. Based on the above
considerations, we propose a new method to quantify and calibrate the
prediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically,
we propose a rating calibration method that dynamically adjusts excessive
ratings to mitigate overconfidence based on user personalization. We also
design a confidence loss function to reduce the overconfidence of negative
samples and effectively improve recommendation performance. Experiments on
public datasets demonstrate the validity of Conf-GNNRec in prediction
confidence and recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented
  Generation Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongru Song, Yu-an Liu, Ruqing Zhang, Jiafeng Guo, Yixing Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) systems can effectively mitigate the
hallucination problem of large language models (LLMs),but they also possess
inherent vulnerabilities. Identifying these weaknesses before the large-scale
real-world deployment of RAG systems is of great importance, as it lays the
foundation for building more secure and robust RAG systems in the future.
Existing adversarial attack methods typically exploit knowledge base poisoning
to probe the vulnerabilities of RAG systems, which can effectively deceive
standard RAG models. However, with the rapid advancement of deep reasoning
capabilities in modern LLMs, previous approaches that merely inject incorrect
knowledge are inadequate when attacking RAG systems equipped with deep
reasoning abilities. Inspired by the deep thinking capabilities of LLMs, this
paper extracts reasoning process templates from R1-based RAG systems, uses
these templates to wrap erroneous knowledge into adversarial documents, and
injects them into the knowledge base to attack RAG systems. The key idea of our
approach is that adversarial documents, by simulating the chain-of-thought
patterns aligned with the model's training signals, may be misinterpreted by
the model as authentic historical reasoning processes, thus increasing their
likelihood of being referenced. Experiments conducted on the MS MARCO passage
ranking dataset demonstrate the effectiveness of our proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages,3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flow Matching based Sequential Recommender Model <span class="chip">IJCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feng Liu, Lixin Zou, Xiangyu Zhao, Min Tang, Liming Dong, Dan Luo, Xiangyang Luo, Chenliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models, particularly diffusion model, have emerged as powerful
tools for sequential recommendation. However, accurately modeling user
preferences remains challenging due to the noise perturbations inherent in the
forward and reverse processes of diffusion-based methods. Towards this end,
this study introduces FMRec, a Flow Matching based model that employs a
straight flow trajectory and a modified loss tailored for the recommendation
task. Additionally, from the diffusion-model perspective, we integrate a
reconstruction loss to improve robustness against noise perturbations, thereby
retaining user preferences during the forward process. In the reverse process,
we employ a deterministic reverse sampler, specifically an ODE-based updating
function, to eliminate unnecessary randomness, thereby ensuring that the
generated recommendations closely align with user needs. Extensive evaluations
on four benchmark datasets reveal that FMRec achieves an average improvement of
6.53% over state-of-the-art methods. The replication code is available at
https://github.com/FengLiu-1/FMRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 8 figures, IJCAI 2025 Accepted Work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine
  Retrieval and Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16133v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16133v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinyu Guo, Xunlei Chen, Qiyang Xia, Zhaokun Wang, Jie Ou, Libo Qin, Shunyu Yao, Wenhong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) encounters efficiency challenges when
scaling to massive knowledge bases while preserving contextual relevance. We
propose Hash-RAG, a framework that integrates deep hashing techniques with
systematic optimizations to address these limitations. Our queries directly
learn binary hash codes from knowledgebase code, eliminating intermediate
feature extraction steps, and significantly reducing storage and computational
overhead. Building upon this hash-based efficient retrieval framework, we
establish the foundation for fine-grained chunking. Consequently, we design a
Prompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved
hash-indexed propositions and their original document segments through prompt
engineering to enhance the LLM's contextual awareness. Experimental evaluations
on NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a
90% reduction in retrieval time compared to conventional methods while
maintaining considerate recall performance. Additionally, The proposed system
outperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emotion-based Recommender System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16121v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16121v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender system is one of the most critical technologies for large
internet companies such as Amazon and TikTok. Although millions of users use
recommender systems globally everyday, and indeed, much data analysis work has
been done to improve the technical accuracy of the system, to our limited
knowledge, there has been little attention paid to analysis of users' emotion
in recommender systems. In this paper, we create a new theory and metrics that
could capture users' emotion when they are interacting with recommender
systems. We also provide effective and efficient visualization techniques for
visualization of users' emotion and its change in the customers' lifetime
cycle. In the end, we design a framework for emotion-based recommendation
algorithms, illustrated in a straightforward example with experimental results
to demonstrate the effectiveness of our new theory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ User Feedback Alignment for LLM-powered Exploration in Large-scale
  Recommendation Systems <span class="chip">ACL'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05522v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05522v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianling Wang, Yifan Liu, Yinghao Sun, Xuejian Ma, Yueqi Wang, He Ma, Zhengyang Su, Minmin Chen, Mingyan Gao, Onkar Dalal, Ed H. Chi, Lichan Hong, Ningren Han, Haokai Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exploration, the act of broadening user experiences beyond their established
preferences, is challenging in large-scale recommendation systems due to
feedback loops and limited signals on user exploration patterns. Large Language
Models (LLMs) offer potential solutions by leveraging their world knowledge to
recommend novel content outside these loops. A key challenge is aligning LLMs
with user preferences while preserving their knowledge and reasoning. To
enhance planning for new user interests using LLMs, this paper introduces a
novel approach that combines hierarchical planning with LLM inference-time
scaling. This method aims to improve recommendation relevancy without
compromising novelty. We decouple novelty and user-alignment, training separate
LLMs for each objective. We then scale up the novelty-focused LLM's inference
and select the best-of-n predictions using the user-aligned LLM. Live
experiments demonstrate efficacy, showing significant gains in both user
satisfaction (measured by watch activity and active user counts) and
exploration diversity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL'25 (Industry) Oral</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MOHPER: Multi-objective Hyperparameter Optimization Framework for
  E-commerce Retrieval System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05227v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05227v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jungbae Park, Heonseok Jang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  E-commerce search optimization has evolved to include a wider range of
metrics that reflect user engagement and business objectives. Modern search
frameworks now incorporate advanced quality features, such as sales counts and
document-query relevance, to better align search results with these goals.
Traditional methods typically focus on click-through rate (CTR) as a measure of
engagement or relevance, but this can miss true purchase intent, creating a gap
between user interest and actual conversions. Joint training with the
click-through conversion rate (CTCVR) has become essential for understanding
buying behavior, although its sparsity poses challenges for reliable
optimization. This study presents MOHPER, a Multi-Objective Hyperparameter
Optimization framework for E-commerce Retrieval systems. Utilizing Bayesian
optimization and sampling, it jointly optimizes both CTR, CTCVR, and relevant
objectives, focusing on engagement and conversion of the users. In addition, to
improve the selection of the best configuration from multi-objective
optimization, we suggest advanced methods for hyperparameter selection,
including a meta-configuration voting strategy and a cumulative training
approach that leverages prior optimal configurations, to improve speeds of
training and efficiency. Currently deployed in a live setting, our proposed
framework substantiates its practical efficacy in achieving a balanced
optimization that aligns with both user satisfaction and revenue goals.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ThinkRec: Thinking-based recommendation via LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15091v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15091v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qihang Yu, Kairui Fu, Shengyu Zhang, Zheqi Lv, Fan Wu, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) have enabled more
semantic-aware recommendations through natural language generation. Existing
LLM for recommendation (LLM4Rec) methods mostly operate in a System 1-like
manner, relying on superficial features to match similar items based on click
history, rather than reasoning through deeper behavioral logic. This often
leads to superficial and erroneous recommendations. Motivated by this, we
propose ThinkRec, a thinking-based framework that shifts LLM4Rec from System 1
to System 2 (rational system). Technically, ThinkRec introduces a thinking
activation mechanism that augments item metadata with keyword summarization and
injects synthetic reasoning traces, guiding the model to form interpretable
reasoning chains that consist of analyzing interaction histories, identifying
user preferences, and making decisions based on target items. On top of this,
we propose an instance-wise expert fusion mechanism to reduce the reasoning
difficulty. By dynamically assigning weights to expert models based on users'
latent features, ThinkRec adapts its reasoning path to individual users,
thereby enhancing precision and personalization. Extensive experiments on
real-world datasets demonstrate that ThinkRec significantly improves the
accuracy and interpretability of recommendations. Our implementations are
available in anonymous Github: https://github.com/Yu-Qi-hang/ThinkRec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion
  for Multimodal Recommendation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04452v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04452v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinfeng Xu, Zheyu Chen, Wei Wang, Xiping Hu, Sang-Wook Kim, Edith C. H. Ngai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works in multimodal recommendations, which leverage diverse modal
information to address data sparsity and enhance recommendation accuracy, have
garnered considerable interest. Two key processes in multimodal recommendations
are modality fusion and representation learning. Previous approaches in
modality fusion often employ simplistic attentive or pre-defined strategies at
early or late stages, failing to effectively handle irrelevant information
among modalities. In representation learning, prior research has constructed
heterogeneous and homogeneous graph structures encapsulating user-item,
user-user, and item-item relationships to better capture user interests and
item profiles. Modality fusion and representation learning were considered as
two independent processes in previous work. In this paper, we reveal that these
two processes are complementary and can support each other. Specifically,
powerful representation learning enhances modality fusion, while effective
fusion improves representation quality. Stemming from these two processes, we
introduce a COmposite grapH convolutional nEtwork with dual-stage fuSION for
the multimodal recommendation, named COHESION. Specifically, it introduces a
dual-stage fusion strategy to reduce the impact of irrelevant information,
refining all modalities using ID embedding in the early stage and fusing their
representations at the late stage. It also proposes a composite graph
convolutional network that utilizes user-item, user-user, and item-item graphs
to extract heterogeneous and homogeneous latent relationships within users and
items. Besides, it introduces a novel adaptive optimization to ensure balanced
and reasonable representations across modalities. Extensive experiments on
three widely used datasets demonstrate the significant superiority of COHESION
over various competitive baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for
  Exploration and Exploitation in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13865v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13865v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiyao Ma, Menglin Yang, Mingxuan Ju, Tong Zhao, Neil Shah, Rex Ying
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern recommender systems often create information cocoons, restricting
users' exposure to diverse content. A key challenge lies in balancing content
exploration and exploitation while allowing users to adjust their
recommendation preferences. Intuitively, this balance can be modeled as a
tree-structured representation, where depth search facilitates exploitation and
breadth search enables exploration. However, existing approaches face two
fundamental limitations: Euclidean methods struggle to capture hierarchical
structures, while hyperbolic methods, despite their superior hierarchical
modeling, lack semantic understanding of user and item profiles and fail to
provide a principled mechanism for balancing exploration and exploitation. To
address these challenges, we propose HERec, a hyperbolic graph-LLM framework
that effectively balances exploration and exploitation in recommender systems.
Our framework introduces two key innovations: (1) a semantic-enhanced
hierarchical mechanism that aligns rich textual descriptions processed by large
language models (LLMs) with collaborative information directly in hyperbolic
space, allowing for more nuanced updates that respect the underlying
hierarchical structure in user-item profiles; (2) an automatic hierarchical
representation by optimizing Dasgupta's cost, which discovers hierarchical
structures without requiring predefined hyperparameters, enabling
user-adjustable exploration-exploitation trade-offs. Extensive experiments
demonstrate that HERec consistently outperforms both Euclidean and hyperbolic
baselines, achieving up to 5.49% improvement in utility metrics and 11.39%
increase in diversity metrics, effectively mitigating information cocoons. We
open-source our model implementation at https://github.com/Martin-qyma/HERec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Deconfounding via Confounder Disentanglement for Dual-Target
  Cross-Domain Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11180v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11180v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajie Zhu, Yan Wang, Feng Zhu, Zhu Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, dual-target Cross-Domain Recommendation (CDR) has been
proposed to capture comprehensive user preferences in order to ultimately
enhance the recommendation accuracy in both data-richer and data-sparser
domains simultaneously. However, in addition to users' true preferences, the
user-item interactions might also be affected by confounders (e.g., free
shipping, sales promotion). As a result, dual-target CDR has to meet two
challenges: (1) how to effectively decouple observed confounders, including
single-domain confounders and cross-domain confounders, and (2) how to preserve
the positive effects of observed confounders on predicted interactions, while
eliminating their negative effects on capturing comprehensive user preferences.
To address the above two challenges, we propose a Causal Deconfounding
framework via Confounder Disentanglement for dual-target Cross-Domain
Recommendation, called CD2CDR. In CD2CDR, we first propose a confounder
disentanglement module to effectively decouple observed single-domain and
cross-domain confounders. We then propose a causal deconfounding module to
preserve the positive effects of such observed confounders and eliminate their
negative effects via backdoor adjustment, thereby enhancing the recommendation
accuracy in each domain. Extensive experiments conducted on seven real-world
datasets demonstrate that CD2CDR significantly outperforms the state-of-the-art
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM TOIS for publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GLTW: Joint Improved Graph <span class="highlight-title">Transformer</span> and LLM via Three-Word Language
  for Knowledge Graph Completion <span class="chip">ACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11471v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11471v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Yingli Shen, Zhu Liu, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Graph Completion (KGC), which aims to infer missing or incomplete
facts, is a crucial task for KGs. However, integrating the vital structural
information of KGs into Large Language Models (LLMs) and outputting predictions
deterministically remains challenging. To address this, we propose a new method
called GLTW, which encodes the structural information of KGs and merges it with
LLMs to enhance KGC performance. Specifically, we introduce an improved Graph
Transformer (iGT) that effectively encodes subgraphs with both local and global
structural information and inherits the characteristics of language model,
bypassing training from scratch. Also, we develop a subgraph-based
multi-classification training objective, using all entities within KG as
classification objects, to boost learning efficiency.Importantly, we combine
iGT with an LLM that takes KG language prompts as input.Our extensive
experiments on various KG datasets show that GLTW achieves significant
performance gains compared to SOTA baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL2025(Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unifying Search and Recommendation: A Generative Paradigm Inspired by
  Information Theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.06714v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.06714v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jujia Zhao, Wenjie Wang, Chen Xu, Xiuying Chen, Zhaochun Ren, Suzan Verberne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems and search engines serve as foundational elements of
online platforms, with the former delivering information proactively and the
latter enabling users to seek information actively. Unifying both tasks in a
shared model is promising since it can enhance user modeling and item
understanding. Previous approaches mainly follow a discriminative paradigm,
utilizing shared encoders to process input features and task-specific heads to
perform each task. However, this paradigm encounters two key challenges:
gradient conflict and manual design complexity. From the information theory
perspective, these challenges potentially both stem from the same issue -- low
mutual information between the input features and task-specific outputs during
the optimization process.
  To tackle these issues, we propose GenSR, a novel generative paradigm for
unifying search and recommendation (S&R), which leverages task-specific prompts
to partition the model's parameter space into subspaces, thereby enhancing
mutual information. To construct effective subspaces for each task, GenSR first
prepares informative representations for each subspace and then optimizes both
subspaces in one unified model. Specifically, GenSR consists of two main
modules: (1) Dual Representation Learning, which independently models
collaborative and semantic historical information to derive expressive item
representations; and (2) S&R Task Unifying, which utilizes contrastive learning
together with instruction tuning to generate task-specific outputs effectively.
Extensive experiments on two public datasets show GenSR outperforms
state-of-the-art methods across S&R tasks. Our work introduces a new generative
paradigm compared with previous discriminative methods and establishes its
superiority from the mutual information perspective.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PoisonArena: Uncovering Competing Poisoning Attacks in
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12574v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12574v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liuji Chen, Xiaofang Yang, Yuanzhuo Lu, Jinghao Zhang, Xin Sun, Qiang Liu, Shu Wu, Jing Dong, Liang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) systems, widely used to improve the
factual grounding of large language models (LLMs), are increasingly vulnerable
to poisoning attacks, where adversaries inject manipulated content into the
retriever's corpus. While prior research has predominantly focused on
single-attacker settings, real-world scenarios often involve multiple,
competing attackers with conflicting objectives. In this work, we introduce
PoisonArena, the first benchmark to systematically study and evaluate competing
poisoning attacks in RAG. We formalize the multi-attacker threat model, where
attackers vie to control the answer to the same query using mutually exclusive
misinformation. PoisonArena leverages the Bradley-Terry model to quantify each
method's competitive effectiveness in such adversarial environments. Through
extensive experiments on the Natural Questions and MS MARCO datasets, we
demonstrate that many attack strategies successful in isolation fail under
competitive pressure. Our findings highlight the limitations of conventional
evaluation metrics like Attack Success Rate (ASR) and F1 score and underscore
the need for competitive evaluation to assess real-world attack robustness.
PoisonArena provides a standardized framework to benchmark and develop future
attack and defense strategies under more realistic, multi-adversary conditions.
Project page: https://github.com/yxf203/PoisonArena.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating LLM-based Approaches to Legal Citation Prediction:
  Domain-specific <span class="highlight-title">Pre-train</span>ing, Fine-tuning, or RAG? A Benchmark and an
  Australian Law Case Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.06272v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.06272v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiuzhou Han, Paul Burgess, Ehsan Shareghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated strong potential across legal
tasks, yet the problem of legal citation prediction remains under-explored. At
its core, this task demands fine-grained contextual understanding and precise
identification of relevant legislation or precedent. We introduce the AusLaw
Citation Benchmark, a real-world dataset comprising 55k Australian legal
instances and 18,677 unique citations which to the best of our knowledge is the
first of its scale and scope. We then conduct a systematic benchmarking across
a range of solutions: (i) standard prompting of both general and
law-specialised LLMs, (ii) retrieval-only pipelines with both generic and
domain-specific embeddings, (iii) supervised fine-tuning, and (iv) several
hybrid strategies that combine LLMs with retrieval augmentation through query
expansion, voting ensembles, or re-ranking. Results show that neither general
nor law-specific LLMs suffice as stand-alone solutions, with performance near
zero. Instruction tuning (of even a generic open-source LLM) on task-specific
dataset is among the best performing solutions. We highlight that database
granularity along with the type of embeddings play a critical role in
retrieval-based approaches, with hybrid methods which utilise a trained
re-ranker delivering the best results. Despite this, a performance gap of
nearly 50% remains, underscoring the value of this challenging benchmark as a
rigorous test-bed for future research in legal-domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>For code, data, and models see https://auslawbench.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Process vs. Outcome Reward: Which is Better for Agentic RAG
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14069v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14069v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenlin Zhang, Xiangyang Li, Kuicai Dong, Yichao Wang, Pengyue Jia, Xiaopeng Li, Yingyi Zhang, Derong Xu, Zhaocheng Du, Huifeng Guo, Ruiming Tang, Xiangyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) enhances the text generation
capabilities of large language models (LLMs) by integrating external knowledge
and up-to-date information. However, traditional RAG systems are limited by
static workflows and lack the adaptability required for multistep reasoning and
complex task management. To address these limitations, agentic RAG systems
(e.g., DeepResearch) have been proposed, enabling dynamic retrieval strategies,
iterative context refinement, and adaptive workflows for handling complex
search queries beyond the capabilities of conventional RAG. Recent advances,
such as Search-R1, have demonstrated promising gains using outcome-based
reinforcement learning, where the correctness of the final answer serves as the
reward signal. Nevertheless, such outcome-supervised agentic RAG methods face
challenges including low exploration efficiency, gradient conflict, and sparse
reward signals. To overcome these challenges, we propose to utilize
fine-grained, process-level rewards to improve training stability, reduce
computational costs, and enhance efficiency. Specifically, we introduce a novel
method ReasonRAG that automatically constructs RAG-ProGuide, a high-quality
dataset providing process-level rewards for (i) query generation, (ii) evidence
extraction, and (iii) answer generation, thereby enhancing model inherent
capabilities via process-supervised reinforcement learning. With the
process-level policy optimization, the proposed framework empowers LLMs to
autonomously invoke search, generate queries, extract relevant evidence, and
produce final answers. Compared to existing approaches such as Search-R1 and
traditional RAG systems, ReasonRAG, leveraging RAG-ProGuide, achieves superior
performance on five benchmark datasets using only 5k training instances,
significantly fewer than the 90k training instances required by Search-R1.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph-based Confidence Calibration for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02454v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02454v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reliable confidence estimation is essential for enhancing the trustworthiness
of large language models (LLMs), especially in high-stakes scenarios. Despite
its importance, accurately estimating confidence in LLM responses remains a
significant challenge. In this work, we propose using an auxiliary learning
model to assess response correctness based on the self-consistency of multiple
outputs generated by the LLM. Our method builds a consistency graph to
represent the agreement among multiple responses and uses a graph neural
network (GNN) to estimate the likelihood that each response is correct.
Experiments demonstrate that this method has strong calibration performance on
various benchmark datasets and generalizes well to out-of-domain cases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework <span class="chip">PAKDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12459v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12459v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chia-Hsuan Chang, Jui-Tse Tsai, Yi-Hang Tsai, San-Yih Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic modeling is widely used for uncovering thematic structures within text
corpora, yet traditional models often struggle with specificity and coherence
in domain-focused applications. Guided approaches, such as SeededLDA and CorEx,
incorporate user-provided seed words to improve relevance but remain
labor-intensive and static. Large language models (LLMs) offer potential for
dynamic topic refinement and discovery, yet their application often incurs high
API costs. To address these challenges, we propose the LLM-assisted Iterative
Topic Augmentation framework (LITA), an LLM-assisted approach that integrates
user-provided seeds with embedding-based clustering and iterative refinement.
LITA identifies a small number of ambiguous documents and employs an LLM to
reassign them to existing or new topics, minimizing API costs while enhancing
topic quality. Experiments on two datasets across topic quality and clustering
performance metrics demonstrate that LITA outperforms five baseline models,
including LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an
efficient and adaptable framework for advancing topic modeling and text
clustering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to PAKDD 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation
  with Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengqi Duan, Rongyao Fang, Yuqing Wang, Kun Wang, Linjiang Huang, Xingyu Zeng, Hongsheng Li, Xihui Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual generation models have made remarkable progress in creating realistic
images from text prompts, yet struggle with complex prompts that specify
multiple objects with precise spatial relationships and attributes. Effective
handling of such prompts requires explicit reasoning about the semantic content
and spatial layout. We present GoT-R1, a framework that applies reinforcement
learning to enhance semantic-spatial reasoning in visual generation. Building
upon the Generation Chain-of-Thought approach, GoT-R1 enables models to
autonomously discover effective reasoning strategies beyond predefined
templates through carefully designed reinforcement learning. To achieve this,
we propose a dual-stage multi-dimensional reward framework that leverages MLLMs
to evaluate both the reasoning process and final output, enabling effective
supervision across the entire generation pipeline. The reward system assesses
semantic alignment, spatial accuracy, and visual quality in a unified approach.
Experimental results demonstrate significant improvements on T2I-CompBench
benchmark, particularly in compositional tasks involving precise spatial
relationships and attribute binding. GoT-R1 advances the state-of-the-art in
image generation by successfully transferring sophisticated reasoning
capabilities to the visual generation domain. To facilitate future research, we
make our code and pretrained models publicly available at
https://github.com/gogoduan/GoT-R1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github page refer to: https://github.com/gogoduan/GoT-R1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose
  Interaction <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16980v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16980v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong Li, Wenqi Zhong, Wei Yu, Yingwei Pan, Dingwen Zhang, Ting Yao, Junwei Han, Tao Mei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video virtual try-on aims to seamlessly dress a subject in a video with a
specific garment. The primary challenge involves preserving the visual
authenticity of the garment while dynamically adapting to the pose and physique
of the subject. While existing methods have predominantly focused on
image-based virtual try-on, extending these techniques directly to videos often
results in temporal inconsistencies. Most current video virtual try-on
approaches alleviate this challenge by incorporating temporal modules, yet
still overlook the critical spatiotemporal pose interactions between human and
garment. Effective pose interactions in videos should not only consider spatial
alignment between human and garment poses in each frame but also account for
the temporal dynamics of human poses throughout the entire video. With such
motivation, we propose a new framework, namely Dynamic Pose Interaction
Diffusion Models (DPIDM), to leverage diffusion models to delve into dynamic
pose interactions for video virtual try-on. Technically, DPIDM introduces a
skeleton-based pose adapter to integrate synchronized human and garment poses
into the denoising network. A hierarchical attention module is then exquisitely
designed to model intra-frame human-garment pose interactions and long-term
human pose dynamics across frames through pose-aware spatial and temporal
attention mechanisms. Moreover, DPIDM capitalizes on a temporal regularized
attention loss between consecutive frames to enhance temporal consistency.
Extensive experiments conducted on VITON-HD, VVT and ViViD datasets demonstrate
the superiority of our DPIDM against the baseline methods. Notably, DPIDM
achieves VFID score of 0.506 on VVT dataset, leading to 60.5% improvement over
the state-of-the-art GPD-VVTO approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Incorporating Visual Correspondence into Diffusion Model for Virtual
  Try-On <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16977v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16977v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siqi Wan, Jingwen Chen, Yingwei Pan, Ting Yao, Tao Mei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have shown preliminary success in virtual try-on (VTON)
task. The typical dual-branch architecture comprises two UNets for implicit
garment deformation and synthesized image generation respectively, and has
emerged as the recipe for VTON task. Nevertheless, the problem remains
challenging to preserve the shape and every detail of the given garment due to
the intrinsic stochasticity of diffusion model. To alleviate this issue, we
novelly propose to explicitly capitalize on visual correspondence as the prior
to tame diffusion process instead of simply feeding the whole garment into UNet
as the appearance reference. Specifically, we interpret the fine-grained
appearance and texture details as a set of structured semantic points, and
match the semantic points rooted in garment to the ones over target person
through local flow warping. Such 2D points are then augmented into 3D-aware
cues with depth/normal map of target person. The correspondence mimics the way
of putting clothing on human body and the 3D-aware cues act as semantic point
matching to supervise diffusion model training. A point-focused diffusion loss
is further devised to fully take the advantage of semantic point matching.
Extensive experiments demonstrate strong garment detail preservation of our
approach, evidenced by state-of-the-art VTON performances on both VITON-HD and
DressCode datasets. Code is publicly available at:
https://github.com/HiDream-ai/SPM-Diff.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. Code is publicly available at:
  https://github.com/HiDream-ai/SPM-Diff</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Creatively Upscaling Images with Global-Regional Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16976v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16976v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yurui Qian, Qi Cai, Yingwei Pan, Ting Yao, Tao Mei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contemporary diffusion models show remarkable capability in text-to-image
generation, while still being limited to restricted resolutions (e.g., 1,024 X
1,024). Recent advances enable tuning-free higher-resolution image generation
by recycling pre-trained diffusion models and extending them via regional
denoising or dilated sampling/convolutions. However, these models struggle to
simultaneously preserve global semantic structure and produce creative regional
details in higher-resolution images. To address this, we present C-Upscale, a
new recipe of tuning-free image upscaling that pivots on global-regional priors
derived from given global prompt and estimated regional prompts via Multimodal
LLM. Technically, the low-frequency component of low-resolution image is
recognized as global structure prior to encourage global semantic consistency
in high-resolution generation. Next, we perform regional attention control to
screen cross-attention between global prompt and each region during regional
denoising, leading to regional attention prior that alleviates object
repetition issue. The estimated regional prompts containing rich descriptive
details further act as regional semantic prior to fuel the creativity of
regional detail generation. Both quantitative and qualitative evaluations
demonstrate that our C-Upscale manages to generate ultra-high-resolution images
(e.g., 4,096 X 4,096 and 8,192 X 8,192) with higher visual fidelity and more
creative regional details.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>International Journal of Computer Vision (IJCV) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representation Discrepancy Bridging Method for Remote Sensing Image-Text
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16756v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16756v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hailong Ning, Siying Wang, Tao Lei, Xiaopeng Cao, Huanmin Dou, Bin Zhao, Asoke K. Nandi, Petia Radeva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in
geographic information interpretation, disaster monitoring, and urban planning
by establishing semantic associations between image and textual descriptions.
Existing Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language
Pre-training (VLP) models typically adopt symmetric adapter structures for
exploring cross-modal correlations. However, the strong discriminative nature
of text modality may dominate the optimization process and inhibits image
representation learning. The nonnegligible imbalanced cross-modal optimization
remains a bottleneck to enhancing the model performance. To address this issue,
this study proposes a Representation Discrepancy Bridging (RDB) method for the
RSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is
designed to enable modality-specific optimization and improve feature
alignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text
Semantic Adapter (TSA). VEA mines fine-grained image features by Differential
Attention (DA) mechanism, while TSA identifies key textual semantics through
Hierarchical Attention (HA) mechanism. On the other hand, this study extends
the traditional single-task retrieval framework to a dual-task optimization
framework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves
cross-modal alignment robustness through an adaptive weighted combination of
cross-modal, classification, and exponential moving average consistency
constraints. Experiments on RSICD and RSITMD datasets show that the proposed
RDB method achieves a 6%-11% improvement in mR metrics compared to
state-of-the-art PEFT methods and a 1.15%-2% improvement over the full
fine-tuned GeoRSCLIP model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16663v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16663v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haihong Hao, Mingfei Han, Changlin Li, Zhihui Li, Xiaojun Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied navigation demands comprehensive scene understanding and precise
spatial reasoning. While image-text models excel at interpreting pixel-level
color and lighting cues, 3D-text models capture volumetric structure and
spatial relationships. However, unified fusion approaches that jointly fuse 2D
images, 3D point clouds, and textual instructions face challenges in limited
availability of triple-modality data and difficulty resolving conflicting
beliefs among modalities. In this work, we introduce CoNav, a collaborative
cross-modal reasoning framework where a pretrained 3D-text model explicitly
guides an image-text navigation agent by providing structured spatial-semantic
knowledge to resolve ambiguities during navigation. Specifically, we introduce
Cross-Modal Belief Alignment, which operationalizes this cross-modal guidance
by simply sharing textual hypotheses from the 3D-text model to the navigation
agent. Through lightweight fine-tuning on a small 2D-3D-text corpus, the
navigation agent learns to integrate visual cues with spatial-semantic
knowledge derived from the 3D-text model, enabling effective reasoning in
embodied navigation. CoNav achieves significant improvements on four standard
embodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial
reasoning benchmarks (ScanQA, SQA3D). Moreover, under close navigation Success
Rate, CoNav often generates shorter paths compared to other methods (as
measured by SPL), showcasing the potential and challenges of fusing data from
different modalities in embodied navigation. Project Page:
https://oceanhao.github.io/CoNav/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Joint Flow And Feature Refinement Using Attention For Video Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ranjith Merugu, Mohammad Sameer Suhail, Akshay P Sarashetti, Venkata Bharath Reddy Reddem, Pankaj Kumar Bajpai, Amit Satish Unde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in video restoration have focused on recovering
high-quality video frames from low-quality inputs. Compared with static images,
the performance of video restoration significantly depends on efficient
exploitation of temporal correlations among successive video frames. The
numerous techniques make use of temporal information via flow-based strategies
or recurrent architectures. However, these methods often encounter difficulties
in preserving temporal consistency as they utilize degraded input video frames.
To resolve this issue, we propose a novel video restoration framework named
Joint Flow and Feature Refinement using Attention (JFFRA). The proposed JFFRA
is based on key philosophy of iteratively enhancing data through the
synergistic collaboration of flow (alignment) and restoration. By leveraging
previously enhanced features to refine flow and vice versa, JFFRA enables
efficient feature enhancement using temporal information. This interplay
between flow and restoration is executed at multiple scales, reducing the
dependence on precise flow estimation. Moreover, we incorporate an
occlusion-aware temporal loss function to enhance the network's capability in
eliminating flickering artifacts. Comprehensive experiments validate the
versatility of JFFRA across various restoration tasks such as denoising,
deblurring, and super-resolution. Our method demonstrates a remarkable
performance improvement of up to 1.62 dB compared to state-of-the-art
approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie
  Dubbing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Zheng, Zihao Chen, Chaofan Ding, Yunming Liang, Yihan Fan, Huan Yang, Lei Xie, Xinhan Di
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current movie dubbing technology can produce the desired speech using a
reference voice and input video, maintaining perfect synchronization with the
visuals while effectively conveying the intended emotions. However, crucial
aspects of movie dubbing, including adaptation to various dubbing styles,
effective handling of dialogue, narration, and monologues, as well as
consideration of subtle details such as speaker age and gender, remain
insufficiently explored. To tackle these challenges, we introduce a multi-modal
generative framework. First, it utilizes a multi-modal large vision-language
model (VLM) to analyze visual inputs, enabling the recognition of dubbing types
and fine-grained attributes. Second, it produces high-quality dubbing using
large speech generation models, guided by multi-modal inputs. Additionally, a
movie dubbing dataset with annotations for dubbing types and subtle details is
constructed to enhance movie understanding and improve dubbing quality for the
proposed multi-modal framework. Experimental results across multiple benchmark
datasets show superior performance compared to state-of-the-art (SOTA) methods.
In details, the LSE-D, SPK-SIM, EMO-SIM, and MCD exhibit improvements of up to
1.09%, 8.80%, 19.08%, and 18.74%, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures, accepted by Interspeech 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DualComp: End-to-End Learning of a Unified Dual-Modality Lossless
  Compressor 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16256v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16256v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Qunshan Gu, Qi Wang, Li Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most learning-based lossless compressors are designed for a single modality,
requiring separate models for multi-modal data and lacking flexibility.
However, different modalities vary significantly in format and statistical
properties, making it ineffective to use compressors that lack
modality-specific adaptations. While multi-modal large language models (MLLMs)
offer a potential solution for modality-unified compression, their excessive
complexity hinders practical deployment. To address these challenges, we focus
on the two most common modalities, image and text, and propose DualComp, the
first unified and lightweight learning-based dual-modality lossless compressor.
Built on a lightweight backbone, DualComp incorporates three key structural
enhancements to handle modality heterogeneity: modality-unified tokenization,
modality-switching contextual learning, and modality-routing
mixture-of-experts. A reparameterization training strategy is also used to
boost compression performance. DualComp integrates both modality-specific and
shared parameters for efficient parameter utilization, enabling near real-time
inference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp
achieves compression performance on par with the SOTA LLM-based methods for
both text and image datasets. Its simplified single-modality variant surpasses
the previous best image compressor on the Kodak dataset by about 9% using just
1.2% of the model size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 11 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Copy-Move Forgery Detection and Question Answering for Remote Sensing
  Image 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.02575v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.02575v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ze Zhang, Enyuan Zhao, Di Niu, Jie Nie, Xinyue Liang, Lei Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Driven by practical demands in land resource monitoring and national defense
security, this paper introduces the Remote Sensing Copy-Move Question Answering
(RSCMQA) task. Unlike traditional Remote Sensing Visual Question Answering
(RSVQA), RSCMQA focuses on interpreting complex tampering scenarios and
inferring relationships between objects. We present a suite of global RSCMQA
datasets, comprising images from 29 different regions across 14 countries.
Specifically, we propose five distinct datasets, including the basic dataset
RS-CMQA, the category-balanced dataset RS-CMQA-B, the high-authenticity dataset
Real-RSCM, the extended dataset RS-TQA, and the extended category-balanced
dataset RS-TQA-B. These datasets fill a critical gap in the field while
ensuring comprehensiveness, balance, and challenge. Furthermore, we introduce a
region-discrimination-guided multimodal copy-move forgery perception framework
(CMFPF), which enhances the accuracy of answering questions about tampered
images by leveraging prompt about the differences and connections between the
source and tampered domains. Extensive experiments demonstrate that our method
provides a stronger benchmark for RSCMQA compared to general VQA and RSVQA
models. Our datasets and code are publicly available at
https://github.com/shenyedepisa/RSCMQA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 figs, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-21T00:00:00Z">2025-05-21</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">33</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated
  Synthetic Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruijie Xi, He Ba, Hao Yuan, Rishu Agrawal, Arul Prakash
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embedding-Based Retrieval (EBR) is an important technique in modern search
engines, enabling semantic match between search queries and relevant results.
However, search logging data on platforms like Facebook Marketplace lacks the
diversity and details needed for effective EBR model training, limiting the
models' ability to capture nuanced search patterns. To address this challenge,
we propose Aug2Search, an EBR-based framework leveraging synthetic data
generated by Generative AI (GenAI) models, in a multimodal and multitask
approach to optimize query-product relevance. This paper investigates the
capabilities of GenAI, particularly Large Language Models (LLMs), in generating
high-quality synthetic data, and analyzing its impact on enhancing EBR models.
We conducted experiments using eight Llama models and 100 million data points
from Facebook Marketplace logs. Our synthetic data generation follows three
strategies: (1) generate queries, (2) enhance product listings, and (3)
generate queries from enhanced listings. We train EBR models on three different
datasets: sampled engagement data or original data ((e.g., "Click" and "Listing
Interactions")), synthetic data, and a mixture of both engagement and synthetic
data to assess their performance across various training sets. Our findings
underscore the robustness of Llama models in producing synthetic queries and
listings with high coherence, relevance, and diversity, while maintaining low
levels of hallucination. Aug2Search achieves an improvement of up to 4% in
ROC_AUC with 100 million synthetic data samples, demonstrating the
effectiveness of our approach. Moreover, our experiments reveal that with the
same volume of training data, models trained exclusively on synthetic data
often outperform those trained on original data only or a mixture of original
and synthetic data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NEXT-EVAL: Next Evaluation of Traditional and LLM Web Data Record
  Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17125v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17125v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soyeon Kim, Namhee Kim, Yeonwoo Jeong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective evaluation of web data record extraction methods is crucial, yet
hampered by static, domain-specific benchmarks and opaque scoring practices.
This makes fair comparison between traditional algorithmic techniques, which
rely on structural heuristics, and Large Language Model (LLM)-based approaches,
offering zero-shot extraction across diverse layouts, particularly challenging.
To overcome these limitations, we introduce a concrete evaluation framework.
Our framework systematically generates evaluation datasets from arbitrary MHTML
snapshots, annotates XPath-based supervision labels, and employs
structure-aware metrics for consistent scoring, specifically preventing text
hallucination and allowing only for the assessment of positional hallucination.
It also incorporates preprocessing strategies to optimize input for LLMs while
preserving DOM semantics: HTML slimming, Hierarchical JSON, and Flat JSON.
Additionally, we created a publicly available synthetic dataset by transforming
DOM structures and modifying content. We benchmark deterministic heuristic
algorithms and off-the-shelf LLMs across these multiple input formats. Our
benchmarking shows that Flat JSON input enables LLMs to achieve superior
extraction accuracy (F1 score of 0.9567) and minimal hallucination compared to
other input formats like Slimmed HTML and Hierarchical JSON. We establish a
standardized foundation for rigorous benchmarking, paving the way for the next
principled advancements in web data record extraction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Web Data Record Extraction, Zero-Shot Extraction, Large Language
  Models (LLMs) Evaluation Framework, Comparative Analysis</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Atlas of In-Context Learning: How Attention Heads Shape In-Context
  Retrieval Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Kahardipraja, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models are able to exploit in-context learning to access
external knowledge beyond their training data through retrieval-augmentation.
While promising, its inner workings remain unclear. In this work, we shed light
on the mechanism of in-context retrieval augmentation for question answering by
viewing a prompt as a composition of informational components. We propose an
attribution-based method to identify specialized attention heads, revealing
in-context heads that comprehend instructions and retrieve relevant contextual
information, and parametric heads that store entities' relational knowledge. To
better understand their roles, we extract function vectors and modify their
attention weights to show how they can influence the answer generation process.
Finally, we leverage the gained insights to trace the sources of knowledge used
during inference, paving the way towards more safe and transparent language
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConvSearch-R1: Enhancing Query Reformulation for Conversational Search
  with Reasoning via Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15776v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15776v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changtai Zhu, Siyin Wang, Ruijun Feng, Kai Song, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational search systems require effective handling of context-dependent
queries that often contain ambiguity, omission, and coreference. Conversational
Query Reformulation (CQR) addresses this challenge by transforming these
queries into self-contained forms suitable for off-the-shelf retrievers.
However, existing CQR approaches suffer from two critical constraints: high
dependency on costly external supervision from human annotations or large
language models, and insufficient alignment between the rewriting model and
downstream retrievers. We present ConvSearch-R1, the first self-driven
framework that completely eliminates dependency on external rewrite supervision
by leveraging reinforcement learning to optimize reformulation directly through
retrieval signals. Our novel two-stage approach combines Self-Driven Policy
Warm-Up to address the cold-start problem through retrieval-guided
self-distillation, followed by Retrieval-Guided Reinforcement Learning with a
specially designed rank-incentive reward shaping mechanism that addresses the
sparsity issue in conventional retrieval metrics. Extensive experiments on
TopiOCQA and QReCC datasets demonstrate that ConvSearch-R1 significantly
outperforms previous state-of-the-art methods, achieving over 10% improvement
on the challenging TopiOCQA dataset while using smaller 3B parameter models
without any external supervision.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Text-to-Pipeline: Bridging Natural Language and Data Preparation
  Pipelines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15874v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15874v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Ge, Yachuan Liu, Yuren Mao, Yunjun Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data preparation (DP) transforms raw data into a form suitable for downstream
applications, typically by composing operations into executable pipelines.
Building such pipelines is time-consuming and requires sophisticated
programming skills. If we can build the pipelines with natural language (NL),
the technical barrier of DP will be significantly reduced. However,
constructing DP pipelines from NL instructions remains underexplored. To fill
the gap, we introduce Text-to-Pipeline, a new task that translates NL data
preparation instructions into DP pipelines. Furthermore, we develop a benchmark
named PARROT to support systematic evaluation. To simulate realistic DP
scenarios, we mined transformation patterns from production pipelines and
instantiated them on 23,009 real-world tables collected from six public
sources. The resulting benchmark comprises ~18,000 pipelines covering 16 core
DP operators. We evaluated cutting-edge large language models on PARROTand
observed that they only solved 72.86% of the cases, revealing notable
limitations in instruction understanding and multi-step reasoning. To address
this, we propose Pipeline-Agent, a stronger baseline that iteratively predicts
and executes operations with intermediate table feedback, achieving the best
performance of 76.17%. Despite this improvement, there remains substantial room
for progress on Text-to-Pipeline. Our data, codes, and evaluation tools are
available at https://anonymous.4open.science/r/Text-to-Pipeline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distance Adaptive Beam Search for Provably Accurate Graph-Based Nearest
  Neighbor Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yousef Al-Jazzazi, Haya Diwan, Jinrui Gou, Cameron Musco, Christopher Musco, Torsten Suel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nearest neighbor search is central in machine learning, information
retrieval, and databases. For high-dimensional datasets, graph-based methods
such as HNSW, DiskANN, and NSG have become popular thanks to their empirical
accuracy and efficiency. These methods construct a directed graph over the
dataset and perform beam search on the graph to find nodes close to a given
query. While significant work has focused on practical refinements and
theoretical understanding of graph-based methods, many questions remain. We
propose a new distance-based termination condition for beam search to replace
the commonly used condition based on beam width. We prove that, as long as the
search graph is navigable, our resulting Adaptive Beam Search method is
guaranteed to approximately solve the nearest-neighbor problem, establishing a
connection between navigability and the performance of graph-based search. We
also provide extensive experiments on our new termination condition for both
navigable graphs and approximately navigable graphs used in practice, such as
HNSW and Vamana graphs. We find that Adaptive Beam Search outperforms standard
beam search over a range of recall values, data sets, graph constructions, and
target number of nearest neighbors. It thus provides a simple and practical way
to improve the performance of popular methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIRB: Mathematical Information Retrieval Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15585v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15585v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haocheng Ju, Bin Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical Information Retrieval (MIR) is the task of retrieving
information from mathematical documents and plays a key role in various
applications, including theorem search in mathematical libraries, answer
retrieval on math forums, and premise selection in automated theorem proving.
However, a unified benchmark for evaluating these diverse retrieval tasks has
been lacking. In this paper, we introduce MIRB (Mathematical Information
Retrieval Benchmark) to assess the MIR capabilities of retrieval models. MIRB
includes four tasks: semantic statement retrieval, question-answer retrieval,
premise retrieval, and formula retrieval, spanning a total of 12 datasets. We
evaluate 13 retrieval models on this benchmark and analyze the challenges
inherent to MIR. We hope that MIRB provides a comprehensive framework for
evaluating MIR systems and helps advance the development of more effective
retrieval models tailored to the mathematical domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code and data are available at https://github.com/j991222/mirb
  and https://huggingface.co/collections/hcju/mirb-6827001711765454f58c5a76</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do RAG Systems Suffer From Positional Bias? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florin Cuconasu, Simone Filice, Guy Horowitz, Yoelle Maarek, Fabrizio Silvestri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation enhances LLM accuracy by adding passages
retrieved from an external corpus to the LLM prompt. This paper investigates
how positional bias - the tendency of LLMs to weight information differently
based on its position in the prompt - affects not only the LLM's capability to
capitalize on relevant passages, but also its susceptibility to distracting
passages. Through extensive experiments on three benchmarks, we show how
state-of-the-art retrieval pipelines, while attempting to retrieve relevant
passages, systematically bring highly distracting ones to the top ranks, with
over 60% of queries containing at least one highly distracting passage among
the top-10 retrieved passages. As a result, the impact of the LLM positional
bias, which in controlled settings is often reported as very prominent by
related works, is actually marginal in real scenarios since both relevant and
distracting passages are, in turn, penalized. Indeed, our findings reveal that
sophisticated strategies that attempt to rearrange the passages based on LLM
positional preferences do not perform better than random shuffling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Directional Non-Commutative Monoidal Structures for Compositional
  Embeddings in Machine Learning <span class="chip">NeurIPS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahesh Godavarti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a new algebraic structure for multi-dimensional compositional
embeddings, built on directional non-commutative monoidal operators. The core
contribution of this work is this novel framework, which exhibits appealing
theoretical properties (associativity along each dimension and an interchange
law ensuring global consistency) while remaining compatible with modern machine
learning architectures. Our construction defines a distinct composition
operator circ_i for each axis i, ensuring associative combination along each
axis without imposing global commutativity. Importantly, all axis-specific
operators commute with one another, enforcing a global interchange law that
enables consistent crossaxis compositions. This is, to our knowledge, the first
approach that provides a common foundation that generalizes classical
sequence-modeling paradigms (e.g., structured state-space models (SSMs) and
transformer self-attention) to a unified multi-dimensional framework. For
example, specific one-dimensional instances of our framework can recover the
familiar affine transformation algebra, vanilla self-attention, and the
SSM-style recurrence. The higher-dimensional generalizations naturally support
recursive, structure-aware operations in embedding spaces. We outline several
potential applications unlocked by this structure-including structured
positional encodings in Transformers, directional image embeddings, and
symbolic modeling of sequences or grids-indicating that it could inform future
deep learning model designs. We formally establish the algebraic properties of
our framework and discuss efficient implementations. Finally, as our focus is
theoretical, we include no experiments here and defer empirical validation to
future work, which we plan to undertake.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages submitted to NeurIPS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reranking with Compressed Document Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15394v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15394v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hervé Déjean, Stéphane Clinchant
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reranking, the process of refining the output of a first-stage retriever, is
often considered computationally expensive, especially with Large Language
Models. Borrowing from recent advances in document compression for RAG, we
reduce the input size by compressing documents into fixed-size embedding
representations. We then teach a reranker to use compressed inputs by
distillation. Although based on a billion-size model, our trained reranker
using this compressed input can challenge smaller rerankers in terms of both
effectiveness and efficiency, especially for long documents. Given that text
compressors are still in their early development stages, we view this approach
as promising.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deliberation on Priors: Trustworthy Reasoning of Large Language Models
  on Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15210v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15210v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Ma, Ning Qu, Zhitao Gao, Rui Xing, Jun Liu, Hongbin Pei, Jiang Xie, Linyun Song, Pinghui Wang, Jing Tao, Zhou Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge graph-based retrieval-augmented generation seeks to mitigate
hallucinations in Large Language Models (LLMs) caused by insufficient or
outdated knowledge. However, existing methods often fail to fully exploit the
prior knowledge embedded in knowledge graphs (KGs), particularly their
structural information and explicit or implicit constraints. The former can
enhance the faithfulness of LLMs' reasoning, while the latter can improve the
reliability of response generation. Motivated by these, we propose a
trustworthy reasoning framework, termed Deliberation over Priors (DP), which
sufficiently utilizes the priors contained in KGs. Specifically, DP adopts a
progressive knowledge distillation strategy that integrates structural priors
into LLMs through a combination of supervised fine-tuning and Kahneman-Tversky
optimization, thereby improving the faithfulness of relation path generation.
Furthermore, our framework employs a reasoning-introspection strategy, which
guides LLMs to perform refined reasoning verification based on extracted
constraint priors, ensuring the reliability of response generation. Extensive
experiments on three benchmark datasets demonstrate that DP achieves new
state-of-the-art performance, especially a Hit@1 improvement of 13% on the
ComplexWebQuestions dataset, and generates highly trustworthy responses. We
also conduct various analyses to verify its flexibility and practicality. The
code is available at https://github.com/reml-group/Deliberation-on-Priors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Relevance Feedback for Interactive Known-Item Video Search <span class="chip">ICMR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhixin Ma, Chong-Wah Ngo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Known-item search (KIS) involves only a single search target, making
relevance feedback-typically a powerful technique for efficiently identifying
multiple positive examples to infer user intent-inapplicable. PicHunter
addresses this issue by asking users to select the top-k most similar examples
to the unique search target from a displayed set. Under ideal conditions, when
the user's perception aligns closely with the machine's perception of
similarity, consistent and precise judgments can elevate the target to the top
position within a few iterations. However, in practical scenarios, expecting
users to provide consistent judgments is often unrealistic, especially when the
underlying embedding features used for similarity measurements lack
interpretability. To enhance robustness, we first introduce a pairwise relative
judgment feedback that improves the stability of top-k selections by mitigating
the impact of misaligned feedback. Then, we decompose user perception into
multiple sub-perceptions, each represented as an independent embedding space.
This approach assumes that users may not consistently align with a single
representation but are more likely to align with one or several among multiple
representations. We develop a predictive user model that estimates the
combination of sub-perceptions based on each user feedback instance. The
predictive user model is then trained to filter out the misaligned
sub-perceptions. Experimental evaluations on the large-scale open-domain
dataset V3C indicate that the proposed model can optimize over 60% search
targets to the top rank when their initial ranks at the search depth between 10
and 50. Even for targets initially ranked between 1,000 and 5,000, the model
achieves a success rate exceeding 40% in optimizing ranks to the top,
demonstrating the enhanced robustness of relevance feedback in KIS despite
inconsistent feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICMR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Empirical Study on Reinforcement Learning for Reasoning-Search
  Interleaved LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15117v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15117v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jin, Jinsung Yoon, Priyanka Kargupta, Sercan O. Arik, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) has demonstrated strong potential in training
large language models (LLMs) capable of complex reasoning for real-world
problem solving. More recently, RL has been leveraged to create sophisticated
LLM-based search agents that adeptly combine reasoning with search engine use.
While the use of RL for training search agents is promising, the optimal design
of such agents remains not fully understood. In particular, key factors -- such
as (1) reward formulation, (2) the choice and characteristics of the underlying
LLM, and (3) the role of the search engine in the RL process -- require further
investigation. In this work, we conduct comprehensive empirical studies to
systematically investigate these and offer actionable insights. We highlight
several key findings: format rewards are effective in improving final
performance, whereas intermediate retrieval rewards have limited impact; the
scale and initialization of the LLM (general-purpose vs. reasoning-specialized)
significantly influence RL outcomes; and the choice of search engine plays a
critical role in shaping RL training dynamics and the robustness of the trained
agent during inference. These establish important guidelines for successfully
building and deploying LLM-based search agents in real-world applications. Code
is available at https://github.com/PeterGriffinJin/Search-R1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziliang Wang, Xuhui Zheng, Kang An, Cijun Ouyang, Jialu Cai, Yuhang Wang, Yichao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient multi-hop reasoning requires Large Language Models (LLMs) based
agents to acquire high-value external knowledge iteratively. Previous work has
explored reinforcement learning (RL) to train LLMs to perform search-based
document retrieval, achieving notable improvements in QA performance, but
underperform on complex, multi-hop QA resulting from the sparse rewards from
global signal only. To address this gap in existing research, we introduce
StepSearch, a framework for search LLMs that trained with step-wise proximal
policy optimization method. It consists of richer and more detailed
intermediate search rewards and token-level process supervision based on
information gain and redundancy penalties to better guide each search step. We
constructed a fine-grained question-answering dataset containing
sub-question-level search trajectories based on open source datasets through a
set of data pipeline method. On standard multi-hop QA benchmarks, it
significantly outperforms global-reward baselines, achieving 11.2% and 4.2%
absolute improvements for 3B and 7B models over various search with RL
baselines using only 19k training data, demonstrating the effectiveness of
fine-grained, stepwise supervision in optimizing deep search LLMs. Our
implementation is publicly available at
https://github.com/zxh20001117/StepSearch.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AutoData: A Multi-Agent System for Open Web Data Collection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15859v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15859v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Ma, Yiyue Qian, Zheyuan Zhang, Zehong Wang, Xiaoye Qian, Feifan Bai, Yifan Ding, Xuwei Luo, Shinan Zhang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential growth of data-driven systems and AI technologies has
intensified the demand for high-quality web-sourced datasets. While existing
datasets have proven valuable, conventional web data collection approaches face
significant limitations in terms of human effort and scalability. Current
data-collecting solutions fall into two categories: wrapper-based methods that
struggle with adaptability and reproducibility, and large language model
(LLM)-based approaches that incur substantial computational and financial
costs. To address these challenges, we propose AutoData, a novel multi-agent
system for Automated web Data collection, that requires minimal human
intervention, i.e., only necessitating a natural language instruction
specifying the desired dataset. In addition, AutoData is designed with a robust
multi-agent architecture, featuring a novel oriented message hypergraph
coordinated by a central task manager, to efficiently organize agents across
research and development squads. Besides, we introduce a novel hypergraph cache
system to advance the multi-agent collaboration process that enables efficient
automated data collection and mitigates the token cost issues prevalent in
existing LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark
dataset supporting live data collection from web sources across three domains:
academic, finance, and sports. Comprehensive evaluations over Instruct2DS and
three existing benchmark datasets demonstrate AutoData's superior performance
compared to baseline methods. Case studies on challenging tasks such as picture
book collection and paper extraction from surveys further validate its
applicability. Our source code and dataset are available at
https://github.com/GraphResearcher/AutoData.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoTime: A <span class="highlight-title">Dataset</span> Suite for Multimodal Time Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Zhou, Weiqing Wang, Francisco J. Baldán, Wray Buntine, Christoph Bergmeir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While multimodal data sources are increasingly available from real-world
forecasting, most existing research remains on unimodal time series. In this
work, we present MoTime, a suite of multimodal time series forecasting datasets
that pair temporal signals with external modalities such as text, metadata, and
images. Covering diverse domains, MoTime supports structured evaluation of
modality utility under two scenarios: 1) the common forecasting task, where
varying-length history is available, and 2) cold-start forecasting, where no
historical data is available. Experiments show that external modalities can
improve forecasting performance in both scenarios, with particularly strong
benefits for short series in some datasets, though the impact varies depending
on data characteristics. By making datasets and findings publicly available, we
aim to support more comprehensive and realistic benchmarks in future multimodal
time series forecasting research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Alternative to FLOPS Regularization to Effectively Productionize
  SPLADE-Doc <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aldo Porco, Dhruv Mehra, Igor Malioutov, Karthik Radhakrishnan, Moniba Keymanesh, Daniel Preoţiuc-Pietro, Sean MacAvaney, Pengxiang Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learned Sparse Retrieval (LSR) models encode text as weighted term vectors,
which need to be sparse to leverage inverted index structures during retrieval.
SPLADE, the most popular LSR model, uses FLOPS regularization to encourage
vector sparsity during training. However, FLOPS regularization does not ensure
sparsity among terms - only within a given query or document. Terms with very
high Document Frequencies (DFs) substantially increase latency in production
retrieval engines, such as Apache Solr, due to their lengthy posting lists. To
address the issue of high DFs, we present a new variant of FLOPS
regularization: DF-FLOPS. This new regularization technique penalizes the usage
of high-DF terms, thereby shortening posting lists and reducing retrieval
latency. Unlike other inference-time sparsification methods, such as stopword
removal, DF-FLOPS regularization allows for the selective inclusion of
high-frequency terms in cases where the terms are truly salient. We find that
DF-FLOPS successfully reduces the prevalence of high-DF terms and lowers
retrieval latency (around 10x faster) in a production-grade engine while
maintaining effectiveness both in-domain (only a 2.2-point drop in MRR@10) and
cross-domain (improved performance in 12 out of 13 tasks on which we tested).
With retrieval latencies on par with BM25, this work provides an important step
towards making LSR practical for deployment in production-grade search engines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a short paper at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GitHub Repository Complexity Leads to Diminished Web Archive
  Availability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15042v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15042v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Calano, Michele C. Weigle, Michael L. Nelson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Software is often developed using versioned controlled software, such as Git,
and hosted on centralized Web hosts, such as GitHub and GitLab. These Web
hosted software repositories are made available to users in the form of
traditional HTML Web pages for each source file and directory, as well as a
presentational home page and various descriptive pages. We examined more than
12,000 Web hosted Git repository project home pages, primarily from GitHub, to
measure how well their presentational components are preserved in the Internet
Archive, as well as the source trees of the collected GitHub repositories to
assess the extent to which their source code has been preserved. We found that
more than 31% of the archived repository home pages examined exhibited some
form of minor page damage and 1.6% exhibited major page damage. We also found
that of the source trees analyzed, less than 5% of their source files were
archived, on average, with the majority of repositories not having source files
saved in the Internet Archive at all. The highest concentration of archived
source files available were those linked directly from repositories' home pages
at a rate of 14.89% across all available repositories and sharply dropping off
at deeper levels of a repository's directory tree.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are the confidence scores of <span class="highlight-title">review</span>ers consistent with the <span class="highlight-title">review</span>
  content? Evidence from top conference proceedings in AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15031v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15031v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqing Wu, Haixu Xi, Chengzhi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Peer review is vital in academia for evaluating research quality. Top AI
conferences use reviewer confidence scores to ensure review reliability, but
existing studies lack fine-grained analysis of text-score consistency,
potentially missing key details. This work assesses consistency at word,
sentence, and aspect levels using deep learning and NLP conference review data.
We employ deep learning to detect hedge sentences and aspects, then analyze
report length, hedge word/sentence frequency, aspect mentions, and sentiment to
evaluate text-score alignment. Correlation, significance, and regression tests
examine confidence scores' impact on paper outcomes. Results show high
text-score consistency across all levels, with regression revealing higher
confidence scores correlate with paper rejection, validating expert assessments
and peer review fairness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CRAFT: Training-Free Cascaded Retrieval for Tabular QA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14984v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14984v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adarsh Singh, Kushal Raj Bhandari, Jianxi Gao, Soham Dan, Vivek Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Table Question Answering (TQA) involves retrieving relevant tables from a
large corpus to answer natural language queries. Traditional dense retrieval
models, such as DTR and ColBERT, not only incur high computational costs for
large-scale retrieval tasks but also require retraining or fine-tuning on new
datasets, limiting their adaptability to evolving domains and knowledge. In
this work, we propose $\textbf{CRAFT}$, a cascaded retrieval approach that
first uses a sparse retrieval model to filter a subset of candidate tables
before applying more computationally expensive dense models and neural
re-rankers. Our approach achieves better retrieval performance than
state-of-the-art (SOTA) sparse, dense, and hybrid retrievers. We further
enhance table representations by generating table descriptions and titles using
Gemini Flash 1.5. End-to-end TQA results using various Large Language Models
(LLMs) on NQ-Tables, a subset of the Natural Questions Dataset, demonstrate
$\textbf{CRAFT}$ effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LiDDA: Data Driven Attribution at LinkedIn 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.09861v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.09861v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Bencina, Erkut Aykutlug, Yue Chen, Zerui Zhang, Stephanie Sorenson, Shao Tang, Changshuai Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data Driven Attribution, which assigns conversion credits to marketing
interactions based on causal patterns learned from data, is the foundation of
modern marketing intelligence and vital to any marketing businesses and
advertising platform. In this paper, we introduce a unified transformer-based
attribution approach that can handle member-level data, aggregate-level data,
and integration of external macro factors. We detail the large scale
implementation of the approach at LinkedIn, showcasing significant impact. We
also share learning and insights that are broadly applicable to the marketing
and ad tech fields.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Worse than Zero-shot? A Fact-Checking <span class="highlight-title">Dataset</span> for Evaluating the
  Robustness of RAG Against Misleading Retrievals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linda Zeng, Rithwik Gupta, Divij Motwani, Diji Yang, Yi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has shown impressive capabilities in
mitigating hallucinations in large language models (LLMs). However, LLMs
struggle to handle misleading retrievals and often fail to maintain their own
reasoning when exposed to conflicting or selectively-framed evidence, making
them vulnerable to real-world misinformation. In such real-world retrieval
scenarios, misleading and conflicting information is rampant, particularly in
the political domain, where evidence is often selectively framed, incomplete,
or polarized. However, existing RAG benchmarks largely assume a clean retrieval
setting, where models succeed by accurately retrieving and generating answers
from gold-standard documents. This assumption fails to align with real-world
conditions, leading to an overestimation of RAG system performance. To bridge
this gap, we introduce RAGuard, a fact-checking dataset designed to evaluate
the robustness of RAG systems against misleading retrievals. Unlike prior
benchmarks that rely on synthetic noise, our dataset constructs its retrieval
corpus from Reddit discussions, capturing naturally occurring misinformation.
It categorizes retrieved evidence into three types: supporting, misleading, and
irrelevant, providing a realistic and challenging testbed for assessing how
well RAG systems navigate different retrieval information. Our benchmark
experiments reveal that when exposed to misleading retrievals, all tested
LLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no
retrieval at all), highlighting their susceptibility to noisy environments. To
the best of our knowledge, RAGuard is the first benchmark to systematically
assess RAG robustness against misleading evidence. We expect this benchmark
will drive future research toward improving RAG systems beyond idealized
datasets, making them more reliable for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spark: A System for Scientifically Creative Idea Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.20090v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.20090v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large language models (LLMs) have shown promising abilities to
generate novel research ideas in science, a direction which coincides with many
foundational principles in computational creativity (CC). In light of these
developments, we present an idea generation system named Spark that couples
retrieval-augmented idea generation using LLMs with a reviewer model named
Judge trained on 600K scientific reviews from OpenReview. Our work is both a
system demonstration and intended to inspire other CC researchers to explore
grounding the generation and evaluation of scientific ideas within foundational
CC principles. To this end, we release the annotated dataset used to train
Judge, inviting other researchers to explore the use of LLMs for idea
generation and creative evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICCC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIRACL-VISION: A Large, multilingual, visual document retrieval
  benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11651v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11651v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Radek Osmulski, Gabriel de Souza P. Moreira, Ronay Ak, Mengyao Xu, Benedikt Schifferer, Even Oldridge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document retrieval is an important task for search and Retrieval-Augmented
Generation (RAG) applications. Large Language Models (LLMs) have contributed to
improving the accuracy of text-based document retrieval. However, documents
with complex layout and visual elements like tables, charts and infographics
are not perfectly represented in textual format. Recently, image-based document
retrieval pipelines have become popular, which use visual large language models
(VLMs) to retrieve relevant page images given a query. Current evaluation
benchmarks on visual document retrieval are limited, as they primarily focus
only English language, rely on synthetically generated questions and offer a
small corpus size. Therefore, we introduce MIRACL-VISION, a multilingual visual
document retrieval evaluation benchmark. MIRACL-VISION covers 18 languages, and
is an extension of the MIRACL dataset, a popular benchmark to evaluate
text-based multilingual retrieval pipelines. MIRACL was built using a
human-intensive annotation process to generate high-quality questions. In order
to reduce MIRACL-VISION corpus size to make evaluation more compute friendly
while keeping the datasets challenging, we have designed a method for
eliminating the "easy" negatives from the corpus. We conducted extensive
experiments comparing MIRACL-VISION with other benchmarks, using popular public
text and image models. We observe a gap in state-of-the-art VLM-based embedding
models on multilingual capabilities, with up to 59.7% lower retrieval accuracy
than a text-based retrieval models. Even for the English language, the visual
models retrieval accuracy is 12.1% lower compared to text-based models.
MIRACL-VISION is a challenging, representative, multilingual evaluation
benchmark for visual retrieval pipelines and will help the community build
robust models for document retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Predictive Optimization and Generation for Business AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.09847v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.09847v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyang Zhao, Olurotimi Seton, Himadeep Reddy Reddivari, Suvendu Jena, Shadow Zhao, Rachit Kumar, Changshuai Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The sales process involves sales functions converting leads or opportunities
to customers and selling more products to existing customers. The optimization
of the sales process thus is key to success of any B2B business. In this work,
we introduce a principled approach to sales optimization and business AI,
namely the Causal Predictive Optimization and Generation, which includes three
layers: 1) prediction layer with causal ML 2) optimization layer with
constraint optimization and contextual bandit 3) serving layer with Generative
AI and feedback-loop for system enhancement. We detail the implementation and
deployment of the system in LinkedIn, showcasing significant wins over legacy
systems and sharing learning and insight broadly applicable to this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explain What You Mean: Intent Augmented Knowledge Graph Recommender
  Built With An LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.10900v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.10900v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqing Zheng, Noah Fatsi, Daniel Barcklow, Dmitri Kalaev, Steven Yao, Owen Reinert, C. Bayan Bruss, Daniele Rosa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interaction sparsity is a long-standing challenge in recommendation systems.
Sparsity manifests in environments with disproportional cardinality of
groupings of entities, such as users and products in an online marketplace. It
is also found for newly introduced entities, described as the cold-start
problem. Recent efforts to mitigate this issue either enrich the connectivity
data by incorporating social networks or external knowledge graphs, or
fine-tune LLMs into interaction augmenters or next-item recommenders. However,
these techniques tend to be resource demanding, requiring high computational
power. They also have several limitations, including data availability, low
quality, or synthetic noise issues. In this work, we propose LLM-based Intent
Knowledge Graph Recommender (IKGR), a novel framework that leverages
retrieval-augmented generation and an encoding approach to construct and
densify a knowledge graph. IKGR leverages latent user-item affinities from an
interaction knowledge graph and further densifies it through mutual intent
connectivity. This addresses sparsity issues and allows the model to make
intent-grounded recommendations with an interpretable embedding translation
layer. Through extensive experiments on real-world datasets, we demonstrate
that IKGR overcomes knowledge gaps and achieves substantial gains over
state-of-the-art baselines on both publicly available and our internal
recommendation datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aggregation Schemes for Single-Vector WSI Representation Learning in
  Digital Pathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17822v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17822v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A crucial step to efficiently integrate Whole Slide Images (WSIs) in
computational pathology is assigning a single high-quality feature vector,
i.e., one embedding, to each WSI. With the existence of many pre-trained deep
neural networks and the emergence of foundation models, extracting embeddings
for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,
given their high resolution and gigapixel nature, inputting them into existing
GPUs as a single image is not feasible. As a result, WSIs are usually split
into many patches. Feeding each patch to a pre-trained model, each WSI can then
be represented by a set of patches, hence, a set of embeddings. Hence, in such
a setup, WSI representation learning reduces to set representation learning
where for each WSI we have access to a set of patch embeddings. To obtain a
single embedding from a set of patch embeddings for each WSI, multiple
set-based learning schemes have been proposed in the literature. In this paper,
we evaluate the WSI search performance of multiple recently developed
aggregation techniques (mainly set representation learning techniques)
including simple average or max pooling operations, Deep Sets, Memory networks,
Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse
and binary Fisher Vector on four different primary sites including bladder,
breast, kidney, and Colon from TCGA. Further, we benchmark the search
performance of these methods against the median of minimum distances of patch
embeddings, a non-aggregating approach used for WSI retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Variations in Relevance Judgments and the Shelf Life of Test Collections <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20937v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20937v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Parry, Maik Fröbe, Harrisen Scells, Ferdinand Schlatt, Guglielmo Faggioli, Saber Zerhoudi, Sean MacAvaney, Eugene Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fundamental property of Cranfield-style evaluations, that system rankings
are stable even when assessors disagree on individual relevance decisions, was
validated on traditional test collections. However, the paradigm shift towards
neural retrieval models affected the characteristics of modern test
collections, e.g., documents are short, judged with four grades of relevance,
and information needs have no descriptions or narratives. Under these changes,
it is unclear whether assessor disagreement remains negligible for system
comparisons. We investigate this aspect under the additional condition that the
few modern test collections are heavily re-used. Given more possible query
interpretations due to less formalized information needs, an ``expiration
date'' for test collections might be needed if top-effectiveness requires
overfitting to a single interpretation of relevance. We run a reproducibility
study and re-annotate the relevance judgments of the 2019~TREC Deep Learning
track. We can reproduce prior work in the neural retrieval setting, showing
that assessor disagreement does not affect system rankings. However, we observe
that some models substantially degrade with our new relevance judgments, and
some have already reached the effectiveness of humans as rankers, providing
evidence that test collections can expire.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 tables, 5 figures, Accepted to SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Securing RAG: A Risk Assessment and Mitigation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.08728v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.08728v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation (RAG) has emerged as the de facto industry
standard for user-facing NLP applications, offering the ability to integrate
data without re-training or fine-tuning Large Language Models (LLMs). This
capability enhances the quality and accuracy of responses but also introduces
novel security and privacy challenges, particularly when sensitive data is
integrated. With the rapid adoption of RAG, securing data and services has
become a critical priority. This paper first reviews the vulnerabilities of RAG
pipelines, and outlines the attack surface from data pre-processing and data
storage management to integration with LLMs. The identified risks are then
paired with corresponding mitigations in a structured overview. In a second
step, the paper develops a framework that combines RAG-specific security
considerations, with existing general security guidelines, industry standards,
and best practices. The proposed framework aims to guide the implementation of
robust, compliant, secure, and trustworthy RAG systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures, Sara Ott and Lukas Ammann contributed equally.
  This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive Evaluation of Large Language Models on Temporal Event
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11638v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11638v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation (RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast, fine-tuning
LLMs with raw texts can significantly improve performance. Additionally, LLMs
enhanced with retrieval modules can effectively capture temporal relational
patterns hidden in historical events. However, issues such as popularity bias
and the long-tail problem persist in LLMs, particularly in the
retrieval-augmented generation (RAG) method. These findings not only deepen our
understanding of LLM-based event forecasting methods but also highlight several
promising research directions. We consider that this comprehensive evaluation,
along with the identified research opportunities, will significantly contribute
to future research on temporal event forecasting through LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are AI Agents interacting with Online Ads? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.07112v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.07112v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreas Stöckl, Joel Nitu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As AI-driven agents become increasingly integrated into the digital
ecosystem, they reshape how online advertising is perceived and processed.
Particularly in the travel and hotel booking sector, these autonomous systems
influence the effectiveness of traditional advertising formats. While visual
cues and emotional appeals sway human users, AI agents prioritize structured
data such as price, availability, and specifications. This study examines how
different AI agents interact with online advertising, whether they incorporate
ads into their decision-making processes, and which ad formats prove most
effective. We analyze interaction patterns, click behavior, and decision-making
strategies through experiments with multimodal language models such as OpenAI
GPT-4o, Anthropic Claude, and Google Gemini 2.0 Flash. Our findings reveal that
AI agents neither ignore nor systematically avoid advertisements but instead
favor certain features-particularly keywords and structured data. These
insights have significant implications for the future design of advertising
strategies in AI-dominated digital environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIRe: Enhancing Multimodal Queries Representation via Fusion-Free
  Modality Interaction for Multimodal Retrieval <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.08334v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.08334v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent multimodal retrieval methods have endowed text-based retrievers with
multimodal capabilities by utilizing pre-training strategies for visual-text
alignment. They often directly fuse the two modalities for cross-reference
during the alignment to understand multimodal queries. However, existing
methods often overlook crucial visual information due to a text-dominant issue,
which overly depends on text-driven signals. In this paper, we introduce MIRe,
a retrieval framework that achieves modality interaction without fusing textual
features during the alignment. Our method allows the textual query to attend to
visual embeddings while not feeding text-driven signals back into the visual
representations. Additionally, we construct a pre-training dataset for
multimodal query retrieval by transforming concise question-answer pairs into
extended passages. Our experiments demonstrate that our pre-training strategy
significantly enhances the understanding of multimodal queries, resulting in
strong performance across four multimodal retrieval benchmarks under zero-shot
settings. Moreover, our ablation studies and analyses explicitly verify the
effectiveness of our framework in mitigating the text-dominant issue. Our code
is publicly available: https://github.com/yeongjoonJu/MIRe
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2025 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boosting Text-to-Chart Retrieval through Training with Synthesized
  Semantic Insights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.10043v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.10043v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Wu, Lutao Yan, Yizhang Zhu, Yinan Mei, Jiannan Wang, Nan Tang, Yuyu Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Charts are crucial for data analysis and decision-making.Text-to-chart
retrieval systems have become increasingly important for Business Intelligence
(BI), where users need to find relevant charts that match their analytical
needs. These needs can be categorized into precise queries that are
well-specified and fuzzy queries that are more exploratory -- both require
understanding the semantics and context of the charts. However, existing
text-to-chart retrieval solutions often fail to capture the semantic content
and contextual information of charts, primarily due to the lack of
comprehensive metadata (or semantic insights). To address this limitation, we
propose a training data development pipeline that automatically synthesizes
hierarchical semantic insights for charts, covering visual patterns
(visual-oriented), statistical properties (statistics-oriented), and practical
applications (task-oriented), which produces 207,498 semantic insights for
69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to
learn better representations of charts for text-to-chart retrieval. Our method
leverages rich semantic insights during the training phase to develop a model
that understands both visual and semantic aspects of charts.To evaluate
text-to-chart retrieval performance, we curate the first benchmark, CRBench,
for this task with 21,862 charts and 326 text queries from real-world BI
applications, with ground-truth labels verified by the crowd
workers.Experiments show that ChartFinder significantly outperforms existing
methods in text-to-chart retrieval tasks across various settings. For precise
queries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than
state-of-the-art models. In fuzzy query tasks, our method also demonstrates
consistent improvements, with an average increase of 5% across nearly all
metrics.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Signals of Provenance: Practices & Challenges of Navigating Indicators
  in AI-Generated Media for Sighted and Blind Individuals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16057v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16057v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayae Ide, Tory Park, Jaron Mink, Tanusree Sharma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI-Generated (AIG) content has become increasingly widespread by recent
advances in generative models and the easy-to-use tools that have significantly
lowered the technical barriers for producing highly realistic audio, images,
and videos through simple natural language prompts. In response, platforms are
adopting provable provenance with platforms recommending AIG to be
self-disclosed and signaled to users. However, these indicators may be often
missed, especially when they rely solely on visual cues and make them
ineffective to users with different sensory abilities. To address the gap, we
conducted semi-structured interviews (N=28) with 15 sighted and 13 BLV
participants to examine their interaction with AIG content through
self-disclosed AI indicators. Our findings reveal diverse mental models and
practices, highlighting different strengths and weaknesses of content-based
(e.g., title, description) and menu-aided (e.g., AI labels) indicators. While
sighted participants leveraged visual and audio cues, BLV participants
primarily relied on audio and existing assistive tools, limiting their ability
to identify AIG. Across both groups, they frequently overlooked menu-aided
indicators deployed by platforms and rather interacted with content-based
indicators such as title and comments. We uncovered usability challenges
stemming from inconsistent indicator placement, unclear metadata, and cognitive
overload. These issues were especially critical for BLV individuals due to the
insufficient accessibility of interface elements. We provide practical
recommendations and design implications for future AIG indicators across
several dimensions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CP-LLM: Context and Pixel Aware Large Language Model for Video Quality
  Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.16025v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.16025v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Wen, Yaohong Wu, Yue Sheng, Neil Birkbeck, Balu Adsumilli, Yilin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video quality assessment (VQA) is a challenging research topic with broad
applications. Effective VQA necessitates sensitivity to pixel-level distortions
and a comprehensive understanding of video context to accurately determine the
perceptual impact of distortions. Traditional hand-crafted and learning-based
VQA models mainly focus on pixel-level distortions and lack contextual
understanding, while recent LLM-based models struggle with sensitivity to small
distortions or handle quality scoring and description as separate tasks. To
address these shortcomings, we introduce CP-LLM: a Context and Pixel aware
Large Language Model. CP-LLM is a novel multimodal LLM architecture featuring
dual vision encoders designed to independently analyze perceptual quality at
both high-level (video context) and low-level (pixel distortion) granularity,
along with a language decoder subsequently reasons about the interplay between
these aspects. This design enables CP-LLM to simultaneously produce robust
quality scores and interpretable quality descriptions, with enhanced
sensitivity to pixel distortions (e.g. compression artifacts). The model is
trained via a multi-task pipeline optimizing for score prediction, description
generation, and pairwise comparisons. Experiment results demonstrate that
CP-LLM achieves state-of-the-art cross-dataset performance on established VQA
benchmarks and superior robustness to pixel distortions, confirming its
efficacy for comprehensive and practical video quality assessment in real-world
scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Relationship Analysis of Image-Text Pair in SNS Posts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takuto Nabeoka, Yijun Duan, Qiang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social networking services (SNS) contain vast amounts of image-text posts,
necessitating effective analysis of their relationships for improved
information retrieval. This study addresses the classification of image-text
pairs in SNS, overcoming prior limitations in distinguishing relationships
beyond similarity. We propose a graph-based method to classify image-text pairs
into similar and complementary relationships. Our approach first embeds images
and text using CLIP, followed by clustering. Next, we construct an Image-Text
Relationship Clustering Line Graph (ITRC-Line Graph), where clusters serve as
nodes. Finally, edges and nodes are swapped in a pseudo-graph representation. A
Graph Convolutional Network (GCN) then learns node and edge representations,
which are fused with the original embeddings for final classification.
Experimental results on a publicly available dataset demonstrate the
effectiveness of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAVEN: Query-Guided Representation Alignment for Question Answering over
  Audio, Video, Embedded Sensors, and Natural Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17114v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17114v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subrata Biswas, Mohammad Nur Hossain Khan, Bashima Islam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal question answering (QA) often requires identifying which video,
audio, or sensor tokens are relevant to the question. Yet modality
disagreements are common: off-camera speech, background noise, or motion
outside the field of view often mislead fusion models that weight all streams
equally. We present RAVEN, a unified QA architecture whose core is QuART, a
query-conditioned cross-modal gating module that assigns scalar relevance
scores to each token across modalities, enabling the model to amplify
informative signals and suppress distractors before fusion. RAVEN is trained
through a three-stage pipeline comprising unimodal pretraining, query-aligned
fusion, and disagreement-oriented fine-tuning -- each stage targeting a
distinct challenge in multi-modal reasoning: representation quality,
cross-modal relevance, and robustness to modality mismatch. To support training
and evaluation, we release AVS-QA, a dataset of 300K synchronized
Audio--Video-Sensor streams paired with automatically generated question-answer
pairs. Experimental results on seven multi-modal QA benchmarks -- including
egocentric and exocentric tasks -- show that RAVEN achieves up to 14.5\% and
8.0\% gains in accuracy compared to state-of-the-art multi-modal large language
models, respectively. Incorporating sensor data provides an additional 16.4\%
boost, and the model remains robust under modality corruption, outperforming
SOTA baselines by 50.23\%. Our code and dataset are available at
https://github.com/BASHLab/RAVEN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing Through Deception: Uncovering Misleading Creator Intent in
  Multimodal News with Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaying Wu, Fanxiao Li, Min-Yen Kan, Bryan Hooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The real-world impact of misinformation stems from the underlying misleading
narratives that creators seek to convey. As such, interpreting misleading
creator intent is essential for multimodal misinformation detection (MMD)
systems aimed at effective information governance. In this paper, we introduce
an automated framework that simulates real-world multimodal news creation by
explicitly modeling creator intent through two components: the desired
influence and the execution plan. Using this framework, we construct
DeceptionDecoded, a large-scale benchmark comprising 12,000 image-caption pairs
aligned with trustworthy reference articles. The dataset captures both
misleading and non-misleading intents and spans manipulations across visual and
textual modalities. We conduct a comprehensive evaluation of 14
state-of-the-art vision-language models (VLMs) on three intent-centric tasks:
(1) misleading intent detection, (2) misleading source attribution, and (3)
creator desire inference. Despite recent advances, we observe that current VLMs
fall short in recognizing misleading intent, often relying on spurious cues
such as superficial cross-modal consistency, stylistic signals, and heuristic
authenticity hints. Our findings highlight the pressing need for intent-aware
modeling in MMD and open new directions for developing systems capable of
deeper reasoning about multimodal misinformation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.17104v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.17104v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Sun, Enhao Pan, Zhengkai Yang, Kaixin Sui, Jiajun Shi, Xianfu Cheng, Tongliang Li, Wenhao Huang, Ge Zhang, Jian Yang, Zhoujun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Academic posters are vital for scholarly communication, yet their manual
creation is time-consuming. However, automated academic poster generation faces
significant challenges in preserving intricate scientific details and achieving
effective visual-textual integration. Existing approaches often struggle with
semantic richness and structural nuances, and lack standardized benchmarks for
evaluating generated academic posters comprehensively. To address these
limitations, we introduce P2P, the first flexible, LLM-based multi-agent
framework that generates high-quality, HTML-rendered academic posters directly
from research papers, demonstrating strong potential for practical
applications. P2P employs three specialized agents-for visual element
processing, content generation, and final poster assembly-each integrated with
dedicated checker modules to enable iterative refinement and ensure output
quality. To foster advancements and rigorous evaluation in this domain, we
construct and release P2PInstruct, the first large-scale instruction dataset
comprising over 30,000 high-quality examples tailored for the academic
paper-to-poster generation task. Furthermore, we establish P2PEval, a
comprehensive benchmark featuring 121 paper-poster pairs and a dual evaluation
methodology (Universal and Fine-Grained) that leverages LLM-as-a-Judge and
detailed, human-annotated checklists. Our contributions aim to streamline
research dissemination and provide the community with robust tools for
developing and evaluating next-generation poster generation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive
  Routing for Efficient LLM/MLLM Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinghui Lu, Haiyang Yu, Siliang Xu, Shiwei Ran, Guozhi Tang, Siqi Wang, Bin Shan, Teng Fu, Hao Feng, Jingqun Tang, Han Wang, Can Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in reasoning have significantly enhanced the capabilities
of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
across diverse tasks. However, excessive reliance on chain-of-thought (CoT)
reasoning can impair model performance and brings unnecessarily lengthened
outputs, reducing efficiency. Our work reveals that prolonged reasoning does
not universally improve accuracy and even degrade performance on simpler tasks.
To address this, we propose Certainty-based Adaptive Reasoning (CAR), a novel
framework that dynamically switches between short answers and long-form
reasoning based on the model perplexity. CAR first generates a short answer and
evaluates its perplexity, triggering reasoning only when the model exhibits low
confidence (i.e., high perplexity). Experiments across diverse multimodal
VQA/KIE benchmarks and text reasoning datasets show that CAR outperforms both
short-answer and long-form reasoning approaches, striking an optimal balance
between accuracy and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Relevance Feedback for Interactive Known-Item Video Search <span class="chip">ICMR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhixin Ma, Chong-Wah Ngo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Known-item search (KIS) involves only a single search target, making
relevance feedback-typically a powerful technique for efficiently identifying
multiple positive examples to infer user intent-inapplicable. PicHunter
addresses this issue by asking users to select the top-k most similar examples
to the unique search target from a displayed set. Under ideal conditions, when
the user's perception aligns closely with the machine's perception of
similarity, consistent and precise judgments can elevate the target to the top
position within a few iterations. However, in practical scenarios, expecting
users to provide consistent judgments is often unrealistic, especially when the
underlying embedding features used for similarity measurements lack
interpretability. To enhance robustness, we first introduce a pairwise relative
judgment feedback that improves the stability of top-k selections by mitigating
the impact of misaligned feedback. Then, we decompose user perception into
multiple sub-perceptions, each represented as an independent embedding space.
This approach assumes that users may not consistently align with a single
representation but are more likely to align with one or several among multiple
representations. We develop a predictive user model that estimates the
combination of sub-perceptions based on each user feedback instance. The
predictive user model is then trained to filter out the misaligned
sub-perceptions. Experimental evaluations on the large-scale open-domain
dataset V3C indicate that the proposed model can optimize over 60% search
targets to the top rank when their initial ranks at the search depth between 10
and 50. Even for targets initially ranked between 1,000 and 5,000, the model
achieves a success rate exceeding 40% in optimizing ranks to the top,
demonstrating the enhanced robustness of relevance feedback in KIS despite
inconsistent feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICMR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Long-Form Text-to-Music Generation with Adaptive <span class="highlight-title">Prompt</span>s: A Case Study
  in Tabletop Role-Playing Games Soundtracks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03948v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03948v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felipe Marra, Lucas N. Ferreira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the capabilities of text-to-audio music generation
models in producing long-form music with prompts that change over time,
focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We
introduce Babel Bardo, a system that uses Large Language Models (LLMs) to
transform speech transcriptions into music descriptions for controlling a
text-to-music model. Four versions of Babel Bardo were compared in two TRPG
campaigns: a baseline using direct speech transcriptions, and three LLM-based
versions with varying approaches to music description generation. Evaluations
considered audio quality, story alignment, and transition smoothness. Results
indicate that detailed music descriptions improve audio quality while
maintaining consistency across consecutive descriptions enhances story
alignment and transition smoothness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 1st Latin American Music Information Retrieval
  Workshop (LAMIR), pg 80</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SEA: Low-Resource Safety Alignment for Multimodal Large Language Models
  via Synthetic Embeddings <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12562v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12562v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have serious security
vulnerabilities.While safety alignment using multimodal datasets consisting of
text and data of additional modalities can effectively enhance MLLM's security,
it is costly to construct these datasets. Existing low-resource security
alignment methods, including textual alignment, have been found to struggle
with the security risks posed by additional modalities. To address this, we
propose Synthetic Embedding augmented safety Alignment (SEA), which optimizes
embeddings of additional modality through gradient updates to expand textual
datasets. This enables multimodal safety alignment training even when only
textual data is available. Extensive experiments on image, video, and
audio-based MLLMs demonstrate that SEA can synthesize a high-quality embedding
on a single RTX3090 GPU within 24 seconds. SEA significantly improves the
security of MLLMs when faced with threats from additional modalities. To assess
the security risks introduced by video and audio, we also introduced a new
benchmark called VA-SafetyBench. High attack success rates across multiple
MLLMs validate its challenge. Our code and data will be available at
https://github.com/ZeroNLP/SEA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ACL 2025 Main Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14336v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14336v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy
environments by integrating visual cues. While recent advances integrate Large
Language Models (LLMs) into AVSR, their high computational cost hinders
deployment in resource-constrained settings. To address this, we propose
Llama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of
Projectors (SMoP) module to scale model capacity without increasing inference
costs. By incorporating sparsely-gated mixture-of-experts (MoE) projectors,
Llama-SMoP enables the use of smaller LLMs while maintaining strong
performance. We explore three SMoP configurations and show that Llama-SMoP DEDR
(Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and
experts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation
studies confirm its effectiveness in expert activation, scalability, and noise
robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Interspeech 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via
  Fine-Grained Alignment <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.01237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.01237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edson Araujo, Andrew Rouditchenko, Yuan Gong, Saurabhchand Bhati, Samuel Thomas, Brian Kingsbury, Leonid Karlinsky, Rogerio Feris, James R. Glass, Hilde Kuehne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in audio-visual learning have shown promising results in
learning representations across modalities. However, most approaches rely on
global audio representations that fail to capture fine-grained temporal
correspondences with visual frames. Additionally, existing methods often
struggle with conflicting optimization objectives when trying to jointly learn
reconstruction and cross-modal alignment. In this work, we propose CAV-MAE Sync
as a simple yet effective extension of the original CAV-MAE framework for
self-supervised audio-visual learning. We address three key challenges: First,
we tackle the granularity mismatch between modalities by treating audio as a
temporal sequence aligned with video frames, rather than using global
representations. Second, we resolve conflicting optimization goals by
separating contrastive and reconstruction objectives through dedicated global
tokens. Third, we improve spatial localization by introducing learnable
register tokens that reduce semantic load on patch tokens. We evaluate the
proposed approach on AudioSet, VGG Sound, and the ADE20K Sound dataset on
zero-shot retrieval, classification and localization tasks demonstrating
state-of-the-art performance and outperforming more complex architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be published at CVPR 2025, code available at
  https://github.com/edsonroteia/cav-mae-sync</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MatchDance: Collaborative Mamba-<span class="highlight-title">Transformer</span> Architecture Matching for
  High-Quality 3D Dance Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixing Yang, Xulong Tang, Yuxuan Hu, Jiahao Yang, Hongyan Liu, Qinnan Zhang, Jun He, Zhaoxin Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music-to-dance generation represents a challenging yet pivotal task at the
intersection of choreography, virtual reality, and creative content generation.
Despite its significance, existing methods face substantial limitation in
achieving choreographic consistency. To address the challenge, we propose
MatchDance, a novel framework for music-to-dance generation that constructs a
latent representation to enhance choreographic consistency. MatchDance employs
a two-stage design: (1) a Kinematic-Dynamic-based Quantization Stage (KDQS),
which encodes dance motions into a latent representation by Finite Scalar
Quantization (FSQ) with kinematic-dynamic constraints and reconstructs them
with high fidelity, and (2) a Hybrid Music-to-Dance Generation Stage(HMDGS),
which uses a Mamba-Transformer hybrid architecture to map music into the latent
representation, followed by the KDQS decoder to generate 3D dance motions.
Additionally, a music-dance retrieval framework and comprehensive metrics are
introduced for evaluation. Extensive experiments on the FineDance dataset
demonstrate state-of-the-art performance. Code will be released upon
acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIRe: Enhancing Multimodal Queries Representation via Fusion-Free
  Modality Interaction for Multimodal Retrieval <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.08334v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.08334v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent multimodal retrieval methods have endowed text-based retrievers with
multimodal capabilities by utilizing pre-training strategies for visual-text
alignment. They often directly fuse the two modalities for cross-reference
during the alignment to understand multimodal queries. However, existing
methods often overlook crucial visual information due to a text-dominant issue,
which overly depends on text-driven signals. In this paper, we introduce MIRe,
a retrieval framework that achieves modality interaction without fusing textual
features during the alignment. Our method allows the textual query to attend to
visual embeddings while not feeding text-driven signals back into the visual
representations. Additionally, we construct a pre-training dataset for
multimodal query retrieval by transforming concise question-answer pairs into
extended passages. Our experiments demonstrate that our pre-training strategy
significantly enhances the understanding of multimodal queries, resulting in
strong performance across four multimodal retrieval benchmarks under zero-shot
settings. Moreover, our ablation studies and analyses explicitly verify the
effectiveness of our framework in mitigating the text-dominant issue. Our code
is publicly available: https://github.com/yeongjoonJu/MIRe
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2025 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hearing from Silence: Reasoning Audio Descriptions from Silent Videos
  via Vision-Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Ren, Chenxing Li, Le Xu, Hao Gu, Duzhen Zhang, Yujie Chen, Manjie Xu, Ruibo Fu, Shan Yang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can intuitively infer sounds from silent videos, but whether
multimodal large language models can perform modal-mismatch reasoning without
accessing target modalities remains relatively unexplored. Current
text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but
struggle to acquire audio descriptions during inference. We introduce the task
of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this
challenge and investigate vision-language models' (VLMs) capabilities on this
task. To further enhance the VLMs' reasoning capacity for the SVAD task, we
construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based
supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks
demonstrate our method's effectiveness in two key aspects: significantly
improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing
the challenge of acquiring audio descriptions during VT2A inference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Interspeech 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Microphone Conversion: Many-to-Many Device Mapping via
  Feature-wise Linear Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18322v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18322v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Myeonghoon Ryu, Hongseok Oh, Suji Lee, Han Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Unified Microphone Conversion, a unified generative framework
designed to bolster sound event classification (SEC) systems against device
variability. While our prior CycleGAN-based methods effectively simulate device
characteristics, they require separate models for each device pair, limiting
scalability. Our approach overcomes this constraint by conditioning the
generator on frequency response data, enabling many-to-many device mappings
through unpaired training. We integrate frequency-response information via
Feature-wise Linear Modulation, further enhancing scalability. Additionally,
incorporating synthetic frequency response differences improves the
applicability of our framework for real-world application. Experimental results
show that our method outperforms the state-of-the-art by 2.6% and reduces
variability by 0.8% in macro-average F1 score.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Interspeech 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized
  Diffusion-based Voice Cloning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12332v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12332v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion Models (DMs) have achieved remarkable success in realistic voice
cloning (VC), while they also increase the risk of malicious misuse. Existing
proactive defenses designed for traditional VC models aim to disrupt the
forgery process, but they have been proven incompatible with DMs due to the
intricate generative mechanisms of diffusion. To bridge this gap, we introduce
VoiceCloak, a multi-dimensional proactive defense framework with the goal of
obfuscating speaker identity and degrading perceptual quality in potential
unauthorized VC. To achieve these goals, we conduct a focused analysis to
identify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt
the cloning process by introducing adversarial perturbations into the reference
audio. Specifically, to obfuscate speaker identity, VoiceCloak first targets
speaker identity by distorting representation learning embeddings to maximize
identity variation, which is guided by auditory perception principles.
Additionally, VoiceCloak disrupts crucial conditional guidance processes,
particularly attention context, thereby preventing the alignment of vocal
characteristics that are essential for achieving convincing cloning. Then, to
address the second objective, VoiceCloak introduces score magnitude
amplification to actively steer the reverse trajectory away from the generation
of high-quality speech. Noise-guided semantic corruption is further employed to
disrupt structural speech semantics captured by DMs, degrading output quality.
Extensive experiments highlight VoiceCloak's outstanding defense success rate
against unauthorized diffusion-based voice cloning.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-20T00:00:00Z">2025-05-20</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">36</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Privacy Preserving Conversion Modeling in Data Clean Room <span class="chip">RecSys '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kungang Li, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Behnam Rezaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the realm of online advertising, accurately predicting the conversion rate
(CVR) is crucial for enhancing advertising efficiency and user satisfaction.
This paper addresses the challenge of CVR prediction while adhering to user
privacy preferences and advertiser requirements. Traditional methods face
obstacles such as the reluctance of advertisers to share sensitive conversion
data and the limitations of model training in secure environments like data
clean rooms. We propose a novel model training framework that enables
collaborative model training without sharing sample-level gradients with the
advertising platform. Our approach introduces several innovative components:
(1) utilizing batch-level aggregated gradients instead of sample-level
gradients to minimize privacy risks; (2) applying adapter-based
parameter-efficient fine-tuning and gradient compression to reduce
communication costs; and (3) employing de-biasing techniques to train the model
under label differential privacy, thereby maintaining accuracy despite
privacy-enhanced label perturbations. Our experimental results, conducted on
industrial datasets, demonstrate that our method achieves competitive ROCAUC
performance while significantly decreasing communication overhead and complying
with both advertiser privacy requirements and user privacy choices. This
framework establishes a new standard for privacy-preserving, high-performance
CVR prediction in the digital advertising landscape.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Proceedings of the 18th ACM Conference on Recommender
  Systems. 2024 (RecSys '24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Diffusion Model Reshapes Cold-Start Bundle Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14901v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14901v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan-Nghia Bui, Huy-Son Nguyen, Cam-Van Thi Nguyen, Hoang-Quynh Le, Duc-Trong Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bundle recommendation aims to recommend a set of items to each user. However,
the sparser interactions between users and bundles raise a big challenge,
especially in cold-start scenarios. Traditional collaborative filtering methods
do not work well for this kind of problem because these models rely on
interactions to update the latent embedding, which is hard to work in a
cold-start setting. We propose a new approach (DisCo), which relies on a
personalized Diffusion backbone, enhanced by disentangled aspects for the
user's interest, to generate a bundle in distribution space for each user to
tackle the cold-start challenge. During the training phase, DisCo adjusts an
additional objective loss term to avoid bias, a prevalent issue while using the
generative model for top-$K$ recommendation purposes. Our empirical experiments
show that DisCo outperforms five comparative baselines by a large margin on
three real-world datasets. Thereby, this study devises a promising framework
and essential viewpoints in cold-start recommendation. Our materials for
reproducibility are available at: https://github.com/bt-nghia/DisCo.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster
  Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15856v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15856v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Yin, Xiangjue Dong, Chengkai Liu, Lipai Huang, Yiming Xiao, Zhewei Liu, Ali Mostafavi, James Caverlee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective disaster management requires timely access to accurate and
contextually relevant information. Existing Information Retrieval (IR)
benchmarks, however, focus primarily on general or specialized domains, such as
medicine or finance, neglecting the unique linguistic complexity and diverse
information needs encountered in disaster management scenarios. To bridge this
gap, we introduce DisastIR, the first comprehensive IR evaluation benchmark
specifically tailored for disaster management. DisastIR comprises 9,600 diverse
user queries and more than 1.3 million labeled query-passage pairs, covering 48
distinct retrieval tasks derived from six search intents and eight general
disaster categories that include 301 specific event types. Our evaluations of
30 state-of-the-art retrieval models demonstrate significant performance
variances across tasks, with no single model excelling universally.
Furthermore, comparative analyses reveal significant performance gaps between
general-domain and disaster management-specific tasks, highlighting the
necessity of disaster management-specific benchmarks for guiding IR model
selection to support effective decision-making in disaster management
scenarios. All source codes and DisastIR are available at
https://github.com/KaiYin97/Disaster_IR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisTopics: A Visual Semantic Unsupervised Approach to Topic Modeling of
  Video and Image Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14868v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14868v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayse D Lokmanoglu, Dror Walter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding visual narratives is crucial for examining the evolving
dynamics of media representation. This study introduces VisTopics, a
computational framework designed to analyze large-scale visual datasets through
an end-to-end pipeline encompassing frame extraction, deduplication, and
semantic clustering. Applying VisTopics to a dataset of 452 NBC News videos
resulted in reducing 11,070 frames to 6,928 deduplicated frames, which were
then semantically analyzed to uncover 35 topics ranging from political events
to environmental crises. By integrating Latent Dirichlet Allocation with
caption-based semantic analysis, VisTopics demonstrates its potential to
unravel patterns in visual framing across diverse contexts. This approach
enables longitudinal studies and cross-platform comparisons, shedding light on
the intersection of media, technology, and public discourse. The study
validates the method's reliability through human coding accuracy metrics and
emphasizes its scalability for communication research. By bridging the gap
between visual representation and semantic meaning, VisTopics provides a
transformative tool for advancing the methodological toolkit in computational
media studies. Future research may leverage VisTopics for comparative analyses
across media outlets or geographic regions, offering insights into the shifting
landscapes of media narratives and their societal implications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Two Experts Are All You Need for Steering Thinking: Reinforcing
  Cognitive Effort in MoE Reasoning Models Without Additional Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14681v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14681v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, Zhaopeng Tu, Xiaolong Li, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs)
have achieved impressive reasoning capabilities by selectively activating
experts to facilitate structured cognitive processes. Despite notable advances,
existing reasoning models often suffer from cognitive inefficiencies like
overthinking and underthinking. To address these limitations, we introduce a
novel inference-time steering methodology called Reinforcing Cognitive Experts
(RICE), designed to improve reasoning performance without additional training
or complex heuristics. Leveraging normalized Pointwise Mutual Information
(nPMI), we systematically identify specialized experts, termed ''cognitive
experts'' that orchestrate meta-level reasoning operations characterized by
tokens like ''<think>''. Empirical evaluations with leading MoE-based LRMs
(DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning
benchmarks demonstrate noticeable and consistent improvements in reasoning
accuracy, cognitive efficiency, and cross-domain generalization. Crucially, our
lightweight approach substantially outperforms prevalent reasoning-steering
techniques, such as prompt design and decoding constraints, while preserving
the model's general instruction-following skills. These results highlight
reinforcing cognitive experts as a promising, practical, and interpretable
direction to enhance cognitive efficiency within advanced reasoning models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunhao Dai, Wenjie Wang, Liang Pang, Jun Xu, See-Kiong Ng, Ji-Rong Wen, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative AI search is reshaping information retrieval by offering
end-to-end answers to complex queries, reducing users' reliance on manually
browsing and summarizing multiple web pages. However, while this paradigm
enhances convenience, it disrupts the feedback-driven improvement loop that has
historically powered the evolution of traditional Web search. Web search can
continuously improve their ranking models by collecting large-scale,
fine-grained user feedback (e.g., clicks, dwell time) at the document level. In
contrast, generative AI search operates through a much longer search pipeline,
spanning query decomposition, document retrieval, and answer generation, yet
typically receives only coarse-grained feedback on the final answer. This
introduces a feedback loop disconnect, where user feedback for the final output
cannot be effectively mapped back to specific system components, making it
difficult to improve each intermediate stage and sustain the feedback loop. In
this paper, we envision NExT-Search, a next-generation paradigm designed to
reintroduce fine-grained, process-level feedback into generative AI search.
NExT-Search integrates two complementary modes: User Debug Mode, which allows
engaged users to intervene at key stages; and Shadow User Mode, where a
personalized user agent simulates user preferences and provides AI-assisted
feedback for less interactive users. Furthermore, we envision how these
feedback signals can be leveraged through online adaptation, which refines
current search outputs in real-time, and offline update, which aggregates
interaction logs to periodically fine-tune query decomposition, retrieval, and
generation models. By restoring human control over key stages of the generative
AI search pipeline, we believe NExT-Search offers a promising direction for
building feedback-rich AI search systems that can evolve continuously alongside
human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2025 Perspective Paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ R2MED: A Benchmark for Reasoning-Driven Medical Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14558v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14558v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Li, Xiao Zhou, Zheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current medical retrieval benchmarks primarily emphasize lexical or shallow
semantic similarity, overlooking the reasoning-intensive demands that are
central to clinical decision-making. In practice, physicians often retrieve
authoritative medical evidence to support diagnostic hypotheses. Such evidence
typically aligns with an inferred diagnosis rather than the surface form of a
patient's symptoms, leading to low lexical or semantic overlap between queries
and relevant documents. To address this gap, we introduce R2MED, the first
benchmark explicitly designed for reasoning-driven medical retrieval. It
comprises 876 queries spanning three tasks: Q&A reference retrieval, clinical
evidence retrieval, and clinical case retrieval. These tasks are drawn from
five representative medical scenarios and twelve body systems, capturing the
complexity and diversity of real-world medical information needs. We evaluate
15 widely-used retrieval systems on R2MED and find that even the best model
achieves only 31.4 nDCG@10, demonstrating the benchmark's difficulty. Classical
re-ranking and generation-augmented retrieval methods offer only modest
improvements. Although large reasoning models improve performance via
intermediate inference generation, the best results still peak at 41.4 nDCG@10.
These findings underscore a substantial gap between current retrieval
techniques and the reasoning demands of real clinical tasks. We release R2MED
as a challenging benchmark to foster the development of next-generation medical
retrieval systems with enhanced reasoning capabilities. Data and code are
available at https://github.com/R2MED/R2MED
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rank-K: Test-Time Reasoning for Listwise Reranking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eugene Yang, Andrew Yates, Kathryn Ricci, Orion Weller, Vivek Chari, Benjamin Van Durme, Dawn Lawrie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieve-and-rerank is a popular retrieval pipeline because of its ability to
make slow but effective rerankers efficient enough at query time by reducing
the number of comparisons. Recent works in neural rerankers take advantage of
large language models for their capability in reasoning between queries and
passages and have achieved state-of-the-art retrieval effectiveness. However,
such rerankers are resource-intensive, even after heavy optimization. In this
work, we introduce Rank-K, a listwise passage reranking model that leverages
the reasoning capability of the reasoning language model at query time that
provides test time scalability to serve hard queries. We show that Rank-K
improves retrieval effectiveness by 23\% over the RankZephyr, the
state-of-the-art listwise reranker, when reranking a BM25 initial ranked list
and 19\% when reranking strong retrieval results by SPLADE-v3. Since Rank-K is
inherently a multilingual model, we found that it ranks passages based on
queries in different languages as effectively as it does in monolingual
retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Taming Recommendation Bias with Causal Intervention on Evolving Personal
  Popularity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14310v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14310v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiyin Tan, Dongyuan Li, Renhe Jiang, Zhen Wang, Xingtong Yu, Manabu Okumura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Popularity bias occurs when popular items are recommended far more frequently
than they should be, negatively impacting both user experience and
recommendation accuracy. Existing debiasing methods mitigate popularity bias
often uniformly across all users and only partially consider the time evolution
of users or items. However, users have different levels of preference for item
popularity, and this preference is evolving over time. To address these issues,
we propose a novel method called CausalEPP (Causal Intervention on Evolving
Personal Popularity) for taming recommendation bias, which accounts for the
evolving personal popularity of users. Specifically, we first introduce a
metric called {Evolving Personal Popularity} to quantify each user's preference
for popular items. Then, we design a causal graph that integrates evolving
personal popularity into the conformity effect, and apply deconfounded training
to mitigate the popularity bias of the causal graph. During inference, we
consider the evolution consistency between users and items to achieve a better
recommendation. Empirical studies demonstrate that CausalEPP outperforms
baseline methods in reducing popularity bias while improving recommendation
accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Technical Report on classification of literature related to children
  speech disorder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14242v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14242v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziang Wang, Amir Aryani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This technical report presents a natural language processing (NLP)-based
approach for systematically classifying scientific literature on childhood
speech disorders. We retrieved and filtered 4,804 relevant articles published
after 2015 from the PubMed database using domain-specific keywords. After
cleaning and pre-processing the abstracts, we applied two topic modeling
techniques - Latent Dirichlet Allocation (LDA) and BERTopic - to identify
latent thematic structures in the corpus. Our models uncovered 14 clinically
meaningful clusters, such as infantile hyperactivity and abnormal epileptic
behavior. To improve relevance and precision, we incorporated a custom stop
word list tailored to speech pathology. Evaluation results showed that the LDA
model achieved a coherence score of 0.42 and a perplexity of -7.5, indicating
strong topic coherence and predictive performance. The BERTopic model exhibited
a low proportion of outlier topics (less than 20%), demonstrating its capacity
to classify heterogeneous literature effectively. These results provide a
foundation for automating literature reviews in speech-language pathology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Limits of Graph Samplers for Training Inductive Recommender Systems:
  Extended results 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Theis E. Jendal, Matteo Lissandrini, Peter Dolog, Katja Hose
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inductive Recommender Systems are capable of recommending for new users and
with new items thus avoiding the need to retrain after new data reaches the
system. However, these methods are still trained on all the data available,
requiring multiple days to train a single model, without counting
hyperparameter tuning. In this work we focus on graph-based recommender
systems, i.e., systems that model the data as a heterogeneous network. In other
applications, graph sampling allows to study a subgraph and generalize the
findings to the original graph. Thus, we investigate the applicability of
sampling techniques for this task. We test on three real world datasets, with
three state-of-the-art inductive methods, and using six different sampling
methods. We find that its possible to maintain performance using only 50% of
the training data with up to 86% percent decrease in training time; however,
using less training data leads to far worse performance. Further, we find that
when it comes to data for recommendations, graph sampling should also account
for the temporal dimension. Therefore, we find that if higher data reduction is
needed, new graph based sampling techniques should be studied and new inductive
methods should be designed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridge the Gap between Past and Future: Siamese Model Optimization for
  Context-Aware Document Ranking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14180v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14180v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songhao Wu, Quan Tu, Mingjie Zhong, Hong Liu, Jia Xu, Jinjie Gu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the realm of information retrieval, users often engage in multi-turn
interactions with search engines to acquire information, leading to the
formation of sequences of user feedback behaviors. Leveraging the session
context has proven to be beneficial for inferring user search intent and
document ranking. A multitude of approaches have been proposed to exploit
in-session context for improved document ranking. Despite these advances, the
limitation of historical session data for capturing evolving user intent
remains a challenge. In this work, we explore the integration of future
contextual information into the session context to enhance document ranking. We
present the siamese model optimization framework, comprising a
history-conditioned model and a future-aware model. The former processes only
the historical behavior sequence, while the latter integrates both historical
and anticipated future behaviors. Both models are trained collaboratively using
the supervised labels and pseudo labels predicted by the other. The
history-conditioned model, referred to as ForeRanker, progressively learns
future-relevant information to enhance ranking, while it singly uses historical
session at inference time. To mitigate inconsistencies during training, we
introduce the peer knowledge distillation method with a dynamic gating
mechanism, allowing models to selectively incorporate contextual information.
Experimental results on benchmark datasets demonstrate the effectiveness of our
ForeRanker, showcasing its superior performance compared to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Abstractive Summarization of Scientific Papers Using Structure
  Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Bao, Heng Zhang, Chengzhi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Abstractive summarization of scientific papers has always been a research
focus, yet existing methods face two main challenges. First, most summarization
models rely on Encoder-Decoder architectures that treat papers as sequences of
words, thus fail to fully capture the structured information inherent in
scientific papers. Second, existing research often use keyword mapping or
feature engineering to identify the structural information, but these methods
struggle with the structural flexibility of scientific papers and lack
robustness across different disciplines. To address these challenges, we
propose a two-stage abstractive summarization framework that leverages
automatic recognition of structural functions within scientific papers. In the
first stage, we standardize chapter titles from numerous scientific papers and
construct a large-scale dataset for structural function recognition. A
classifier is then trained to automatically identify the key structural
components (e.g., Background, Methods, Results, Discussion), which provides a
foundation for generating more balanced summaries. In the second stage, we
employ Longformer to capture rich contextual relationships across sections and
generating context-aware summaries. Experiments conducted on two
domain-specific scientific paper summarization datasets demonstrate that our
method outperforms advanced baselines, and generates more comprehensive
summaries. The code and dataset can be accessed at
https://github.com/tongbao96/code-for-SFR-AS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unify Graph Learning with Text: Unleashing LLM Potentials for Session
  Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14156v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14156v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session search involves a series of interactive queries and actions to
fulfill user's complex information need. Current strategies typically
prioritize sequential modeling for deep semantic understanding, overlooking the
graph structure in interactions. While some approaches focus on capturing
structural information, they use a generalized representation for documents,
neglecting the word-level semantic modeling. In this paper, we propose Symbolic
Graph Ranker (SGR), which aims to take advantage of both text-based and
graph-based approaches by leveraging the power of recent Large Language Models
(LLMs). Concretely, we first introduce a set of symbolic grammar rules to
convert session graph into text. This allows integrating session history,
interaction process, and task instruction seamlessly as inputs for the LLM.
Moreover, given the natural discrepancy between LLMs pre-trained on textual
corpora, and the symbolic language we produce using our graph-to-text grammar,
our objective is to enhance LLMs' ability to capture graph structures within a
textual format. To achieve this, we introduce a set of self-supervised symbolic
learning tasks including link prediction, node content generation, and
generative contrastive learning, to enable LLMs to capture the topological
information from coarse-grained to fine-grained. Experiment results and
comprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm
the superiority of our approach. Our paradigm also offers a novel and effective
methodology that bridges the gap between traditional search strategies and
modern LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Keyphrase Extraction from Academic Articles Using Section
  Structure Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14149v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14149v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengzhi Zhang, Xinyi Yan, Lei Zhao, Yingyi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential increase in academic papers has significantly increased the
time required for researchers to access relevant literature. Keyphrase
Extraction (KPE) offers a solution to this situation by enabling researchers to
efficiently retrieve relevant literature. The current study on KPE from
academic articles aims to improve the performance of extraction models through
innovative approaches using Title and Abstract as input corpora. However, the
semantic richness of keywords is significantly constrained by the length of the
abstract. While full-text-based KPE can address this issue, it simultaneously
introduces noise, which significantly diminishes KPE performance. To address
this issue, this paper utilized the structural features and section texts
obtained from the section structure information of academic articles to extract
keyphrase from academic papers. The approach consists of two main parts: (1)
exploring the effect of seven structural features on KPE models, and (2)
integrating the extraction results from all section texts used as input corpora
for KPE models via a keyphrase integration algorithm to obtain the keyphrase
integration result. Furthermore, this paper also examined the effect of the
classification quality of section structure on the KPE performance. The results
show that incorporating structural features improves KPE performance, though
different features have varying effects on model efficacy. The keyphrase
integration approach yields the best performance, and the classification
quality of section structure can affect KPE performance. These findings
indicate that using the section structure information of academic articles
contributes to effective KPE from academic articles. The code and dataset
supporting this study are available at https://github.com/yan-xinyi/SSB_KPE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Chains: Bridging Large Language Models and Knowledge Bases in
  Complex Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14099v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14099v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihua Zhu, Qianying Liu, Akiko Aizawa, Hidetoshi Shimodaira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Base Question Answering (KBQA) aims to answer natural language
questions using structured knowledge from KBs. While LLM-only approaches offer
generalization, they suffer from outdated knowledge, hallucinations, and lack
of transparency. Chain-based KG-RAG methods address these issues by
incorporating external KBs, but are limited to simple chain-structured
questions due to the absence of planning and logical structuring. Inspired by
semantic parsing methods, we propose PDRR: a four-stage framework consisting of
Predict, Decompose, Retrieve, and Reason. Our method first predicts the
question type and decomposes the question into structured triples. Then
retrieves relevant information from KBs and guides the LLM as an agent to
reason over and complete the decomposed triples. Experimental results
demonstrate that PDRR consistently outperforms existing methods across various
LLM backbones and achieves superior performance on both chain-structured and
non-chain complex questions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Field Matters: A lightweight LLM-enhanced Method for CTR Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14057v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14057v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Cui, Feng Liu, Jiawei Chen, Xingyu Lou, Changwang Zhang, Jun Wang, Yuegang Sun, Xiaohu Yang, Can Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Click-through rate (CTR) prediction is a fundamental task in modern
recommender systems. In recent years, the integration of large language models
(LLMs) has been shown to effectively enhance the performance of traditional CTR
methods. However, existing LLM-enhanced methods often require extensive
processing of detailed textual descriptions for large-scale instances or
user/item entities, leading to substantial computational overhead. To address
this challenge, this work introduces LLaCTR, a novel and lightweight
LLM-enhanced CTR method that employs a field-level enhancement paradigm.
Specifically, LLaCTR first utilizes LLMs to distill crucial and lightweight
semantic knowledge from small-scale feature fields through self-supervised
field-feature fine-tuning. Subsequently, it leverages this field-level semantic
knowledge to enhance both feature representation and feature interactions. In
our experiments, we integrate LLaCTR with six representative CTR models across
four datasets, demonstrating its superior performance in terms of both
effectiveness and efficiency compared to existing LLM-enhanced methods. Our
code is available at https://anonymous.4open.science/r/LLaCTR-EC46.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangled Multi-span Evolutionary Network against Temporal Knowledge
  Graph Reasoning <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Dong, Ziyue Qiao, Zhiyuan Ning, Qi Hao, Yi Du, Pengyang Wang, Yuanchun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs
(KGs), incorporate the temporal feature to express the transience of knowledge
by describing when facts occur. TKG extrapolation aims to infer possible future
facts based on known history, which has garnered significant attention in
recent years. Some existing methods treat TKG as a sequence of independent
subgraphs to model temporal evolution patterns, demonstrating impressive
reasoning performance. However, they still have limitations: 1) In modeling
subgraph semantic evolution, they usually neglect the internal structural
interactions between subgraphs, which are actually crucial for encoding TKGs.
2) They overlook the potential smooth features that do not lead to semantic
changes, which should be distinguished from the semantic evolution process.
Therefore, we propose a novel Disentangled Multi-span Evolutionary Network
(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution
strategy that captures local neighbor features while perceiving historical
neighbor semantic information, thus enabling internal interactions between
subgraphs during the evolution process. To maximize the capture of semantic
change patterns, we design a disentangle component that adaptively separates
nodes' active and stable features, used to dynamically control the influence of
historical semantics on future evolution. Extensive experiments conducted on
four real-world TKG datasets show that DiMNet demonstrates substantial
performance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%
in MRR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2025 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven
  Graph Partitioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) systems empower large language models
(LLMs) with external knowledge, yet struggle with efficiency-accuracy
trade-offs when scaling to large knowledge graphs. Existing approaches often
rely on monolithic graph retrieval, incurring unnecessary latency for simple
queries and fragmented reasoning for complex multi-hop questions. To address
these challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework
that addresses these limitations with question-driven semantic graph
partitioning and collaborative subgraph retrieval. The innovative framework
first create Semantic Partitioning of Linked Information, then use the
Type-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware
graph segmentation manages to divide knowledge graphs into semantically
coherent subgraphs, ensuring subgraphs align with different query types, while
lightweight LLM agents are assigned to partitioned subgraphs, and only relevant
partitions are activated during retrieval, thus reduce search space while
enhancing efficiency. Finally, a hierarchical merging module resolves
inconsistencies across subgraph-derived answers through logical verifications.
Extensive experimental validation demonstrates considerable improvements
compared to existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DIFF: Dual Side-Information Filtering and Fusion for Sequential
  Recommendation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13974v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13974v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hye-young Kim, Minjin Choi, Sunkyung Lee, Ilwoong Baek, Jongwuk Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Side-information Integrated Sequential Recommendation (SISR) benefits from
auxiliary item information to infer hidden user preferences, which is
particularly effective for sparse interactions and cold-start scenarios.
However, existing studies face two main challenges. (i) They fail to remove
noisy signals in item sequence and (ii) they underutilize the potential of
side-information integration. To tackle these issues, we propose a novel SISR
model, Dual Side-Information Filtering and Fusion (DIFF), which employs
frequency-based noise filtering and dual multi-sequence fusion. Specifically,
we convert the item sequence to the frequency domain to filter out noisy
short-term fluctuations in user interests. We then combine early and
intermediate fusion to capture diverse relationships across item IDs and
attributes. Thanks to our innovative filtering and fusion strategy, DIFF is
more robust in learning subtle and complex item correlations in the sequence.
DIFF outperforms state-of-the-art SISR models, achieving improvements of up to
14.1% and 12.5% in Recall@20 and NDCG@20 across four benchmark datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025. 10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking the Myopic Trap: Positional Bias in Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13950v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13950v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyang Zeng, Dun Zhang, Jiacheng Li, Panxiang Zou, Yuqing Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates a specific form of positional bias, termed the Myopic
Trap, where retrieval models disproportionately attend to the early parts of
documents while overlooking relevant information that appears later. To
systematically quantify this phenomenon, we propose a semantics-preserving
evaluation framework that repurposes the existing NLP datasets into
position-aware retrieval benchmarks. By evaluating the SOTA models of full
retrieval pipeline, including BM25, embedding models, ColBERT-style
late-interaction models, and reranker models, we offer a broader empirical
perspective on positional bias than prior work. Experimental results show that
embedding models and ColBERT-style models exhibit significant performance
degradation when query-related content is shifted toward later positions,
indicating a pronounced head bias. Notably, under the same training
configuration, ColBERT-style approach show greater potential for mitigating
positional bias compared to the traditional single-vector approach. In
contrast, BM25 and reranker models remain largely unaffected by such
perturbations, underscoring their robustness to positional bias. Code and data
are publicly available at: www.github.com/NovaSearch-Team/RAG-Retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, 4 tables. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qifeng Cai, Hao Liang, Hejun Dong, Meiyi Qiang, Ruichuan An, Zhaoyang Han, Zhengzhou Zhu, Bin Cui, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long videos contain a vast amount of information, making video-text retrieval
an essential and challenging task in multimodal learning. However, existing
benchmarks suffer from limited video duration, low-quality captions, and coarse
annotation granularity, which hinder the evaluation of advanced video-text
retrieval methods. To address these limitations, we introduce LoVR, a benchmark
specifically designed for long video-text retrieval. LoVR contains 467 long
videos and over 40,804 fine-grained clips with high-quality captions. To
overcome the issue of poor machine-generated annotations, we propose an
efficient caption generation framework that integrates VLM automatic
generation, caption quality scoring, and dynamic refinement. This pipeline
improves annotation accuracy while maintaining scalability. Furthermore, we
introduce a semantic fusion method to generate coherent full-video captions
without losing important contextual information. Our benchmark introduces
longer videos, more detailed captions, and a larger-scale dataset, presenting
new challenges for video understanding and retrieval. Extensive experiments on
various advanced embedding models demonstrate that LoVR is a challenging
benchmark, revealing the limitations of current approaches and providing
valuable insights for future research. We release the code and dataset link at
https://github.com/TechNomad-ds/LoVR-benchmark
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VulCPE: Context-Aware Cybersecurity Vulnerability Retrieval and
  Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13895v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13895v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuning Jiang, Feiyang Shang, Freedy Tan Wei You, Huilin Wang, Chia Ren Cong, Qiaoran Meng, Nay Oo, Hoon Wei Lim, Biplab Sikdar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamic landscape of cybersecurity demands precise and scalable solutions
for vulnerability management in heterogeneous systems, where
configuration-specific vulnerabilities are often misidentified due to
inconsistent data in databases like the National Vulnerability Database (NVD).
Inaccurate Common Platform Enumeration (CPE) data in NVD further leads to false
positives and incomplete vulnerability retrieval. Informed by our systematic
analysis of CPE and CVEdeails data, revealing more than 50% vendor name
inconsistencies, we propose VulCPE, a framework that standardizes data and
models configuration dependencies using a unified CPE schema (uCPE), entity
recognition, relation extraction, and graph-based modeling. VulCPE achieves
superior retrieval precision (0.766) and coverage (0.926) over existing tools.
VulCPE ensures precise, context-aware vulnerability management, enhancing cyber
resilience.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TranSUN: A Preemptive Paradigm to Eradicate Retransformation Bias
  Intrinsically from Regression Models in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13881v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13881v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Yu, Haozhuang Liu, Yeqiu Yang, Lu Chen, Wu Jian, Yuning Jiang, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regression models are crucial in recommender systems. However,
retransformation bias problem has been conspicuously neglected within the
community. While many works in other fields have devised effective bias
correction methods, all of them are post-hoc cures externally to the model,
facing practical challenges when applied to real-world recommender systems.
Hence, we propose a preemptive paradigm to eradicate the bias intrinsically
from the models via minor model refinement. Specifically, a novel TranSUN
method is proposed with a joint bias learning manner to offer theoretically
guaranteed unbiasedness under empirical superior convergence. It is further
generalized into a novel generic regression model family, termed Generalized
TranSUN (GTS), which not only offers more theoretical insights but also serves
as a generic framework for flexibly developing various bias-free models.
Comprehensive experimental results demonstrate the superiority of our methods
across data from various domains, which have been successfully deployed in two
real-world industrial recommendation scenarios, i.e. product and short video
recommendation scenarios in Guess What You Like business domain in the homepage
of Taobao App (a leading e-commerce platform), to serve the major online
traffic. Codes will be released after this paper is published.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IntentRec: Predicting User Session Intent with Hierarchical Multi-Task
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05353v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05353v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sejoon Oh, Moumita Bhattacharya, Yesu Feng, Sudarshan Lamkhede
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems have played a critical role in diverse digital services
such as e-commerce, streaming media, social networks, etc. If we know what a
user's intent is in a given session (e.g. do they want to watch short videos or
a movie or play games; are they shopping for a camping trip), it becomes easier
to provide high-quality recommendations. In this paper, we introduce IntentRec,
a novel recommendation framework based on hierarchical multi-task neural
network architecture that tries to estimate a user's latent intent using their
short- and long-term implicit signals as proxies and uses the intent prediction
to predict the next item user is likely to engage with. By directly leveraging
the intent prediction, we can offer accurate and personalized recommendations
to users. Our comprehensive experiments on Netflix user engagement data show
that IntentRec outperforms the state-of-the-art next-item and next-intent
predictors. We also share several findings and downstream applications of
IntentRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted @ BayLearn 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Laws for Many-Shot In-Context Learning with Self-Generated
  Annotations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyao Gu, Henry Peng Zou, Yankai Chen, Aiwei Liu, Weizhi Zhang, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The high cost of obtaining high-quality annotated data for in-context
learning (ICL) has motivated the development of methods that use self-generated
annotations in place of ground-truth labels. While these approaches have shown
promising results in few-shot settings, they generally do not scale to
many-shot scenarios. In this work, we study ICL with self-generated examples
using a framework analogous to traditional semi-supervised learning, consisting
of annotation generation, demonstration selection, and in-context inference.
Within this framework, we propose a simple baseline that outperforms
ground-truth ICL in zero-shot, few-shot, and many-shot settings. Notably, we
observe a scaling law with this baseline, where optimal performance is achieved
with more than 1,000 demonstrations. To fully exploit the many-shot
capabilities of semi-supervised ICL, we introduce IterPSD, an iterative
annotation approach that integrates iterative refinement and curriculum
pseudo-labeling techniques from semi-supervised learning, yielding up to 6.8%
additional gains on classification tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context
  RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.06569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.06569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context large language models (LC LLMs) combined with
retrieval-augmented generation (RAG) hold strong potential for complex
multi-hop and large-document tasks. However, existing RAG systems often suffer
from imprecise retrieval, incomplete context coverage under constrained
windows, and fragmented information from suboptimal context construction. We
introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical RAG
framework that compresses and partitions documents into coarse-to-fine
granularities, then adaptively merges relevant contexts through real-time
chunk- and document-level expansions. By initiating with finest-level retrieval
and progressively incorporating broader, higher-level context, MacRAG
constructs effective query-specific long contexts, optimizing both precision
and coverage. Evaluations on challenging LongBench expansions of HotpotQA,
2WikiMultihopQA, and Musique confirm MacRAG consistently surpasses baseline RAG
pipelines in single- and multi-step generation using Llama-3.1-8B,
Gemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient,
scalable solution for real-world long-context, multi-hop reasoning. Our code is
available at https://github.com/Leezekun/MacRAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic Synthetic Data and Fine-grained Adaptive Feature Alignment for
  Composed Person Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16515v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16515v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Delong Liu, Haiwen Li, Zhaohui Hou, Zhicheng Zhao, Fei Su, Yuan Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Person retrieval has attracted rising attention. Existing methods are mainly
divided into two retrieval modes, namely image-only and text-only. However,
they are unable to make full use of the available information and are difficult
to meet diverse application requirements. To address the above limitations, we
propose a new Composed Person Retrieval (CPR) task, which combines visual and
textual queries to identify individuals of interest from large-scale person
image databases. Nevertheless, the foremost difficulty of the CPR task is the
lack of available annotated datasets. Therefore, we first introduce a scalable
automatic data synthesis pipeline, which decomposes complex multimodal data
generation into the creation of textual quadruples followed by
identity-consistent image synthesis using fine-tuned generative models.
Meanwhile, a multimodal filtering method is designed to ensure the resulting
SynCPR dataset retains 1.15 million high-quality and fully synthetic triplets.
Additionally, to improve the representation of composed person queries, we
propose a novel Fine-grained Adaptive Feature Alignment (FAFA) framework
through fine-grained dynamic alignment and masked feature reasoning. Moreover,
for objective evaluation, we manually annotate the Image-Text Composed Person
Retrieval (ITCPR) test set. The extensive experiments demonstrate the
effectiveness of the SynCPR dataset and the superiority of the proposed FAFA
framework when compared with the state-of-the-art methods. All code and data
will be provided at
https://github.com/Delong-liu-bupt/Composed_Person_Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08828v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08828v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal document retrieval aims to identify and retrieve various forms of
multimodal content, such as figures, tables, charts, and layout information
from extensive documents. Despite its increasing popularity, there is a notable
lack of a comprehensive and robust benchmark to effectively evaluate the
performance of systems in such tasks. To address this gap, this work introduces
a new benchmark, named MMDocIR, that encompasses two distinct tasks: page-level
and layout-level retrieval. The former evaluates the performance of identifying
the most relevant pages within a long document, while the later assesses the
ability of detecting specific layouts, providing a more fine-grained measure
than whole-page analysis. A layout refers to a variety of elements, including
textual paragraphs, equations, figures, tables, or charts. The MMDocIR
benchmark comprises a rich dataset featuring 1,685 questions annotated by
experts and 173,843 questions with bootstrapped labels, making it a valuable
resource in multimodal document retrieval for both training and evaluation.
Through rigorous experiments, we demonstrate that (i) visual retrievers
significantly outperform their text counterparts, (ii) MMDocIR training set
effectively enhances the performance of multimodal document retrieval and (iii)
text retrievers leveraging VLM-text significantly outperforms retrievers
relying on OCR-text. Our dataset is available at
https://mmdocrag.github.io/MMDocIR/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://huggingface.co/MMDocIR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05863v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05863v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhao Jia, Xinyi Wu, Hao Li, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In AI-facilitated teaching, leveraging various query styles to interpret
abstract text descriptions is crucial for ensuring high-quality teaching.
However, current retrieval models primarily focus on natural text-image
retrieval, making them insufficiently tailored to educational scenarios due to
the ambiguities in the retrieval process. In this paper, we propose a diverse
expression retrieval task tailored to educational scenarios, supporting
retrieval based on multiple query styles and expressions. We introduce the STEM
Education Retrieval Dataset (SER), which contains over 24,000 query pairs of
different styles, and the Uni-Retrieval, an efficient and style-diversified
retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts
query style features as prototypes and builds a continuously updated Prompt
Bank containing prompt tokens for diverse queries. This bank can updated during
test time to represent domain-specific knowledge for different subject
retrieval scenarios. Our framework demonstrates scalability and robustness by
dynamically retrieving prompt tokens based on prototype similarity, effectively
facilitating learning for unknown queries. Experimental results indicate that
Uni-Retrieval outperforms existing retrieval models in most retrieval tasks.
This advancement provides a scalable and precise solution for diverse
educational needs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MCiteBench: A Multimodal Benchmark for Generating Text with Citations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02589v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02589v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caiyu Hu, Yikai Zhang, Tinghui Zhu, Yiwei Ye, Yanghua Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse
modalities but frequently suffer from hallucination. A promising solution to
mitigate this issue is to generate text with citations, providing a transparent
chain for verification. However, existing work primarily focuses on generating
citations for text-only content, leaving the challenges of multimodal scenarios
largely unexplored. In this paper, we introduce MCiteBench, the first benchmark
designed to assess the ability of MLLMs to generate text with citations in
multimodal contexts. Our benchmark comprises data derived from academic papers
and review-rebuttal interactions, featuring diverse information sources and
multimodal content. Experimental results reveal that MLLMs struggle to ground
their outputs reliably when handling multimodal input. Further analysis
uncovers a systematic modality bias and reveals how models internally rely on
different sources when generating citations, offering insights into model
behavior and guiding future directions for multimodal citation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://caiyuhu.github.io/MCiteBench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contrastive Alignment with Semantic Gap-Aware Corrections in Text-Video
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12499v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12499v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Zhenzhen Hu, Jia Li, Richang Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-video retrieval have been largely driven by
contrastive learning frameworks. However, existing methods overlook a key
source of optimization tension: the separation between text and video
distributions in the representation space (referred to as the modality gap),
and the prevalence of false negatives in batch sampling. These factors lead to
conflicting gradients under the InfoNCE loss, impeding stable alignment. To
mitigate this, we propose GARE, a Gap-Aware Retrieval framework that introduces
a learnable, pair-specific increment Delta_ij between text t_i and video v_j to
offload the tension from the global anchor representation. We first derive the
ideal form of Delta_ij via a coupled multivariate first-order Taylor
approximation of the InfoNCE loss under a trust-region constraint, revealing it
as a mechanism for resolving gradient conflicts by guiding updates along a
locally optimal descent direction. Due to the high cost of directly computing
Delta_ij, we introduce a lightweight neural module conditioned on the semantic
gap between each video-text pair, enabling structure-aware correction guided by
gradient supervision. To further stabilize learning and promote
interpretability, we regularize Delta using three components: a trust-region
constraint to prevent oscillation, a directional diversity term to promote
semantic coverage, and an information bottleneck to limit redundancy.
Experiments across four retrieval benchmarks show that GARE consistently
improves alignment accuracy and robustness to noisy supervision, confirming the
effectiveness of gap-aware tension mitigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced
  Logical Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.10940v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.10940v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qing Yu, Xiaobei Wang, Shuchang Liu, Yandong Bai, Xiaoyu Yang, Xueliang Wang, Chang Meng, Shanshan Wu, Hailan Yang, Huihui Xiao, Xiang Li, Fan Yang, Xiaoqiang Feng, Lantao Hu, Han Li, Kun Gai, Lixin Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems filter contents/items valuable to users by inferring
preferences from user features and historical behaviors. Mainstream approaches
follow the learning-to-rank paradigm, which focus on discovering and modeling
item topics (e.g., categories), and capturing user preferences on these topics
based on historical interactions. However, this paradigm often neglects the
modeling of user characteristics and their social roles, which are logical
confounders influencing the correlated interest and user preference transition.
To bridge this gap, we introduce the user role identification task and the
behavioral logic modeling task that aim to explicitly model user roles and
learn the logical relations between item topics and user social roles. We show
that it is possible to explicitly solve these tasks through an efficient
integration framework of Large Language Model (LLM) and recommendation systems,
for which we propose TagCF. On the one hand, TagCF exploits the (Multi-modal)
LLM's world knowledge and logic inference ability to extract realistic
tag-based virtual logic graphs that reveal dynamic and expressive knowledge of
users, refining our understanding of user behaviors. On the other hand, TagCF
presents empirically effective integration modules that take advantage of the
extracted tag-logic information, augmenting the recommendation performance. We
conduct both online experiments and offline experiments with industrial and
public datasets as verification of TagCF's effectiveness, and we empirically
show that the user role modeling strategy is potentially a better choice than
the modeling of item topics. Additionally, we provide evidence that the
extracted logic graphs are empirically a general and transferable knowledge
that can benefit a wide range of recommendation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Does Topology Bias Distort Message Passing? A Dirichlet Energy
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13892v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13892v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanbiao Ji, Yue Ding, Dan Luo, Chang Liu, Yuxiang Lu, Xin Xin, Hongtao Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-based recommender systems have achieved remarkable effectiveness by
modeling high-order interactions between users and items. However, such
approaches are significantly undermined by popularity bias, which distorts the
interaction graph's structure, referred to as topology bias. This leads to
overrepresentation of popular items, thereby reinforcing biases and fairness
issues through the user-system feedback loop. Despite attempts to study this
effect, most prior work focuses on the embedding or gradient level bias,
overlooking how topology bias fundamentally distorts the message passing
process itself. We bridge this gap by providing an empirical and theoretical
analysis from a Dirichlet energy perspective, revealing that graph message
passing inherently amplifies topology bias and consistently benefits highly
connected nodes. To address these limitations, we propose Test-time Simplicial
Propagation (TSP), which extends message passing to higher-order simplicial
complexes. By incorporating richer structures beyond pairwise connections, TSP
mitigates harmful topology bias and substantially improves the representation
and recommendation of long-tail items during inference. Extensive experiments
across five real-world datasets demonstrate the superiority of our approach in
mitigating topology bias and enhancing recommendation quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Test-Time Inference with Policy-Optimized, Dynamic
  Retrieval-Augmented Generation via KV Caching and Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.01281v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.01281v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a comprehensive framework for enhancing Retrieval-Augmented
Generation (RAG) systems through dynamic retrieval strategies and reinforcement
fine-tuning. This approach significantly improves large language models on
knowledge-intensive tasks, including opendomain question answering and complex
reasoning. Our framework integrates two complementary techniques:
Policy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use
of retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS),
which dynamically determines retrieval timing and content based on contextual
needs. Together, these techniques enhance both the utilization and relevance of
retrieved content, improving factual accuracy and response quality. Designed as
a lightweight solution compatible with any Transformer-based LLM without
requiring additional training, our framework excels in knowledge-intensive
tasks, boosting output accuracy in RAG settings. We further propose CRITIC, a
novel method to selectively compress key-value caches by token importance,
mitigating memory bottlenecks in long-context applications. The framework also
incorporates test-time scaling techniques to dynamically balance reasoning
depth and computational resources, alongside optimized decoding strategies for
faster inference. Experiments on benchmark datasets show that our framework
reduces hallucinations, strengthens domain-specific reasoning, and achieves
significant efficiency and scalability gains over traditional RAG systems. This
integrated approach advances the development of robust, efficient, and scalable
RAG systems across diverse applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation <span class="chip">ICML2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01776v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01776v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tiansheng Wen, Yifei Wang, Zequn Zeng, Zhong Peng, Yudi Su, Xinyang Liu, Bo Chen, Hongwei Liu, Stefanie Jegelka, Chenyu You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many large-scale systems rely on high-quality deep representations
(embeddings) to facilitate tasks like retrieval, search, and generative
modeling. Matryoshka Representation Learning (MRL) recently emerged as a
solution for adaptive embedding lengths, but it requires full model retraining
and suffers from noticeable performance degradations at short lengths. In this
paper, we show that sparse coding offers a compelling alternative for achieving
adaptive representation with minimal overhead and higher fidelity. We propose
Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained
embeddings into a high-dimensional but selectively activated feature space. By
leveraging lightweight autoencoding and task-aware contrastive objectives, CSR
preserves semantic quality while allowing flexible, cost-effective inference at
different sparsity levels. Extensive experiments on image, text, and multimodal
benchmarks demonstrate that CSR consistently outperforms MRL in terms of both
accuracy and retrieval speed-often by large margins-while also cutting training
time to a fraction of that required by MRL. Our results establish sparse coding
as a powerful paradigm for adaptive representation learning in real-world
applications where efficiency and fidelity are both paramount. Code is
available at https://github.com/neilwen987/CSR_Adaptive_Rep
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICML2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisTopics: A Visual Semantic Unsupervised Approach to Topic Modeling of
  Video and Image Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14868v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14868v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayse D Lokmanoglu, Dror Walter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding visual narratives is crucial for examining the evolving
dynamics of media representation. This study introduces VisTopics, a
computational framework designed to analyze large-scale visual datasets through
an end-to-end pipeline encompassing frame extraction, deduplication, and
semantic clustering. Applying VisTopics to a dataset of 452 NBC News videos
resulted in reducing 11,070 frames to 6,928 deduplicated frames, which were
then semantically analyzed to uncover 35 topics ranging from political events
to environmental crises. By integrating Latent Dirichlet Allocation with
caption-based semantic analysis, VisTopics demonstrates its potential to
unravel patterns in visual framing across diverse contexts. This approach
enables longitudinal studies and cross-platform comparisons, shedding light on
the intersection of media, technology, and public discourse. The study
validates the method's reliability through human coding accuracy metrics and
emphasizes its scalability for communication research. By bridging the gap
between visual representation and semantic meaning, VisTopics provides a
transformative tool for advancing the methodological toolkit in computational
media studies. Future research may leverage VisTopics for comparative analyses
across media outlets or geographic regions, offering insights into the shifting
landscapes of media narratives and their societal implications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representation Learning for Semantic Alignment of Language, Audio, and
  Visual Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14562v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14562v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parthasaarathy Sudarsanam, Irene Martín-Morató, Tuomas Virtanen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a single-stage training approach that semantically aligns
three modalities - audio, visual, and text using a contrastive learning
framework. Contrastive training has gained prominence for multimodal alignment,
utilizing large-scale unlabeled data to learn shared representations. Existing
deep learning approach for trimodal alignment involves two-stages, that
separately align visual-text and audio-text modalities. This approach suffers
from mismatched data distributions, resulting in suboptimal alignment.
Leveraging the AVCaps dataset, which provides audio, visual and audio-visual
captions for video clips, our method jointly optimizes the representation of
all the modalities using contrastive training. Our results demonstrate that the
single-stage approach outperforms the two-stage method, achieving a two-fold
improvement in audio based visual retrieval, highlighting the advantages of
unified multimodal representation learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to European Signal Processing Conference (EUSIPCO 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TF-Mamba: Text-enhanced Fusion Mamba with Missing Modalities for Robust
  Multimodal Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Xianfu Cheng, Dezhuang Miao, Xiaoming Zhang, Zhoujun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Sentiment Analysis (MSA) with missing modalities has attracted
increasing attention recently. While current Transformer-based methods leverage
dense text information to maintain model robustness, their quadratic complexity
hinders efficient long-range modeling and multimodal fusion. To this end, we
propose a novel and efficient Text-enhanced Fusion Mamba (TF-Mamba) framework
for robust MSA with missing modalities. Specifically, a Text-aware Modality
Enhancement (TME) module aligns and enriches non-text modalities, while
reconstructing the missing text semantics. Moreover, we develop Text-based
Context Mamba (TC-Mamba) to capture intra-modal contextual dependencies under
text collaboration. Finally, Text-guided Query Mamba (TQ-Mamba) queries
text-guided multimodal information and learns joint representations for
sentiment prediction. Extensive experiments on three MSA datasets demonstrate
the effectiveness and efficiency of the proposed method under missing modality
scenarios. Our code is available at https://github.com/codemous/TF-Mamba.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RETRO: REthinking Tactile Representation Learning with Material PriOrs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihao Xia, Chenliang Zhou, Cengiz Oztireli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tactile perception is profoundly influenced by the surface properties of
objects in contact. However, despite their crucial role in shaping tactile
experiences, these material characteristics have been largely neglected in
existing tactile representation learning methods. Most approaches primarily
focus on aligning tactile data with visual or textual information, overlooking
the richness of tactile feedback that comes from understanding the materials'
inherent properties. In this work, we address this gap by revisiting the
tactile representation learning framework and incorporating material-aware
priors into the learning process. These priors, which represent pre-learned
characteristics specific to different materials, allow tactile models to better
capture and generalize the nuances of surface texture. Our method enables more
accurate, contextually rich tactile feedback across diverse materials and
textures, improving performance in real-world applications such as robotics,
haptic feedback systems, and material editing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/weihaox/RETRO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Efficient Hate Speech Detection via Cross-Lingual Nearest Neighbor
  Retrieval with Limited Labeled Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14272v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14272v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Considering the importance of detecting hateful language, labeled hate speech
data is expensive and time-consuming to collect, particularly for low-resource
languages. Prior work has demonstrated the effectiveness of cross-lingual
transfer learning and data augmentation in improving performance on tasks with
limited labeled data. To develop an efficient and scalable cross-lingual
transfer learning approach, we leverage nearest-neighbor retrieval to augment
minimal labeled data in the target language, thereby enhancing detection
performance. Specifically, we assume access to a small set of labeled training
instances in the target language and use these to retrieve the most relevant
labeled examples from a large multilingual hate speech detection pool. We
evaluate our approach on eight languages and demonstrate that it consistently
outperforms models trained solely on the target language data. Furthermore, in
most cases, our method surpasses the current state-of-the-art. Notably, our
approach is highly data-efficient, retrieving as small as 200 instances in some
cases while maintaining superior performance. Moreover, it is scalable, as the
retrieval pool can be easily expanded, and the method can be readily adapted to
new languages and tasks. We also apply maximum marginal relevance to mitigate
redundancy and filter out highly similar retrieved instances, resulting in
improvements in some languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via
  Deliberative Reasoning with LVLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiyao Cui, Qinglin Zhang, Xuan Ouyang, Renmiao Chen, Zhexin Zhang, Yida Lu, Hongning Wang, Han Qiu, Minlie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Toxicity detection in multimodal text-image content faces growing challenges,
especially with multimodal implicit toxicity, where each modality appears
benign on its own but conveys hazard when combined. Multimodal implicit
toxicity appears not only as formal statements in social platforms but also
prompts that can lead to toxic dialogs from Large Vision-Language Models
(LVLMs). Despite the success in unimodal text or image moderation, toxicity
detection for multimodal content, particularly the multimodal implicit
toxicity, remains underexplored. To fill this gap, we comprehensively build a
taxonomy for multimodal implicit toxicity (MMIT) and introduce an MMIT-dataset,
comprising 2,100 multimodal statements and prompts across 7 risk categories (31
sub-categories) and 5 typical cross-modal correlation modes. To advance the
detection of multimodal implicit toxicity, we build ShieldVLM, a model which
identifies implicit toxicity in multimodal statements, prompts and dialogs via
deliberative cross-modal reasoning. Experiments show that ShieldVLM outperforms
existing strong baselines in detecting both implicit and explicit toxicity. The
model and dataset will be publicly available to support future researches.
Warning: This paper contains potentially sensitive contents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Memory-Centric Embodied Question Answer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13948v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13948v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingliang Zhai, Zhi Gao, Yuwei Wu, Yunde Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied Question Answering (EQA) requires agents to autonomously explore and
understand the environment to answer context-dependent questions. Existing
frameworks typically center around the planner, which guides the stopping
module, memory module, and answering module for reasoning. In this paper, we
propose a memory-centric EQA framework named MemoryEQA. Unlike planner-centric
EQA models where the memory module cannot fully interact with other modules,
MemoryEQA flexible feeds memory information into all modules, thereby enhancing
efficiency and accuracy in handling complex tasks, such as those involving
multiple targets across different regions. Specifically, we establish a
multi-modal hierarchical memory mechanism, which is divided into global memory
that stores language-enhanced scene maps, and local memory that retains
historical observations and state information. When performing EQA tasks, the
multi-modal large language model is leveraged to convert memory information
into the required input formats for injection into different modules. To
evaluate EQA models' memory capabilities, we constructed the MT-HM3D dataset
based on HM3D, comprising 1,587 question-answer pairs involving multiple
targets across various regions, which requires agents to maintain memory of
exploration-acquired target information. Experimental results on HM-EQA,
MT-HM3D, and OpenEQA demonstrate the effectiveness of our framework, where a
19.8% performance gain on MT-HM3D compared to baseline model further
underscores memory capability's pivotal role in resolving complex tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14pages, 7 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MORALISE: A Structured Benchmark for Moral Alignment in Visual Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14728v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14728v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Lin, Zhining Liu, Ze Yang, Gaotang Li, Ruizhong Qiu, Shuke Wang, Hui Liu, Haotian Li, Sumit Keswani, Vishwa Pardeshi, Huijun Zhao, Wei Fan, Hanghang Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Warning: This paper contains examples of harmful language and images. Reader
discretion is advised. Recently, vision-language models have demonstrated
increasing influence in morally sensitive domains such as autonomous driving
and medical analysis, owing to their powerful multimodal reasoning
capabilities. As these models are deployed in high-stakes real-world
applications, it is of paramount importance to ensure that their outputs align
with human moral values and remain within moral boundaries. However, existing
work on moral alignment either focuses solely on textual modalities or relies
heavily on AI-generated images, leading to distributional biases and reduced
realism. To overcome these limitations, we introduce MORALISE, a comprehensive
benchmark for evaluating the moral alignment of vision-language models (VLMs)
using diverse, expert-verified real-world data. We begin by proposing a
comprehensive taxonomy of 13 moral topics grounded in Turiel's Domain Theory,
spanning the personal, interpersonal, and societal moral domains encountered in
everyday life. Built on this framework, we manually curate 2,481 high-quality
image-text pairs, each annotated with two fine-grained labels: (1) topic
annotation, identifying the violated moral topic(s), and (2) modality
annotation, indicating whether the violation arises from the image or the text.
For evaluation, we encompass two tasks, \textit{moral judgment} and
\textit{moral norm attribution}, to assess models' awareness of moral
violations and their reasoning ability on morally salient content. Extensive
experiments on 19 popular open- and closed-source VLMs show that MORALISE poses
a significant challenge, revealing persistent moral limitations in current
state-of-the-art models. The full benchmark is publicly available at
https://huggingface.co/datasets/Ze1025/MORALISE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 11 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05863v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05863v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhao Jia, Xinyi Wu, Hao Li, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In AI-facilitated teaching, leveraging various query styles to interpret
abstract text descriptions is crucial for ensuring high-quality teaching.
However, current retrieval models primarily focus on natural text-image
retrieval, making them insufficiently tailored to educational scenarios due to
the ambiguities in the retrieval process. In this paper, we propose a diverse
expression retrieval task tailored to educational scenarios, supporting
retrieval based on multiple query styles and expressions. We introduce the STEM
Education Retrieval Dataset (SER), which contains over 24,000 query pairs of
different styles, and the Uni-Retrieval, an efficient and style-diversified
retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts
query style features as prototypes and builds a continuously updated Prompt
Bank containing prompt tokens for diverse queries. This bank can updated during
test time to represent domain-specific knowledge for different subject
retrieval scenarios. Our framework demonstrates scalability and robustness by
dynamically retrieving prompt tokens based on prototype similarity, effectively
facilitating learning for unknown queries. Experimental results indicate that
Uni-Retrieval outperforms existing retrieval models in most retrieval tasks.
This advancement provides a scalable and precise solution for diverse
educational needs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can <span class="highlight-title">Prompt</span>ing LLMs Unlock Hate Speech Detection across Languages? A
  Zero-shot and Few-shot Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.06149v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.06149v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite growing interest in automated hate speech detection, most existing
approaches overlook the linguistic diversity of online content. Multilingual
instruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ
offer promising capabilities across languages, but their effectiveness in
identifying hate speech through zero-shot and few-shot prompting remains
underexplored. This work evaluates LLM prompting-based detection across eight
non-English languages, utilizing several prompting techniques and comparing
them to fine-tuned encoder models. We show that while zero-shot and few-shot
prompting lag behind fine-tuned encoder models on most of the real-world
evaluation sets, they achieve better generalization on functional tests for
hate speech detection. Our study also reveals that prompt design plays a
critical role, with each language often requiring customized prompting
techniques to maximize performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeepResonance: Enhancing Multimodal Music Understanding via
  Music-centric Multi-way Instruction Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12623v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12623v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Hiromi Wakaki, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in music large language models (LLMs) have significantly
improved music understanding tasks, which involve the model's ability to
analyze and interpret various musical elements. These improvements primarily
focused on integrating both music and text inputs. However, the potential of
incorporating additional modalities such as images, videos and textual music
features to enhance music understanding remains unexplored. To bridge this gap,
we propose DeepResonance, a multimodal music understanding LLM fine-tuned via
multi-way instruction tuning with multi-way aligned music, text, image, and
video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and
Music4way-Any2T, three 4-way training and evaluation datasets designed to
enable DeepResonance to integrate both visual and textual music feature
content. We also introduce multi-sampled ImageBind embeddings and a pre-LLM
fusion Transformer to enhance modality fusion prior to input into text LLMs,
tailoring DeepResonance for multi-way instruction tuning. Our model achieves
state-of-the-art performances across six music understanding tasks,
highlighting the benefits of the auxiliary modalities and the structural
superiority of DeepResonance. We plan to open-source the models and the newly
constructed datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contrastive Alignment with Semantic Gap-Aware Corrections in Text-Video
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12499v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12499v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Zhenzhen Hu, Jia Li, Richang Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-video retrieval have been largely driven by
contrastive learning frameworks. However, existing methods overlook a key
source of optimization tension: the separation between text and video
distributions in the representation space (referred to as the modality gap),
and the prevalence of false negatives in batch sampling. These factors lead to
conflicting gradients under the InfoNCE loss, impeding stable alignment. To
mitigate this, we propose GARE, a Gap-Aware Retrieval framework that introduces
a learnable, pair-specific increment Delta_ij between text t_i and video v_j to
offload the tension from the global anchor representation. We first derive the
ideal form of Delta_ij via a coupled multivariate first-order Taylor
approximation of the InfoNCE loss under a trust-region constraint, revealing it
as a mechanism for resolving gradient conflicts by guiding updates along a
locally optimal descent direction. Due to the high cost of directly computing
Delta_ij, we introduce a lightweight neural module conditioned on the semantic
gap between each video-text pair, enabling structure-aware correction guided by
gradient supervision. To further stabilize learning and promote
interpretability, we regularize Delta using three components: a trust-region
constraint to prevent oscillation, a directional diversity term to promote
semantic coverage, and an information bottleneck to limit redundancy.
Experiments across four retrieval benchmarks show that GARE consistently
improves alignment accuracy and robustness to noisy supervision, confirming the
effectiveness of gap-aware tension mitigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OT-DETECTOR: Delving into Optimal Transport for Zero-shot
  Out-of-Distribution Detection <span class="chip">IJCAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06442v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06442v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Liu, Hao Tang, Haiqi Zhang, Jing Qin, Zechao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-distribution (OOD) detection is crucial for ensuring the reliability
and safety of machine learning models in real-world applications. While
zero-shot OOD detection, which requires no training on in-distribution (ID)
data, has become feasible with the emergence of vision-language models like
CLIP, existing methods primarily focus on semantic matching and fail to fully
capture distributional discrepancies. To address these limitations, we propose
OT-DETECTOR, a novel framework that employs Optimal Transport (OT) to quantify
both semantic and distributional discrepancies between test samples and ID
labels. Specifically, we introduce cross-modal transport mass and transport
cost as semantic-wise and distribution-wise OOD scores, respectively, enabling
more robust detection of OOD samples. Additionally, we present a semantic-aware
content refinement (SaCR) module, which utilizes semantic cues from ID labels
to amplify the distributional discrepancy between ID and hard OOD samples.
Extensive experiments on several benchmarks demonstrate that OT-DETECTOR
achieves state-of-the-art performance across various OOD detection tasks,
particularly in challenging hard-OOD scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 34th International Joint Conference on Artificial
  Intelligence (IJCAI 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding
  Capabilities of MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.11275v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.11275v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengju Xu, Yan Wang, Shuyuan Zhang, Xuan Zhou, Xin Li, Yue Yuan, Fengzhao Li, Shunyuan Zhou, Xingyu Wang, Yi Zhang, Haiying Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in Multimodal Large Language Models (MLLMs) have
significantly enhanced the ability of artificial intelligence systems to
understand and generate multimodal content. However, these models often exhibit
limited effectiveness when applied to non-Western cultural contexts, which
raises concerns about their wider applicability. To address this limitation, we
propose the Traditional Chinese Culture understanding Benchmark (TCC-Bench), a
bilingual (i.e., Chinese and English) Visual Question Answering (VQA) benchmark
specifically designed for assessing the understanding of traditional Chinese
culture by MLLMs. TCC-Bench comprises culturally rich and visually diverse
data, incorporating images from museum artifacts, everyday life scenes, comics,
and other culturally significant contexts. We adopt a semi-automated pipeline
that utilizes GPT-4o in text-only mode to generate candidate questions,
followed by human curation to ensure data quality and avoid potential data
leakage. The benchmark also avoids language bias by preventing direct
disclosure of cultural concepts within question texts. Experimental evaluations
across a wide range of MLLMs demonstrate that current models still face
significant challenges when reasoning about culturally grounded visual content.
The results highlight the need for further research in developing culturally
inclusive and context-aware multimodal systems. The code and data can be found
at: https://tcc-bench.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast Text-to-Audio Generation with Adversarial Post-Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.08175v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.08175v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zachary Novack, Zach Evans, Zack Zukowski, Josiah Taylor, CJ Carr, Julian Parker, Adnan Al-Sinan, Gian Marco Iodice, Julian McAuley, Taylor Berg-Kirkpatrick, Jordi Pons
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-audio systems, while increasingly performant, are slow at inference
time, thus making their latency unpractical for many creative applications. We
present Adversarial Relativistic-Contrastive (ARC) post-training, the first
adversarial acceleration algorithm for diffusion/flow models not based on
distillation. While past adversarial post-training methods have struggled to
compare against their expensive distillation counterparts, ARC post-training is
a simple procedure that (1) extends a recent relativistic adversarial
formulation to diffusion/flow post-training and (2) combines it with a novel
contrastive discriminator objective to encourage better prompt adherence. We
pair ARC post-training with a number optimizations to Stable Audio Open and
build a model capable of generating $\approx$12s of 44.1kHz stereo audio in
$\approx$75ms on an H100, and $\approx$7s on a mobile edge-device, the fastest
text-to-audio model to our knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-19T00:00:00Z">2025-05-19</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">22</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-Based Compact Reranking with Document Features for Scientific
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13757v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13757v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runchu Tian, Xueqiang Xu, Bowen Jin, SeongKu Kang, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific retrieval is essential for advancing academic discovery. Within
this process, document reranking plays a critical role by refining first-stage
retrieval results. However, large language model (LLM) listwise reranking faces
unique challenges in the scientific domain. First-stage retrieval is often
suboptimal in the scientific domain, so relevant documents are ranked lower.
Moreover, conventional listwise reranking uses the full text of candidate
documents in the context window, limiting the number of candidates that can be
considered. As a result, many relevant documents are excluded before reranking,
which constrains overall retrieval performance. To address these challenges, we
explore compact document representations based on semantic features such as
categories, sections, and keywords, and propose a training-free, model-agnostic
reranking framework for scientific retrieval called CoRank. The framework
involves three stages: (i) offline extraction of document-level features, (ii)
coarse reranking using these compact representations, and (iii) fine-grained
reranking on full texts of the top candidates from stage (ii). This hybrid
design provides a high-level abstraction of document semantics, expands
candidate coverage, and retains critical details required for precise ranking.
Experiments on LitSearch and CSFCube show that CoRank significantly improves
reranking performance across different LLM backbones, increasing nDCG@10 from
32.0 to 39.7. Overall, these results highlight the value of information
extraction for reranking in scientific retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GMM-Based Comprehensive Feature Extraction and Relative Distance
  Preservation For Few-Shot Cross-Modal Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13306v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13306v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengsong Sun, Weiping Li, Xiang Li, Yuankun Liu, Lianlei Shan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Few-shot cross-modal retrieval focuses on learning cross-modal
representations with limited training samples, enabling the model to handle
unseen classes during inference. Unlike traditional cross-modal retrieval
tasks, which assume that both training and testing data share the same class
distribution, few-shot retrieval involves data with sparse representations
across modalities. Existing methods often fail to adequately model the
multi-peak distribution of few-shot cross-modal data, resulting in two main
biases in the latent semantic space: intra-modal bias, where sparse samples
fail to capture intra-class diversity, and inter-modal bias, where
misalignments between image and text distributions exacerbate the semantic gap.
These biases hinder retrieval accuracy. To address these issues, we propose a
novel method, GCRDP, for few-shot cross-modal retrieval. This approach
effectively captures the complex multi-peak distribution of data using a
Gaussian Mixture Model (GMM) and incorporates a multi-positive sample
contrastive learning mechanism for comprehensive feature modeling.
Additionally, we introduce a new strategy for cross-modal semantic alignment,
which constrains the relative distances between image and text feature
distributions, thereby improving the accuracy of cross-modal representations.
We validate our approach through extensive experiments on four benchmark
datasets, demonstrating superior performance over six state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tommaso Mario Buonocore, Enea Parimbelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Content moderation for large language models (LLMs) remains a significant
challenge, requiring flexible and adaptable solutions that can quickly respond
to emerging threats. This paper introduces Retrieval Augmented Rejection (RAR),
a novel approach that leverages a retrieval-augmented generation (RAG)
architecture to dynamically reject unsafe user queries without model
retraining. By strategically inserting and marking malicious documents into the
vector database, the system can identify and reject harmful requests when these
documents are retrieved. Our preliminary results show that RAR achieves
comparable performance to embedded moderation in LLMs like Claude 3.5 Sonnet,
while offering superior flexibility and real-time customization capabilities, a
fundamental feature to timely address critical vulnerabilities. This approach
introduces no architectural changes to existing RAG systems, requiring only the
addition of specially crafted documents and a simple rejection mechanism based
on retrieval results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 4 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Retrieval Augmented Generation for Object Constraint Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Chenhao Li, Vahid Zolfaghari, Nenad Petrovic, Fengjunjie Pan, Alois Knoll
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Object Constraint Language (OCL) is essential for defining precise
constraints within Model-Based Systems Engineering (MBSE). However, manually
writing OCL rules is complex and time-consuming. This study explores the
optimization of Retrieval-Augmented Generation (RAG) for automating OCL rule
generation, focusing on the impact of different retrieval strategies. We
evaluate three retrieval approaches $\unicode{x2013}$ BM25 (lexical-based),
BERT-based (semantic retrieval), and SPLADE (sparse-vector retrieval)
$\unicode{x2013}$ analyzing their effectiveness in providing relevant context
for a large language model.
  To further assess our approach, we compare and benchmark our
retrieval-optimized generation results against PathOCL, a state-of-the-art
graph-based method. We directly compare BM25, BERT, and SPLADE retrieval
methods with PathOCL to understand how different retrieval methods perform for
a unified evaluation framework. Our experimental results, focusing on
retrieval-augmented generation, indicate that while retrieval can enhance
generation accuracy, its effectiveness depends on the retrieval method and the
number of retrieved chunks (k). BM25 underperforms the baseline, whereas
semantic approaches (BERT and SPLADE) achieve better results, with SPLADE
performing best at lower k values. However, excessive retrieval with high k
parameter can lead to retrieving irrelevant chunks which degrades model
performance. Our findings highlight the importance of optimizing retrieval
configurations to balance context relevance and output consistency. This
research provides insights into improving OCL rule generation using RAG and
underscores the need for tailoring retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for
  Question-Answering Over Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13572v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13572v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yousouf Taghzouti, Franck Michel, Tao Jiang, Louis-Félix Nothias, Fabien Gandon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The SPARQL query language is the standard method to access knowledge graphs
(KGs). However, formulating SPARQL queries is a significant challenge for
non-expert users, and remains time-consuming for the experienced ones. Best
practices recommend to document KGs with competency questions and example
queries to contextualise the knowledge they contain and illustrate their
potential applications. In practice, however, this is either not the case or
the examples are provided in limited numbers. Large Language Models (LLMs) are
being used in conversational agents and are proving to be an attractive
solution with a wide range of applications, from simple question-answering
about common knowledge to generating code in a targeted programming language.
However, training and testing these models to produce high quality SPARQL
queries from natural language questions requires substantial datasets of
question-query pairs. In this paper, we present Q${}^2$Forge that addresses the
challenge of generating new competency questions for a KG and corresponding
SPARQL queries. It iteratively validates those queries with human feedback and
LLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular,
meaning that the different modules of the application (CQ generation, query
generation and query refinement) can be used separately, as an integrated
pipeline, or replaced by alternative services. The result is a complete
pipeline from competency question formulation to query evaluation, supporting
the creation of reference query sets for any target KG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CPRet: A <span class="highlight-title">Dataset</span>, Benchmark, and Model for Retrieval in Competitive
  Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Deng, Yuan Meng, Shixiang Tang, Wanli Ouyang, Xinzhu Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Competitive programming benchmarks are widely used in scenarios such as
programming contests and large language model assessments. However, the growing
presence of duplicate or highly similar problems raises concerns not only about
competition fairness, but also about the validity of competitive programming as
a benchmark for model evaluation. In this paper, we propose a new problem --
similar question retrieval -- to address this issue. Due to the lack of both
data and models, solving this problem is challenging. To this end, we introduce
CPRet, a retrieval-oriented benchmark suite for competitive programming,
covering four retrieval tasks: two code-centric (i.e., Text-to-Code and
Code-to-Code) and two newly proposed problem-centric tasks (i.e.,
Problem-to-Duplicate and Simplified-to-Full), built from a combination of
automatically crawled problem-solution data and manually curated annotations.
Our contribution includes both high-quality training data and temporally
separated test sets for reliable evaluation. In addition, we develop two
task-specialized retrievers based on this dataset: CPRetriever-Code, trained
with a novel Group-InfoNCE loss for problem-code alignment, and
CPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both
models achieve strong results and are open-sourced for local use. Finally, we
analyze LiveCodeBench and find that high-similarity problems inflate model pass
rates and reduce differentiation, underscoring the need for similarity-aware
evaluation in future benchmarks.
  Code and data are available at: https://github.com/coldchair/CPRet
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main 9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AMAQA: A Metadata-based QA <span class="highlight-title">Dataset</span> for RAG Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Bruni, Marco Avvenuti, Nicola Tonellotto, Maurizio Tesconi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) systems are widely used in
question-answering (QA) tasks, but current benchmarks lack metadata
integration, hindering evaluation in scenarios requiring both textual data and
external information. To address this, we present AMAQA, a new open-access QA
dataset designed to evaluate tasks combining text and metadata. The integration
of metadata is especially important in fields that require rapid analysis of
large volumes of data, such as cybersecurity and intelligence, where timely
access to relevant information is critical. AMAQA includes about 1.1 million
English messages collected from 26 public Telegram groups, enriched with
metadata such as timestamps, topics, emotional tones, and toxicity indicators,
which enable precise and contextualized queries by filtering documents based on
specific criteria. It also includes 450 high-quality QA pairs, making it a
valuable resource for advancing research on metadata-driven QA and RAG systems.
To the best of our knowledge, AMAQA is the first single-hop QA benchmark to
incorporate metadata and labels such as topics covered in the messages. We
conduct extensive tests on the benchmark, establishing a new standard for
future research. We show that leveraging metadata boosts accuracy from 0.12 to
0.61, highlighting the value of structured context. Building on this, we
explore several strategies to refine the LLM input by iterating over provided
context and enriching it with noisy documents, achieving a further 3-point gain
over the best baseline and a 14-point improvement over simple metadata
filtering. The dataset is available at
https://anonymous.4open.science/r/AMAQA-5D0D/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlearning for Federated Online Learning to Rank: A Reproducibility
  Study <span class="chip">SIGIR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiling Tao, Shuyi Wang, Jiaxi Yang, Guido Zuccon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper reports on findings from a comparative study on the effectiveness
and efficiency of federated unlearning strategies within Federated Online
Learning to Rank (FOLTR), with specific attention to systematically analysing
the unlearning capabilities of methods in a verifiable manner.
  Federated approaches to ranking of search results have recently garnered
attention to address users privacy concerns. In FOLTR, privacy is safeguarded
by collaboratively training ranking models across decentralized data sources,
preserving individual user data while optimizing search results based on
implicit feedback, such as clicks.
  Recent legislation introduced across numerous countries is establishing the
so called "the right to be forgotten", according to which services based on
machine learning models like those in FOLTR should provide capabilities that
allow users to remove their own data from those used to train models. This has
sparked the development of unlearning methods, along with evaluation practices
to measure whether unlearning of a user data successfully occurred. Current
evaluation practices are however often controversial, necessitating the use of
multiple metrics for a more comprehensive assessment -- but previous proposals
of unlearning methods only used single evaluation metrics.
  This paper addresses this limitation: our study rigorously assesses the
effectiveness of unlearning strategies in managing both under-unlearning and
over-unlearning scenarios using adapted, and newly proposed evaluation metrics.
Thanks to our detailed analysis, we uncover the strengths and limitations of
five unlearning strategies, offering valuable insights into optimizing
federated unlearning to balance data privacy and system performance within
FOLTR. We publicly release our code and complete results at
https://github.com/Iris1026/Unlearning-for-FOLTR.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large
  Multimodal-Models Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Zhang, Xingyu Chen, Xiaofeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Multimodal Models (LMMs) have become a pivotal research focus in deep
learning, demonstrating remarkable capabilities in 3D scene understanding.
However, current 3D LMMs employing thousands of spatial tokens for multimodal
reasoning suffer from critical inefficiencies: excessive computational overhead
and redundant information flows. Unlike 2D VLMs processing single images, 3D
LMMs exhibit inherent architectural redundancy due to the heterogeneous
mechanisms between spatial tokens and visual tokens. To address this challenge,
we propose AdaToken-3D, an adaptive spatial token optimization framework that
dynamically prunes redundant tokens through spatial contribution analysis. Our
method automatically tailors pruning strategies to different 3D LMM
architectures by quantifying token-level information flows via attention
pattern mining. Extensive experiments on LLaVA-3D (a 7B parameter 3D-LMM)
demonstrate that AdaToken-3D achieves 21\% faster inference speed and 63\%
FLOPs reduction while maintaining original task accuracy. Beyond efficiency
gains, this work systematically investigates redundancy patterns in multimodal
spatial information flows through quantitative token interaction analysis. Our
findings reveal that over 60\% of spatial tokens contribute minimally ($<$5\%)
to the final predictions, establishing theoretical foundations for efficient 3D
multimodal learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ JIR-Arena: The First Benchmark <span class="highlight-title">Dataset</span> for Just-in-time Information
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13550v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13550v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ke Yang, Kevin Ros, Shankar Kumar Senthil Kumar, ChengXiang Zhai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Just-in-time Information Recommendation (JIR) is a service designed to
deliver the most relevant information precisely when users need it, ,
addressing their knowledge gaps with minimal effort and boosting
decision-making and efficiency in daily life. Advances in device-efficient
deployment of foundation models and the growing use of intelligent wearable
devices have made always-on JIR assistants feasible. However, there has been no
systematic effort to formally define JIR tasks or establish evaluation
frameworks. To bridge this gap, we present the first mathematical definition of
JIR tasks and associated evaluation metrics. Additionally, we introduce
JIR-Arena, a multimodal benchmark dataset featuring diverse,
information-request-intensive scenarios to evaluate JIR systems across critical
dimensions: i) accurately inferring user information needs, ii) delivering
timely and relevant recommendations, and iii) avoiding irrelevant content that
may distract users.
  Developing a JIR benchmark dataset poses challenges due to subjectivity in
estimating user information needs and uncontrollable system variables affecting
reproducibility. To address these, JIR-Arena: i) combines input from multiple
humans and large AI models to approximate information need distributions; ii)
assesses JIR quality through information retrieval outcomes using static
knowledge base snapshots; and iii) employs a multi-turn, multi-entity
validation framework to improve objectivity and generality. Furthermore, we
implement a baseline JIR system capable of processing real-time information
streams aligned with user inputs. Our evaluation of this baseline system on
JIR-Arena indicates that while foundation model-based JIR systems simulate user
needs with reasonable precision, they face challenges in recall and effective
content retrieval. To support future research in this new area, we fully
release our code and data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards A Generalist Code Embedding Model Based On Massive Data
  Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaofan Li, Jianlyu Chen, Yingxia Shao, Defu Lian, Zheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code embedding models attract increasing attention due to the widespread
popularity of retrieval-augmented generation (RAG) in software development.
These models are expected to capture the rich semantic relationships inherent
to code, which differ significantly from those found in text. However, existing
models remain severely limited due to the scarcity of high-quality training
data. In this work, we introduce \textbf{CodeR} (\underline{Code}
\underline{R}etrieval), a state-of-the-art embedding model for general-purpose
code retrieval. The superior performance of CodeR is built upon CodeR-Pile, a
large-scale synthetic dataset constructed under the DRU (Diversity,
Reliability, Usability) principle via a novel data synthesis pipeline. To
optimize training effectiveness, we propose Annealing, a curriculum learning
strategy that enables effective knowledge transfer across heterogeneous sources
of data. We evaluate CodeR based on 16 diverse code retrieval tasks, where it
significantly outperforms existing baselines and exhibits strong out-of-domain
generalization performance. We have publicly released our code and the
well-trained model to facilitate further research in this critical area.
https://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_Coder.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12694v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12694v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenya Abe, Kunihiro Takeoka, Makoto P. Kato, Masafumi Oyamada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query expansion (QE) enhances retrieval by incorporating relevant terms, with
large language models (LLMs) offering an effective alternative to traditional
rule-based and statistical methods. However, LLM-based QE suffers from a
fundamental limitation: it often fails to generate relevant knowledge,
degrading search performance. Prior studies have focused on hallucination, yet
its underlying cause--LLM knowledge deficiencies--remains underexplored. This
paper systematically examines two failure cases in LLM-based QE: (1) when the
LLM lacks query knowledge, leading to incorrect expansions, and (2) when the
query is ambiguous, causing biased refinements that narrow search coverage. We
conduct controlled experiments across multiple datasets, evaluating the effects
of knowledge and query ambiguity on retrieval performance using sparse and
dense retrieval models. Our results reveal that LLM-based QE can significantly
degrade the retrieval effectiveness when knowledge in the LLM is insufficient
or query ambiguity is high. We introduce a framework for evaluating QE under
these conditions, providing insights into the limitations of LLM-based
retrieval augmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025 short paper track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Know Or Not: a library for evaluating out-of-knowledge base robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jessica Foo, Pradyumna Shyama Prasad, Shaun Khoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While the capabilities of large language models (LLMs) have progressed
significantly, their use in high-stakes applications have been limited due to
risks of hallucination. One key approach in reducing hallucination is
retrieval-augmented generation (RAG), but even in such setups, LLMs may still
hallucinate when presented with questions outside of the knowledge base. Such
behavior is unacceptable in high-stake applications where LLMs are expected to
abstain from answering queries it does not have sufficient context on. In this
work, we present a novel methodology for systematically evaluating
out-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not
know) in the RAG setting, without the need for manual annotation of gold
standard answers. We implement our methodology in knowornot, an open-source
library that enables users to develop their own customized evaluation data and
pipelines for OOKB robustness. knowornot comprises four main features. Firstly,
it provides a unified, high-level API that streamlines the process of setting
up and running robustness benchmarks. Secondly, its modular architecture
emphasizes extensibility and flexibility, allowing users to easily integrate
their own LLM clients and RAG settings. Thirdly, its rigorous data modeling
design ensures experiment reproducibility, reliability and traceability.
Lastly, it implements a comprehensive suite of tools for users to customize
their pipelines. We demonstrate the utility of knowornot by developing a
challenging benchmark, PolicyBench, which spans four Question-Answer (QA)
chatbots on government policies, and analyze its OOKB robustness. The source
code of knowornot is available
https://github.com/govtech-responsibleai/KnowOrNot.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Pairwise Learning-To-Rank At Airbnb 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.09795v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.09795v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Malay Haldar, Daochen Zha, Huiji Gao, Liwei He, Sanjeev Katariya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There are three fundamental asks from a ranking algorithm: it should scale to
handle a large number of items, sort items accurately by their utility, and
impose a total order on the items for logical consistency. But here's the
catch-no algorithm can achieve all three at the same time. We call this
limitation the SAT theorem for ranking algorithms. Given the dilemma, how can
we design a practical system that meets user needs? Our current work at Airbnb
provides an answer, with a working solution deployed at scale. We start with
pairwise learning-to-rank (LTR) models-the bedrock of search ranking tech
stacks today. They scale linearly with the number of items ranked and perform
strongly on metrics like NDCG by learning from pairwise comparisons. They are
at a sweet spot of performance vs. cost, making them an ideal choice for
several industrial applications. However, they have a drawback-by ignoring
interactions between items, they compromise on accuracy. To improve accuracy,
we create a "true" pairwise LTR model-one that captures interactions between
items during pairwise comparisons. But accuracy comes at the expense of
scalability and total order, and we discuss strategies to counter these
challenges. For greater accuracy, we take each item in the search result, and
compare it against the rest of the items along two dimensions: (1) Superiority:
How strongly do searchers prefer the given item over the remaining ones? (2)
Similarity: How similar is the given item to all the other items? This forms
the basis of our "all-pairwise" LTR framework, which factors in interactions
across all items at once. Looking at items on the search result page all
together-superiority and similarity combined-gives us a deeper understanding of
what searchers truly want. We quantify the resulting improvements in searcher
experience through offline and online experiments at Airbnb.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Supporting Evidence-Based Medicine by Finding Both Relevant and
  Significant Works 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18383v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18383v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sameh Frihat, Norbert Fuhr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a new approach to improving the relevance and
reliability of medical IR, which builds upon the concept of Level of Evidence
(LoE). LoE framework categorizes medical publications into 7 distinct levels
based on the underlying empirical evidence. Despite LoE framework's relevance
in medical research and evidence-based practice, only few medical publications
explicitly state their LoE. Therefore, we develop a classification model for
automatically assigning LoE to medical publications, which successfully
classifies over 26 million documents in MEDLINE database into LoE classes. The
subsequent retrieval experiments on TREC PM datasets show substantial
improvements in retrieval relevance, when LoE is used as a search filter.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Collaborative Filtering Meets Spectrum Shift: Connecting User-Item
  Interaction with Graph-Structured Side Information <span class="chip">KDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08071v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08071v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunhang He, Cong Xu, Jun Wang, Wei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) have demonstrated their superiority in
collaborative filtering, where the user-item (U-I) interaction bipartite graph
serves as the fundamental data format. However, when graph-structured side
information (e.g., multimodal similarity graphs or social networks) is
integrated into the U-I bipartite graph, existing graph collaborative filtering
methods fall short of achieving satisfactory performance. We quantitatively
analyze this problem from a spectral perspective. Recall that a bipartite graph
possesses a full spectrum within the range of [-1, 1], with the highest
frequency exactly achievable at -1 and the lowest frequency at 1; however, we
observe as more side information is incorporated, the highest frequency of the
augmented adjacency matrix progressively shifts rightward. This spectrum shift
phenomenon has caused previous approaches built for the full spectrum [-1, 1]
to assign mismatched importance to different frequencies. To this end, we
propose Spectrum Shift Correction (dubbed SSC), incorporating shifting and
scaling factors to enable spectral GNNs to adapt to the shifted spectrum.
Unlike previous paradigms of leveraging side information, which necessitate
tailored designs for diverse data types, SSC directly connects traditional
graph collaborative filtering with any graph-structured side information.
Experiments on social and multimodal recommendation demonstrate the
effectiveness of SSC, achieving relative improvements of up to 23% without
incurring any additional computational overhead. Our code is available at
https://github.com/yhhe2004/SSC-KDD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at KDD 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse
  Modalities and Granularities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.20734v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.20734v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has shown substantial promise in
improving factual accuracy by grounding model responses with external knowledge
relevant to queries. However, most existing RAG approaches are limited to a
text-only corpus, and while recent efforts have extended RAG to other
modalities such as images and videos, they typically operate over a single
modality-specific corpus. In contrast, real-world queries vary widely in the
type of knowledge they require, which a single type of knowledge source cannot
address. To address this, we introduce UniversalRAG, a novel RAG framework
designed to retrieve and integrate knowledge from heterogeneous sources with
diverse modalities and granularities. Specifically, motivated by the
observation that forcing all modalities into a unified representation space
derived from a single aggregated corpus causes a modality gap, where the
retrieval tends to favor items from the same modality as the query, we propose
a modality-aware routing mechanism that dynamically identifies the most
appropriate modality-specific corpus and performs targeted retrieval within it.
Also, beyond modality, we organize each modality into multiple granularity
levels, enabling fine-tuned retrieval tailored to the complexity and scope of
the query. We validate UniversalRAG on 8 benchmarks spanning multiple
modalities, showing its superiority over various modality-specific and unified
baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page : https://universalrag.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FaMTEB: Massive Text Embedding Benchmark in Persian Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11571v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11571v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erfan Zinvandi, Morteza Alikhani, Mehran Sarmadi, Zahra Pourbahman, Sepehr Arvin, Reza Kazemi, Arash Amini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a comprehensive benchmark for Persian (Farsi)
text embeddings, built upon the Massive Text Embedding Benchmark (MTEB). Our
benchmark includes 63 datasets spanning seven different tasks: classification,
clustering, pair classification, reranking, retrieval, summary retrieval, and
semantic textual similarity. The datasets are formed as a combination of
existing, translated, and newly generated data, offering a diverse evaluation
framework for Persian language models. Given the increasing use of text
embedding models in chatbots, evaluation datasets are becoming inseparable
ingredients in chatbot challenges and Retrieval-Augmented Generation systems.
As a contribution, we include chatbot evaluation datasets in the MTEB benchmark
for the first time. In addition, in this paper, we introduce the new task of
summary retrieval which is not part of the tasks included in standard MTEB.
Another contribution of this paper is the introduction of a substantial number
of new Persian language NLP datasets suitable for training and evaluation, some
of which have no previous counterparts in Persian. We evaluate the performance
of several Persian and multilingual embedding models in a range of tasks. This
work introduces an open-source benchmark with datasets, code and a public
leaderboard.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model as Universal Retriever in Industrial-Scale
  Recommender System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03041v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03041v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junguang Jiang, Yanwen Huang, Bin Liu, Xiaoyu Kong, Xinhang Li, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In real-world recommender systems, different retrieval objectives are
typically addressed using task-specific datasets with carefully designed model
architectures. We demonstrate that Large Language Models (LLMs) can function as
universal retrievers, capable of handling multiple objectives within a
generative retrieval framework. To model complex user-item relationships within
generative retrieval, we propose multi-query representation. To address the
challenge of extremely large candidate sets in industrial recommender systems,
we introduce matrix decomposition to boost model learnability,
discriminability, and transferability, and we incorporate probabilistic
sampling to reduce computation costs. Finally, our Universal Retrieval Model
(URM) can adaptively generate a set from tens of millions of candidates based
on arbitrary given objective while keeping the latency within tens of
milliseconds. Applied to industrial-scale data, URM outperforms expert models
elaborately designed for different retrieval objectives on offline experiments
and significantly improves the core metric of online advertising platform by
$3\%$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Watermarking for Sequential Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12989v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12989v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sixiao Zhang, Cheng Long, Wei Yuan, Hongxu Chen, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of large foundation models, data has become a crucial component in
building high-performance AI systems. As the demand for high-quality and
large-scale data continues to rise, data copyright protection is attracting
increasing attention. In this work, we explore the problem of data watermarking
for sequential recommender systems, where a watermark is embedded into the
target dataset and can be detected in models trained on that dataset. We focus
on two settings: dataset watermarking, which protects the ownership of the
entire dataset, and user watermarking, which safeguards the data of individual
users. We present a method named Dataset Watermarking for Recommender Systems
(DWRS) to address them. We define the watermark as a sequence of consecutive
items inserted into normal users' interaction sequences. We define a Receptive
Field (RF) to guide the inserting process to facilitate the memorization of the
watermark. Extensive experiments on five representative sequential
recommendation models and three benchmark datasets demonstrate the
effectiveness of DWRS in protecting data copyright while preserving model
utility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CXMArena: Unified <span class="highlight-title">Dataset</span> to benchmark performance in realistic CXM
  Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.09436v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.09436v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raghav Garg, Kapil Sharma, Karan Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) hold immense potential for revolutionizing
Customer Experience Management (CXM), particularly in contact center
operations. However, evaluating their practical utility in complex operational
environments is hindered by data scarcity (due to privacy concerns) and the
limitations of current benchmarks. Existing benchmarks often lack realism,
failing to incorporate deep knowledge base (KB) integration, real-world noise,
or critical operational tasks beyond conversational fluency. To bridge this
gap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset
specifically designed for evaluating AI in operational CXM contexts. Given the
diversity in possible contact center features, we have developed a scalable
LLM-powered pipeline that simulates the brand's CXM entities that form the
foundation of our datasets-such as knowledge articles including product
specifications, issue taxonomies, and contact center conversations. The
entities closely represent real-world distribution because of controlled noise
injection (informed by domain experts) and rigorous automated validation.
Building on this, we release CXMArena, which provides dedicated benchmarks
targeting five important operational tasks: Knowledge Base Refinement, Intent
Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with
Integrated Tools. Our baseline experiments underscore the benchmark's
difficulty: even state of the art embedding and generation models achieve only
68% accuracy on article search, while standard embedding methods yield a low F1
score of 0.3 for knowledge base refinement, highlighting significant challenges
for current models necessitating complex pipelines and solutions over
conventional techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Grained Patch Training for Efficient LLM-based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15087v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15087v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Liao, Ruobing Xie, Sihang Li, Xiang Wang, Xingwu Sun, Zhanhui Kang, Xiangnan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have emerged as a new paradigm for
recommendation by converting interacted item history into language modeling.
However, constrained by the limited context length of LLMs, existing approaches
have to truncate item history in the prompt, focusing only on recent
interactions and sacrificing the ability to model long-term history. To enable
LLMs to model long histories, we pursue a concise embedding representation for
items and sessions. In the LLM embedding space, we construct an item's
embedding by aggregating its textual token embeddings; similarly, we construct
a session's embedding by aggregating its item embeddings. While efficient, this
way poses two challenges since it ignores the temporal significance of user
interactions and LLMs do not natively interpret our custom embeddings. To
overcome these, we propose PatchRec, a multi-grained patch training method
consisting of two stages: (1) Patch Pre-training, which familiarizes LLMs with
aggregated embeddings -- patches, and (2) Patch Fine-tuning, which enables LLMs
to capture time-aware significance in interaction history. Extensive
experiments show that PatchRec effectively models longer behavior histories
with improved efficiency. This work facilitates the practical use of LLMs for
modeling long behavior histories. Codes are available at
https://github.com/ljy0ustc/PatchRec.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural-Enhanced Rate Adaptation and Computation Distribution for
  Emerging mmWave Multi-User 3D Video Streaming Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Babak Badnava, Jacob Chakareski, Morteza Hashemi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate multitask edge-user communication-computation resource
allocation for $360^\circ$ video streaming in an edge-computing enabled
millimeter wave (mmWave) multi-user virtual reality system. To balance the
communication-computation trade-offs that arise herein, we formulate a video
quality maximization problem that integrates interdependent
multitask/multi-user action spaces and rebuffering time/quality variation
constraints. We formulate a deep reinforcement learning framework for
\underline{m}ulti-\underline{t}ask \underline{r}ate adaptation and
\underline{c}omputation distribution (MTRC) to solve the problem of interest.
Our solution does not rely on a priori knowledge about the environment and uses
only prior video streaming statistics (e.g., throughput, decoding time, and
transmission delay), and content information, to adjust the assigned video
bitrates and computation distribution, as it observes the induced streaming
performance online. Moreover, to capture the task interdependence in the
environment, we leverage neural network cascades to extend our MTRC method to
two novel variants denoted as R1C2 and C1R2. We train all three methods with
real-world mmWave network traces and $360^\circ$ video datasets to evaluate
their performance in terms of expected quality of experience (QoE), viewport
peak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We
outperform state-of-the-art rate adaptation algorithms, with C1R2 showing best
results and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time
reduction, and $4.14-4.50$ dB quality variation reduction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to be published in IEEE Transaction on Multimedia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Driven Elastic Task Multi-Connectivity Immersive Computing
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Babak Badnava, Jacob Chakareski, Morteza Hashemi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In virtual reality (VR) environments, computational tasks exhibit an elastic
nature, meaning they can dynamically adjust based on various user and system
constraints. This elasticity is essential for maintaining immersive
experiences; however, it also introduces challenges for communication and
computing in VR systems. In this paper, we investigate elastic task offloading
for multi-user edge-computing-enabled VR systems with multi-connectivity,
aiming to maximize the computational energy-efficiency (computational
throughput per unit of energy consumed). To balance the induced communication,
computation, energy consumption, and quality of experience trade-offs due to
the elasticity of VR tasks, we formulate a constrained stochastic computational
energy-efficiency optimization problem that integrates the
multi-connectivity/multi-user action space and the elastic nature of VR
computational tasks. We formulate a centralized phasic policy gradient (CPPG)
framework to solve the problem of interest online, using only prior elastic
task offloading statistics (energy consumption, response time, and transmission
time), and task information (i.e., task size and computational intensity),
while observing the induced system performance (energy consumption and
latency). We further extend our approach to decentralized learning by
formulating an independent phasic policy gradient (IPPG) method and a
decentralized shared multi-armed bandit (DSMAB) method. We train our methods
with real-world 4G, 5G, and WiGig network traces and 360 video datasets to
evaluate their performance in terms of response time, energy efficiency,
scalability, and delivered quality of experience. We also provide a
comprehensive analysis of task size and its effect on offloading policy and
system performance. In particular, we show that CPPG reduces latency by 28% and
energy consumption by 78% compared to IPPG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review by IEEE Transaction on Mobile Computing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio,
  Music, and Their Mix 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13032v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13032v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyang Ma, Yinghao Ma, Yanqiao Zhu, Chen Yang, Yi-Wen Chao, Ruiyang Xu, Wenxi Chen, Yuanzhe Chen, Zhuo Chen, Jian Cong, Kai Li, Keliang Li, Siyou Li, Xinfeng Li, Xiquan Li, Zheng Lian, Yuzhe Liang, Minghao Liu, Zhikang Niu, Tianrui Wang, Yuping Wang, Yuxuan Wang, Yihao Wu, Guanrou Yang, Jianwei Yu, Ruibin Yuan, Zhisheng Zheng, Ziya Zhou, Haina Zhu, Wei Xue, Emmanouil Benetos, Kai Yu, Eng-Siong Chng, Xie Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MMAR, a new benchmark designed to evaluate the deep reasoning
capabilities of Audio-Language Models (ALMs) across massive multi-disciplinary
tasks. MMAR comprises 1,000 meticulously curated audio-question-answer
triplets, collected from real-world internet videos and refined through
iterative error corrections and quality checks to ensure high quality. Unlike
existing benchmarks that are limited to specific domains of sound, music, or
speech, MMAR extends them to a broad spectrum of real-world audio scenarios,
including mixed-modality combinations of sound, music, and speech. Each
question in MMAR is hierarchically categorized across four reasoning layers:
Signal, Perception, Semantic, and Cultural, with additional sub-categories
within each layer to reflect task diversity and complexity. To further foster
research in this area, we annotate every question with a Chain-of-Thought (CoT)
rationale to promote future advancements in audio reasoning. Each item in the
benchmark demands multi-step deep reasoning beyond surface-level understanding.
Moreover, a part of the questions requires graduate-level perceptual and
domain-specific knowledge, elevating the benchmark's difficulty and depth. We
evaluate MMAR using a broad set of models, including Large Audio-Language
Models (LALMs), Large Audio Reasoning Models (LARMs), Omni Language Models
(OLMs), Large Language Models (LLMs), and Large Reasoning Models (LRMs), with
audio caption inputs. The performance of these models on MMAR highlights the
benchmark's challenging nature, and our analysis further reveals critical
limitations of understanding and reasoning capabilities among current models.
We hope MMAR will serve as a catalyst for future advances in this important but
little-explored area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Open-source at https://github.com/ddlBoJack/MMAR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based
  Inpainters under Unknown Conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.13023v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.13023v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yimao Guo, Zuomin Qu, Wei Lu, Xiangyang Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As diffusion-based malicious image manipulation becomes increasingly
prevalent, multiple proactive defense methods are developed to safeguard images
against unauthorized tampering. However, most proactive defense methods only
can safeguard images against manipulation under known conditions, and fail to
protect images from manipulations guided by tampering conditions crafted by
malicious users. To tackle this issue, we propose Anti-Inpainting, a proactive
defense method that achieves adequate protection under unknown conditions
through a triple mechanism to address this challenge. Specifically, a
multi-level deep feature extractor is presented to obtain intricate features
during the diffusion denoising process to improve protective effectiveness. We
design multi-scale semantic-preserving data augmentation to enhance the
transferability of adversarial perturbations across unknown conditions by
multi-scale transformations while preserving semantic integrity. In addition,
we propose a selection-based distribution deviation optimization strategy to
improve the protection of adversarial perturbation against manipulation under
diverse random seeds. Extensive experiments indicate the proactive defensive
performance of Anti-Inpainting against diffusion-based inpainters guided by
unknown conditions in InpaintGuardBench and CelebA-HQ. At the same time, we
also demonstrate the proposed approach's robustness under various image
purification methods and its transferability across different versions of
diffusion models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for
  Multimodal Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12728v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12728v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihua Wang, Ruibo Li, Haozhe Du, Joey Tianyi Zhou, Yu Zhang, Xu Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language and multimodal models (LLMs and LMMs) exhibit strong inference
capabilities but are often limited by slow decoding speeds. This challenge is
especially acute in LMMs, where visual inputs typically comprise more tokens
with lower information density than text -- an issue exacerbated by recent
trends toward finer-grained visual tokenizations to boost performance.
Speculative decoding has been effective in accelerating LLM inference by using
a smaller draft model to generate candidate tokens, which are then selectively
verified by the target model, improving speed without sacrificing output
quality. While this strategy has been extended to LMMs, existing methods
largely overlook the unique properties of visual inputs and depend solely on
text-based draft models. In this work, we propose \textbf{FLASH} (Fast
Latent-Aware Semi-Autoregressive Heuristics), a speculative decoding framework
designed specifically for LMMs, which leverages two key properties of
multimodal data to design the draft model. First, to address redundancy in
visual tokens, we propose a lightweight latent-aware token compression
mechanism. Second, recognizing that visual objects often co-occur within a
scene, we employ a semi-autoregressive decoding strategy to generate multiple
tokens per forward pass. These innovations accelerate draft decoding while
maintaining high acceptance rates, resulting in faster overall inference.
Experiments show that FLASH significantly outperforms prior speculative
decoding approaches in both unimodal and multimodal settings, achieving up to
\textbf{2.68$\times$} speed-up on video captioning and \textbf{2.55$\times$} on
visual instruction tuning tasks compared to the original LMM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Text2midi-InferAlign: Improving Symbolic Music Generation with
  Inference-Time Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhinaba Roy, Geeta Puri, Dorien Herremans
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Text2midi-InferAlign, a novel technique for improving symbolic
music generation at inference time. Our method leverages text-to-audio
alignment and music structural alignment rewards during inference to encourage
the generated music to be consistent with the input caption. Specifically, we
introduce two objectives scores: a text-audio consistency score that measures
rhythmic alignment between the generated music and the original text caption,
and a harmonic consistency score that penalizes generated music containing
notes inconsistent with the key. By optimizing these alignment-based objectives
during the generation process, our model produces symbolic music that is more
closely tied to the input captions, thereby improving the overall quality and
coherence of the generated compositions. Our approach can extend any existing
autoregressive model without requiring further training or fine-tuning. We
evaluate our work on top of Text2midi - an existing text-to-midi generation
model, demonstrating significant improvements in both objective and subjective
evaluation metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 1 figure, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Bounding Box is Worth One Token: Interleaving Layout and Text in a
  Large Language Model for Document Understanding <span class="chip">ACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01976v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01976v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, many studies have demonstrated that exclusively incorporating
OCR-derived text and spatial layouts with large language models (LLMs) can be
highly effective for document understanding tasks. However, existing methods
that integrate spatial layouts with text have limitations, such as producing
overly long text sequences or failing to fully leverage the autoregressive
traits of LLMs. In this work, we introduce Interleaving Layout and Text in a
Large Language Model (LayTextLLM)} for document understanding. LayTextLLM
projects each bounding box to a single embedding and interleaves it with text,
efficiently avoiding long sequence issues while leveraging autoregressive
traits of LLMs. LayTextLLM not only streamlines the interaction of layout and
textual data but also shows enhanced performance in KIE and VQA. Comprehensive
benchmark evaluations reveal significant improvements of LayTextLLM, with a
15.2% increase on KIE tasks and 10.7% on VQA tasks compared to previous SOTA
OCR-based LLMs. All resources are available at
https://github.com/LayTextLLM/LayTextLLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept to ACL2025 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scene-Text Grounding for Text-Based Video Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14319v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14319v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheng Zhou, Junbin Xiao, Xun Yang, Peipei Song, Dan Guo, Angela Yao, Meng Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing efforts in text-based video question answering (TextVideoQA) are
criticized for their opaque decisionmaking and heavy reliance on scene-text
recognition. In this paper, we propose to study Grounded TextVideoQA by forcing
models to answer questions and spatio-temporally localize the relevant
scene-text regions, thus decoupling QA from scenetext recognition and promoting
research towards interpretable QA. The task has three-fold significance. First,
it encourages scene-text evidence versus other short-cuts for answer
predictions. Second, it directly accepts scene-text regions as visual answers,
thus circumventing the problem of ineffective answer evaluation by stringent
string matching. Third, it isolates the challenges inherited in VideoQA and
scene-text recognition. This enables the diagnosis of the root causes for
failure predictions, e.g., wrong QA or wrong scene-text recognition? To achieve
Grounded TextVideoQA, we propose the T2S-QA model that highlights a
disentangled temporal-to-spatial contrastive learning strategy for
weakly-supervised scene-text grounding and grounded TextVideoQA. To facilitate
evaluation, we construct a new dataset ViTXT-GQA which features 52K scene-text
bounding boxes within 2.2K temporal segments related to 2K questions and 729
videos. With ViTXT-GQA, we perform extensive experiments and demonstrate the
severe limitations of existing techniques in Grounded TextVideoQA. While T2S-QA
achieves superior results, the large performance gap with human leaves ample
space for improvement. Our further analysis of oracle scene-text inputs posits
that the major challenge is scene-text recognition. To advance the research of
Grounded TextVideoQA, our dataset and code are at
https://github.com/zhousheng97/ViTXT-GQA.git
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TMM</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-05-18T00:00:00Z">2025-05-18</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Protocol as Poetry: Case Study on Pak's Protocol Arts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.12393v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.12393v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Botao Amber Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protocol art emerges at the confluence of blockchain-based smart contracts
and a century-long lineage of conceptual art, participatory art, and
algorithmic generative art practices. Yet existing definitions-most notably
Primavera De Filippi's "protocolism"-struggle to demarcate this nascent genre
from other art forms in practice. Addressing this definition-to-practice gap,
this paper offers a focused case study of pioneering protocol artworks by Pak,
an early and influential pseudonymous protocol artist who treats smart
contracts as medium and protocol participation as message. Tracing the
evolution from early open-edition releases of The Fungible and the dynamic
mechanics of Merge to the soul-bound messaging of Censored and the reflective
absence of Not Found, we examine how Pak choreographs distributed agency across
collectors and autonomous contracts, showing how programmable protocols become
a social fabric in artistic meaning-making. Through thematic analysis of Pak's
works, we identify seven core characteristics that distinguish protocol art:
(1) system-centric rather than object-centric composition, (2) autonomous
governance for open-ended control, (3) distributed agency and communal
authorship, (4) temporal dynamism and lifecycle aesthetics, (5) economic-driven
engagement, (6) poetic message embedding in interaction rituals, and (7)
interoperability enabling composability for emergence. We then discuss how
these features set protocol art apart from adjacent artistic movements. By
developing a theoretical framework grounded in Pak's practice, we contribute to
the emerging literature on protocolism while offering design implications for
artists shaping this evolving art form.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to Ars Electronica Expanded Conference 2025 Research Paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ REArtGS: Reconstructing and Generating Articulated Objects via 3D
  Gaussian Splatting with Geometric and Motion Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06677v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06677v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Wu, Liu Liu, Zhou Linli, Anran Huang, Liangtu Song, Qiaojun Yu, Qi Wu, Cewu Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Articulated objects, as prevalent entities in human life, their 3D
representations play crucial roles across various applications. However,
achieving both high-fidelity textured surface reconstruction and dynamic
generation for articulated objects remains challenging for existing methods. In
this paper, we present REArtGS, a novel framework that introduces additional
geometric and motion constraints to 3D Gaussian primitives, enabling
high-quality textured surface reconstruction and generation for articulated
objects. Specifically, given multi-view RGB images of arbitrary two states of
articulated objects, we first introduce an unbiased Signed Distance Field (SDF)
guidance to regularize Gaussian opacity fields, enhancing geometry constraints
and improving surface reconstruction quality. Then we establish deformable
fields for 3D Gaussians constrained by the kinematic structures of articulated
objects, achieving unsupervised generation of surface meshes in unseen states.
Extensive experiments on both synthetic and real datasets demonstrate our
approach achieves high-quality textured surface reconstruction for given
states, and enables high-fidelity surface generation for unseen states. Codes
will be released after acceptance and the project website is at
https://sites.google.com/view/reartgs/home.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-05-26T05:30:52.958002160Z">
            2025-05-26 05:30:52 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
